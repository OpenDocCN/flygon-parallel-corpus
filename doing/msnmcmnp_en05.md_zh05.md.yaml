- en: Chapter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 五、使用 NumPy 对批发分销商的客户进行聚类
- en: Clustering Clients of a Wholesale Distributor Using NumPy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ''
- en: You are definitely advancing your skills by seeing NumPy in action for various
    use cases. This chapter is about a different type of analysis than what you have
    seen so far. Clustering is an unsupervised learning technique that is used for
    understanding and capturing the various formations in your dataset. Since you
    don't have label to supervise your learning algorithm, in many cases, visualization
    is the key, which is why you will see various visualization techniques as well.
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看 NumPy 在各种使用案例中的使用，您肯定可以提高自己的技能。 本章介绍的分析类型与迄今为止所见不同。 聚类是一种无监督的学习技术，用于理解和捕获数据集中的各种形式。
    由于您没有标签来监督您的学习算法，因此在很多情况下，可视化是关键，这就是为什么您也会看到各种可视化技术的原因。
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下主题：
- en: Unsupervised learning and clustering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督学习和聚类
- en: Hyperparameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数
- en: Extending simple algorithm to cluster the clients of a wholesale distributor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展简单算法来聚类批发分销商的客户
- en: Chapter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ''
- en: Unsupervised learning and clustering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无监督学习和聚类
- en: 'Let''s quickly review supervised learning with an example. When you are training
    machine-learning algorithms, you are able to observe and direct the learning by
    providing labels. Think about the following dataset, where each row indicates
    a customer and each column represents a different feature such as **Age**, **Gender**,
    **Income**, **Profession**, **Tenure** and **City**. Take a look at this table:'
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个例子快速回顾一下监督学习。 在训练机器学习算法时，您可以通过提供标签来观察和指导学习。 考虑下面的数据集，其中每一行代表一个客户，每一列代表一个不同的特征，例如**年龄**，**性别**，**收入**，**职业**
    ，**任期**和**城市**。 看看这个表：
- en: '![](img/02358621-6b55-4da1-83a4-2e4bf484aa87.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/02358621-6b55-4da1-83a4-2e4bf484aa87.png)'
- en: 'You may want to perform different kinds of analysis. One of them could be to
    predict which of the customers is likely to leave, namely, churn analysis. To
    do that, you need to label each customer based on their history to indicate which
    customers have left or stayed, as displayed here, in this table:'
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能需要执行不同类型的分析。 其中一项可能是预测哪些客户可能会离开，即客户流失分析。 为此，您需要根据每个客户的历史记录为其标记标签，以指示哪些客户已离开或留下，如下表所示：
- en: '![](img/d54dbe06-b0b4-4d01-9428-1806029a6ed9.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d54dbe06-b0b4-4d01-9428-1806029a6ed9.png)'
- en: Your algorithm will learn the characteristics of customers based on their label.
    Algorithm will learn the characteristics of customers who left or stayed, and,
    when you would like to score a new customer based on these features, algorithm
    will make its predictions based on that learning. This is called **supervised
    learning**.
  prefs: []
  type: TYPE_NORMAL
  zh: 您的算法将根据客户的标签了解客户的特征。 算法将学习离开或留下的客户的特征，并且，当您希望根据这些特征为新客户评分时，算法将根据该学习进行预测。 这称为**监督学习**。
- en: 'Another question which could be asked about this dataset could be this: How
    many customer groups that are present in this dataset so that every customer within
    its group is similar to others and dissimilar to customers which belong to other
    groups. Popular clustering algorithm such as k-means can help you figure that
    out. For example once k-means assign customers to different clusters, one cluster
    can mostly include customers who are less than 30 years old and have **IT** as
    profession and another cluster can mostly include customers who are above 60 years
    old and has **Teacher** as profession. You don''t need to label your dataset to
    perform this analysis, as it''s enough for the algorithm to see the records and
    work out the similarity between them. This type of learning is called **unsupervised
    learning** since there is no supervision.'
  prefs: []
  type: TYPE_NORMAL
  zh: 关于此数据集可能要问的另一个问题可能是：此数据集中存在多少个客户组，以便其组中的每个客户都与其他客户相似，而与属于其他组的客户不同。 流行的聚类算法（例如
    K 均值）可以帮助您解决这一问题。 例如，一旦 K 均值将客户分配到不同的簇，则一个簇可以大体上包括 30 岁以下且以 **IT** 作为职业的客户，而另一个簇可以大体上包括
    60 岁以上的客户并且职业为**老师**。 您无需标记数据集即可执行此分析，因为算法足以查看记录并确定它们之间的相似性。 由于没有监督，因此这种学习称为**无监督学习**。
- en: It's helpful to visualize the dataset first when you conduct such analysis.
    You can start with available datasets to build your processing and modeling workflow.
    The following code snippets show you how to visualize three-dimensional datasets
    with `plotly`. `plotly` is a library that allows you to draw many different interactive
    charts for exploratory analysis, and makes data exploration easier.
  prefs: []
  type: TYPE_NORMAL
  zh: 进行此类分析时，首先可视化数据集会很有帮助。 您可以从可用的数据集开始构建您的处理和建模工作流程。 以下代码段显示了如何使用`plotly`可视化三维数据集。`plotly`是一个库，可让您绘制许多不同的交互式图表以进行探索性分析，并使数据探索更加容易。
- en: 'First, you need to install the necessary libraries with the following snippet:'
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您需要使用以下代码段安装必要的库：
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, you import the necessary libraries, using this code:'
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用以下代码导入必要的库：
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You will use the `iris` dataset, which is available in the `sklearn.datasets`
    module, as shown here:'
  prefs: []
  type: TYPE_NORMAL
  zh: 您将使用`sklearn.datasets`模块中可用的`iris`数据集，如下所示：
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`iris` data has four features; they are as follows:'
  prefs: []
  type: TYPE_NORMAL
  zh: '`iris`数据具有四个特征； 它们如下：'
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'First, let''s check the first two features, which are these:'
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们检查一下前两个特征：
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Create a `trace`, then data and the figure, as shown here:'
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个`trace`，然后创建数据和图形，如下所示：
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This will give you the following output, as shown in this diagram:'
  prefs: []
  type: TYPE_NORMAL
  zh: 如下图所示，这将为您提供以下输出：
- en: '![](img/27928393-9fa9-4d43-8323-73aaa4ab6b92.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/27928393-9fa9-4d43-8323-73aaa4ab6b92.png)'
- en: 'You can keep looking at other variables, but to better understand relationships
    between features in one chart, you can use the `scatterplot` matrix. Creating
    a `pandas.DataFrame` to use with `plotly` is more convenient here:'
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以继续查看其他变量，但是要更好地理解一张图表中要素之间的关系，可以使用`scatterplot`矩阵。 创建`pandas.DataFrame`与`plotly`结合使用会更加方便：
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](img/4efc6da5-306b-4a6f-9b02-f42c648329bf.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4efc6da5-306b-4a6f-9b02-f42c648329bf.png)'
- en: 'Using the `plotly` figure factory, you can plot `scatterplot` matrix, as shown
    here:'
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`plotly`图形工厂，可以绘制`scatterplot`矩阵，如下所示：
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This will give you the following plot, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为您提供以下图表，如下图所示：
- en: '![](img/ce5c8a35-ae6c-45c1-9b64-f49c8facbee8.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ce5c8a35-ae6c-45c1-9b64-f49c8facbee8.png)'
- en: 'At first look, **petal length**, **petal width**, and **sepal length** seem
    to be good candidates for modeling. You can use 3D charts to inspect this dataset
    further, by using this code:'
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，**花瓣长度**，**花瓣宽度**和**萼片长度**似乎是建模的不错选择。 您可以通过以下代码使用 3D 图表进一步检查该数据集：
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This will give you the following plot, which is interactive, as shown in this
    diagram:'
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为您提供以下交互式图表，如下图所示：
- en: '![](img/9e97195c-0dd0-4dca-aec7-2ceb712a5503.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9e97195c-0dd0-4dca-aec7-2ceb712a5503.png)'
- en: 'Interactive plotting of petal
    length, petal width, and sepal length'
  prefs: []
  type: TYPE_NORMAL
  zh: 花瓣长度、花瓣宽度和萼片长度的交互式绘图
- en: Using these charts, you can understand your data better and prepare for modeling.
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些图表，您可以更好地理解数据并为建模做准备。
- en: Chapter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ''
- en: Hyperparameters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超参数
- en: '**Hyperparameter** could be considered as high-level parameter which determines
    one of the various properties of a model such as complexity, training behavior
    and learning rate. These parameters naturally differ from model parameters as
    they need to be set before training starts.'
  prefs: []
  type: TYPE_NORMAL
  zh: '**超参数**可以被视为确定模型各种属性之一的高级参数，例如复杂性，训练行为和学习率。 这些参数自然与模型参数有所不同，因为它们需要在训练开始之前设置。'
- en: For example, the k in k-means or k-nearest-neighbors is a hyperparameter for
    these algorithms. The k in k-means denotes the number of clusters to be found,
    and the k in k-nearest-neighbors denotes the number of closest records to be used
    to make predictions.
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，K 均值或 K 最近邻中的 k 是这些算法的超参数。 K 均值中的 K 表示要找到的聚类数，K 最近邻中的 k 表示用于进行预测的最近记录数。
- en: '**Tuning hyperparameters** is a crucial step in any machine learning project
    to improve predictive performance. There are different techniques for tuning,
    such as grid search, randomized search and bayesian optimization, but these techniques
    are beyond the scope of this chapter.'
  prefs: []
  type: TYPE_NORMAL
  zh: '**调整超参数**是任何机器学习项目中提高预测性能的关键步骤。 有多种调优技术，例如网格搜索，随机搜索和贝叶斯优化，但这些技术不在本章范围之内。'
- en: 'Let''s have a quick look at the k-means algorithms parameters from the scikit-learn
    library via this screenshot:'
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过以下屏幕快照快速浏览 scikit-learn 库中的 K 均值算法参数：
- en: '![](img/014189dd-f3fd-4c24-8a5c-2b4dc33d6468.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/014189dd-f3fd-4c24-8a5c-2b4dc33d6468.png)'
- en: As you can see, there are many parameters to play with, and you should at least
    look at the function signature of algorithms to see the options you have before
    running algorithms.
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，有许多参数可以使用，并且至少应查看算法的函数签名，以查看运行算法之前的选项。
- en: 'Let''s play with some of them. The baseline model will work with the sample
    data, with almost default settings, as shown here:'
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一起玩吧。 基线模型将与样本数据一起使用，几乎具有默认设置，如下所示：
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '`y_hat` is keeping the membership information of clusters, and this is the
    same with the original labels, as you can see here:'
  prefs: []
  type: TYPE_NORMAL
  zh: '`y_hat`保留簇的成员身份信息，这与原始标签相同，如您在此处看到的：'
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: You can play with different options to see how it will affect the training and
    predictions.
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用不同的选项来查看它如何影响训练和预测。
- en: Chapter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ''
- en: The loss function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 损失函数
- en: 'The loss function helps algorithms to update model parameters during training
    through measuring the error, which is an indication of predictive performance.
    Loss function is usually denoted as follows:'
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数通过测量误差来帮助算法在训练过程中更新模型参数，这是预测性能的指标。 损失函数通常表示为：
- en: '![](img/e099f216-c305-416c-bb6d-022f4be67269.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e099f216-c305-416c-bb6d-022f4be67269.png)'
- en: Where *L* measures the difference between the prediction and the actual value.
    During the training process, this error is minimized. Different algorithms have
    different loss functions, and the number of iterations will depend on convergence
    conditions.
  prefs: []
  type: TYPE_NORMAL
  zh: 其中`L`测量预测值与实际值之间的差。 在训练过程中，此误差被最小化。 不同的算法具有不同的损失函数，迭代次数将取决于收敛条件。
- en: 'For example, the loss function for k-means minimizes the square distances between
    a points and closest cluster mean as follows:'
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，K 均值的损失函数使点与最接近的簇均值之间的平方距离最小化，如下所示：
- en: '![](img/71bd2d1c-df7f-40ad-9ace-4bfafaf23193.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/71bd2d1c-df7f-40ad-9ace-4bfafaf23193.png)'
- en: You will see detailed implementation in the following section.
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在以下部分中看到详细的实现。
- en: Chapter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ''
- en: Implementing our algorithm for a single variable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为单个变量实现我们的算法
- en: 'Let''s implement the k-means algorithm for a single variable. You will start
    with one dimensional vector, which has 20 records, as shown here:'
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为单个变量实现 K 均值算法。 您将从一维向量开始，该向量具有 20 条记录，如下所示：
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This will output following plot, as shown in this diagram:'
  prefs: []
  type: TYPE_NORMAL
  zh: 如下图所示，将输出以下图表：
- en: '![](img/b67abfd4-d390-4559-ae9d-43984d789009.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b67abfd4-d390-4559-ae9d-43984d789009.png)'
- en: 'Our aim is to find `3` clusters which are visible in the data. In order to
    start implementing the k-means algorithm, you need to initialize cluster centers
    by choosing random indexes, as shown here:'
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是找到在数据中可见的`3`簇。 为了开始实施 K 均值算法，您需要通过选择随机索引来初始化簇中心，如下所示：
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Next, you need to calculate distances between each point and the cluster centers,
    so use this code:'
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您需要计算每个点与聚类中心之间的距离，因此请使用以下代码：
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now cluster membership can be calculated, by using this code:'
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，可以使用以下代码来计算簇成员资格：
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now you need to calculate distances between records and cluster centers, by
    using this code:'
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您需要使用以下代码来计算记录和群集中心之间的距离：
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This was one iteration; you could continue calculating new cluster centers until
    there is no improvement.
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一次迭代； 您可以继续计算新的群集中心，直到没有任何改善为止。
- en: 'You can write a function to wrap all this functionality, as shown here:'
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以编写一个函数来包装所有这些功能，如下所示：
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s chart the cluster centers, using this code:'
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以下代码绘制簇中心的图表：
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Take a look at the following diagram. The given code will output the following:'
  prefs: []
  type: TYPE_NORMAL
  zh: 看下图。 给定的代码将输出以下内容：
- en: '![](img/e4fb86ba-9fac-4bf7-863d-17eb3dd5b5e7.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e4fb86ba-9fac-4bf7-863d-17eb3dd5b5e7.png)'
- en: You can clearly see that each element can be assigned one of the cluster centers.
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以清楚地看到，可以为每个元素分配一个聚类中心。
- en: Chapter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ''
- en: Modifying our algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 修改我们的算法
- en: Now you have understood the internal of k-means on a single variable, you can
    extend this implementation to multiple variables and apply it to a more realistic
    dataset.
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经了解了单个变量的 K 均值内部，可以将该实现扩展到多个变量，并将其应用于更实际的数据集。
- en: 'The dataset to be used in this section is from the *UCI Machine Learning Repository*
    ([https://archive.ics.uci.edu/ml/datasets/wholesale+customers](https://archive.ics.uci.edu/ml/datasets/wholesale+customers)),
    and it includes the client information of wholesales distributor. There 440 customers
    with eight features. In the following list, first six features are related to
    annual spending for corresponding products, seventh feature shows the channel
    that this product is bought and the eighth feature shows the region:'
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中使用的数据集来自 *UCI 机器学习仓库*（[`archive.ics.uci.edu/ml/datasets/wholesale+customers`](https://archive.ics.uci.edu/ml/datasets/wholesale+customers)），它包括批发分销商的客户信息。
    有 440 个具有八项特征的客户。 在下面的列表中，前六个特征与相应产品的年度支出相关，第七个特征显示了购买该产品的渠道，第八个特征显示了该地区：
- en: FRESH
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FRESH`'
- en: MILK
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MILK`'
- en: GROCERY
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GROCERY`'
- en: FROZEN
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FROZEN`'
- en: DETERGENTS_PAPER
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DETERGENTS_PAPER`'
- en: DELICATESSEN
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DELICATESSEN`'
- en: CHANNEL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CHANNEL`'
- en: REGION
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`REGION`'
- en: 'First download the dataset and read the it as a `numpy` array:'
  prefs: []
  type: TYPE_NORMAL
  zh: 首先下载数据集并将其读取为`numpy`数组：
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'You can have a quick look at the data. Here it is:'
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以快速查看数据。 这里是：
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Checking `shape` will show you the number of rows and variables, as shown here:'
  prefs: []
  type: TYPE_NORMAL
  zh: 选中`shape`将显示行数和变量数，如下所示：
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This dataset has `440` records with `8` features each.
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集具有`440`个记录，每个记录都有`8`个特征。
- en: 'It''s a good idea to normalize your dataset, by using this code:'
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用以下代码来规范化数据集是一个好主意：
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You can read the dataset into the `pandas.DataFrame`, by using this code:'
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下代码将数据集读取到`pandas.DataFrame`中：
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](img/715c7e75-4762-4dfc-8e6c-2798adfc86b1.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/715c7e75-4762-4dfc-8e6c-2798adfc86b1.png)'
- en: 'Let''s create a `scatterplot` matrix to have a closer look at the dataset.
    Take a look at the code:'
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个`scatterplot`矩阵以更仔细地查看数据集。 看一下代码：
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![](img/9ae9f69f-2c52-4415-b5f1-bb78ff6b3088.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9ae9f69f-2c52-4415-b5f1-bb78ff6b3088.png)'
- en: 'You can also check the correlations between features by running the following
    command:'
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过运行以下命令来检查要素之间的相关性：
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This will give you a correlation table, as shown here:'
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为您提供一个关联表，如下所示：
- en: '![](img/2b798028-b763-4919-b811-a6594d4ab218.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2b798028-b763-4919-b811-a6594d4ab218.png)'
- en: 'You can also use `seaborn` heatmap, as shown here:'
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用`seaborn`热图，如下所示：
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![](img/c7332d64-cf8c-4939-9692-e70d1b14ac06.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c7332d64-cf8c-4939-9692-e70d1b14ac06.png)'
- en: 'Correlations between the
    features'
  prefs: []
  type: TYPE_NORMAL
  zh: 特征间的相关性
- en: You can see that there are some strong correlations between features, such as
    the correlation between `Grocery` and `Detergents_Paper`.
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到特征之间存在一些很强的相关性，例如`Grocery`和`Detergents_Paper`之间的相关性。
- en: 'Let''s plot three features, `Grocery`, `Detergents_Paper`, and `Milk`, by using
    this code:'
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以下代码绘制`Grocery`，`Detergents_Paper`和`Milk`三个特征：
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![](img/2b58de54-b70b-4f43-a8c5-4234cbdb798e.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2b58de54-b70b-4f43-a8c5-4234cbdb798e.png)'
- en: 'You will now go ahead and extend the k-means algorithm you have implemented
    for higher dimensions. First, you can drop `Channel` and `Region` from the dataset,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您将继续扩展已为更高维度实现的 K 均值算法。 首先，您可以从数据集中删除`Channel`和`Region`，如下所示：
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '![](img/b85b4d26-673a-48e9-9e92-eabca7aa45ec.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b85b4d26-673a-48e9-9e92-eabca7aa45ec.png)'
- en: 'In terms of implementation, you can also use `np.linalg.norm` for calculating
    distances, and it''s really up to you what kind of distance function you use.
    Another alternative is `distance.euclidean` from `scipy.spatial`, as shown here:'
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现方面，您还可以使用`np.linalg.norm`来计算距离，这实际上取决于您使用哪种距离函数。 另一个替代方法是`scipy.spatial`中的`distance.euclidean`，如下所示：
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '`Grocery` and `Detergents_Paper` will be used in clustering, and `k` will be
    set as `3`. Normally, you should use visual inspection or an elbow method to decide
    `k`, as shown here:'
  prefs: []
  type: TYPE_NORMAL
  zh: '`Grocery`和`Detergents_Paper`将用于聚类，并且`k`将设置为`3`。 通常，应使用外观检查或弯头方法确定`k`，如下所示：'
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now, you can add one more column to your dataset, by using the following:'
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以使用以下命令在数据集中再添加一列：
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'You can visualize the result first to see whether the results make sense, by
    using this code:'
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下代码来首先可视化结果，以查看结果是否有意义：
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '![](img/b847c521-c98c-4b82-9de5-3a2936883e43.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b847c521-c98c-4b82-9de5-3a2936883e43.png)'
- en: 'Plotting the clusters'
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制簇
- en: At first glance, the clusters may look reasonable, and will ultimately depend
    on the interpretation that will be supported by domain knowledge.
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，簇看起来很合理，并将最终取决于领域知识支持的解释。
- en: 'You can easily look at the average spend for each feature per cluster, by using
    this code:'
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下代码轻松查看每个簇每个特征的平均支出：
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '![](img/5375e48c-b03a-4166-85c8-89816266d94c.png)'
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5375e48c-b03a-4166-85c8-89816266d94c.png)'
- en: You can see from this simple clustering that the third cluster has the highest
    spenders for `Milk`, `Grocery`, and `Detergents_Paper`. The second cluster has
    low spenders, and the first cluster inclines toward `Milk`, `Grocery`, and `Detergents_Paper`,
    hence `k=2` might work too.
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个简单的簇中可以看出，第三簇在`Milk`，`Grocery`和`Detergents_Paper`上的支出最高。 第二个簇的支出较低，第一个簇倾向于`Milk`，`Grocery`和`Detergents_Paper`，因此`k=2`也可以使用。
- en: Chapter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ''
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you have learned the basics of unsupervised learning and using
    the k-means algorithm for clustering.
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您学习了无监督学习的基础知识，并使用 K 均值算法进行聚类。
- en: There are many clustering algorithms that show different behavior. Visualization
    is key when it comes to unsupervised learning algorithms, and you have seen a
    couple of different ways to visualize and inspect your dataset.
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多聚类算法显示不同的行为。 当涉及到无监督学习算法时，可视化是关键，并且您已经看到了几种不同的方式来可视化和检查数据集。
- en: In the next chapter, you will learn other libraries which are commonly used
    with NumPy such as SciPy, Pandas and scikit-learn. These are all important libraries
    in the practitioner's toolkit, and they complement one another. You will find
    yourself using these libraries together with NumPy, as each will make certain
    tasks easier; hence, it's important to know more about the Python data science
    stack.
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将学习 NumPy 常用的其他库，例如 SciPy，Pandas 和 scikit-learn。 这些都是从业者工具包中的重要库，它们相互补充。
    您会发现自己将这些库与 NumPy 一起使用，因为每个库都会使某些任务变得更容易。 因此，重要的是要了解有关 Python 数据科学堆栈的更多信息。

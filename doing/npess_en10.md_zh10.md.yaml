- en: Chapter 10. Further Reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第十章：扩展阅读
- en: NumPy is a powerful scientific module in Python; hopefully, in the previous
    nine chapters, we have shown you enough to prove this to you. `ndarray` is the
    core of all other Python scientific modules. The best way to use NumPy is by using `numpy.ndarray`
    as the basic data format and combining it with other scientific modules for preprocess,
    analyze, compute, export, and so on. In this chapter, our focus is on introducing
    you to a couple of modules that can work with NumPy and make your work/research
    more efficient.
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 是 Python 中功能强大的科学模块； 希望在前九章中，我们已经向您展示了足以向您证明这一点的内容。 `ndarray`是所有其他 Python
    科学模块的核心。 使用 NumPy 的最佳方法是使用`numpy.ndarray`作为基本数据格式，并将其与其他科学模块组合以进行预处理，分析，计算，导出等。
    在本章中，我们的重点是向您介绍可以与 NumPy 一起使用的两个模块，并使您的工作/研究效率更高。
- en: 'In this chapter, we will be covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: pandas
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pandas
- en: scikit-learn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn
- en: netCDF4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: netCDF4
- en: scipy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SciPy
- en: pandas
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pandas
- en: pandas is, by far, the most preferable data preprocessing module in Python.
    The way it handles data is very similar to R. Its data frame not only gives you
    visually appealing printouts of tables, but also allows you to access data in
    a more instinctive way. If you are not familiar with R, try to think of using
    a spreadsheet software such as Microsoft Excel or SQL tables but in a programmatic
    way. This covers a lot of that what pandas does.
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，pandas 是 Python 中最可取的数据预处理模块。 它处理数据的方式与 R 非常相似。它的数据框不仅为您提供视觉上吸引人的表打印输出，而且还允许您以更直观的方式访问数据。
    如果您不熟悉 R，请尝试考虑以编程方式使用电子表格软件（例如 Microsoft Excel 或 SQL 表）。 这涵盖了 Pandas 所做的很多事情。
- en: You can download and install pandas from its official site at [http://pandas.pydata.org/](http://pandas.pydata.org/)
    . A more preferable way is to use pip or install Python scientific distributions,
    such as Anaconda.
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从 Pandas 官方网站下载并安装 Pandas，位于[`pandas.pydata.org`](http://pandas.pydata.org/)。 一种更可取的方法是使用 pip 或安装
    Python 科学发行版，例如 Anaconda。
- en: Remember how we used `numpy.genfromtxt()` to read the `csv` data in [Chapter
    4](text00034.html#ch04 "Chapter 4. NumPy Core and Libs Submodules") ,  *NumPy
    Core and Libs Submodules* ? Actually, using pandas to read tables and pass pre-processed
    data to `ndarray` (simply performing `np.array(data_frame)` will transfer a data
    frame into a multidimensional `ndarray` ) would be a more preferable workflow
    for analytics. In this section, we are going to show you two basic data structures
    in pandas: `Series` (for one-dimension) and `DataFrame` (two or multi-dimensions).Then,
    we will show you how to use pandas to read a table and pass data to
  prefs: []
  type: TYPE_NORMAL
  zh: 还记得我们如何使用`numpy.genfromtxt()`读取第 4 章， “Numpy 核心和子模块”中的`csv`数据吗？ 实际上，使用 Pandas
    来读取表格并将经过预处理的数据传递给`ndarray`（简单地执行`np.array(data_frame)`会将数据帧转换为多维`ndarray`）对于分析来说是更可取的工作流程。
    在本节中，我们将向您展示 Pandas 的两个基本数据结构：`Series`（用于一维）和`DataFrame`（用于二维或多维）。然后，我们将向您展示如何使用
    Pandas 来读取表并将数据传递给它。
- en: 'Then, we will show you how to use pandas to read a table and pass data to `ndarray`
    for further analysis. Let''s start with `pandas.Series` :'
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将向您展示如何使用 Pandas 读取表并将数据传递给`ndarray`进行进一步分析。 让我们从`pandas.Series`开始：
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In the preceding example, you can see that we''ve converted the Python list
    into a pandas `series`  and that, when we printed `series` , the values are lined
    up perfectly and have an index number associated with them (0 to 4). We can, of
    course, specify our own index (which starts from *1* or is in the form of alphabets).
    Take a look at the following code example:'
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，您可以看到我们已经将 Python 列表转换为 Pandas`series`，并且在打印`series`时，这些值完美对齐并具有与之关联的索引号（0
    到 4）。 当然，我们可以指定自己的索引（以`1`开头或以字母形式）。 看下面的代码示例：
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We changed the indices from numbers to alphabets ranging from *A ~ E* . More
    conveniently, when we convert a Python dictionary to the pandas `Series` , the
    key required to do this will become the index automatically. Try practicing converting
    the dictionary. Next, we are going to explore `DataFrame` , which is the data
    structure that''s used most often in pandas:'
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将索引从数字更改为从`A-E`的字母。 更方便的是，当我们将 Python 词典转换为 Pandas `Series`时，执行此操作所需的键将自动成为索引。
    尝试练习转换字典。 接下来，我们将探索`DataFrame`，这是 Pandas 中最常用的数据结构：
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In the preceding example, we created `DataFrame` , which contains two columns:
    the first one is `Name` and the second one is `Age` . You can see from the printouts
    that it just looks like a table because it''s well formatted. Of course, you can
    also change the index of the data frame. But the advantages of a data frame are
    much more than just this. We can access or sort the data in each column (by its
    column name, where two notations are required to access the `data_frame.column_name`
    or `data_frame[column_name]` ); we can even analyze summary statistics. To do
    this, take a look at this code example:'
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们创建了`DataFrame`，其中包含两列：第一个是`Name`，第二个是`Age`。 您可以从打印输出中看到它看起来像一张表格，因为它的格式正确。
    当然，您也可以更改数据帧的索引。 但是，数据帧的优势远不止于此。 我们可以访问每列中的数据或对其进行排序（按列名，访问`data_frame.column_name`或`data_frame[column_name]`需要两个符号）；
    我们甚至可以分析汇总统计信息。 为此，请看以下代码示例：
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In the preceding example, we obtained only the `Age` column and sorted `DataFrame`
    by `Age` . When we use `describe()` , it calculates summary statistics (including
    counts, mean, standard deviation, minimum, maximum, and percentiles) for all numeric
    fields.In the last part of this section, we are going to use pandas to read a
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们仅获得`Age`列，并按`Age`对`DataFrame`进行排序。 当我们使用`describe()`时，它将计算所有数字字段的摘要统计信息（包括计数，均值，标准差，最小值，最大值和百分位数）。在本节的最后部分，我们将使用
    Pandas 读取
- en: 'In the last part of this section, we are going to use pandas to read a `csv`
    file and pass one field value to `ndarray` for further computation. The `example.csv`
    file is from the **Office for National Statistics** ( **ONS** ). Visit [http://www.ons.gov.uk/ons/datasets-and-tables/index.html](http://www.ons.gov.uk/ons/datasets-and-tables/index.html)
    for more details. We will use  *Sale counts by dwelling type and local authority,
    England and Wales* on the ONS website. You can search it by the topic name to
    access the download page or pick any dataset that you are interested in. In the
    following example, we renamed our example dataset to `sales.csv` :'
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的最后部分，我们将使用 Pandas 读取`csv`文件并将一个字段值传递给`ndarray`以进行进一步的计算。 `example.csv`文件来自**国家统计局**（**ONS**）。
    请访问[`www.ons.gov.uk/ons/datasets-and-tables/index.html`](http://www.ons.gov.uk/ons/datasets-and-tables/index.html)了解更多详细信息。 我们将在
    ONS 网站上使用`Sale counts by dwelling type and local authority, England and Wales`（房屋类型和地方当局（英格兰和威尔士）的销售计数）。
    您可以按主题名称搜索它，以访问下载页面或选择您感兴趣的任何数据集。在以下示例中，我们将示例数据集重命名为`sales.csv`：
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: First, we read in `sale.csv` into a `DataFrame` object called `sales` ; when
    we printed out the `shapes` of sales, we found that there were 384 records and
    97 columns in the data frame. The return list of the `DataFrame column` attribute
    is an ordinary Python list, and we printed out the first three columns in the
    data: `LA_Code` , `LA_Name` , and `1995_COUNT_ALL_TYPES` . Then, we printed the
    first five records in `1995_COUNT_ALL_TYPES` using the `head()` function (the `tail()`
    function will print the last five records).
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将`sale.csv`读入名为`sales`的`DataFrame`对象; 当我们打印销售的`shapes`时，我们发现数据框中有 384 条记录和
    97 列。 `DataFrame column`属性的返回列表是一个普通的 Python 列表，我们在数据中打印了前三列：`LA_Code`，`LA_Name`和`1995_COUNT_ALL_TYPES`。
    然后，我们使用`head()`函数在`1995_COUNT_ALL_TYPES`中打印了前五个记录（`tail()`函数将打印后五个记录）。
- en: Again, pandas is a powerful preprocessing module in Python (its data handling
    in general more than its preprocessing power, but in the preceding example, we
    only covered the preprocessing part), and it has many handy functions to help
    you clean your data and prepare your analytics. This section is just an introduction;
    there is a lot that we can't cover due to space restrictions, such as pivoting,
    `datetime` , and more. Hopefully, you can get the idea and start making your scripts
    more efficient.
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，pandas 是 Python 中一个功能强大的预处理模块（通常，其数据处理能力超过其预处理功能，但在前面的示例中，我们仅介绍了预处理部分），并且它具有许多方便的功能来帮助您清理数据并准备数据。
    您的分析。 本节仅作介绍； 由于空间限制，我们无法涵盖很多内容，例如数据透视，`datetime`等。 希望您能理解并开始提高脚本的效率。
- en: scikit-learn
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: scikit-learn
- en: Scikit is short for SciPy Toolkits, which are add-on packages for SciPy. It
    provides a wide range of analytics modules and scikit-learn is one of them; this
    is by far the most comprehensive machine learning module for Python. scikit-learn
    provides a simple and efficient way to perform data mining and data analysis,
    and it has a very active user community.
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit 是 SciPy 工具包的缩写，它是 SciPy 的附加包。 它提供了广泛的分析模块，而 scikit-learn 是其中之一。 这是迄今为止最全面的
    Python 机器学习模块。 scikit-learn 提供了一种简单有效的方法来执行数据挖掘和数据分析，并且它拥有非常活跃的用户社区。
- en: You can download and install scikit-learn from its official website at [http://scikit-learn.org/stable/](http://scikit-learn.org/stable/)
    . If you are using a Python scientific distribution, such as Anaconda, it is included
    here as well.
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从 scikit-learn 的官方网站下载并安装它，位于[`scikit-learn.org/stable`](http://scikit-learn.org/stable/)。 如果您使用的是 Python
    科学发行版（例如 Anaconda），则也包含在其中。
- en: Now, it's time for some machine learning using scikit-learn. One of the advantages
    of scikit-learn is that it provides some sample datasets (demo datasets) for practice.
    Let's load the diabetes dataset first.
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候使用 scikit-learn 进行一些机器学习了。 scikit-learn 的优点之一是它提供了一些用于实践的样本数据集（演示数据集）。
    让我们首先加载糖尿病数据集。
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We loaded a sample dataset called `diabetes` from `sklearn.datasets` ; it contains
    442 observations, 10 dimensions, and ranges from -2 to 2\. The `Toy` dataset also
    provides labeled data for supervised learning (if you are not familiar with machine
    learning, try to think of the labelled data as categories). In our example, labeled
    data from the `diabetes` dataset can be called from `diabetes.target` , and it
    has a range from 25 to 346.
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从`sklearn.datasets`中加载了一个名为`diabetes`的样本数据集； 它包含 442 个观测值，10 个维度，范围从 -2 到
    2。 `Toy`数据集还提供了标记数据用于监督学习（如果您不熟悉机器学习，请尝试将标记数据视为类别）。 在我们的示例中，可以从`diabetes.target`调用`diabetes`数据集中的标记数据，范围为
    25 到 346。
- en: 'Remember how we performed linear regression in [Chapter 5](text00037.html#ch05
    "Chapter 5. Linear Algebra in NumPy") ,  *Linear Algebra in Numpy* ? We''re going
    to perform it one more time using scikit-learn instead. Again, I recommend that,
    when you''re developing a script to help you in your research or analytics, use
    NumPy `ndarray` as your general data format; however, for computation, using scipy,
    scikit-learn, or other scientific modules would be more preferable. One advantage
    of machine learning is model evaluation (where you train and test the result).
    Using this, we will split our data into two datasets: training datasets and test
    datasets, and then pass the two datasets for the purpose of linear regression:'
  prefs: []
  type: TYPE_NORMAL
  zh: 还记得我们在第 5 章， “numpy 中的线性代数”中如何进行线性回归吗？ 我们将使用 scikit-learn 再次执行它。 同样，我建议您在开发脚本以帮助您进行研究或分析时，请使用
    NumPy `ndarray`作为常规数据格式； 但是，对于计算，使用 scipy，scikit-learn 或其他科学模块会更好。 机器学习的优势之一是模型评估（您可以在其中训练和测试结果）。
    使用此方法，我们将数据分为两个数据集：训练数据集和测试数据集，然后将这两个数据集传递给线性回归：
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In the preceding example, we split up the diabetes dataset into training and
    test datasets (for both the data and its categories) using the `train_test_split()`
    function. The first two parameters are arrays that we want to split; the `random_state`
    parameter is optional, which means that a pseudo random number generator state
    is used for random sampling. The default split ratio is 0.25, which means that
    75% of the data is split into the training set and 25% is split into the test
    set. You can try to print out the training/test datasets we just created to take
    a look at its distribution (in the preceding code example, `X_train` represents
    the training dataset for the diabetes data, `X_test` represents the diabetes test
    data, `y_train` represents the categorized diabetes training data, and `y_test`
    represents the categorized diabetes test data).
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们使用`train_test_split()`函数将糖尿病数据集分为训练和测试数据集（针对数据及其类别）。 前两个参数是我们要拆分的数组。
    `random_state`参数是可选的，这意味着伪随机数生成器状态用于随机采样。 默认拆分率是 0.25，这意味着 75% 的数据拆分为训练集，而 25%
    的数据拆分为测试集。 您可以尝试打印出我们刚刚创建的训练/测试数据集，以查看其分布情况（在前面的代码示例中，`X_train`代表糖尿病数据的训练数据集，`X_test`代表糖尿病测试数据，`y_train`代表分类的糖尿病训练数据，`y_test`代表分类的糖尿病测试数据。
- en: 'Next, we are going to fit our datasets into a linear regression model:'
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将数据集拟合为线性回归模型：
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'First, we created a `LinearRegression` object from `sklearn.linear_model` and
    used the `fit()` function to fit the `X_train` and `y_train` datasets. We can
    check the estimated coefficients for the linear regression by calling its `coef_`
    attribute. Furthermore, we can use the fitted linear regression for prediction.
    Take a look at the following example:'
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从`sklearn.linear_model`创建了一个`LinearRegression`对象，并使用`fit()`函数拟合了`X_train`和`y_train`数据集。
    我们可以通过调用`coef_`属性来检查线性回归的估计系数。 此外，我们可以使用拟合的线性回归进行预测。 看下面的例子：
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `predict()` function is used to predict the test dataset based on the linear
    regression we fit with the training datasets; in the preceding example, we printed
    out the first 10 predicted values. Here is the plot of the predicted and test
    value of `y` :'
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict()`函数用于基于我们拟合训练数据集的线性回归来预测测试数据集； 在前面的示例中，我们打印了前 10 个预测值。 这是`y`的预测值和测试值的图：'
- en: '![scikit-learn](img/00039.jpeg)'
  prefs: []
  type: TYPE_IMG
  zh: '![scikit-learn](img/00039.jpeg)'
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Then, we can check the determination R-square of the prediction using the `score()`
    function.
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用`score()`函数检查预测的确定 R 平方。
- en: This is pretty much the standard fitting and predicting process in scikit-learn,
    and it's pretty intuitive and easy to use. Of course, besides regression, there
    are many analytics that scikit-learn can carry out such as classification, clustering,
    and modeling. Hope this section helps you in your scripts.
  prefs: []
  type: TYPE_NORMAL
  zh: 这几乎是 scikit-learn 中的标准拟合和预测过程，并且非常直观且易于使用。 当然，除了回归之外，scikit-learn 还可以执行许多分析，例如分类，聚类和建模。
    希望本节对您的脚本有所帮助。
- en: netCDF4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: netCDF4
- en: netCDF4 is the fourth version of the netCDF library that's implemented on top
    of HDF5 (Hierarchical Data Format, designed to store and organize large amounts
    of data), which makes it possible to manage extremely large and complex multidimensional
    data. The greatest advantage of netCDF4 is that it is a completely portable file
    format with no limit on the number or size of data objects in a collection, and
    it's appendable while being archivable as well. Many scientific research organizations
    use it for data storage. Python also has an interface to access and create this
    type of data format.
  prefs: []
  type: TYPE_NORMAL
  zh: netCDF4 是 netCDF 库的第四个版本，该库是在 HDF5（分层数据格式，旨在存储和组织大量数据）的基础上实现的，从而可以管理非常大和复杂的多维数据。
    netCDF4 的最大优点是，它是一种完全可移植的文件格式，对集合中数据对象的数量或大小没有限制，并且在可归档的同时也可以追加。 许多科研组织将其用于数据存储。
    Python 还具有访问和创建此类数据格式的接口。
- en: You can download and install the module from its official documentation page
    at [http://unidata.github.io/netcdf4-python/](http://unidata.github.io/netcdf4-python/)
    , or clone it from its GitHub repository at [https://github.com/Unidata/netcdf4-python](https://github.com/Unidata/netcdf4-python)
    . It's not included in the standard Python Scientific distribution, but it's built
    into NumPy and can build with Cython (this is recommended but not required).
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从官方文档页面下载和安装该模块，位于[`unidata.github.io/netcdf4-python`](http://unidata.github.io/netcdf4-python/)，或从 Github 仓库克隆它，位于[`github.com/Unidata/netcdf4-python`](https://github.com/Unidata/netcdf4-python)。
    它不包含在标准的 Python 科学发行版中，但已内置在 NumPy 中，可以与 Cython 一起构建（建议但并非必需）。
- en: For the following example, we are going to use the sample `netCDF4` file on
    the Unidata website at [http://www.unidata.ucar.edu/software/netcdf/examples/files.html](http://www.unidata.ucar.edu/software/netcdf/examples/files.html)
    , and we will use the climate system model as an example: `sresa1b_ncar_ccsm3-example.nc`
  prefs: []
  type: TYPE_NORMAL
  zh: 对于以下示例，我们将使用 Unidata 网站上的示例`netCDF4`文件，该文件位于[`www.unidata.ucar.edu/software/netcdf/examples/files.html`](http://www.unidata.ucar.edu/software/netcdf/examples/files.html)，并且我们将以气候系统模型为例：`sresa1b_ncar_ccsm3-example.nc`
- en: 'First, we will use the `netCDF4` module to explore the dataset a bit, and extract
    the values we need for further analysis:'
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用`netCDF4`模块稍微探索一下数据集，并提取我们需要进行进一步分析的值：
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We imported the python `netCDF4` module, and we used the `Dataset()` function
    to read the sample `netCDF4` file. The `r` parameter means the file is in read-only
    mode, so we can also specify `a` when we want to append the file or `w` to create
    a new file. Then, we obtained all the variables stored in the dataset and saved
    them to a list called variables (note that the variables attribute will return
    a Python dictionary of the object of the variables). Lastly, we printed out the
    variables in the dataset using this command:'
  prefs: []
  type: TYPE_NORMAL
  zh: 我们导入了 python `netCDF4`模块，并使用`Dataset()`函数读取了示例`netCDF4`文件。 `r`参数表示文件处于只读模式，因此当我们要附加文件或`w`创建新文件时，我们也可以指定`a`。
    然后，我们获得了存储在数据集中的所有变量，并将它们保存到名为变量的列表中（请注意，`variables`属性将返回变量对象的 Python 字典）。 最后，我们使用以下命令在数据集中打印出变量：
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the preceding example, we picked a variable named `pr` and saved it to `precipitation`
    . As we all know `netCDF4` is a self-describing file format; you can create and
    access any user-defined attribute stored in the variable, though the most common
    one is `standard_name` , which tells us that the variable represents the precipitation
    flux. We checked another commonly used attribute, `missing_value` , which represents
    the no-data value stored in the `netCDF4` file. Then, we printed the number of
    dimensions of the precipitation variable by its `ndim` and the shape by the `shape`
    attribute. Lastly, we want to get the value of row 1, that is, the first 10 columns
    in the `netCDF4` file; to do this, just use the indexing as we always do.
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们选择了一个名为`pr`的变量并将其保存到`precipitation`中。 众所周知`netCDF4`是一种自我描述的文件格式; 您可以创建和访问存储在变量中的任何用户定义属性，尽管最常见的是`standard_name`，它告诉我们该变量代表降水通量。
    我们检查了另一个常用属性`missing_value`，该属性表示存储在`netCDF4`文件中的无数据值。 然后，我们通过`ndim`来打印降水量的维数，并通过`shape`属性来打印形状。
    最后，我们要获取第 1 行的值，即`netCDF4`文件中的前 10 列; 为此，只需像往常一样使用索引。
- en: 'Next, we are going to cover the basics of creating a `netCDF4` file and storing
    a three-dimensional NumPy `ndarray` as a variable:'
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍创建`netCDF4`文件并将三维 NumPy `ndarray`作为变量存储的基础知识：
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'First, we prepared a three-dimensional `ndarray` (data) to store in the `netCDF4`
    file; the data is built in three dimensions, which are time (`time` , size of
    10), latitude (`lat` , size of 8), and longitude (`lon` , size of 6). In `netCDF4`
    , time is not a `datetime` object, but the number of time units (these can be
    seconds, hours, days, and so on) from the defined start time (specified in the `unit`
    attribute; we will explain this to you later). Now, we have all the data we want
    to store in the file, so let''s build the netCDF structure:'
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们准备了一个三维`ndarray`（数据）以存储在`netCDF4`文件中； 数据建立在三个维度中，分别是时间（`time`，大小为 10），纬度（`lat`，大小为
    8）和经度（`lon`，大小为 6）。 在`netCDF4`中，时间不是`datetime`对象，而是从定义的开始时间（在`unit`属性中指定）开始的时间单位数（可以是秒，小时，天等）。
    稍后再向您解释）。 现在，我们拥有了要存储在文件中的所有数据，因此让我们构建 netCDF 结构：
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We initialized the `netCDF4` file by specifying the file path and using the `w`
    write mode. Then, we built the structure using `createDimension()` to specify
    the dimensions: `time` , `lat` , and `lon` . Each dimension has a variable to
    represent its values, just like the scales for an axis. Next, we are going to
    save the three-dimensional data to the file:'
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过指定文件路径并使用`w`写入模式来初始化`netCDF4`文件。 然后，我们使用`createDimension()`构建结构以指定尺寸：`time`，`lat`和`lon`。
    每个尺寸都有一个变量来表示其值，就像轴的刻度一样。 接下来，我们将把三维数据保存到文件中：
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The creation of a variable always starts with the `createVariable()` function
    and specifies the variable name, variable datatype, and the dimensions associated
    with it. The second step is to pass the same shape of `ndarray` into the declared
    variable. Now that we have the entire data store in the file, we can specify the
    attribute to help describe the dataset. The following example uses the `time`
    variable to show how we can specify the attribute:'
  prefs: []
  type: TYPE_NORMAL
  zh: 变量的创建始终从`createVariable()`函数开始，并指定变量名称，变量数据类型以及与其关联的维。 第二步是将`ndarray` 的相同形状传递到声明的变量中。
    现在我们已经将整个数据存储在文件中，我们可以指定属性以帮助描述数据集。 以下示例使用`time`变量说明如何指定属性：
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'So, now that the time variable has the unit and calendar associated with it,
    the `ndarray` time will be converted to a date based on the unit and calendar
    that we specified; this is similar to all the variables. When the creation of
    `netCDF4` file is done, the last step is to close the file connection:'
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在时间变量已与单位和日历相关联，因此`ndarray`时间将根据我们指定的单位和日历转换为日期； 这类似于所有变量。 完成`netCDF4`文件的创建后，最后一步是关闭文件连接：
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The preceding code shows you the usage of Python netCDF4 API in order to read
    and create a `netCDF4` file. This module doesn't include any scientific computations
    (so it's not included in any Python scientific distribution), but the target is
    in the interface for the file I/O, which can be the very first or last stage in
    your research and analytics.
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码向您展示了 Python netCDF4 API 的用法，以便读取和创建`netCDF4`文件。 该模块不包含任何科学计算（因此它不包含在任何
    Python 科学发行版中），但是目标位于文件 I/O 的接口中，该接口可以是研究和分析的第一阶段或最后阶段。
- en: SciPy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SciPy
- en: 'SciPy is a well-known Python library focusing on scientific computing (it contains
    modules for optimization, linear algebra, integration, interpolation, and special
    functions such as FFT, signal, and image processing). It builds on the NumPy Array
    object, and NumPy is part of the whole SciPy stack (remember that we introduced
    the Scientific Python family in [Chapter 1](text00015.html#page "Chapter 1. An
    Introduction to NumPy") ,  *An Introduction to NumPy* ). However, the SciPy module
    contains various topics that we can''t cover in just one section. Let''s look
    at an example of image processing (noise removal) to help you get some idea of
    what SciPy can do:'
  prefs: []
  type: TYPE_NORMAL
  zh: SciPy 是一个着名的 Python 库，专注于科学计算（它包含用于优化，线性代数，积分，内插以及诸如 FFT，信号和图像处理等特殊功能的模块）。 它建立在
    NumPy 数组对象的基础上，并且 NumPy 是整个 SciPy 栈的一部分（请记住，我们在第 1 章， “NumPy 简介”）。 但是，SciPy 模块包含各种主题，而我们不能仅在一个部分中进行介绍。
    让我们看一个图像处理（降噪）示例，以帮助您了解 SciPy 可以做什么：
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'First, we import three functions from SciPy''s miscellaneous routines: `imread`
    , `imsave` , and `ascent` . In the following example, we use the built-in image `ascent`
    , which is a 512 by 512 greyscale image. Of course, you may use your own image;
    simply call `imread(''your_image_name'')` and it will load as an `ndarray` .'
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从 SciPy 的其他例程中导入三个函数：`imread`，`imsave`和`ascent`。 在下面的示例中，我们使用内置图像`ascent`，它是`512
    x 512`灰度图像。 当然，您可以使用自己的图像。 只需调用`imread('your_image_name')`，它将作为`ndarray`加载。
- en: 'The `pyplot` result from the `matplotlib` module we imported here is just for
    displaying the image; we did this in [Chapter 6](text00043.html#page "Chapter 6. Fourier
    Analysis in NumPy") ,  *Fourier Analysis in NumPy* . Here is the built-in image `ascent`
    :'
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在此处导入的`matplotlib`模块的`pyplot`结果仅用于显示图像； 我们在第 6 章，“在 NumPy 中进行傅里叶分析”这样做了。 这是内置图像`ascent`：
- en: '![SciPy](img/00040.jpeg)'
  prefs: []
  type: TYPE_IMG
  zh: '![SciPy](img/00040.jpeg)'
- en: 'Now, we can add some noise to the image and use the `pyplot` module to show
    the noised image:'
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以为图像添加一些噪点，并使用`pyplot`模块显示噪点图像：
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'In this code snippet, we import `numpy` to generate some random noise based
    on the image shape. Then, we save the noised image to `noise_img.png` . The noised
    image looks like this:'
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码段中，我们导入`numpy`以根据图像形状生成一些随机噪声。 然后，将噪点图像保存到`noise_img.png`。 噪点图像如下所示：
- en: '![SciPy](img/00041.jpeg)'
  prefs: []
  type: TYPE_IMG
  zh: '![SciPy](img/00041.jpeg)'
- en: 'Next, we are going to use the multidimensional image-processing module in SciPy,
    `scipy.ndimage` , to apply filters to the noised image in order to smooth it.
    The `ndimage` module provides various filters; for a detailed list, refer to [http://docs.scipy.org/doc/scipy/reference/ndimage.html](http://docs.scipy.org/doc/scipy/reference/ndimage.html)
    , but in the following example, we will just use the Gaussian and Uniform filters:'
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用 SciPy `scipy.ndimage`中的多维图像处理模块对噪波图像应用滤镜以使其平滑。 `ndimage`模块提供各种过滤器；
    有关详细列表，请参考[`docs.scipy.org/doc/scipy/reference/ndimage.html`](http://docs.scipy.org/doc/scipy/reference/ndimage.html)，但是在以下示例中，我们将仅使用高斯和均匀滤波器：
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![SciPy](img/00042.jpeg)'
  prefs: []
  type: TYPE_IMG
  zh: '![SciPy](img/00042.jpeg)'
- en: First, we import `ndimage` from SciPy, apply the Gaussian filter on `noise_image`
    , set the `sigma` (the standard deviation for the Gaussian kernel) to `3` , and
    save it to `gaussian_denoised.png` . Look at the the left-hand side of the preceding
    image. In general, the larger the sigma, the smoother the image will be, which
    means a loss of detail. The second filter we applied is the Uniform filter and
    took all the default values for the parameters, which results in the right-hand
    part of the previous image. Though the uniform filter retains more details from
    the raw image, the image still contains noise.
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从 SciPy 导入`ndimage`，在`noise_image`上应用高斯滤波器，将`sigma`（高斯内核的标准偏差）设置为`3`，然后将其保存到`gaussian_denoised.png`。
    查看上一张图片的左侧。 通常，`sigma`越大，图像将越平滑，这意味着细节丢失。 我们应用的第二个过滤器是均匀过滤器，并采用了所有参数的默认值，这将导致上一张图像的右侧。
    尽管统一滤波器保留了原始图像的更多细节，但图像仍包含噪点。
- en: The previous example was a simple image-processing example using SciPy. However,
    SciPy can do more than image processing, it can also perform many types of analytical/scientific
    computation. For details, refer to *Learning SciPy for Numerical and Scientific
    Computing* ,  *Second Edition* ,  *Packt Publishing* .
  prefs: []
  type: TYPE_NORMAL
  zh: 上一个示例是使用 SciPy 的简单图像处理示例。 但是，SciPy 不仅可以处理图像处理，还可以执行许多类型的分析/科学计算。 有关详细信息，请参阅《SciPy
    数值和科学计算学习手册第二版》，*Packt Publishing*。
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: 'NumPy is certainly the core to scientific computation using Python: many modules
    are based on it. Although sometimes you might find that NumPy has no analytics
    modules, it certainly provides you with a way of reaching out to a wide range
    of scientific modules.'
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 当然是使用 Python 进行科学计算的核心：许多模块都基于 NumPy。 尽管有时您可能会发现 NumPy 没有分析模块，但它无疑为您提供了一种接触广泛科学模块的方法。
- en: We hope the last chapter of this book has given you a good idea about using
    these modules with NumPy and makes your script more efficient (there are still
    so many handy NumPy modules we can't cover in this book; just spend an afternoon
    on GitHub or PyPI, and you may find a handful of them). Last but not least, thank
    you for spending time with us going through so many functions. Have some fun with
    NumPy now!
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望本书的最后一章为您提供了一个关于将这些模块与 NumPy 一起使用的好主意，并使您的脚本更加有效（本书中无法涵盖很多便捷的 NumPy 模块；仅在
    GitHub 或 PyPI 上度过一个下午，您可能会发现其中的少数几个）。 最后但并非最不重要的一点，感谢您花时间与我们一起完成许多功能。 现在与 NumPy
    一起玩吧！

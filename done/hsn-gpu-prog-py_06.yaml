- en: Debugging and Profiling Your CUDA Code
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调试和分析您的CUDA代码
- en: In this chapter, we will finally learn how to debug and profile our GPU code
    using several different methods and tools. While we can easily debug pure Python
    code using IDEs such as Spyder and PyCharm, we can't use these tools to debug
    the actual GPU code, remembering that the GPU code itself is written in CUDA-C
    with PyCUDA providing an interface. The first and easiest method for debugging
    a CUDA kernel is the usage of `printf` statements, which we can actually call
    directly in the middle of a CUDA kernel to print to the standard output. We will
    see how to use `printf` in the context of CUDA and how to apply it effectively for
    debugging.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将最终学习如何使用多种不同的方法和工具调试和分析我们的GPU代码。虽然我们可以使用Spyder和PyCharm等IDE轻松调试纯Python代码，但我们无法使用这些工具来调试实际的GPU代码，记住GPU代码本身是用CUDA-C编写的，PyCUDA提供了一个接口。调试CUDA内核的第一种最简单的方法是使用`printf`语句，我们实际上可以直接在CUDA内核中调用它来打印到标准输出。我们将看到如何在CUDA的上下文中使用`printf`以及如何有效地应用它进行调试。
- en: Next, we will fill in some of the gaps in our CUDA-C programming so that we
    can directly write CUDA programs within the NVIDIA Nsight IDE, which will allow
    us to make test cases in CUDA-C for some of the code we have been writing. We
    will take a look at how to compile CUDA-C programs, both from the command line
    with `nvcc` and also with the Nsight IDE. We will then see how to debug within
    Nsight and use Nsight to understand the CUDA lockstep property. Finally, we will
    have an overview of the NVIDIA command line and Visual Profilers for profiling
    our code.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将填补CUDA-C编程中的一些空白，以便我们可以直接在NVIDIA Nsight IDE中编写CUDA程序，这将允许我们为我们一直在编写的一些代码创建CUDA-C的测试用例。我们将看看如何使用`nvcc`命令行编译CUDA-C程序，以及如何在Nsight
    IDE中进行编译。然后，我们将看看如何在Nsight中进行调试，并使用Nsight了解CUDA lockstep属性。最后，我们将概述NVIDIA命令行和Visual
    Profilers以对我们的代码进行分析。
- en: 'The learning outcomes for this chapter include the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的学习成果包括以下内容：
- en: Using `printf` effectively as a debugging tool for CUDA kernels
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有效地使用`printf`作为CUDA内核的调试工具
- en: Writing complete CUDA-C programs outside of Python, especially for creating
    test cases for debugging
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Python之外编写完整的CUDA-C程序，特别是用于创建调试的测试用例
- en: Compiling CUDA-C programs on the command line with the `nvcc` compiler
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`nvcc`编译器在命令行上编译CUDA-C程序
- en: Developing and debugging CUDA programs with the NVIDIA Nsight IDE
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用NVIDIA Nsight IDE开发和调试CUDA程序
- en: Understanding the CUDA warp lockstep property and why we should avoid branch
    divergence within a single CUDA warp
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解CUDA warp lockstep属性以及为什么我们应该避免单个CUDA warp内的分支分歧
- en: Learn to effectively use the NVIDIA command line and Visual Profilers for GPU
    code
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学会有效使用NVIDIA命令行和Visual Profilers进行GPU代码的调试
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: A Linux or Windows 10 PC with a modern NVIDIA GPU (2016—onward) is required
    for this chapter, with all necessary GPU drivers and the CUDA Toolkit (9.0–onward)
    installed. A suitable Python 2.7 installation (such as Anaconda Python 2.7) with
    the PyCUDA module is also required.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要一台安装了现代NVIDIA GPU（2016年以后）的Linux或Windows 10 PC，并安装了所有必要的GPU驱动程序和CUDA Toolkit（9.0及以上）。还需要一个合适的Python
    2.7安装（如Anaconda Python 2.7），并安装了PyCUDA模块。
- en: This chapter's code is also available on GitHub at [https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA](https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码也可以在GitHub上找到：[https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA](https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA)。
- en: For more information about the prerequisites, check the *Preface* of this book,
    and for the software and hardware requirements, check the README in [https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA](https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 有关先决条件的更多信息，请查看本书的*前言*，有关软件和硬件要求，请查看[https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA](https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA)中的README。
- en: Using printf from within CUDA kernels
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在CUDA内核中使用printf
- en: It may come as a surprise, but we can actually print text to the standard output
    from directly within a CUDA kernel; not only that, each individual thread can
    print its own output. This will come in particularly handy when we are debugging
    our kernels, as we may need to monitor the values of particular variables or computations
    at particular points in our code and it will also free us from the shackles of
    using a debugger to go through step by step. Printing output from a CUDA kernel
    is done with none other than the most fundamental function in all of C/C++ programming,
    the function that most people will learn when they write their first `Hello world` program
    in C: `printf`. Of course, `printf` is the standard function that prints a string
    to the standard output, and is really the equivalent in the C programming language
    of Python's `print` function.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 也许会让人惊讶，但我们实际上可以直接从CUDA内核中将文本打印到标准输出；不仅如此，每个单独的线程都可以打印自己的输出。当我们调试内核时，这将特别方便，因为我们可能需要监视特定变量或代码中特定点的计算值，这也将使我们摆脱使用调试器逐步进行调试的束缚。从CUDA内核中打印输出的方法是使用C/C++编程中最基本的函数，大多数人在编写他们的第一个C程序“Hello
    world”时会学到的函数：`printf`。当然，`printf`是将字符串打印到标准输出的标准函数，实际上在C编程语言中相当于Python的`print`函数。
- en: 'Let''s now briefly review how to use `printf` before we see how to use it in
    CUDA. The first thing to remember is that `printf` always takes a string as its
    first parameter; so printing "Hello world!" in C is done with `printf("Hello world!\n");`.
    (Of course, `\n` indicates "new line" or "return", which moves the output in the
    Terminal to the next line.) `printf` can also take a variable number of parameters
    in the case that we want to print any constants or variables from directly within
    C: if we want to print the `123` integers to the output, we do this with `printf("%d",
    123);` (where `%d` indicates that an integer follows the string.)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们简要回顾一下如何在CUDA中使用`printf`。首先要记住的是，`printf`总是以字符串作为其第一个参数；因此，在C中打印"Hello
    world!"是用`printf("Hello world!\n");`来完成的。（当然，`\n`表示"新行"或"返回"，它将输出在终端上移到下一行。）`printf`还可以在我们想要直接在C中打印任何常量或变量的情况下，采用可变数量的参数：如果我们想要将`123`整数打印到输出，我们可以使用`printf("%d",
    123);`（其中`%d`表示字符串后面跟着一个整数。）
- en: Similarly, we use `%f`, `%e`, or `%g` to print floating-point values (where
    `%f` is the decimal notation, `%e` is the scientific notation, and `%g` is the
    shortest representation whether decimal or scientific). We can even print several
    values in a row, remembering to place these specifiers in the correct order: `printf("%d
    is a prime number, %f is close to pi, and %d is even.\n", 17, 3.14, 4);` will
    print "17 is a prime number, 3.14 is close to pi, and 4 is even." on the Terminal.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们使用`%f`，`%e`或`%g`来打印浮点值（其中`%f`是十进制表示法，`%e`是科学表示法，`%g`是最短的表示法，无论是十进制还是科学表示法）。我们甚至可以连续打印几个值，记得按正确的顺序放置这些指示符：`printf("%d
    is a prime number, %f is close to pi, and %d is even.\n", 17, 3.14, 4);`将在终端上打印"17
    is a prime number, 3.14 is close to pi, and 4 is even."。
- en: 'Now, nearly halfway through this book, we will finally embark on creating our
    first parallel `Hello world` program in CUDA! We start by importing the appropriate
    modules into Python and then write our kernel. We will start out by printing the
    thread and grid identification of each individual thread (we will only launch
    this in one-dimensional blocks and grids, so we only need the `x` values):'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在这本书的近一半时，我们终于要开始创建我们的第一个并行`Hello world`程序了！我们首先导入适当的模块到Python中，然后编写我们的内核。我们将首先打印每个单独线程的线程和网格标识（我们只会在一维块和网格中启动这个，所以我们只需要`x`值）：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Let's stop for a second and note that we wrote `\\n` rather than `\n`. This
    is due to the fact that the triple quote in Python itself will interpret `\n` as
    a "new line", so we have to indicate that we mean this literally by using a double
    backslash so as to pass the `\n` directly into the CUDA compiler.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们停下来注意一下，我们写的是`\\n`而不是`\n`。这是因为Python中的三引号本身会将`\n`解释为"新行"，所以我们必须使用双反斜杠来表示我们是字面意思，以便将`\n`直接传递给CUDA编译器。
- en: We will now print some information about the block and grid dimensions, but
    we want to ensure that it is printed after every thread has already finished its
    initial `printf` command. We can do this by putting in `__syncthreads();` to ensure
    each individual thread will be synchronized after the first `printf` function
    is executed.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将打印有关块和网格维度的一些信息，但我们希望确保它在每个线程完成其初始`printf`命令后打印。我们可以通过放入`__syncthreads();`来确保每个单独的线程在执行第一个`printf`函数后同步。
- en: 'Now, we only want to print the block and grid dimensions to the terminal only
    once; if we just place `printf` statements here, every single thread will print
    out the same information. We can do this by having only one specified thread print
    to the output; let''s go with the 0th thread of the 0th block, which is the only
    thread that is guaranteed to exist no matter the block and grid dimensionality
    we choose. We can do this with a C `if` statement:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们只想将块和网格的维度打印到终端一次；如果我们在这里放置`printf`语句，每个线程都会打印相同的信息。我们可以通过只有一个指定的线程打印输出来实现这一点；让我们选择第0个块的第0个线程，这是唯一保证存在的线程，无论我们选择的块和网格的维度如何。我们可以通过C的`if`语句来实现这一点：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We will now print the dimensionality of our block and grid and close up the
    `if` statement, and that will be the end of our CUDA kernel:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将打印出我们的块和网格的维度，并关闭`if`语句，这将是我们的CUDA内核的结束：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We will now extract the kernel and then launch it over a grid consisting of
    two blocks, where each block has five threads:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将提取内核，然后在由两个块组成的网格上启动它，每个块有五个线程：
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let''s run this right now (this program is also available in `hello-world_gpu.py`
    under `6` in the repository):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在运行这个程序（该程序也可以在存储库中的`hello-world_gpu.py`的`6`下找到）：
- en: '![](assets/2c945416-8c8a-4eae-8d57-ef1479dd2798.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/2c945416-8c8a-4eae-8d57-ef1479dd2798.png)'
- en: Using printf for debugging
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用printf进行调试
- en: Let's go over an example to see how we can approach debugging a CUDA kernel
    with `printf` with an example before we move on. There is no exact science to
    this method, but it is a skill that can be learned through experience. We will
    start with a CUDA kernel that is for matrix-matrix multiplication, but that has
    several bugs in it. (The reader is encouraged to go through the code as we go
    along, which is available as the `broken_matrix_ker.py` file in the `6` directories
    within the repository.)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来看看如何使用`printf`调试CUDA内核，然后再继续。这种方法并没有确切的科学依据，但通过经验可以学会这种技能。我们将从一个CUDA内核开始，用于矩阵乘法，但其中有几个错误。（鼓励读者随着我们的步骤阅读代码，该代码可在存储库中的`6`目录中的`broken_matrix_ker.py`文件中找到。）
- en: Let's briefly review matrix-matrix multiplication before we continue. Suppose
    we have two matrices ![](assets/0e03608a-7c0c-4629-b61b-ec90b15d0cf7.png), *A*
    and *B*, and we multiply these together to get another matrix, *C*, of the same
    size as follows: ![](assets/60101910-7794-4484-b69f-7ddaad3994db.png). We do this
    by iterating over all tuples ![](assets/f550491f-6b50-49dd-be38-817b363525b9.png) and
    setting the value of ![](assets/54c310e8-02c5-4bbc-b645-9f33465d4e77.png) to the
    dot product of the *i*^(th) row of *A* and the *j*^(th) column of *B*: ![](assets/615e6730-f5b3-48d2-9ac2-fb9a7dc535de.png).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，让我们简要回顾一下矩阵乘法。假设我们有两个矩阵*A*和*B*，我们将它们相乘得到另一个相同大小的矩阵*C*，如下所示：![](assets/60101910-7794-4484-b69f-7ddaad3994db.png)。我们通过迭代所有元组![](assets/f550491f-6b50-49dd-be38-817b363525b9.png)来做到这一点，并将![](assets/54c310e8-02c5-4bbc-b645-9f33465d4e77.png)的值设置为*A*的第*i*行和*B*的第*j*列的点积：![](assets/615e6730-f5b3-48d2-9ac2-fb9a7dc535de.png)。
- en: In other words, we set each *i, j* element in the output matrix *C* as follows:   ![](assets/8870cb22-35f8-4612-aa78-b1cc92fd38f9.png)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们将输出矩阵*C*中的每个*i, j*元素设置如下：![](assets/8870cb22-35f8-4612-aa78-b1cc92fd38f9.png)
- en: Suppose we already wrote a kernel that is to perform matrix-matrix multiplication,
    which takes in two arrays representing the input matrices, an additional pre allocated
    float array that the output will be written to, and an integer that indicates
    the height and width of each matrix (we will assume that all matrices are the
    same size and square-shaped). These matrices are all to be represented as one-dimensional
    `float *` arrays in a row-wise one-dimensional layout. Furthermore, this will
    be implemented so that each CUDA thread will handle a single row/column tuple
    in the output matrix.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们已经编写了一个内核，用于执行矩阵乘法，它接受表示输入矩阵的两个数组，一个额外的预先分配的浮点数组，输出将写入其中，并且一个表示每个矩阵的高度和宽度的整数（我们将假设所有矩阵都是相同大小和正方形的）。这些矩阵都将以一维的`float
    *`数组以行优先的一维布局表示。此外，这将被实现为每个CUDA线程处理输出矩阵中的单个行/列元组。
- en: 'We make a small test case and check it against the output of the matrix multiplication
    in CUDA, and it fails as an assertion check on two 4 x 4 matrices, as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了一个小的测试案例，并将其与CUDA中矩阵乘法的输出进行了检查，对于两个4 x 4矩阵，它作为断言检查失败，如下所示：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We will run this program right now, and unsurprisingly get the following output:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将运行这个程序，并且不出所料地得到以下输出：
- en: '![](assets/7fb29cbf-af3a-4fd1-a75a-cd05d3f56a44.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/7fb29cbf-af3a-4fd1-a75a-cd05d3f56a44.png)'
- en: 'Let''s now look at the CUDA C code, which consists of a kernel and a device
    function:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下CUDA C代码，其中包括一个内核和一个设备函数：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Our goal is to place `printf` invocations intelligently throughout our CUDA
    code so that we can monitor a number of appropriate values and variables in the
    kernel and device function; we should also be sure to print out the thread and
    block numbers alongside these values at every `printf` invocation.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是在我们的CUDA代码中聪明地放置`printf`调用，以便我们可以监视内核和设备函数中的许多适当的值和变量；我们还应该确保在每个`printf`调用中打印出线程和块号。
- en: 'Let''s start at the entry point of our kernel. We see two variables, `row`
    and `col`, so we should check these right away. Let''s put the following line
    right after we set them (since this is parallelized over two dimensions, we should
    print the *x* and *y* values of `threadIdx` and `blockIdx`):'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从内核的入口点开始。我们看到两个变量`row`和`col`，所以我们应该立即检查这些。让我们在设置它们之后立即放上一行代码（因为这是在两个维度上并行化的，我们应该打印`threadIdx`和`blockIdx`的*x*和*y*值）：
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Running the code again, we get this output:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 再次运行代码，我们得到了这个输出：
- en: '![](assets/579c6bb8-3bee-4788-b606-aff8d5d15812.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/579c6bb8-3bee-4788-b606-aff8d5d15812.png)'
- en: 'There are two things that are immediately salient: that there are repeated
    values for row and column tuples (every individual tuple should be represented
    only once), and that the row and column values never exceed two, when they both
    should reach three (since this unit test is using 4 x 4 matrices). This should
    indicate to us that we are calculating the row and column values wrongly; indeed,
    we are forgetting to multiply the `blockIdx` values by the `blockDim` values to
    find the objective row/column values. We fix this as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 有两件事情立即引人注目：行和列元组有重复的值（每个单独的元组应该只表示一次），而且行和列的值从未超过两，而它们都应该达到三（因为这个单元测试使用4 x
    4的矩阵）。这应该告诉我们，我们正在错误地计算行和列的值；确实，我们忘记了将`blockIdx`的值乘以`blockDim`的值来找到目标行/列值。我们按照以下方式修复这个问题：
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If we run the program again, though, we still get an assertion error. Let''s
    keep our original `printf` invocation in place, so we can monitor the values as
    we continue. We see that there is an invocation to a device function in the kernel, `rowcol_dot`,
    so we decide to look into there. Let''s first ensure that the variables are being
    passed into the device function correctly by putting this `printf` invocation
    at the beginning:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们再次运行程序，我们仍然会得到一个断言错误。让我们保留原始的`printf`调用，这样我们就可以在继续进行的过程中监视这些值。我们看到在内核中有一个对设备函数`rowcol_dot`的调用，所以我们决定去看一下。让我们首先确保变量被正确传递到设备函数中，通过在开始处放置这个`printf`调用：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'When we run our program, even more lines will come out, however, we will see
    one that says—`threadIdx.x,y: 0,0 blockIdx.x,y: 1,0 -- row is 2, col is 0.` and
    yet another that says—`threadIdx.x,y: 0,0 blockIdx.x,y: 1,0 -- row is 0, col is
    2, N is 4`. By the `threadIdx` and `blockIdx` values, we see that this is the
    same thread in the same block, but with the `row` and `col` values reversed. Indeed,
    when we look at the invocation of the `rowcol_dot` device function, we see that
    `row` and `col` are indeed reversed from that in the declaration of the device
    function. We fix this, but when we run the program again, we get yet another assertion
    error.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '当我们运行程序时，会有更多的行输出，但我们会看到一行说—`threadIdx.x,y: 0,0 blockIdx.x,y: 1,0 -- row is
    2, col is 0.`，还有另一行说—`threadIdx.x,y: 0,0 blockIdx.x,y: 1,0 -- row is 0, col is
    2, N is 4`。通过`threadIdx`和`blockIdx`的值，我们看到这是同一个块中的同一个线程，但`row`和`col`的值是颠倒的。实际上，当我们查看`rowcol_dot`设备函数的调用时，我们看到`row`和`col`确实是与设备函数声明中的相反。我们修复了这个问题，但当我们再次运行程序时，又出现了另一个断言错误。'
- en: 'Let''s place another `printf` invocation in the device function, within the
    `for` loop; this, of course, is the *dot product* that is to perform a dot product
    between rows of matrix `A` with columns of matrix `B`. We will check the values
    of the matrices we are multiplying, as well as `k`; we will also only look at
    the values of the very first thread, or else we will get an incoherent mess of
    an output:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在设备函数中的`for`循环内放置另一个`printf`调用；这当然是*点积*，用于在矩阵`A`的行与矩阵`B`的列之间执行点积。我们将检查我们正在相乘的矩阵的值，以及`k`；我们还将只查看第一个线程的值，否则我们将得到一个不连贯的输出混乱。
- en: '[PRE9]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let''s look at the values of the `A` and `B` matrices that are set up for our
    unit tests before we continue:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，让我们看一下为我们的单元测试设置的`A`和`B`矩阵的值：
- en: '![](assets/b2580d2a-f34e-4d83-abbd-43ebc163aba7.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/b2580d2a-f34e-4d83-abbd-43ebc163aba7.png)'
- en: 'We see that both matrices vary when we switch between columns but are constant
    when we change between rows. Therefore, by the nature of matrix multiplication,
    the values of matrix `A` should vary across `k` in our `for` loop, while the values
    of `B` should remain constant. Let''s run the program again and check the pertinent
    output:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，当我们在列之间切换时，两个矩阵都会变化，但在行之间变化时是恒定的。因此，根据矩阵乘法的性质，矩阵`A`的值应该在我们的`for`循环中随着`k`的变化而变化，而`B`的值应该保持恒定。让我们再次运行程序并检查相关的输出：
- en: '![](assets/47f4367a-3282-4718-9ec9-e818e0a16ffb.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/47f4367a-3282-4718-9ec9-e818e0a16ffb.png)'
- en: 'So, it appears that we are not accessing the elements of the matrices in a
    correct way; remembering that these matrices are stored in a row-wise format,
    we modify the indices so that their values are accessed in the proper manner:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，看起来我们没有以正确的方式访问矩阵的元素；记住这些矩阵是以行方式存储的，我们修改索引，以便以正确的方式访问它们的值：
- en: '[PRE10]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Running the program again will yield no assertion errors. Congratulations, you
    just debugged a CUDA kernel using the only `printf`!
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 再次运行程序将不会产生断言错误。恭喜，您刚刚使用唯一的`printf`调试了一个CUDA内核！
- en: Filling in the gaps with CUDA-C
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用CUDA-C填补空白
- en: We will now go through the very basics of how to write a full-on CUDA-C program.
    We'll start small and just translate the *fixed* version of the little matrix
    multiplication test program we just debugged in the last section to a pure CUDA-C
    program, which we will then compile from the command line with NVIDIA's `nvcc`
    compiler into a native Windows or Linux executable file (we will see how to use
    the Nsight IDE in the next section, so we will just be doing this with only a
    text editor and the command line for now). Again, the reader is encouraged to
    look at the code we are translating from Python as we go along, which is available
    as the `matrix_ker.py` file in the repository.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将介绍如何编写一个完整的CUDA-C程序的基础知识。我们将从小处开始，将我们刚刚在上一节中调试的小矩阵乘法测试程序的*修复*版本翻译成纯CUDA-C程序，然后使用NVIDIA的`nvcc`编译器从命令行编译成本机Windows或Linux可执行文件（我们将在下一节中看到如何使用NVIDIA的Nsight
    IDE，所以现在我们只使用文本编辑器和命令行）。同样，鼓励读者在我们进行翻译时查看我们正在翻译的Python代码，该代码在存储库中作为`matrix_ker.py`文件可用。
- en: Now, let's open our favorite text editor and create a new file entitled `matrix_ker.cu`.
    The extension will indicate that this is a CUDA-C program, which can be compiled
    with the `nvcc` compiler.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们打开我们最喜欢的文本编辑器，创建一个名为`matrix_ker.cu`的新文件。扩展名将表明这是一个CUDA-C程序，可以使用`nvcc`编译器进行编译。
- en: CUDA-C program and library source code filenames always use the `.cu` file extension.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA-C程序和库源代码的文件名总是使用`.cu`文件扩展名。
- en: Let's start at the beginning—as Python uses the `import` keyword at the beginning
    of a program for libraries, we recall the C language uses `#include`. We will
    need to include a few import libraries before we continue.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从头开始——正如Python在程序开头使用`import`关键字导入库一样，我们回忆C语言使用`#include`。在继续之前，我们需要包含一些导入库。
- en: 'Let''s start with these:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从这些开始：
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Let's briefly think about what we need these for: `cuda_runtime.h` is the header
    file that has the declarations of all of the particular CUDA datatypes, functions,
    and structures that we will need for our program. We will need to include this
    for any pure CUDA-C program that we write. `stdio.h`, of course, gives us all
    of the standard I/O functions for the host such as `printf`, and we need `stdlib.h`
    for using the `malloc` and `free` dynamic memory allocation functions on the host.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要地思考一下我们需要这些的原因：`cuda_runtime.h`是一个头文件，其中包含了我们程序所需的所有特定CUDA数据类型、函数和结构的声明。我们需要为我们编写的任何纯CUDA-C程序包含这个头文件。`stdio.h`当然为我们提供了主机的所有标准I/O函数，如`printf`，我们需要`stdlib.h`来使用主机上的`malloc`和`free`动态内存分配函数。
- en: Remember to always put `#include <cuda_runtime.h>` at the beginning of every
    pure CUDA-C program!
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，始终在每个纯CUDA-C程序的开头放置`#include <cuda_runtime.h>`！
- en: 'Now, before we continue, we remember that we will ultimately have to check
    the output of our kernel with a correct known output, as we did with NumPy''s
    `allclose` function. Unfortunately, we don''t have a standard or easy-to-use numerical
    math library in C as Python has with NumPy. More often than not, it''s just easier
    to write your own equivalent function if it''s something simple, as in this case.
    This means that we will now explicitly have to make our own equivalent to NumPy''s
    `allclose`. We will do so as such: we will use the `#define` macro in C to set
    up a value called `_EPSILON`, which will act as a constant to indicate the minimum
    value between the output and expected output to be considered the same, and we
    will also set up a macro called `_ABS`, which will tell us the absolute difference
    between two numbers. We do so as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在我们继续之前，我们记得我们最终将不得不检查我们的内核输出与正确的已知输出，就像我们在NumPy的`allclose`函数中所做的那样。不幸的是，在C中，我们没有像Python中的NumPy那样的标准或易于使用的数值数学库。往往，如果是一些简单的东西，编写自己的等效函数会更容易，就像在这种情况下一样。这意味着我们现在将明确地制作我们自己的等效于NumPy的`allclose`。我们将这样做：我们将使用C中的`#define`宏来设置一个名为`_EPSILON`的值，它将作为一个常数来指示输出和期望输出之间的最小值，以便被认为是相同的，我们还将设置一个名为`_ABS`的宏，它将告诉我们两个数字之间的绝对差异。我们这样做如下：
- en: '[PRE12]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can now create our own version of `allclose`. This will take in two float
    pointers and an integer value, `len`. We loop through both arrays and check them:
    if any points differ by more than `_EPSILON`, we return -1, otherwise we return
    0 to indicate that the two arrays do indeed match.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以创建我们自己的`allclose`版本。这将接受两个浮点指针和一个整数值`len`，我们循环遍历两个数组并检查它们：如果任何点的差异超过`_EPSILON`，我们返回-1，否则我们返回0，表示这两个数组确实匹配。
- en: 'We note one thing: since we are using CUDA-C, we precede the definition of
    the function with `__host__`, to indicate that this function is intended to be
    run on the CPU rather than on the GPU:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到一件事：由于我们使用CUDA-C，我们在函数定义之前加上`__host__`，以表明这个函数是打算在CPU上运行而不是在GPU上运行的：
- en: '[PRE13]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We now can cut and paste the device and kernel functions exactly as they appear
    in our Python version here:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将设备和内核函数剪切并粘贴到这里，就像它们在我们的Python版本中出现的那样：
- en: '[PRE14]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Again, in contrast with `__host__`, notice that the CUDA device function is
    preceded by `__device__`, while the CUDA kernel is preceded by `__global__`.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，与`__host__`相比，注意CUDA设备函数前面有`__device__`，而CUDA内核前面有`__global__`。
- en: 'Now, as in any C program, we will need to write the `main` function, which
    will run on the host, where we will set up our test case and from which we explicitly
    launch our CUDA kernel onto GPU. Again, in contrast to vanilla C, we will have
    explicitly to specify that this is also to be run on the CPU with `__host__`:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，就像在任何C程序中一样，我们需要编写`main`函数，它将在主机上运行，我们将在其中设置我们的测试案例，并从中显式地启动我们的CUDA内核到GPU上。再次，与普通的C相比，我们将明确指定这也要在CPU上运行，并使用`__host__`：
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The first thing we will have to do is select and initialize our GPU. We do
    so with `cudaSetDevice` as follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要做的第一件事是选择和初始化我们的GPU。我们可以使用`cudaSetDevice`来这样做：
- en: '[PRE16]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '`cudaSetDevice(0)` will select the default GPU. If you have multiple GPUs installed
    in your system, you can select and use them instead with `cudaSetDevice(1)`, `cudaSetDevice(2)`,
    and so on.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`cudaSetDevice(0)`将选择默认的GPU。如果您的系统中安装了多个GPU，您可以选择并使用它们，而不是使用`cudaSetDevice(1)`，`cudaSetDevice(2)`等。'
- en: 'We will now set up `N` as in Python to indicate the height/width of our matrix.
    Since our test case will consist only of 4 x 4 matrices, we set it to `4`. Since
    we will be working with dynamically allocated arrays and pointers, we will also
    have to set up a value that will indicate the number of bytes our test matrices
    will require. The matrices will consist of *N* x *N* floats, and we can determine
    the number of bytes required by a float with the `sizeof` keyword in C:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将设置`N`，就像在Python中一样，以指示矩阵的高度/宽度。由于我们的测试案例将只包括4 x 4矩阵，我们将其设置为`4`。由于我们将使用动态分配的数组和指针，我们还必须设置一个值，以指示我们的测试矩阵将需要的字节数。矩阵将由*N*
    x *N*浮点数组成，我们可以使用C中的`sizeof`关键字确定浮点数所需的字节数：
- en: '[PRE17]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We now set up our test matrices as such; these will correspond exactly to the
    `test_a` and `test_b` matrices that we saw in our Python test program (notice
    how we use the `h_` prefix to indicate that these arrays are stored on the host,
    rather than on the device):'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们设置我们的测试矩阵如下；这些将与我们在Python测试程序中看到的`test_a`和`test_b`矩阵完全对应（请注意我们如何使用`h_`前缀来表示这些数组存储在主机上，而不是设备上）：
- en: '[PRE18]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We now set up another array, which will indicate the expected output of the
    matrix multiplication of the prior test matrices. We will have to calculate this
    explicitly and put these values into our C code. Ultimately, we will compare this
    to the GPU output at the end of the program, but let''s just set it up and get
    it out of the way:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们设置另一个数组，它将指示先前测试矩阵的矩阵乘法的预期输出。我们将不得不明确计算这一点，并将这些值放入我们的C代码中。最终，我们将在程序结束时将其与GPU输出进行比较，但让我们先设置它并将其放在一边：
- en: '[PRE19]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We now declare some pointers for arrays that will live on the GPU, and for
    that we will copy the values of `h_A` and `h_B` and pointer to the GPU''s output.
    Notice how we just use standard float pointers for this. Also, notice the prefix
    `d_`— this is another standard CUDA-C convention that indicates that these will
    exist on the device:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们声明一些指针，这些指针将存在于GPU上的数组，并且我们将复制`h_A`和`h_B`的值并指向GPU的输出。请注意，我们只是使用标准的浮点指针。还要注意前缀`d_`
    - 这是另一个标准的CUDA-C约定，表示这些将存在于设备上：
- en: '[PRE20]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, we will allocate some memory on the device for `d_A` and `d_B` with `cudaMalloc`,
    which is almost the same as `malloc` in C; this is what PyCUDA `gpuarray` functions
    such as `empty` or `to_gpu` have been calling us invisibly to allocate memory
    arrays on the GPU throughout this book:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用`cudaMalloc`在设备上为`d_A`和`d_B`分配一些内存，这几乎与C中的`malloc`相同；这就是PyCUDA `gpuarray`函数（如`empty`或`to_gpu`）在本书中无形地调用我们分配GPU上的内存数组的方式：
- en: '[PRE21]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s think a bit about how this works: in C functions, we can get the address
    of a variable by preceding it with an ampersand (`&`); if you have an integer, `x`,
    we can get its address with `&x`. `&x` will be a pointer to an integer, so its
    type will be `int *`. We can use this to set values of parameters into a C function,
    rather than use only pure return values.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们思考一下这是如何工作的：在C函数中，我们可以通过在变量前加上一个取地址运算符（`&`）来获取变量的地址；如果有一个整数`x`，我们可以用`&x`来获取它的地址。`&x`将是一个指向整数的指针，因此它的类型将是`int
    *`。我们可以使用这个来将参数的值设置到C函数中，而不仅仅使用纯返回值。
- en: Since `cudaMalloc` sets the pointer through a parameter rather than with the
    return value (in contrast to the regular `malloc`), we have to use the ampersand
    operator, which will be a pointer to a pointer, as it is a pointer to a float
    pointer as here (`float **`). We have to typecast this value explicitly with the
    parenthesis since `cudaMalloc` can allocate arrays of any type. Finally, in the
    second parameter, we have to indicate how many bytes to allocate on the GPU; we
    already set up `num_bytes` previously to be the number of bytes we will need to
    hold a 4 x 4 matrix consisting of floats, so we plug this in and continue.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`cudaMalloc`通过参数设置指针而不是使用返回值（与常规的`malloc`相反），我们必须使用取地址运算符，它将是一个指向指针的指针，因为它是一个指向浮点指针的指针，所以我们必须使用括号显式地转换这个值，因为`cudaMalloc`可以分配任何类型的数组。最后，在第二个参数中，我们必须指示在GPU上分配多少字节；我们之前已经设置了`num_bytes`，以便它是我们需要保存由浮点数组成的4
    x 4矩阵所需的字节数，所以我们将其插入并继续。
- en: 'We can now copy the values from `h_A` and `h_B` to `d_A` and `d_B` respectively
    with two invocations of the function `cudaMemcpy`, as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用两次`cudaMemcpy`函数将`h_A`和`h_B`的值分别复制到`d_A`和`d_B`中：
- en: '[PRE22]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '`cudaMemcpy` always takes a destination pointer as the first argument, a source
    pointer as the second, the number of bytes to copy as the third argument, and
    a final parameter. The last parameter will indicate if we are copying from the
    host to the GPU with `cudaMemcpyHostToDevice` , from the GPU to the host with
    `cudaMemcpyDeviceToHost`, or between two arrays on the GPU with `cudaMemcpyDeviceToDevice`.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`cudaMemcpy`总是以目标指针作为第一个参数，源指针作为第二个参数，要复制的字节数作为第三个参数，并且还有一个最后的参数。最后一个参数将指示我们是使用`cudaMemcpyHostToDevice`从主机到GPU进行复制，使用`cudaMemcpyDeviceToHost`从GPU到主机进行复制，还是在GPU上的两个数组之间进行复制`cudaMemcpyDeviceToDevice`。'
- en: 'We will now allocate an array to hold the output of our matrix multiplication
    on the GPU with another invocation of `cudaMalloc`:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将分配一个数组来保存我们在GPU上进行矩阵乘法的输出，使用`cudaMalloc`的另一个调用：
- en: '[PRE23]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Finally, we will have to have some memory set up on the host that will store
    the output of the GPU when we want to check the output of our kernel. Let''s set
    up a regular C float pointer and allocate memory with `malloc` as we would normally:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当我们想要检查内核的输出时，我们将在主机上设置一些存储GPU输出的内存。让我们设置一个常规的C浮点指针，并使用`malloc`分配内存，就像我们通常做的那样：
- en: '[PRE24]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now, we are almost ready to launch our kernel. CUDA uses a data structure called
    `dim3` to indicate block and grid sizes for kernel launches; we will set these
    up as such, since we want a grid with a dimension of 2 x 2 and blocks that are
    also of a dimension of 2 x 2:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们几乎准备好启动我们的内核。CUDA使用一个名为`dim3`的数据结构来指示内核启动的块和网格大小；我们将设置这些，因为我们想要一个2 x 2维度的网格和也是2
    x 2维度的块：
- en: '[PRE25]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We are now ready to launch our kernel; we use the triple-triangle brackets
    to indicate to the CUDA-C compiler the block and grid sizes that the kernel should
    be launched over:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备启动我们的内核；我们使用三角形括号来指示CUDA-C编译器内核应该启动的块和网格大小：
- en: '[PRE26]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, of course, before we can copy the output of the kernel back to the host,
    we have to ensure that the kernel has finished executing. We do this by calling
    `cudaDeviceSynchronize`, which will block the host from issuing any more commands
    to the GPU until the kernel has finished execution:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当然，在我们可以将内核的输出复制回主机之前，我们必须确保内核已经执行完毕。我们通过调用`cudaDeviceSynchronize`来做到这一点，这将阻止主机向GPU发出更多命令，直到内核执行完毕：
- en: '[PRE27]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We now can copy the output of our kernel to the array we''ve allocated on the
    host:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将内核的输出复制到我们在主机上分配的数组中：
- en: '[PRE28]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Again, we synchronize:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们同步：
- en: '[PRE29]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Before we check the output, we realize that we no longer need any of the arrays
    we allocated on the GPU. We free this memory by calling `cudaFree` on each array:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查输出之前，我们意识到我们不再需要在GPU上分配的任何数组。我们通过在每个数组上调用`cudaFree`来释放这些内存：
- en: '[PRE30]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We''re done with the GPU, so we call `cudaDeviceReset`:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了GPU的工作，所以我们调用`cudaDeviceReset`：
- en: '[PRE31]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now, we finally check the output we copied onto the host with the `allclose`
    function we wrote at the beginning of this chapter. If the actual output doesn''t
    match the expected output, we print an error and return `-1`, otherwise, we print
    that it does match and we return 0. We then put a closing bracket on our program''s
    `main` function:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们最终检查我们在主机上复制的输出，使用我们在本章开头编写的`allclose`函数。如果实际输出与预期输出不匹配，我们打印一个错误并返回`-1`，否则，我们打印匹配并返回0。然后我们在程序的`main`函数上放一个闭括号：
- en: '[PRE32]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Notice that we make one final invocation to the standard C free function since
    we have allocated memory to `h_output `, in both cases.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于我们已经为`h_output`分配了内存，在这两种情况下，我们最后调用了标准的C free函数。
- en: 'We now save our file, and compile it into a Windows or Linux executable file
    from the command line with `nvcc matrix_ker.cu -o matrix_ker`. This should output
    a binary executable file, `matrix_ker.exe` (in Windows) or `matrix_ker` (in Linux).
    Let''s try compiling and running it right now:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在保存我们的文件，并从命令行编译成Windows或Linux可执行文件，使用`nvcc matrix_ker.cu -o matrix_ker`。这应该输出一个二进制可执行文件，`matrix_ker.exe`（在Windows中）或`matrix_ker`（在Linux中）。让我们尝试编译和运行它：
- en: '![](assets/ada8e5c8-9443-40ce-81d9-03100f570855.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ada8e5c8-9443-40ce-81d9-03100f570855.png)'
- en: Congratulations, you've just created your first pure CUDA-C program! (This example
    is available as `matrix_ker.cu` in the repository, under `7`.)
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜，您刚刚创建了您的第一个纯CUDA-C程序！（此示例在存储库中作为`matrix_ker.cu`在`7`下可用。）
- en: Using the Nsight IDE for CUDA-C development and debugging
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Nsight IDE进行CUDA-C开发和调试
- en: Let's now learn how to use the Nsight IDE for developing CUDA-C programs. We
    will see how to import the program we just wrote, and compile and debug it from
    within Nsight. Note that there are differences between the Windows and Linux versions
    of Nsight, since it is effectively a plugin of the Visual Studio IDE under Windows
    and in the Eclipse IDE under Linux. We will cover both in the following two subsections;
    feel free to skip whatever operating system does not apply to you here.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们学习如何使用Nsight IDE开发CUDA-C程序。我们将看到如何导入我们刚刚编写的程序，并在Nsight内部进行编译和调试。请注意，由于在Windows下它实际上是Visual
    Studio IDE的插件，在Linux下是Eclipse IDE的插件，因此Windows和Linux版本的Nsight之间存在差异。我们将在接下来的两个子部分中涵盖两者；如果不适用于您的操作系统，请随意跳过。
- en: Using Nsight with Visual Studio in Windows
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Windows中使用Visual Studio的Nsight
- en: 'Open up Visual Studio, and click on File, then choose New | Project.... A window
    will pop up where you set the type of project: choose the NVIDIA drop-down item,
    and then choose CUDA 9.2:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 打开Visual Studio，点击文件，然后选择新建|项目....会弹出一个窗口，您可以在其中设置项目类型：选择NVIDIA下拉项，然后选择CUDA
    9.2：
- en: '![](assets/e5b3c450-388f-44ac-9d77-8f7cf574bf69.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/e5b3c450-388f-44ac-9d77-8f7cf574bf69.png)'
- en: Give the project some appropriate name and then click OK. A project should appear
    in the solution explorer window with a simple premade CUDA test program, consisting
    of one source file, `kernel.cu`, which consists of a simple parallel add kernel
    with test code. If you want to see whether this compiles and runs, click the green
    right-pointing arrow at the top marked Local Windows Debugger. A Terminal should
    pop up with some text output from the kernel and then close immediately.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 给项目取一个合适的名称，然后点击确定。在解决方案资源管理器窗口中应该会出现一个项目，其中包含一个简单的预制CUDA测试程序，由一个源文件`kernel.cu`组成，其中包含一个简单的并行加法内核和测试代码。如果您想查看这是否编译和运行，请点击顶部标有本地Windows调试器的绿色向右箭头。一个终端应该弹出，显示内核的一些文本输出，然后立即关闭。
- en: If you have problems with a Windows Terminal-based application closing after
    you run it from Visual Studio, try adding `getchar();` to the end of the main
    function, which will keep the Terminal open until you press a key. (Alternatively,
    you can also use a debugger breakpoint at the end of the program.)
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在从Visual Studio运行后关闭基于Windows终端的应用程序时遇到问题，请尝试在主函数的末尾添加`getchar();`，这将使终端保持打开状态，直到您按下一个键。（或者，您也可以在程序的末尾使用调试器断点。）
- en: Now, let's add the CUDA-C program we just wrote. In the Solution Explorer window,
    right-click  `kernel.cu`, and click Remove on `kernel.cu`. Now, right-click on
    the project name, and choose Add, and then choose Existing item. We will now be
    able to select an existing file, so find where the path is to `matrix_ker.cu` and
    add it to the project. Click on the green arrow marked Local Windows Debugger
    at the top of the IDE and the program should compile and run, again in a Windows
    Terminal. So, that's it—we can set up and compile a complete CUDA program in Visual
    Studio now, just from those few steps.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们添加刚刚编写的CUDA-C程序。在解决方案资源管理器窗口中，右键单击`kernel.cu`，然后单击`kernel.cu`上的删除。现在，右键单击项目名称，选择添加，然后选择现有项目。现在我们可以选择一个现有文件，找到`matrix_ker.cu`的路径，并将其添加到项目中。点击IDE顶部标有本地Windows调试器的绿色箭头，程序应该会在Windows终端中再次编译和运行。这就是我们可以在Visual
    Studio中设置和编译完整的CUDA程序的全部步骤。
- en: 'Let''s now see how to debug our CUDA kernel. Let''s start by adding one breakpoint
    to our code at the entry point of the kernel `matrix_mult_ker`, where we set the
    value of `row` and `col`. We can add this breakpoint by clicking on the gray column
    left of the line numbers on the window; a red dot should appear there for every
    breakpoint we add. (You can ignore any red squiggly lines that the Visual Studio
    editor may place under your code; this is due to the fact that CUDA is not a *native* language
    to Visual Studio):'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何调试我们的CUDA内核。让我们首先在代码的入口点`matrix_mult_ker`处添加一个断点，我们在那里设置了`row`和`col`的值。我们可以通过在窗口的行号左侧的灰色列上单击来添加此断点；每个我们添加的断点都应该在那里显示一个红点。（您可以忽略Visual
    Studio编辑器可能在您的代码下方放置的任何红色波浪线；这是因为CUDA不是Visual Studio的*本地*语言）：
- en: '![](assets/b4408001-ab3d-42fb-9741-1e1a3c896491.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/b4408001-ab3d-42fb-9741-1e1a3c896491.png)'
- en: We can now start debugging. From the top menu, choose the Nsight drop-down menu
    and choose Start CUDA Debugging. There may be two options here, Start CUDA Debugging
    (Next-Gen) and Start CUDA Debugging (Legacy). It doesn't matter which one, but
    you may have issues with Next-Gen depending on your GPU; in that case, choose
    Legacy.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以开始调试。从顶部菜单中选择Nsight下拉菜单，然后选择开始CUDA调试。这里可能有两个选项，开始CUDA调试（Next-Gen）和开始CUDA调试（Legacy）。无论选择哪一个都可以，但是根据您的GPU，可能会在Next-Gen上遇到问题；在这种情况下，请选择Legacy。
- en: 'Your program should start up, and the debugger should halt at the breakpoint
    in our kernel that we just set. Let''s press *F10* to step over the line, and
    now see if the `row` variable gets set correctly. Let''s look at the Locals window
    in the Variable Explorer:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 您的程序应该启动，并且调试器应该在我们刚刚设置的内核中的断点处停止。让我们按*F10*跳过这一行，现在看看`row`变量是否被正确设置。让我们在变量资源管理器中的本地窗口中查看：
- en: '![](assets/4bbfaa46-46cb-44cc-ac0b-055dc9ce89ca.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/4bbfaa46-46cb-44cc-ac0b-055dc9ce89ca.png)'
- en: 'We can see that we are currently in the very first thread in the very first
    block in the grid by checking the values of `threadIdx` and `blockIdx`; `row`
    is set to `0`, which does indeed correspond to the correct value. Now, let''s
    check the value of row for some different thread. To do this, we have to switch
    the **thread focus** in the IDE; we do this by clicking the Nsight drop-down menu
    above, then choosing Windows|CUDA Debug Focus.... A new menu should appear allowing
    you to choose a new thread and block. Change thread from 0, 0, 0 to 1, 0, 0 in
    the menu, and click OK:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查`threadIdx`和`blockIdx`的值，我们可以看到我们当前位于网格中的第一个块中的第一个线程；`row`设置为`0`，这确实对应于正确的值。现在，让我们检查一些不同线程的`row`值。为了做到这一点，我们必须在IDE中切换**线程焦点**；我们可以通过单击上面的Nsight下拉菜单，然后选择Windows|CUDA
    Debug Focus...来实现这一点。应该会出现一个新菜单，允许您选择一个新的线程和块。在菜单中将线程从0, 0, 0更改为1, 0, 0，然后单击确定：
- en: '![](assets/c5f2b196-8ce2-45b6-807a-11f8d86fe86b.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/c5f2b196-8ce2-45b6-807a-11f8d86fe86b.png)'
- en: 'When you check the variables again, you should see the correct value is set
    for `row` for this thread:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 当您再次检查变量时，您应该看到为此线程设置了正确的`row`值：
- en: '![](assets/f2f27821-5df5-4ea7-a847-385967ba54a0.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/f2f27821-5df5-4ea7-a847-385967ba54a0.png)'
- en: In a nutshell, that is how you debug with Nsight in Visual Studio. We now have
    the basics of how to debug a CUDA program from Nsight/Visual Studio in Windows,
    and we can use all of the regular conventions as we would for debugging a regular
    Windows program as with any other IDE (setting breakpoints, starting the debugger,
    continue/resume, step over, step in, and step out). Namely, the main difference
    is you have to know how to switch between CUDA threads and blocks to check variables,
    otherwise, it's pretty much the same.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，这就是您在Visual Studio中使用Nsight进行调试的方法。我们现在已经掌握了如何在Windows中使用Nsight/Visual
    Studio调试CUDA程序的基础知识，我们可以像调试常规Windows程序一样使用所有常规约定（设置断点，启动调试器，继续/恢复，跳过，步入和步出）。主要的区别在于您必须知道如何在CUDA线程和块之间切换以检查变量，否则它基本上是一样的。
- en: Using Nsight with Eclipse in Linux
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Linux中使用Nsight与Eclipse
- en: 'We will now see how to use Nsight in Linux. You can open Nsight from either
    your desktop by selecting it or you can run it from a command line with the `nsight` command.
    The Nsight IDE will open. From the top of the IDE, click on File, then choose
    New... from the drop-down menu, and from there choose New CUDA C/C++ Project.
    A new window will appear, and from here choose CUDA Runtime Project. Give the
    project some appropriate name, and then click Next. You''ll be prompted to give
    further settings options, but the defaults will work fine for our purposes for
    now. (Be sure to note where the source folder and project paths will be located
    in the third and fourth screens here.) You''ll get to a final screen, where you
    can press Finish to create the project:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将看到如何在Linux中使用Nsight。您可以从桌面上选择它打开Nsight，也可以使用`nsight`命令从命令行运行它。Nsight IDE将打开。从IDE顶部，单击文件，然后从下拉菜单中选择新建...，然后选择新建CUDA
    C/C++项目。将出现一个新窗口，在这里选择CUDA Runtime项目。给项目取一个合适的名字，然后点击下一步。您将被提示提供进一步的设置选项，但默认设置对我们的目的来说现在可以工作得很好。（请确保注意这里第三和第四屏幕中源文件和项目路径的位置。）您将进入最终屏幕，在这里您可以按完成来创建项目：
- en: '![](assets/e2f72961-a2fe-4c06-a4c2-2ab6653c140b.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/e2f72961-a2fe-4c06-a4c2-2ab6653c140b.png)'
- en: Finally, you'll end up at a project view with your new project and some placeholder
    code open; as of CUDA 9.2, this will consist of a reciprocal kernel example.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您将在项目视图中看到您的新项目和一些占位代码；从CUDA 9.2开始，这将包括一个倒数内核示例。
- en: 'We can now import our code. Either you can just use the editor in Nsight to
    delete all of the code in the default source file and cut and paste it in, or
    you can manually delete the file from the project''s source directory, manually
    copy the `matrix_ker.cu` file into the source directory, and then choose to refresh
    the source directory view in Nsight by selecting it and then pressing *F5*. You
    can now build the project with *Ctrl* + *B*, and run it with *F11*. The output
    of our program should appear within the IDE itself within the Console subwindow,
    as follows:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以导入我们的代码。您可以使用Nsight中的编辑器删除默认源文件中的所有代码并剪切粘贴，或者您可以手动从项目的源目录中删除文件，手动将`matrix_ker.cu`文件复制到源目录中，然后选择刷新Nsight中的源目录视图，然后按*F5*。现在可以使用*Ctrl*
    + *B*构建项目，并使用*F11*运行它。我们程序的输出应该出现在IDE的Console子窗口中，如下所示：
- en: '![](assets/1e287f83-ed1a-416e-aca7-511b375c1568.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/1e287f83-ed1a-416e-aca7-511b375c1568.png)'
- en: We can now set a breakpoint within our CUDA code; let's set it at the entry
    point of our kernel where the row value is set. We set the cursor onto that row
    in the Eclipse editor, and then press *Ctrl* + *Shift* + *B* to set it.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以在CUDA代码中设置断点；让我们在内核的入口点设置一个断点，那里设置了`row`值。我们将光标放在Eclipse编辑器中的该行上，然后按*Ctrl*
    + *Shift* + *B*进行设置。
- en: We can now begin debugging by pressing *F11* (or clicking the bug icon). The
    program should be paused at the very beginning of the `main` function, so press
    *F8* to *resume* to the first breakpoint. You should see the first line in our
    CUDA kernel highlighted with an arrow pointing to it in the IDE; let's step over
    the current line by pressing *F6*, which will ensure that the row has been set.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以通过按*F11*（或单击bug图标）开始调试。程序应该在`main`函数的开头暂停，所以按*F8*继续到第一个断点。您应该在IDE中看到我们的CUDA内核中的第一行被箭头指向。让我们通过按*F6*跳过当前行，确保`row`已经设置。
- en: 'Now, we can easily switch between different threads and blocks in our CUDA
    grid to check the current values that they hold as follows: from the top of the
    IDE, click on the Window drop-down menu, then click Show view, and then choose
    CUDA. A window with the currently running kernel should open, and from here you
    can see a list of all of the blocks that this kernel is running over.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以轻松地在CUDA网格中切换不同的线程和块，以检查它们当前持有的值：从IDE顶部，单击窗口下拉菜单，然后单击显示视图，然后选择CUDA。应该会打开一个显示当前运行内核的窗口，从这里您可以看到此内核正在运行的所有块的列表。
- en: 'Click on the first one and from here you will be able to see all of the individual
    threads that are running within the block:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 点击第一个，从这里你将能够看到块内运行的所有单个线程：
- en: '![](assets/429490aa-3a80-48af-8833-9cc6a4988a7f.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/429490aa-3a80-48af-8833-9cc6a4988a7f.png)'
- en: 'Now, we can look at the variable corresponding to the very first thread in
    the very first block by clicking on the Variables tab—here, row should be 0, as
    expected:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以通过单击“变量”选项卡来查看与第一个块中的第一个线程对应的变量，这里，row应该是0，正如我们所期望的：
- en: '![](assets/2d42ba20-c3bb-4f76-acc9-054fa1cc3960.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/2d42ba20-c3bb-4f76-acc9-054fa1cc3960.png)'
- en: 'Now, we can check the values for a different thread by again going to the CUDA
    tab, choosing the appropriate thread, and switching back. Let''s stay in the same
    block, but choose thread (1, 0, 0) this time, and check the value of row again:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以通过再次转到CUDA选项卡，选择适当的线程并切换回来，来检查不同线程的值。让我们留在同一个块中，但这次选择线程（1,0,0），再次检查row的值：
- en: '![](assets/ca99eb7a-04e5-40a0-982e-8a605b3cc697.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ca99eb7a-04e5-40a0-982e-8a605b3cc697.png)'
- en: We see that the value of row is now 1, as we expect.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到row的值现在是1，正如我们所期望的。
- en: We now have the basics of how to debug a CUDA program from Nsight/Eclipse in
    Linux, and we can use all of the regular conventions as you would for debugging
    a regular Linux program as with any other IDE (setting breakpoints, starting the
    debugger, continue/resume, step over, step in, and step out). Namely, the main
    difference here is we have to know how to switch between CUDA threads and blocks
    to check variables, otherwise, it's pretty much the same.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经掌握了如何从Nisight/Eclipse在Linux中调试CUDA程序的基础知识，我们可以像调试其他IDE中的常规Linux程序一样使用所有常规约定（设置断点、启动调试器、继续/恢复、步进、步入和步出）。主要的区别在于我们必须知道如何在CUDA线程和块之间切换以检查变量，否则，它基本上是一样的。
- en: Using Nsight to understand the warp lockstep property in CUDA
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Nisight来理解CUDA中的warp lockstep属性
- en: 'We will now use Nsight to step through some code to help us better understand
    some of the CUDA GPU architecture, and how **branching** within a kernel is handled.
    This will give us some insight about how to write more efficient CUDA kernels.
    By branching, we mean how the GPU handles control flow statements such as `if`,
    `else`, or `switch` within a CUDA kernel. In particular, we are interested in
    how **branch divergence** is handled within a kernel, which is what happens when
    one thread in a kernel satisfies the conditions to be an `if` statement, while
    another doesn''t and is an `else` statement: they are divergent because they are
    executing different pieces of code.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用Nisight逐步执行一些代码，以帮助我们更好地理解一些CUDA GPU架构，以及内核内的**分支**是如何处理的。这将使我们对如何编写更有效的CUDA内核有一些见解。通过分支，我们指的是GPU如何处理CUDA内核中的`if`、`else`或`switch`等控制流语句。特别是，我们对内核内的**分支分歧**如何处理感兴趣，即当内核中的一个线程满足成为`if`语句的条件时，而另一个线程不满足条件并成为`else`语句时会发生什么：它们是分歧的，因为它们执行不同的代码片段。
- en: 'Let''s write a small CUDA-C program as an experiment: we will start with a
    small kernel that prints one output if its `threadIdx.x` value is even and another
    if it is odd. We then write a `main` function that will launch this kernel over
    one single block consisting of 32 different threads:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们写一个小的CUDA-C程序作为实验：我们将从一个小内核开始，如果其`threadIdx.x`值是偶数，则打印一个输出，如果是奇数，则打印另一个输出。然后，我们编写一个`main`函数，将这个内核启动到由32个不同线程组成的一个单一块上：
- en: '[PRE33]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: (This code is also available as `divergence_test.cu` in the repository.)
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: （此代码也可在存储库中的`divergence_test.cu`中找到。）
- en: If we compile and run this from the command line, we might naively expect there
    to be an interleaved sequence of strings from even and odd threads; or maybe they
    will be randomly interleaved—since all of the threads run concurrently and branch
    about the same time, this would make sense.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们从命令行编译和运行这个程序，我们可能天真地期望偶数和奇数线程之间会有交错的字符串序列；或者它们可能会随机交错——因为所有线程都是并发运行并且大约在同一时间分支，这是有道理的。
- en: 'Instead, every single time we run this, we always get this output:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，每次我们运行这个程序，我们总是得到这个输出：
- en: '![](assets/38c855ca-4bd8-4ab6-9e6b-371a9c9c0bb1.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/38c855ca-4bd8-4ab6-9e6b-371a9c9c0bb1.png)'
- en: All of the strings corresponding to even threads are printed first, while all
    of the odd strings are printed second. Perhaps the Nsight debugger can shed some
    light on this; let's import this little program into an Nsight project as we did
    in the last section, putting a breakpoint at the first `if` statement in our kernel.
    We will then do a *step over*, so that the debugger stops where the first `printf`
    statement is. Since the default thread in Nsight is (0,0,0), this should have
    satisfied the first `if` statement so it will be stuck there until the debugger
    continues.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 所有与偶数线程对应的字符串都先打印出来，而所有与奇数线程对应的字符串都在第二次打印出来。也许Nisight调试器可以解释一些问题；让我们像在上一节中那样将这个小程序导入Nisight项目，并在内核的第一个`if`语句处设置断点。然后我们将执行*step
    over*，这样调试器就会在第一个`printf`语句处停下来。由于Nisight中的默认线程是（0,0,0），这应该满足了第一个`if`语句，所以它会一直停在那里，直到调试器继续。
- en: 'Let''s switch over to an odd thread, say (1,0,0), and see where it is in our
    program now:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们切换到一个奇数线程，比如（1,0,0），看看它现在在我们的程序中的位置：
- en: '![](assets/58816167-07da-44ae-954a-4b6c3e911bbd.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/58816167-07da-44ae-954a-4b6c3e911bbd.png)'
- en: Very strange! Thread (1,0,0) is also at the same place in execution as thread
    (0,0,0). Indeed, if we check every single other odd thread here, it will be stuck
    in the same place—at a `printf` statement that all of the odd threads should have
    skipped right past.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 非常奇怪！线程（1,0,0）在执行中也与线程（0,0,0）处于相同的位置。实际上，如果我们在这里检查每一个其他奇数线程，它们都会停在同一个地方——在一个所有奇数线程应该跳过的`printf`语句处。
- en: What gives? This is known as the **warp lockstep property**. A **warp** in the
    CUDA architecture is a unit of 32 "lanes" within which our GPU executes kernels
    and grids over, where each lane will execute a single thread. A major limitation
    of warps is that all threads executing on a single warp must step through the
    same exact code in **lockstep**; this means that not every thread does indeed
    run the same code, but just ignores steps that are not applicable to it. (This
    is called lockstep because it's like a group of soldiers marching *lockstep* in
    unison—whether they want to march, or not!)
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这是什么？这被称为**warp锁步特性**。CUDA架构中的一个**warp**是一个由32个“通道”组成的单元，在这个单元中，我们的GPU执行内核和网格，其中每个通道将执行一个线程。warp的一个主要限制是，所有在一个warp上执行的线程必须以**锁步**的方式执行相同的代码；这意味着并非每个线程确实运行相同的代码，而只是忽略对它不适用的步骤。（这被称为锁步，因为就像一群士兵一起*锁步*行进一样——不管他们是否想要行进！）
- en: The lockstep property implies that if one single thread running on a warp diverges
    from all 31 other threads in a single `if` statement, all 31 other threads have
    their execution delayed until this single anomalous thread finishes and returns
    from its solitary `if` divergence. This is a property that you should always keep
    in mind when writing kernels, and why branch divergence should be minimized as
    much as possible as a general rule in CUDA programming.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 锁步特性意味着如果一个warp上运行的单个线程在单个`if`语句中与其他31个线程产生分歧，所有其他31个线程的执行都会延迟，直到这个单独的异常线程完成并从其孤立的`if`分歧中返回。这是在编写内核时应该牢记的一个特性，也是为什么在CUDA编程中，分支分歧应该尽量减少的一般规则。
- en: Using the NVIDIA nvprof profiler and Visual Profiler
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用NVIDIA nvprof分析器和Visual Profiler
- en: We will end with a brief overview of the command-line Nvidia `nvprof` profiler.
    In contrast to the Nsight IDE, we can freely use any Python code that we have
    written—we won't be compelled here to write full-on, pure CUDA-C test function
    code.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将简要概述命令行Nvidia `nvprof`分析器。与Nsight IDE相比，我们可以自由使用我们编写的任何Python代码——我们不必在这里强制编写完整的、纯粹的CUDA-C测试函数代码。
- en: 'We can do a basic profiling of a binary executable program with the `nvprof
    program` command; we can likewise profile a Python script by using the `python`
    command as the first argument, and the script as the second as follows: `nvprof
    python program.py`. Let''s profile the simple matrix-multiplication CUDA-C executable
    program that we wrote earlier, with `nvprof matrix_ker`:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '我们可以使用`nvprof program`命令对二进制可执行程序进行基本分析；同样，我们可以使用`python`命令作为第一个参数，使用脚本作为第二个参数来对Python脚本进行分析，如下所示：`nvprof
    python program.py`。让我们使用`nvprof matrix_ker`对我们之前编写的简单矩阵乘法CUDA-C可执行程序进行分析： '
- en: '![](assets/41fb00d0-582b-4b22-81ea-b9ae1988ad84.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/41fb00d0-582b-4b22-81ea-b9ae1988ad84.png)'
- en: We see that this is very similar to the output of the Python cProfiler module
    that we first used to analyze a Mandelbrot algorithm way back in [Chapter 1](f9c54d0e-6a18-49fc-b04c-d44a95e011a2.xhtml),
    *Why GPU Programming?*—only now, this exclusively tells us only about all of the
    CUDA operations that were executed. So, we can use this when we specifically want
    to optimize on the GPU, rather than concern ourselves with any of the Python or
    other commands that executed on the host. (We can further analyze each individual
    CUDA kernel operation with block and grid size launch parameters if we add the
    command-line option, `--print-gpu-trace`.)
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到这与我们最初使用的Python cProfiler模块输出非常相似，我们用它来分析[第1章](f9c54d0e-6a18-49fc-b04c-d44a95e011a2.xhtml)中的Mandelbrot算法——只是现在，这专门告诉我们有关执行的所有CUDA操作。因此，当我们专门想要在GPU上进行优化时，我们可以使用它，而不必关心在主机上执行的任何Python或其他命令。（如果我们添加`--print-gpu-trace`命令行选项，我们可以进一步分析每个单独的CUDA内核操作，包括块和网格大小的启动参数。）
- en: Let's look at one more trick to help us *visualize* the execution time of all
    of the operations of a program; we will use `nvprof` to dump a file that can then
    be read by the NVIDIA Visual Profiler, which will show this to us graphically.
    Let's do this using an example from the last chapter, `multi-kernel_streams.py`
    (this is available in the repository under `5`). Let's recall that this was one
    of our introductory examples to the idea of CUDA streams, which allow us to execute
    and organize multiple GPU operations concurrently. Let's dump the output to a
    file with the `.nvvp` file suffix with the `-o` command-line option as follows: `nvprof
    -o m.nvvp python multi-kernel_streams.py`. We can now load this file into the
    NVIDIA Visual Profiler with the `nvvp m.nvvp` command.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看一个技巧，帮助我们*可视化*程序所有操作的执行时间；我们将使用`nvprof`来转储一个文件，然后可以由NVIDIA Visual Profiler读取，以图形方式显示给我们。我们将使用上一章的示例`multi-kernel_streams.py`（在存储库的`5`下可用）来做这个。让我们回忆一下，这是我们对CUDA流概念的介绍示例之一，它允许我们同时执行和组织多个GPU操作。我们将使用`-o`命令行选项将输出转储到一个带有`.nvvp`文件后缀的文件中，如下所示：`nvprof
    -o m.nvvp python multi-kernel_streams.py`。现在我们可以使用`nvvp m.nvvp`命令将此文件加载到NVIDIA
    Visual Profiler中。
- en: 'We should see a timeline across all CUDA streams as such (remembering that
    the name of the kernel used in this program is called `mult_ker`):'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该在所有CUDA流上看到一个时间线（记住，此程序中使用的内核名称为`mult_ker`）：
- en: '![](assets/37df8c10-9b93-4d86-bb74-ff00920e7470.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/37df8c10-9b93-4d86-bb74-ff00920e7470.png)'
- en: Not only can we see all kernel launches, but also memory allocations, memory
    copies, and other operations. This can be useful for getting an intuitive and
    visual understanding of how your program is using your GPU over time.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅可以看到所有的内核启动，还可以看到内存分配、内存复制和其他操作。这对于直观和视觉上理解程序如何随着时间使用GPU是有用的。
- en: Summary
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'We started out in this chapter by seeing how `printf` can be used within a
    CUDA kernel to output data from individual threads; we saw in particular how useful
    this can be for debugging code. We then covered some of the gaps in our knowledge
    in CUDA-C, so that we can write full test programs that we can compile into proper
    executable binary files: there is a lot of overhead here that was hidden from
    us before that we have to be meticulous about. Next, we saw how to create and
    compile a project in the Nsight IDE and how to use it for debugging. We saw how
    to stop at any breakpoint we set in a CUDA kernel and switch between individual
    threads to see the different local variables. We also used the Nsight debugger
    to learn about the warp lockstep property and why it is important to avoid branch
    divergence in CUDA kernels. Finally, we had a very brief overview of the NVIDIA
    command-line `nvprof` profiler and Visual Profiler for analyzing our GPU code.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章开始时看到了如何在CUDA内核中使用`printf`来输出来自各个线程的数据；我们特别看到了这对于调试代码有多么有用。然后，我们涵盖了CUDA-C中我们知识的一些空白，以便我们可以编写完整的测试程序，将其编译成适当的可执行二进制文件：这里有很多开销在我们之前是隐藏的，我们必须非常谨慎。接下来，我们看到了如何在Nsight
    IDE中创建和编译项目以及如何使用它进行调试。我们看到了如何在CUDA内核中停止我们设置的任何断点，并在不同的本地变量之间切换以查看各个线程。我们还使用了Nsight调试器来了解warp锁步属性以及为什么在CUDA内核中避免分支分歧很重要。最后，我们对NVIDIA命令行`nvprof`分析器和Visual
    Profiler进行了非常简要的概述，用于分析我们的GPU代码。
- en: Questions
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'In the first CUDA-C program that we wrote, we didn''t use a `cudaDeviceSynchronize`
    command after the calls we made to allocate memory arrays on the GPU with `cudaMalloc`.
    Why was this not necessary? (Hint: Review the last chapter.)'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们编写的第一个CUDA-C程序中，我们在使用`cudaMalloc`在GPU上分配内存数组之后没有使用`cudaDeviceSynchronize`命令。为什么这是不必要的？（提示：回顾上一章。）
- en: Suppose we have a single kernel that is launched over a grid consisting of two
    blocks, where each block has 32 threads. Suppose all of the threads in the first
    block execute an `if` statement, while all of the threads in the second block
    execute the corresponding `else` statement. Will all of the threads in the second
    block have to "lockstep" through the commands in the `if` statement as the threads
    in the first block are actually executing them?
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设我们有一个单个内核，它在由两个块组成的网格上启动，每个块有32个线程。假设第一个块中的所有线程都执行一个`if`语句，而第二个块中的所有线程都执行相应的`else`语句。第二个块中的所有线程是否必须像第一个块中的线程一样“锁步”执行`if`语句中的命令？
- en: What if we executed a similar piece of code, only over a grid consisting of
    one single block executed over 64 threads, where the first 32 threads execute
    an `if` and the second 32 execute an `else` statement?
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们执行类似的代码片段，只是在由64个线程执行的一个单一块组成的网格上执行，其中前32个线程执行一个`if`，而后32个执行一个`else`语句，会怎么样？
- en: What can the `nvprof` profiler measure for us that Python's cProfiler cannot?
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`nvprof`分析器可以为我们测量哪些Python的cProfiler无法测量的内容？'
- en: Name some contexts where we might prefer to use `printf` to debug a CUDA kernel
    and other contexts where it might be easier to use Nsight to debug a CUDA kernel.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列举一些我们可能更喜欢使用`printf`来调试CUDA内核的情境，以及其他一些情境，其中使用Nsight来调试CUDA内核可能更容易。
- en: What is the purpose of the `cudaSetDevice` command in CUDA-C?
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`cudaSetDevice`命令在CUDA-C中的目的是什么？'
- en: Why do we have to use `cudaDeviceSynchronize` after every kernel launch or memory
    copy in CUDA-C?
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么我们在每次CUDA-C中的内核启动或内存复制后都必须使用`cudaDeviceSynchronize`？

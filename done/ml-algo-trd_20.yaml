- en: '20'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '20'
- en: Autoencoders for Conditional Risk Factors and Asset Pricing
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于条件风险因素和资产定价的自动编码器
- en: This chapter shows how unsupervised learning can leverage deep learning for
    trading. More specifically, we'll discuss **autoencoders** that have been around
    for decades but have recently attracted fresh interest.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了无监督学习如何利用深度学习进行交易。更具体地说，我们将讨论几十年来一直存在但最近引起新兴兴趣的**自动编码器**。
- en: '**Unsupervised learning** addresses practical ML challenges such as the limited
    availability of labeled data and the curse of dimensionality, which requires exponentially
    more samples for successful learning from complex, real-life data with many features.
    At a conceptual level, unsupervised learning resembles human learning and the
    development of common sense much more closely than supervised and reinforcement
    learning, which we''ll cover in the next chapter. It is also called **predictive
    learning** because it aims to discover structure and regularities from data so
    that it can predict missing inputs, that is, fill in the blanks from the observed
    parts.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**无监督学习**解决了实际的机器学习挑战，例如有限标记数据的可用性和维度诅咒，这要求从具有许多特征的复杂现实数据中成功学习需要指数级增加的样本。在概念上，无监督学习更类似于人类学习和常识的发展，而不是监督学习和强化学习，我们将在下一章中讨论。它也被称为**预测学习**，因为它旨在从数据中发现结构和规律，以便可以预测缺失的输入，即从观察到的部分填补空白。'
- en: 'An **autoencode**r is a **neural network** (**NN**) trained to reproduce the
    input while learning a new representation of the data, encoded by the parameters
    of a hidden layer. Autoencoders have long been used for nonlinear dimensionality
    reduction and manifold learning (see *Chapter 13*, *Data-Driven Risk Factors and
    Asset Allocation with Unsupervised Learning*). A variety of designs leverage the
    feedforward, convolutional, and recurrent network architectures we covered in
    the last three chapters. We will see how autoencoders can underpin a **trading
    strategy**: we will build a deep neural network that uses an autoencoder to extract
    risk factors and predict equity returns, conditioned on a range of equity attributes
    (Gu, Kelly, and Xiu 2020).'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**自动编码器**是一个经过训练的**神经网络**（**NN**），用于复制输入并学习数据的新表示，由隐藏层的参数编码。自动编码器长期以来一直用于非线性降维和流形学习（见*第13章*，*使用无监督学习进行数据驱动的风险因素和资产配置*）。各种设计利用了我们在最后三章中涵盖的前馈、卷积和循环网络架构。我们将看到自动编码器如何支撑**交易策略**：我们将构建一个深度神经网络，该网络使用自动编码器来提取风险因素并预测股票回报，条件是一系列股票属性（Gu、Kelly和Xiu
    2020）。'
- en: 'More specifically, in this chapter you will learn about:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，在本章中，您将学习：
- en: Which types of autoencoders are of practical use and how they work
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些类型的自动编码器是实用的，以及它们是如何工作的
- en: Building and training autoencoders using Python
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python构建和训练自动编码器
- en: Using autoencoders to extract data-driven risk factors that take into account
    asset characteristics to predict returns
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用自动编码器提取数据驱动的风险因素，考虑资产特征以预测回报
- en: You can find the code samples for this chapter and links to additional resources
    in the corresponding directory of the GitHub repository. The notebooks include
    color versions of the images.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在GitHub存储库的相应目录中找到本章的代码示例和其他资源的链接。笔记本包括图像的彩色版本。
- en: Autoencoders for nonlinear feature extraction
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于非线性特征提取的自动编码器
- en: In *Chapter 17*, *Deep Learning for Trading*, we saw how neural networks succeed
    at supervised learning by extracting a hierarchical feature representation useful
    for the given task. **Convolutional neural networks** (**CNNs**), for example,
    learn and synthesize increasingly complex patterns from grid-like data, for example,
    to identify or detect objects in an image or to classify time series.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第17章*，*交易的深度学习*中，我们看到神经网络如何通过提取对给定任务有用的分层特征表示而成功进行监督学习。例如，**卷积神经网络**（**CNNs**）学习并合成来自类似网格的数据的越来越复杂的模式，例如，识别或检测图像中的对象或对时间序列进行分类。
- en: An autoencoder, in contrast, is a neural network designed exclusively to learn
    a **new representation** that encodes the input in a way that helps solve another
    task. To this end, the training forces the network to reproduce the input. Since
    autoencoders typically use the same data as input and output, they are also considered
    an instance of **self-supervised learning**. In the process, the parameters of
    a hidden layer *h* become the code that represents the input, similar to the word2vec
    model covered in *Chapter 16*, *Word Embeddings for Earnings Calls and SEC Filings*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，自动编码器是专门设计用于学习**编码输入**的神经网络，以帮助解决另一个任务。为此，训练迫使网络复制输入。由于自动编码器通常使用相同的数据作为输入和输出，因此它们也被认为是**自监督学习**的一个实例。在这个过程中，隐藏层*h*的参数成为代表输入的代码，类似于*第16章*中涵盖的word2vec模型，*用于收益电话和SEC文件的词嵌入*。
- en: 'More specifically, the network can be viewed as consisting of an encoder function
    *h=f(x)* that learns the hidden layer''s parameters from input *x*, and a decoder
    function g that learns to reconstruct the input from the encoding *h*. Rather
    than learning the identity function:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，网络可以被视为由一个编码器函数*h=f(x)*组成，该函数从输入*x*中学习隐藏层的参数，并且一个解码器函数*g*学习从编码*h*中重构输入。而不是学习身份函数：
- en: '![](img/B15439_20_001.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/B15439_20_001.png)
- en: which simply copies the input, autoencoders use **constraints** that force the
    hidden layer to **prioritize which aspects of the data to encod**e. The goal is
    to obtain a representation of practical value.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 与简单复制输入不同，自动编码器使用**约束**来迫使隐藏层**优先考虑数据的哪些方面进行编码**。目标是获得实用价值的表示。
- en: Autoencoders can also be viewed as a **special case of a feedforward neural
    network** (see *Chapter 17*, *Deep Learning for Trading*) and can be trained using
    the same techniques. Just as with other models, excess capacity will lead to overfitting,
    preventing the autoencoder from producing an informative encoding that generalizes
    beyond the training samples. See *Chapters 14* and *15* of Goodfellow, Bengio,
    and Courville (2016) for additional background.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器也可以被视为**前馈神经网络的特例**（见第17章《交易的深度学习》），并且可以使用相同的技术进行训练。与其他模型一样，过多的容量会导致过拟合，阻止自编码器产生超出训练样本的信息编码。有关更多背景信息，请参阅Goodfellow、Bengio和Courville（2016）的第14章和第15章。
- en: Generalizing linear dimensionality reduction
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推广线性降维
- en: 'A traditional use case includes dimensionality reduction, achieved by limiting
    the size of the hidden layer and thus creating a "bottleneck" so that it performs
    lossy compression. Such an autoencoder is called **undercomplete**, and the purpose
    is to learn the most salient properties of the data by minimizing a loss function
    *L* of the form:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的用例包括通过限制隐藏层的大小来实现降维，从而创建一个“瓶颈”，使其执行有损压缩。这样的自编码器被称为欠完备的，其目的是通过最小化形式为*L*的损失函数来学习数据的最显著特性：
- en: '![](img/B15439_20_002.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_002.png)'
- en: An example loss function that we will explore in the next section is simply
    the mean squared error evaluated on the pixel values of the input images and their
    reconstruction. We will also use this loss function to extract risk factors from
    time series of financial features when we build a conditional autoencoder for
    trading.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中探讨的一个示例损失函数简单地是对输入图像的像素值及其重构进行的均方误差评估。当我们构建用于交易的条件自编码器时，我们还将使用这个损失函数来从金融特征的时间序列中提取风险因素。
- en: Undercomplete autoencoders differ from linear dimensionality reduction methods
    like **principal component analysis** (**PCA**; see *Chapter 13*, *Data-Driven
    Risk Factors and Asset Allocation with Unsupervised Learning*) when they use **nonlinear
    activation functions**; otherwise, they learn the same subspace as PCA. They can
    thus be viewed as a nonlinear generalization of PCA capable of learning a wider
    range of encodings.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 欠完备自编码器与线性降维方法（如主成分分析（PCA）；见第13章《基于数据驱动的无监督学习的风险因素和资产配置》）不同，因为它们使用非线性激活函数；否则，它们学习与PCA相同的子空间。因此，它们可以被视为能够学习更广泛编码的PCA的非线性推广。
- en: '*Figure 20.1* illustrates the encoder-decoder logic of an undercomplete feedforward
    autoencoder with three hidden layers: the encoder and decoder have one hidden
    layer each plus a shared encoder output/decoder input layer containing the encoding.
    The three hidden layers use nonlinear activation functions, like **rectified linear
    units** (**ReLU**), *sigmoid*, or *tanh* (see *Chapter 17*, *Deep Learning for
    Trading*) and have fewer units than the input that the network aims to reconstruct.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20.1*说明了具有三个隐藏层的欠完备前馈自编码器的编码器-解码器逻辑：编码器和解码器各有一个隐藏层，以及一个包含编码的共享编码器输出/解码器输入层。三个隐藏层使用非线性激活函数，如修正线性单元（ReLU）、*sigmoid*或*tanh*（见第17章《交易的深度学习》），并且比网络旨在重构的输入单元更少。'
- en: '![](img/B15439_20_01.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_01.png)'
- en: 'Figure 20.1: Undercomplete encoder-decoder architecture'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.1：欠完备编码器-解码器架构
- en: Depending on the task, a simple autoencoder with a single encoder and decoder
    layer may be adequate. However, **deeper autoencoders** with additional layers
    can have several advantages, just as for other neural networks. These advantages
    include the ability to learn more complex encodings, achieve better compression,
    and do so with less computational effort and fewer training samples, subject to
    the perennial risk of overfitting.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 根据任务的不同，一个具有单个编码器和解码器层的简单自编码器可能是足够的。然而，具有额外层的**深度自编码器**可以具有几个优势，就像其他神经网络一样。这些优势包括学习更复杂的编码、实现更好的压缩，并且在更少的计算工作量和更少的训练样本的情况下实现，但也面临着过拟合的永恒风险。
- en: Convolutional autoencoders for image compression
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于图像压缩的卷积自编码器
- en: As discussed in *Chapter 18*, *CNNs for Financial Time Series and Satellite
    Images*, fully connected feedforward architectures are not well suited to capture
    local correlations typical to data with a grid-like structure. Instead, autoencoders
    can also use convolutional layers to learn a hierarchical feature representation.
    Convolutional autoencoders leverage convolutions and parameter sharing to learn
    hierarchical patterns and features irrespective of their location, translation,
    or changes in size.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如第18章《金融时间序列和卫星图像的CNN》中所讨论的，全连接的前馈架构不适合捕捉具有网格结构的数据的局部相关性。相反，自编码器也可以使用卷积层来学习分层特征表示。卷积自编码器利用卷积和参数共享来学习层次模式和特征，而不受其位置、平移或大小变化的影响。
- en: We will illustrate different implementations of convolutional autoencoders for
    image data below. Alternatively, convolutional autoencoders could be applied to
    multivariate time series data arranged in a grid-like format as illustrated in
    *Chapter 18*, *CNNs for Financial Time Series and Satellite Images*.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下面说明不同的卷积自编码器对图像数据的实现。另外，卷积自编码器也可以应用于以网格格式排列的多变量时间序列数据，就像第18章《金融时间序列和卫星图像的CNN》中所示。
- en: Managing overfitting with regularized autoencoders
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用正则化自编码器来管理过拟合
- en: The powerful capabilities of neural networks to represent complex functions
    require tight controls of the capacity of encoders and decoders to extract signals
    rather than noise so that the encoding is more useful for a downstream task. In
    other words, when it is too easy for the network to recreate the input, it fails
    to learn only the most interesting aspects of the data and improve the performance
    of a machine learning model that uses the encoding as inputs.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络表示复杂函数的强大能力要求对编码器和解码器的容量进行严格控制，以提取信号而不是噪音，使得编码对下游任务更有用。换句话说，当网络过于容易地重新创建输入时，它无法仅学习数据的最有趣的方面，并提高使用编码作为输入的机器学习模型的性能。
- en: 'Just as for other models with excessive capacity for the given task, **regularization**
    can help to address the **overfitting** challenge by constraining the autoencoder''s
    learning process and forcing it to produce a useful representation (see, for instance,
    *Chapter 7*, *Linear Models – From Risk Factors to Return Forecasts*, on regularization
    for linear models, and *Chapter 17*, *Deep Learning for Trading*, for neural networks).
    Ideally, we could precisely match the model''s capacity to the complexity of the
    distribution of the data. In practice, the optimal model often combines (limited)
    excess capacity with appropriate regularization. To this end, we add a sparsity
    penalty ![](img/B15439_20_003.png) that depends on the weights of the encoding
    layer *h* to the training objective:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 就像其他具有过多任务容量的模型一样，**正则化**可以通过约束自动编码器的学习过程并强制其产生有用的表示来帮助解决**过拟合**挑战（例如，参见*第7章*，*线性模型-从风险因素到收益预测*中关于线性模型的正则化，以及*第17章*，*交易的深度学习*，关于神经网络）。理想情况下，我们可以精确匹配模型的容量与数据分布的复杂性。实际上，最佳模型通常将（有限的）过剩容量与适当的正则化相结合。为此，我们将一个依赖于编码层*h*的权重的稀疏惩罚![](img/B15439_20_003.png)添加到训练目标中：
- en: '![](img/B15439_20_004.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_004.png)'
- en: A common approach that we explore later in this chapter is the use of **L1 regularization**,
    which adds a penalty to the loss function in the form of the sum of the absolute
    values of the weights. The L1 norm results in sparse encodings because it forces
    the values of parameters to zero if they do not capture independent variation
    in the data (see *Chapter 7*, *Linear Models – From Risk Factors to Return Forecasts*).
    As a result, even overcomplete autoencoders with hidden layers of a higher dimension
    than the input may be able to learn signal content.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章后面探讨的一种常见方法是使用**L1正则化**，它在损失函数中添加了一种惩罚，即权重的绝对值之和。L1范数会导致稀疏编码，因为它会强制参数的值为零，如果它们不能捕捉数据中的独立变化（参见*第7章*，*线性模型-从风险因素到收益预测*）。因此，即使隐藏层的超完备自动编码器的维度高于输入，它也可能能够学习信号内容。
- en: Fixing corrupted data with denoising autoencoders
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用去噪自动编码器修复损坏的数据
- en: 'The autoencoders we have discussed so far are designed to reproduce the input
    despite capacity constraints. An alternative approach trains autoencoders with
    corrupted inputs ![](img/B15439_20_005.png) to output the desired, original data
    points. In this case, the autoencoder minimizes a loss *L*:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们讨论的自动编码器旨在在容量约束的情况下重现输入。另一种方法是训练自动编码器使用损坏的输入！[](img/B15439_20_005.png)来输出所需的原始数据点。在这种情况下，自动编码器最小化损失*L*：
- en: '![](img/B15439_20_006.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_006.png)'
- en: Corrupted inputs are a different way of preventing the network from learning
    the identity function and rather extracting the signal or salient features from
    the data. Denoising autoencoders have been shown to learn the data generating
    process of the original data and have become popular in generative modeling where
    the goal is **to learn the probability distribution** that gives rise to the input
    (Vincent et al., 2008).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 损坏的输入是防止网络学习身份函数的另一种方式，而是从数据中提取信号或显著特征。去噪自动编码器已被证明能够学习原始数据的生成过程，并在生成建模中变得流行，其目标是**学习产生输入的概率分布**（Vincent等人，2008）。
- en: Seq2seq autoencoders for time series features
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于时间序列特征的Seq2seq自动编码器
- en: '**Recurrent neural networks** (**RNNs**) have been developed for sequential
    data characterized by longitudinal dependencies between data points, potentially
    over long ranges (*Chapter 19*, *RNNs for Multivariate Time Series and Sentiment
    Analysis*). Similarly, sequence-to-sequence (seq2seq) autoencoders aim to learn
    representations attuned to the nature of data generated in sequence (Srivastava,
    Mansimov, and Salakhutdinov, 2016).'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**循环神经网络**（**RNNs**）已经针对具有数据点之间纵向依赖性的序列数据进行了开发，可能在长距离范围内（*第19章*，*多变量时间序列和情感分析的RNNs*）。同样，序列到序列（seq2seq）自动编码器旨在学习与序列生成的数据性质相适应的表示（Srivastava，Mansimov和Salakhutdinov，2016）。'
- en: Seq2seq autoencoders are based on RNN components like **long short-term memory**
    (**LSTM**) or gated recurrent unit. They learn a representation of sequential
    data and have been successfully applied to video, text, audio, and time series
    data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Seq2seq自动编码器基于RNN组件，如**长短期记忆**（**LSTM**）或门控循环单元。它们学习了顺序数据的表示，并已成功应用于视频、文本、音频和时间序列数据。
- en: 'As mentioned in the last chapter, encoder-decoder architectures allow RNNs
    to process input and output sequences with variable length. These architectures
    underpin many advances in complex sequence prediction tasks, like speech recognition
    and text translation, and are being increasingly applied to (financial) time series.
    At a high level, they work as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 正如上一章所述，编码器-解码器架构允许RNN处理具有可变长度的输入和输出序列。这些架构支撑了复杂序列预测任务的许多进展，例如语音识别和文本翻译，并且越来越多地应用于（金融）时间序列。在高层次上，它们的工作方式如下：
- en: The LSTM encoder processes the input sequence step by step to learn a hidden
    state.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LSTM编码器逐步处理输入序列以学习隐藏状态。
- en: This state becomes a learned representation of the sequence in the form of a fixed-length
    vector.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个状态成为了序列的学习表示，以固定长度的向量形式。
- en: The LSTM decoder receives this state as input and uses it to generate the output
    sequence.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LSTM解码器接收此状态作为输入，并使用它生成输出序列。
- en: See references linked on GitHub for examples on building sequence-to-sequence
    autoencoders to **compress time series data** and **detect anomalies** in time
    series to allow, for example, regulators to uncover potentially illegal trading
    activity.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 有关构建序列到序列自动编码器以**压缩时间序列数据**和**检测时间序列中的异常**的示例，请参见GitHub上的参考资料，以便监管机构可以发现潜在的非法交易活动。
- en: Generative modeling with variational autoencoders
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用变分自动编码器进行生成建模
- en: '**Variational autoencoders** (**VAE**) were developed more recently (Kingma
    and Welling, 2014) and focus on generative modeling. In contrast to a discriminative
    model that learns a predictor given data, a generative model aims to solve the
    more general problem of learning a joint probability distribution over all variables.
    If successful, it could simulate how the data is produced in the first place.
    Learning the data-generating process is very valuable: it reveals underlying causal
    relationships and supports semi-supervised learning to effectively generalize
    from a small labeled dataset to a large unlabeled one.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**变分自动编码器**（**VAE**）是最近开发的（Kingma和Welling，2014），专注于生成建模。与给定数据学习预测器的判别模型相反，生成模型旨在解决学习所有变量的联合概率分布的更一般问题。如果成功，它可以模拟数据最初是如何产生的。学习数据生成过程非常有价值：它揭示了潜在的因果关系，并支持半监督学习，从小标记数据集有效地推广到大型未标记数据集。'
- en: More specifically, VAEs are designed to learn the latent (meaning *unobserved*)
    variables of the model responsible for the input data. Note that we encountered
    latent variables in *Chapter 15*, *Topic Modeling – Summarizing Financial News*,
    and *Chapter 16*, *Word Embeddings for Earnings Calls and SEC Filings*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，VAE旨在学习模型负责输入数据的潜在（意味着*未观察到*）变量。请注意，我们在*第15章*，*主题建模-总结金融新闻*和*第16章*，*用于盈利电话和SEC备案的词嵌入*中遇到了潜在变量。
- en: Just like the autoencoders discussed so far, VAEs do not let the network learn
    arbitrary functions as long as it faithfully reproduces the input. Instead, they
    aim to learn the parameters of a probability distribution that generates the input
    data.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 就像迄今为止讨论的自动编码器一样，VAE不允许网络学习任意函数，只要它忠实地复制输入。相反，它们旨在学习生成输入数据的概率分布的参数。
- en: In other words, VAEs are generative models because, if successful, you can generate
    new data points by sampling from the distribution learned by the VAE.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，VAE是生成模型，因为如果成功，您可以通过从VAE学习的分布中进行采样来生成新的数据点。
- en: The operation of a VAE is more complex than the autoencoders discussed so far
    because it involves stochastic backpropagation, that is, taking derivatives of
    stochastic variables, and the details are beyond the scope of this book. They
    are able to learn high-capacity input encodings without regularization that are
    useful because the models aim to maximize the probability of the training data
    rather than to reproduce the input. For a detailed introduction, see Kingma and
    Welling (2019).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，VAE的操作比讨论过的自动编码器更复杂，因为它涉及随机反向传播，即对随机变量的导数，细节超出了本书的范围。它们能够学习高容量的输入编码，而无需正则化，这是有用的，因为这些模型旨在最大化训练数据的概率，而不是复制输入。有关详细介绍，请参见Kingma和Welling（2019）。
- en: The `variational_autoencoder.ipynb` notebook includes a sample VAE implementation
    applied to the Fashion MNIST data, adapted from a Keras tutorial by Francois Chollet
    to work with TensorFlow 2\. The resources linked on GitHub contain a VAE tutorial
    with references to PyTorch and TensorFlow 2 implementations and many additional
    references. See Wang et al. (2019) for an application that combines a VAE with
    an RNN using LSTM and outperforms various benchmark models in futures markets.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`variational_autoencoder.ipynb`笔记本包括应用于时尚MNIST数据的样本VAE实现，改编自Francois Chollet的Keras教程，以便与TensorFlow
    2一起使用。GitHub上链接的资源包含了一个VAE教程，其中包含了对PyTorch和TensorFlow 2实现的参考以及许多其他参考资料。有关将VAE与使用LSTM的RNN相结合并在期货市场中胜过各种基准模型的应用，请参见Wang等人（2019）。'
- en: Implementing autoencoders with TensorFlow 2
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TensorFlow 2实现自动编码器
- en: In this section, we'll illustrate how to implement several of the autoencoder
    models introduced in the previous section using the Keras interface of TensorFlow
    2\. We'll first load and prepare an image dataset that we'll use throughout this
    section. We will use images instead of financial time series because it makes
    it easier to visualize the results of the encoding process. The next section shows
    how to use an autoencoder with financial data as part of a more complex architecture
    that can serve as the basis for a trading strategy.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将说明如何使用TensorFlow 2的Keras接口实现前一节介绍的几种自动编码器模型。我们将首先加载和准备一个图像数据集，我们将在本节中使用它。我们将使用图像而不是金融时间序列，因为这样更容易可视化编码过程的结果。下一节将展示如何在更复杂的架构中使用自动编码器与金融数据，这可以作为交易策略的基础。
- en: After preparing the data, we'll proceed to build autoencoders using deep feedforward
    nets, sparsity constraints, and convolutions and apply the latter to denoise images.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 准备数据后，我们将继续使用深度前馈网络、稀疏约束和卷积构建自动编码器，并将后者应用于去噪图像。
- en: How to prepare the data
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何准备数据
- en: For illustration, we'll use the Fashion MNIST dataset, a modern drop-in replacement
    for the classic MNIST handwritten digit dataset popularized by Lecun et al. (1998)
    with LeNet. We also relied on this dataset in *Chapter 13*, *Data-Driven Risk
    Factors and Asset Allocation with Unsupervised Learning*, on unsupervised learning.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，我们将使用时尚MNIST数据集，这是Lecun等人（1998）与LeNet一起推广的经典MNIST手写数字数据集的现代替代品。我们在*第13章*，*使用无监督学习进行数据驱动的风险因素和资产配置*中也依赖于这个数据集。
- en: 'Keras makes it easy to access the 60,000 training and 10,000 test grayscale
    samples with a resolution of 28 × 28 pixels:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Keras使得可以轻松访问分辨率为28×28像素的60,000个训练和10,000个测试灰度样本：
- en: '[PRE0]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The data contains clothing items from 10 classes. *Figure 20.2* plots a sample
    image for each class:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 数据包含来自10个类别的服装。*图20.2*绘制了每个类别的一个样本图像：
- en: '![](img/B15439_20_02.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_02.png)'
- en: 'Figure 20.2: Fashion MNIST sample images'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.2：Fashion MNIST样本图像
- en: 'We reshape the data so that each image is represented by a flat one-dimensional
    pixel vector with 28 × 28 = 784 elements normalized to the range [0, 1]:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重新塑造数据，使每个图像由一个扁平的一维像素向量表示，具有28×28 = 784个元素，归一化到范围[0, 1]：
- en: '[PRE1]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: One-layer feedforward autoencoder
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单层前馈自动编码器
- en: We start with a vanilla feedforward autoencoder with a single hidden layer to
    illustrate the general design approach using the Functional Keras API and establish
    a performance baseline.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从一个具有单个隐藏层的普通前馈自动编码器开始，以说明使用Functional Keras API的一般设计方法，并建立性能基线。
- en: 'The first step is a placeholder for the flattened image vectors with 784 elements:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是一个具有784个元素的扁平化图像向量的占位符：
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The encoder part of the model consists of a fully connected layer that learns
    the new, compressed representation of the input. We use 32 units for a compression
    ratio of 24.5:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的编码器部分由一个全连接层组成，学习输入的新的压缩表示。我们使用32个单元来实现24.5的压缩比：
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The decoding part reconstructs the compressed data to its original size in
    a single step:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 解码部分将压缩的数据重构为原始大小的数据：
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We instantiate the `Model` class with the chained input and output elements
    that implicitly define the computational graph as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用链式输入和输出元素实例化`Model`类，隐式地定义了计算图如下：
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The encoder-decoder computation thus defined uses almost 51,000 parameters:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，所定义的编码器-解码器计算使用了近51,000个参数：
- en: '[PRE6]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The Functional API allows us to use parts of the model's chain as separate encoder
    and decoder models that use the autoencoder's parameters learned during training.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Functional API允许我们将模型链的部分用作单独的编码器和解码器模型，这些模型使用训练期间学习的自动编码器参数。
- en: Defining the encoder
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义编码器
- en: 'The encoder just uses the input and hidden layer with about half the total
    parameters:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器只使用输入和隐藏层，总参数的一半左右：
- en: '[PRE7]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We will see shortly that, once we train the autoencoder, we can use the encoder
    to compress the data.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很快将看到，一旦训练自动编码器，我们就可以使用编码器来压缩数据。
- en: Defining the decoder
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义解码器
- en: 'The decoder consists of the last autoencoder layer, fed by a placeholder for
    the encoded data:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器由最后的自动编码器层组成，由编码数据的占位符提供：
- en: '[PRE8]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Training the model
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练模型
- en: 'We compile the model to use the Adam optimizer (see *Chapter 17*, *Deep Learning
    for Trading*) to minimize the mean squared error between the input data and the
    reproduction achieved by the autoencoder. To ensure that the autoencoder learns
    to reproduce the input, we train the model using the same input and output data:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们编译模型以使用Adam优化器（参见*第17章*，*用于交易的深度学习*）来最小化自动编码器实现的输入数据和重现之间的均方误差。为了确保自动编码器学习重现输入，我们使用相同的输入和输出数据来训练模型：
- en: '[PRE9]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Evaluating the results
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估结果
- en: 'Training stops after some 20 epochs with a test RMSE of 0.1121:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 训练在大约20个周期后停止，测试RMSE为0.1121：
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To encode data, we use the encoder we just defined like so:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了编码数据，我们使用刚刚定义的编码器：
- en: '[PRE11]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The decoder takes the compressed data and reproduces the output according to
    the autoencoder training results:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器接收压缩的数据，并根据自动编码器的训练结果重现输出：
- en: '[PRE12]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '*Figure 20.3* shows 10 original images and their reconstruction by the autoencoder
    and illustrates the loss after compression:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20.3*显示了10个原始图像及其自动编码器重建，并说明了压缩后的损失：'
- en: '![](img/B15439_20_03.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_03.png)'
- en: 'Figure 20.3: Sample Fashion MNIST images, original and reconstructed'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.3：Fashion MNIST样本图像，原始和重建
- en: Feedforward autoencoder with sparsity constraints
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 具有稀疏约束的前馈自动编码器
- en: 'The addition of regularization is fairly straightforward. We can apply it to
    the dense encoder layer using Keras'' `activity_regularizer` as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 添加正则化非常简单。我们可以使用Keras的`activity_regularizer`将其应用于密集编码器层，如下所示：
- en: '[PRE13]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The input and decoding layers remain unchanged. In this example with compression
    of factor 24.5, regularization negatively affects performance with a test RMSE
    of 0.1229\.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 输入和解码层保持不变。在这个例子中，压缩因子为24.5，正则化对性能产生负面影响，测试RMSE为0.1229。
- en: Deep feedforward autoencoder
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度前馈自动编码器
- en: 'To illustrate the benefit of adding depth to the autoencoder, we will build
    a three-layer feedforward model that successively compresses the input from 784
    to 128, 64, and 32 units, respectively:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明向自动编码器添加深度的好处，我们将构建一个三层前馈模型，依次将输入从784压缩到128、64和32个单元：
- en: '[PRE14]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The resulting model has over 222,000 parameters, more than four times the capacity
    of the previous single-layer model:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 结果模型有超过222,000个参数，是前一个单层模型容量的四倍多：
- en: '[PRE15]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Training stops after 45 epochs and results in a 14 percent reduction of the
    test RMSE to 0.097\. Due to the low resolution, it is difficult to visually note
    the better reconstruction.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 训练在45个周期后停止，导致测试RMSE减少了14％，达到0.097。由于低分辨率，很难在视觉上注意到更好的重建。
- en: Visualizing the encoding
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可视化编码
- en: We can use the manifold learning technique **t-distributed Stochastic Neighbor
    Embedding** (**t-SNE**; see *Chapter 13*, *Data-Driven Risk Factors and Asset
    Allocation with Unsupervised Learning*) to visualize and assess the quality of
    the encoding learned by the autoencoder's hidden layer.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用流形学习技术**t-分布随机邻居嵌入**（**t-SNE**；参见*第13章*，*使用无监督学习进行数据驱动的风险因子和资产配置*）来可视化和评估自动编码器隐藏层学习到的编码的质量。
- en: 'If the encoding is successful in capturing the salient features of the data,
    then the compressed representation of the data should still reveal a structure
    aligned with the 10 classes that differentiate the observations. We use the output
    of the deep encoder we just trained to obtain the 32-dimensional representation
    of the test set:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如果编码成功地捕获了数据的显著特征，那么数据的压缩表示仍然应该显示出与区分观察结果的10个类别对齐的结构。我们使用刚刚训练的深度编码器的输出来获得测试集的32维表示：
- en: '[PRE16]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '*Figure 20.4* shows that the 10 classes are well separated, suggesting that
    the encoding is useful as a lower-dimensional representation that preserves the
    key characteristics of the data (see the `variational_autoencoder.ipynb` notebook
    for a color version):'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20.4*显示了10个类别被很好地分离，表明编码作为保留数据关键特征的低维表示是有用的（请参阅`variational_autoencoder.ipynb`笔记本以查看彩色版本）：'
- en: '![](img/B15439_20_04.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_04.png)'
- en: 'Figure 20.4: t-SNE visualization of the Fashion MNIST autoencoder embedding'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.4：Fashion MNIST自编码器嵌入的t-SNE可视化
- en: Convolutional autoencoders
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷积自编码器
- en: The insights from *Chapter 18*, *CNNs for Financial Time Series and Satellite
    Images*, on CNNs suggest we incorporate convolutional layers into the autoencoder
    to extract information characteristic of the grid-like structure of image data.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '*第18章*《金融时间序列和卫星图像的CNN》中关于CNN的见解表明，我们应该将卷积层纳入自编码器中，以提取图像数据的网格结构特征。'
- en: 'We define a three-layer encoder that uses 2D convolutions with 32, 16, and
    8 filters, respectively, ReLU activations, and `''same''` padding to maintain
    the input size. The resulting encoding size at the third layer is ![](img/B15439_20_007.png),
    higher than for the previous examples:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个三层编码器，使用2D卷积，分别具有32、16和8个滤波器，ReLU激活，并使用“same”填充以保持输入大小。第三层的结果编码大小为![](img/B15439_20_007.png)，比先前的示例要高：
- en: '[PRE17]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We also define a matching decoder that reverses the number of filters and uses
    2D upsampling instead of max pooling to reverse the reduction of the filter sizes.
    The three-layer autoencoder has 12,785 parameters, a little more than 5 percent
    of the capacity of the deep autoencoder.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还定义了一个匹配的解码器，它逆转了滤波器数量，并使用2D上采样而不是最大池化来逆转滤波器大小的减小。这个三层自编码器有12,785个参数，略多于深度自编码器的容量的5％。
- en: Training stops after 67 epochs and results in a further 9 percent reduction
    in the test RMSE, due to a combination of the ability of convolutional filters
    to learn more efficiently from image data and the larger encoding size.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 训练在67个时期后停止，并导致测试RMSE进一步减少了9％，这是由于卷积滤波器能够更有效地从图像数据中学习以及更大的编码大小的结合。
- en: Denoising autoencoders
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 去噪自编码器
- en: 'The application of an autoencoder to a denoising task only affects the training
    stage. In this example, we add noise from a standard normal distribution to the
    Fashion MNIST data while maintaining the pixel values in the range [0, 1] as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 将自编码器应用于去噪任务只会影响训练阶段。在这个例子中，我们向Fashion MNIST数据添加来自标准正态分布的噪声，同时保持像素值在[0, 1]范围内：
- en: '[PRE18]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We then proceed to train the convolutional autoencoder on noisy inputs, the
    objective being to learn how to generate the uncorrupted originals:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们继续对嘈杂的输入训练卷积自编码器，目标是学习如何生成未经污染的原始图像：
- en: '[PRE19]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The test RMSE after 60 epochs is 0.0931, unsurprisingly higher than before.
    *Figure 20.5* shows, from top to bottom, the original images as well as the noisy
    and denoised versions. It illustrates that the autoencoder is successful in producing
    compressed encodings from the noisy images that are quite similar to those produced
    from the original images:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 60个时期后的测试RMSE为0.0931，毫不奇怪地高于之前。*图20.5*从上到下显示了原始图像以及噪声和去噪版本。它说明自编码器成功地从嘈杂的图像中产生了与原始图像非常相似的压缩编码：
- en: '![](img/B15439_20_05.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_05.png)'
- en: 'Figure 20.5: Denoising input and output examples'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.5：去噪输入和输出示例
- en: A conditional autoencoder for trading
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交易的条件自编码器
- en: Recent research by Gu, Kelly, and Xiu (GKX, 2019) developed an asset pricing
    model based on the exposure of securities to risk factors. It builds on the concept
    of **data-driven risk factors** that we discussed in *Chapter 13*, *Data-Driven
    Risk Factors and Asset Allocation with Unsupervised Learning*, when introducing
    PCA as well as the risk factor models covered in *Chapter 4*, *Financial Feature
    Engineering – How to Research Alpha Factors*. They aim to show that the asset
    characteristics used by factor models to capture the systematic drivers of "anomalies"
    are just proxies for the time-varying exposure to risk factors that cannot be
    directly measured. In this context, anomalies are returns in excess of those explained
    by the exposure to aggregate market risk (see the discussion of the capital asset
    pricing model in *Chapter 5*, *Portfolio Optimization and Performance Evaluation*).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Gu、Kelly和Xiu（GKX，2019）最近的研究开发了一种基于证券对风险因素的敞口的资产定价模型。它建立在我们在*第13章*《数据驱动的风险因素和无监督学习的资产配置》中讨论的**数据驱动风险因素**的概念上，当时我们介绍了PCA以及*第4章*《金融特征工程-如何研究Alpha因子》中涵盖的风险因素模型。他们的目标是表明因子模型用于捕捉“异常”系统驱动因素的资产特征只是无法直接测量的风险因素的暂时替代品。在这种情况下，异常是超过由暴露于总体市场风险所解释的回报（请参阅*第5章*《投资组合优化和绩效评估》中对资本资产定价模型的讨论）。
- en: 'The **Fama-French factor models** discussed in *Chapter 4* and *Chapter 7*
    explain returns by specifying risk factors like firm size based on empirical observations
    of differences in average stock returns beyond those due to aggregate market risk.
    Given such **specific risk factors**, these models are able to measure the reward
    an investor receives for taking on factor risk using portfolios designed accordingly:
    sort stocks by size, buy the smallest quintile, sell the largest quintile, and
    compute the return. The observed risk factor return then allows linear regression
    to estimate the sensitivity of assets to these factors (called **factor loadings**),
    which in turn helps to predict the returns of (many) assets based on forecasts
    of (far fewer) factor returns.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第4章*和*第7章*中讨论的**Fama-French因子模型**通过指定风险因素（如基于对股票平均回报的经验观察而得出的公司规模）来解释回报。鉴于这样的**特定风险因素**，这些模型能够通过相应设计的投资组合来衡量投资者承担因子风险所获得的回报：按规模对股票进行排序，购买最小的五分之一，出售最大的五分之一，并计算回报。观察到的风险因素回报然后允许线性回归来估计资产对这些因素的敏感性（称为**因子负载**），从而有助于根据（远少于）因子回报的预测来预测（许多）资产的回报。
- en: In contrast, GKX treat **risk factors as latent, or non-observable**, drivers
    of covariance among a number of assets large enough to prevent investors from
    avoiding exposure through diversification. Therefore, investors require a reward
    that adjusts like any price to achieve equilibrium, providing in turn an economic
    rationale for return differences that are no longer anomalous. In this view, risk
    factors are purely statistical in nature while the underlying economic forces
    can be of arbitrary and varying origin.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，GKX将**风险因素视为潜在的或不可观测的**，是足够大以至于投资者无法通过分散化来避免暴露的多个资产之间的协方差的驱动因素。因此，投资者需要一种调整奖励，就像任何价格一样来实现均衡，从而提供了一个经济上的理由，解释那些不再是异常的回报差异。在这种观点下，风险因素纯粹是统计性质的，而潜在的经济力量可以是任意的和多样化的。
- en: In another recent paper (Kelly, Pruitt, and Su, 2019), Kelly—who teaches finance
    at Yale, works with AQR, and is one of the pioneers in applying ML to trading—and
    his coauthors developed a linear model dubbed **Instrumented Principal Component
    Analysis** (IPCA) to **estimate latent risk factors and the assets' factor loadings
    from data**. IPCA extends PCA to include asset characteristics as covariates and
    produce time-varying factor loadings. (See *Chapter 13*, *Data-Driven Risk Factors
    and Asset Allocation with Unsupervised Learning*, for coverage of PCA.) By conditioning
    asset exposure to factors on observable asset characteristics, IPCA aims to answer
    whether there is a set of common latent risk factors that explain an observed
    anomaly rather than whether there is a specific observable factor that can do
    so.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一篇最近的论文中（Kelly、Pruitt和Su，2019），Kelly——他在耶鲁大学教授金融学，与AQR合作，并且是将机器学习应用于交易的先驱之一——和他的合著者开发了一个被称为**Instrumented
    Principal Component Analysis**（IPCA）的线性模型，用于**估计潜在风险因素和资产的因子载荷**。IPCA将PCA扩展到包括资产特征作为协变量，并产生时间变化的因子载荷。（有关PCA的覆盖，请参见*第13章*，*使用无监督学习进行数据驱动的风险因素和资产配置*。）通过将资产暴露于可观察的资产特征上的因素，IPCA旨在回答是否存在一组共同的潜在风险因素来解释观察到的异常，而不是是否存在一个特定的可观察因素可以这样做。
- en: GKX creates a **conditional autoencoder architecture** to reflect the nonlinear
    nature of return dynamics ignored by the linear Fama-French models and the IPCA
    approach. The result is a deep neural network that simultaneously learns the premia
    on a given number of unobservable factors using an autoencoder, and the factor
    loadings for a large universe of equities based on a broad range of time-varying
    asset characteristics using a feedforward network. The model succeeds in explaining
    and predicting asset returns. It demonstrates a relationship that is both statistically
    and economically significant, yielding an attractive Sharpe ratio when translated
    into a long-short decile spread strategy similar to the examples we have used
    throughout this book.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: GKX创建了一个**条件自动编码器架构**，以反映线性Fama-French模型和IPCA方法所忽略的回报动态的非线性特性。结果是一个深度神经网络，它同时使用自动编码器学习给定数量的不可观测因素的溢价，以及使用前馈网络学习大范围的时间变化的资产特征的因子载荷。该模型成功地解释和预测了资产回报。它展示了一种在统计上和经济上都显著的关系，将其转化为长-短十分位点差策略后，产生了一个有吸引力的夏普比率，类似于我们在本书中使用的示例。
- en: In this section, we'll create a simplified version of this model to demonstrate
    how you can **leverage autoencoders to generate tradeable signals**. To this end,
    we'll build a new dataset of close to 4,000 US stocks over the 1990-2019 period
    using yfinance, because it provides some additional information that facilitates
    the computation of the asset characteristics. We'll take a few shortcuts, such
    as using fewer assets and only the most important characteristics. We'll also
    omit some implementation details to simplify the exposition. We'll highlight the
    most important differences so that you can enhance the model accordingly.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将创建这个模型的简化版本，以演示如何**利用自动编码器生成可交易的信号**。为此，我们将使用yfinance在1990年至2019年期间构建一个接近4000只美国股票的新数据集，因为它提供了一些额外的信息，有助于计算资产特征。我们将采取一些捷径，比如使用更少的资产和只有最重要的特征。我们还将省略一些实施细节以简化表述。我们将强调最重要的差异，以便您可以相应地增强模型。
- en: We'll first show how to prepare the data before we explain, build, and train
    the model and evaluate its predictive performance. Please see the above references
    for additional background on the theory and implementation.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先展示如何准备数据，然后解释、构建和训练模型，并评估其预测性能。请参考上述参考文献以获取有关理论和实施的更多背景信息。
- en: Sourcing stock prices and metadata information
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 股票价格和元数据信息的来源
- en: The GKX reference implementation uses stock price and firm characteristic data
    for over 30,000 US equities from the Center for Research in Security Prices (CRSP)
    from 1957-2016 at a monthly frequency. It computes 94 metrics that include a broad
    range of asset attributes suggested as predictive of returns in previous academic
    research and listed in Green, Hand, and Zhang (2017), who set out to verify these
    claims.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: GKX参考实现使用了来自CRSP（Center for Research in Security Prices）的超过30,000只美国股票的股价和公司特征数据，时间跨度为1957年至2016年，频率为每月一次。它计算了94个指标，其中包括了前期学术研究中被认为是预测回报的广泛资产属性，这些属性在Green、Hand和Zhang（2017）中列出并进行了验证。
- en: 'Since we do not have access to the high-quality but costly CRSP data, we leverage
    yfinance (see *Chapter 2*, *Market and Fundamental Data – Sources and Techniques*)
    to download price and metadata from Yahoo Finance. There are downsides to choosing
    free data, including:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们无法获取高质量但昂贵的CRSP数据，我们利用yfinance（参见*第2章*，*市场和基本数据-来源和技术*）从Yahoo Finance下载价格和元数据。选择免费数据有一些缺点，包括：
- en: The lack of quality control regarding adjustments
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于调整的质量控制的缺乏
- en: Survivorship bias because we cannot get data for stocks that are no longer listed
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 幸存者偏差，因为我们无法获取不再上市的股票的数据
- en: A smaller scope in terms of both the number of equities and the length of their
    history
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在股票数量和历史长度方面范围较小
- en: The `build_us_stock_dataset.ipynb` notebook contains the relevant code examples
    for this section.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '`build_us_stock_dataset.ipynb`笔记本包含本节的相关代码示例。'
- en: 'To obtain the data, we get a list of the 8,882 currently traded symbols from
    NASDAQ using pandas-datareader (see *Chapter 2*, *Market and Fundamental Data
    – Sources and Techniques*):'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得数据，我们使用pandas-datareader从纳斯达克获取了8,882个当前交易的符号列表（见*第2章*，*市场和基本数据-来源和技术*）：
- en: '[PRE20]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We remove ETFs and create yfinance `Ticker()` objects for the remainder:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们删除ETF，并为剩余的资产创建yfinance `Ticker()`对象：
- en: '[PRE21]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Each ticker''s `.info` attribute contains data points scraped from Yahoo Finance,
    ranging from the outstanding number of shares and other fundamentals to the latest
    market capitalization; coverage varies by security:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 每个股票的`.info`属性包含从Yahoo Finance抓取的数据点，从未偿还的股份数到最新的市值等基本面数据；安全性的覆盖范围因股票而异：
- en: '[PRE22]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: For the tickers with metadata, we download both adjusted and unadjusted prices,
    the latter including corporate actions like stock splits and dividend payments
    that we could use to create a Zipline bundle for strategy backtesting (see *Chapter
    8*, *The ML4T Workflow – From Model to Strategy Backtesting*).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有元数据的股票代码，我们下载调整后和未调整的价格，后者包括股票拆分和股利支付等公司行为，我们可以使用这些数据创建Zipline捆绑包进行策略回测（见*第8章*，*ML4T工作流程-从模型到策略回测*）。
- en: 'We get adjusted OHLCV data on 4,314 stocks as follows:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按以下方式获得4,314只股票的调整后的OHLCV数据：
- en: '[PRE23]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Absent any quality control regarding the underlying price data and the adjustments
    for stock splits, we remove equities with suspicious values such as daily returns
    above 100 percent or below -100 percent:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有关于基础价格数据和股票拆分调整的任何质量控制的情况下，我们删除了具有可疑值的股票，例如日回报超过100％或低于-100％的股票：
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This removes around 10 percent of the tickers, leaving us with close to 3,900
    assets for the 1990-2019 period.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这将删除大约10％的股票代码，使我们在1990-2019年期间拥有接近3,900个资产。
- en: Computing predictive asset characteristics
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算预测资产特征
- en: 'GKX tested 94 asset attributes based on Green et al. (2017) and identified
    the 20 most influential metrics while asserting that feature importance drops
    off quickly thereafter. The top 20 stock characteristics fall into three categories,
    namely:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: GKX根据Green等人（2017年）测试了94种资产属性，并确定了最有影响力的20种指标，同时断言特征重要性在此之后迅速下降。前20种股票特征分为三类，即：
- en: '**Price trend**, including (industry) momentum, short- and long-term reversal,
    or the recent maximum return'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**价格趋势**，包括（行业）动量，短期和长期逆转，或最近的最大回报'
- en: '**Liquidity,** such as turnover, dollar volume, or market capitalization'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流动性**，例如换手率，交易额或市值'
- en: '**Risk measures**, for instance, total and idiosyncratic return volatility
    or market beta'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**风险度量**，例如总体和特异回报波动性或市场贝塔'
- en: Of these 20, we limit the analysis to 16 for which we have or can approximate
    the relevant inputs. The `conditional_autoencoder_for_trading_data.ipynb` notebook
    demonstrates how to calculate the relevant metrics. We highlight a few examples
    in this section; see also the *Appendix*, *Alpha Factor Library*.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 其中16种特征中，我们限制分析为16种，其中我们有或可以近似得到相关输入。`conditional_autoencoder_for_trading_data.ipynb`笔记本演示了如何计算相关指标。我们在本节中突出显示了一些示例；另请参见*附录*，*Alpha因子库*。
- en: 'Some metrics require information like sector, market cap, and outstanding shares,
    so we limit our stock price dataset to the securities with relevant metadata:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 一些指标需要诸如行业、市值和未偿还股份等信息，因此我们将我们的股价数据集限制为具有相关元数据的证券：
- en: '[PRE25]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We run our analysis at a weekly instead of monthly return frequency to compensate
    for the 50 percent shorter time period and around 80 percent lower number of stocks.
    We obtain weekly returns as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以每周的频率而不是每月的频率运行我们的分析，以补偿时间段缩短了50％，股票数量减少了约80％。我们按以下方式获得每周回报：
- en: '[PRE26]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Most metrics are fairly straightforward to compute. **Stock momentum**, the
    11-month cumulative stock returns ending 1 month before the current date, can
    be derived as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数指标都很容易计算。**股票动量**，即截至当前日期前1个月的11个月累积股票回报，可以如下推导：
- en: '[PRE27]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The **Amihud Illiquidity** measure is the ratio of a stock''s absolute returns
    relative to its dollar volume, measured as a rolling 21-day average:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amihud流动性**指标是股票绝对回报与其交易额的比率，以滚动21天平均值表示：'
- en: '[PRE28]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '**Idiosyncratic volatility** is measured as the standard deviation of a regression
    of residuals of weekly returns on the returns of equally weighted market index
    returns for the prior three years. We compute this computationally intensive metric
    using `statsmodels`:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**特异波动性**是指作为标准差的股票周回报的残差回归的标准差，其输入为过去三年的等权市场指数回报。我们使用`statsmodels`计算这个计算密集型的指标：'
- en: '[PRE29]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'For the **market beta**, we can use statsmodels'' `RollingOLS` class with the
    weekly asset returns as outcome and the equal-weighted index as input:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 对于**市场贝塔**，我们可以使用statsmodels的`RollingOLS`类，其中每周资产回报作为结果，等权重指数作为输入：
- en: '[PRE30]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We end up with around 3 million observations on 16 metrics for some 3,800 securities
    over the 1990-2019 period. *Figure 20.6* displays a histogram of the number of
    stock returns per week (the left panel) and boxplots outlining the distribution
    of the number of observations for each characteristic:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在1990-2019年期间，我们得到了大约3,800种证券的大约300万次观察结果，涵盖了16种指标。*图20.6*显示了每周股票回报次数的直方图（左侧面板）和每个特征的观察次数分布的箱线图：
- en: '![](img/B15439_20_06.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_06.png)'
- en: 'Figure 20.6: Number of tickers over time and per - stock characteristic'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.6：随时间和每个-股票特征的股票代码数量
- en: 'To limit the influence of outliers, we follow GKX and rank-normalize the characteristics
    to the [-1, 1] interval:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 为了限制异常值的影响，我们遵循GKX并对特征进行排名标准化，使其落入[-1, 1]区间：
- en: '[PRE31]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Since the neural network cannot handle missing data, we set missing values to
    -2, which lies outside the range for both weekly returns and the characteristics.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 由于神经网络无法处理缺失数据，我们将缺失值设置为-2，这超出了每周回报和特征的范围。
- en: The authors apply additional methods to avoid overweighting microcap stocks
    like market-value-weighted least-squares regression. They also adjust for data-snooping
    biases by factoring in conservative reporting lags for the characteristics.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 作者们应用了额外的方法来避免过度权衡微型股票，如基于市值加权的最小二乘回归。他们还通过考虑保守的报告滞后来调整数据窥探偏差。
- en: Creating the conditional autoencoder architecture
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建条件自动编码器架构
- en: The conditional autoencoder proposed by GKX allows for time-varying return distributions
    that take into account changing asset characteristics. To this end, the authors
    extend standard autoencoder architectures that we discussed in the first section
    of this chapter to allow for features to shape the encoding.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: GKX提出的条件自动编码器允许考虑到不断变化的资产特征的时间变化回报分布。为此，作者们扩展了我们在本章第一节中讨论的标准自动编码器架构，以允许特征来塑造编码。
- en: '*Figure 20.7* illustrates the architecture that models the outcome (asset returns,
    top) as a function of both asset characteristics (left input) and, again, individual
    asset returns (right input). The authors allow for asset returns to be individual
    stock returns or portfolios that are formed from the stocks in the sample based
    on the asset characteristics, similar to the Fama-French factor portfolios we
    discussed in *Chapter 4*, *Financial Feature Engineering – How to Research Alpha
    Factors*, and summarized in the introduction to this section (hence the dotted
    lines from stocks to portfolios in the lower-right box). We will use individual
    stock returns; see GKX for details on how and why to use portfolios instead.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20.7*说明了该架构模拟了结果（资产回报，顶部）作为资产特征（左输入）和个别资产回报（右输入）的函数。作者们允许资产回报是个别股票回报或者是基于资产特征从样本中形成的投资组合，类似于我们在*第4章*中讨论的Fama-French因子投资组合，并在本节介绍中总结（因此在右下角的方框中从股票到投资组合的虚线）。我们将使用个别股票回报；有关如何以及为什么使用投资组合，请参阅GKX获取详细信息。'
- en: '![](img/B15439_20_07.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_07.png)'
- en: 'Figure 20.7: Conditional autoencoder architecture designed by GKX'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.7：GKX设计的条件自动编码器架构
- en: The **feedforward neural network** on the left side of the conditional autoencoder
    models the *K* factor loadings (beta output) of *N* individual stocks as a function
    of their *P* characteristics (input). In our case, *N* is around 3,800 and *P*
    equals 16\. The authors experiment with up to three hidden layers with 32, 16,
    and 8 units, respectively, and find two layers to perform best. Due to the smaller
    number of characteristics, we only use a similar layer and find 8 units most effective.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 条件自动编码器左侧的**前馈神经网络**模拟了*N*个个别股票的*K*因子载荷（beta输出）作为它们*P*特征（输入）的函数。在我们的情况下，*N*大约为3,800，*P*等于16。作者们尝试了最多三个隐藏层，分别为32、16和8个单元，并发现两层效果最好。由于特征数量较少，我们只使用了一个类似的层，并发现8个单元最有效。
- en: The right side of this architecture is a traditional autoencoder when used with
    individual asset returns as inputs because it maps *N* asset returns onto themselves.
    The authors use it in this way to measure how well the derived factors explain
    contemporaneous returns. In addition, they use the autoencoder to predict future
    returns by using input returns from period *t*-1 with output returns from period
    t. We will focus on the use of the architecture for prediction, underlining that
    autoencoders are a special case of a feedforward neural network as mentioned in
    the first section of this chapter.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这个架构的右侧是一个传统的自动编码器，当用个别资产回报作为输入时，因为它将*N*资产回报映射到它们自身。作者们以这种方式使用它来衡量衍生因子如何解释当期回报。此外，他们使用自动编码器来预测未来的回报，方法是使用期间*t*-1的输入回报和期间t的输出回报。我们将重点关注该架构用于预测的用途，并强调自动编码器是本章第一节中提到的前馈神经网络的特例。
- en: The model output is the dot product of the ![](img/B15439_20_008.png) factor
    loadings on the left with the ![](img/B15439_20_009.png) factor premia on the
    right. The authors experiment with values of *K* in the range 2-6, similar to
    established factor models.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 模型输出是左侧的![](img/B15439_20_008.png)因子载荷与右侧的![](img/B15439_20_009.png)因子溢价的点积。作者们尝试了*K*在2-6范围内的值，与已建立的因子模型类似。
- en: 'To create this architecture using TensorFlow 2, we use the Functional Keras
    API and define a `make_model()` function that automates the model compilation
    process as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用TensorFlow 2创建这个架构，我们使用Functional Keras API，并定义一个`make_model()`函数来自动化模型编译过程，如下所示：
- en: '[PRE32]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We follow the authors in using batch normalization and compile the model to
    use mean squared error for this regression task and the Adam optimizer. This model
    has 12,418 parameters (see the notebook).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遵循作者们的做法，使用批量归一化并编译模型，使用均方误差进行回归任务，以及Adam优化器。该模型有12,418个参数（见笔记本）。
- en: The authors use additional regularization techniques such as L1 penalties on
    network weights and combine the results of various networks with the same architecture
    but using different random seeds. They also use early stopping.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 作者们使用额外的正则化技术，如对网络权重的L1惩罚，并结合使用相同架构但使用不同随机种子的各种网络的结果。他们还使用了提前停止。
- en: 'We cross-validate using 20 years for training and predict the following year
    of weekly returns with five folds corresponding to the years 2015-2019\. We evaluate
    combinations of numbers of factors *K* from 2 to 6 and 8, 16, or 32 hidden layer
    units by computing the **information coefficient** (**IC**) for the validation
    set as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用20年的数据进行交叉验证，并预测对应于2015-2019年的五个折叠的下一年的周回报。我们通过计算验证集的**信息系数**（**IC**）来评估从2到6和8、16或32个隐藏层单元的因子*K*的组合。
- en: '[PRE33]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '*Figure 20.8* plots the validation IC averaged over the five annual folds by
    epoch for the five-factor count and three hidden-layer size combinations. The
    upper panel shows the IC across the 52 weeks and the lower panel shows the average
    weekly IC (see the notebook for the color version):'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20.8*绘制了五因子计数和三隐藏层大小组合的每个时期的五年交叉验证IC的平均值。上面的面板显示了52周的IC，下面的面板显示了每周的平均IC（请参阅彩色版本的笔记本）：'
- en: '![](img/B15439_20_08.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_08.png)'
- en: 'Figure 20.8: Cross-validation performance for all factor and hidden-layer size
    combinations'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.8：所有因子和隐藏层大小组合的交叉验证性能
- en: The results suggest that more factors and fewer hidden layer units work better;
    in particular, four and six factors with eight units perform best with overall
    IC values in the range of 0.02-0.03\.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，使用更多因子和更少的隐藏层单元效果更好；特别是，四个和六个因子与八个单元的组合在整体IC值范围为0.02-0.03之间表现最佳。
- en: To evaluate the economic significance of the model's predictive performance,
    we generate predictions for a four-factor model with eight units trained for 15
    epochs. Then we use Alphalens to compute the spreads between equal-weighted portfolios
    invested by a quintile of the predictions for each point in time, while ignoring
    transaction costs (see the `alphalens_analysis.ipynb` notebook).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估模型预测性能的经济意义，我们为训练了15个时期的八个单元的四因子模型生成预测。然后，我们使用Alphalens计算了在每个时间点通过忽略交易成本投资于预测五分位的等权重投资组合之间的差异（请参阅`alphalens_analysis.ipynb`笔记本）。
- en: '*Figure 20.9* shows the mean spread for holding periods from 5 to 21 days.
    For the shorter end that also reflects the prediction horizon, the spread between
    the bottom and the top decile is around 10 basis points:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20.9*显示了持有期从5到21天的平均差异。对于较短的持有期，也反映了预测视野，底部和顶部十分位之间的差异约为10个基点：'
- en: '![](img/B15439_20_09.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_09.png)'
- en: 'Figure 20.9: Mean period-wise spread by prediction quintile'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.9：按预测五分位数的平均周期间差异
- en: 'To evaluate how the predictive performance might translate into returns over
    time, we lot the cumulative returns of similarly invested portfolios, as well
    as the cumulative return for a long-short portfolio invested in the top and bottom
    half, respectively:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估预测性能如何随时间转化为收益，我们绘制了类似投资组合的累积收益，以及分别投资于前半部分和后半部分的多头-空头投资组合的累积收益：
- en: '![](img/B15439_20_10.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_10.png)'
- en: 'Figure 20.10: Cumulative returns of quintile-based and long-short portfolios'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.10：基于五分位数和多头-空头投资组合的累积收益
- en: The results show significant spreads between quintile portfolios and positive
    cumulative returns for the broader-based long-short portfolio over time. This
    supports the hypothesis that the conditional autoencoder model could contribute
    to a profitable trading strategy.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示，五分位数投资组合之间存在显著差异，并且长期以来更广泛的多头-空头投资组合累积收益为正。这支持条件自动编码器模型可能有助于盈利交易策略的假设。
- en: Lessons learned and next steps
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结和下一步
- en: The conditional autoencoder combines a nonlinear version of the data-driven
    risk factors we explored using PCA in *Chapter 13*, *Data-Driven Risk Factors
    and Asset Allocation with Unsupervised Learning*, with the risk factor approach
    to modeling returns discussed in *Chapter 4* and *Chapter 7*. It illustrates how
    deep neural network architectures can be flexibly adapted to various tasks as
    well as the fluid boundary between autoencoders and feedforward neural networks.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 条件自动编码器结合了我们在*第13章*中使用PCA探索的数据驱动风险因素的非线性版本，以及在*第4章*和*第7章*中讨论的建模回报的风险因素方法。它展示了深度神经网络架构如何灵活地适应各种任务，以及自动编码器和前馈神经网络之间的流动边界。
- en: 'The numerous simplifications from the data source to the architecture point
    to several avenues for improvements. Besides sourcing more data of better quality
    that also allows the computation of additional characteristics, the following
    modifications are a starting point—there are certainly many more:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据源到架构的众多简化指向了几个改进的途径。除了获取更多质量更好的数据，还可以计算额外特征的数据外，以下修改是一个起点——当然还有许多其他修改：
- en: Experiment with **data frequencies** other than weekly and forecast horizons
    other than annual, where shorter periods will also increase the amount of training
    data
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试**数据频率**，而不仅仅是每周和预测视野的其他频率，较短的周期也会增加训练数据的数量
- en: Modify the **model architecture**, especially if using more data, which might
    reverse the finding that an even smaller hidden layer would estimate better factor
    loadings
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改**模型架构**，特别是在使用更多数据时，可能会逆转这样的发现，即更小的隐藏层会更好地估计因子载荷
- en: Summary
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we introduced how unsupervised learning leverages deep learning.
    Autoencoders learn sophisticated, nonlinear feature representations that are capable
    of significantly compressing complex data while losing little information. As
    a result, they are very useful to counter the curse of dimensionality associated
    with rich datasets that have many features, especially common datasets with alternative
    data. We also saw how to implement various types of autoencoders using TensorFlow
    2.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了无监督学习如何利用深度学习。自动编码器学习复杂的、非线性的特征表示，能够显著压缩复杂数据而几乎不丢失信息。因此，它们对抗与拥有许多特征的丰富数据相关的维度诅咒非常有用，特别是常见的具有替代数据的数据集。我们还看到了如何使用TensorFlow
    2实现各种类型的自动编码器。
- en: Most importantly, we implemented recent academic research that extracts data-driven
    risk factors from data to predict returns. Different from our linear approach
    to this challenge in *Chapter 13*, *Data-Driven Risk Factors and Asset Allocation
    with Unsupervised Learning*, autoencoders capture nonlinear relationships. Moreover,
    the flexibility of deep learning allowed us to incorporate numerous key asset
    characteristics to model more sensitive factors that helped predict returns.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的是，我们实现了最近的学术研究，从数据中提取数据驱动的风险因素来预测回报。与我们在第13章中对这一挑战的线性方法不同，《数据驱动的风险因素和无监督学习的资产配置》，自编码器捕捉非线性关系。此外，深度学习的灵活性使我们能够整合许多关键资产特征，以建模更敏感的因素，有助于预测回报。
- en: In the next chapter, we focus on generative adversarial networks, which have
    often been called one of the most exciting recent developments in artificial intelligence,
    and see how they are capable of creating synthetic training data.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将专注于生成对抗网络，这经常被称为人工智能领域最激动人心的最新发展之一，并看看它们如何能够创建合成训练数据。

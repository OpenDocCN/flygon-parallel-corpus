- en: Finding Optimal Solutions
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll address various methods for finding the best outcome
    in a given situation. This is called*optimization*and usually involves either
    minimizing or maximizing an objective function. An *objective function* is a function
    that takes a number of parameters as arguments and returns a single scalar value
    that represents the cost or payoff for a given choice of parameters. The problems
    regarding minimizing and maximizing functions are actually equivalent to one another,
    so we'll only discuss minimizing object functions in this chapter. Minimizing
    a function, *f*(*x*), is equivalent to maximizing the function *-f*(*x*). More
    details on this will be provided when we discuss the first recipe.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithms available to us for minimizing a given function depend on the
    nature of the function. For instance, a simple linear function containing one
    or more variables has different algorithms available compared to a non-linear
    function with many variables. The minimization of linear functions falls within
    the category of *linear programming*, which is a well-developed theory. For non-linear
    functions, we usually make use of the gradient (derivative) of a function in order
    to find the minimum points. We will discuss several methods for minimizing various
    functions of different types.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the minima and maxima of the functions of a single variable is especially
    simple, and can be done easily if the derivatives of the function are known. If
    not, then the method described in the appropriate recipe will be applicable. The
    notes in the *Minimizing a non-linear function* recipe give some extra details
    about this.
  prefs: []
  type: TYPE_NORMAL
- en: We'll also provide a very short introduction to *game theory*. Broadly speaking,
    this is a theory surrounding decision-making and has wide-ranging implications
    in subjects such as economics. In particular, we'll discuss how to represent simple
    two-player games as objects in Python, compute payoffs associated with certain
    choices, and compute Nash equilibria for these games.
  prefs: []
  type: TYPE_NORMAL
- en: We will start by looking at how to minimize linear and non-linear functions
    containing one or more variables. Then, we'll move on and look at gradient descent
    methods and curve fitting using least squares. We'll conclude this chapter by
    analyzing two-player games and Nash equilibria.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Minimizing a simple linear function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimizing a non-linear function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using gradient descent methods in optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using least squares to fit a curve to data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing simple two-player games
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computing Nash equilibria
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will need the NumPy package, the SciPy package, and the
    Matplotlib package, as usual. We will also need the Nashpy package for the final
    two recipes. These packages can be installed using your favorite package manager,
    such as `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The code for this chapter can be found in the `Chapter 09` folder of the GitHub
    repository at [https://github.com/PacktPublishing/Applying-Math-with-Python/tree/master/Chapter%2009](https://github.com/PacktPublishing/Applying-Math-with-Python/tree/master/Chapter%2009).
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action: [https://bit.ly/2BjzwGo](https://bit.ly/2BjzwGo).'
  prefs: []
  type: TYPE_NORMAL
- en: Minimizing a simple linear function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The most basic type of problem we face in optimization is finding the parameters
    where a function takes its minimum value. Usually, this problem is *constrained*
    by some bounds on the possible values of the parameters, which increases the complexity
    of the problem. Obviously, the complexity of this problem increases further if
    the function that we are minimizing is also complex. For this reason, we must
    first consider *linear functions*, which are in the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/81d86696-3f59-4c53-9c0b-7610003405b0.png)'
  prefs: []
  type: TYPE_IMG
- en: To solve these kinds of problems, we need to convert the constraints into a
    form that can be used by the computer. In this case, we usually convert them into
    a linear algebra problem (matrices and vectors). Once this is done, we can use
    the tools from the linear algebra packages in NumPy and SciPy to find the parameters
    we seek. Fortunately, since these kinds of problems occur quite frequently, SciPy
    has routines that handle this conversion and subsequent solving.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this recipe, we''ll solve the following constrained linear minimization
    problem using routines from the SciPy `optimize` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bf60d0a9-bda0-4b13-b5b8-a21a96bfe9b0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This will be subject to the following conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/06c40ed3-2f7d-48d6-8d32-53756bc49383.png)'
  prefs: []
  type: TYPE_IMG
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we need to import the NumPy package under the alias `np`,
    the Matplotlib `pyplot` module under the name `plt`, and the SciPy `optimize`
    module. We also need to import the `Axes3D` class from `mpl_toolkits.mplot3d`
    to make 3D plotting available:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to solve a constrained linear minimization problem using
    SciPy:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Set up the system in a form that SciPy can recognize:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to define a routine that evaluates the linear function at a value
    of *x*, which is a vector (a NumPy array):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we create a new figure and add a set of `3d` axes that we can plot the
    function on:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create a grid of values covering the region from the problem and plot
    the value of the function over this region:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we plot the line in the plane of function values that corresponds to the
    critical line, `2*x0 + x1 == 6`, and plot the values that fall within the range
    on top of our plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We repeat this plotting step for the second critical line, `x0 + x1 == -4`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we shade the region that lies within the two critical lines, which corresponds
    to the feasible region for the minimization problem:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot of the function values over the feasible region can be seen in the
    following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/e58a70ae-06b2-4718-892d-8dde0fa89bea.png)Figure 9.1: Values of the
    linear function with the feasible region highlighted'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the minimum value that lies within this shaded region occurs
    at the intersection of the two critical lines.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we use `linprog` to solve the constrained minimization problem with the
    bounds we created in *Step 1*. We print the resulting object in the terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we plot the minimum function value on top of the feasible region:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The updated plot can be seen in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/d18cd25f-8786-4d1e-a253-aebdc3d4bd92.png)Figure 9.2: Minimum value
    plotted on the feasible region'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that the `linprog` routine has indeed found that the minimum
    is at the intersection of the two critical lines.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Constrained linear minimization problems are common in economic situations,
    where you try to minimize costs while maintaining other aspects of the parameters.
    In fact, a lot of the terminology from optimization theory mirrors this fact.
    A very simple algorithm for solving these kinds of problems is called the **simplex
    method**, which uses a sequence of array operations to find the minimal solution.
    Geometrically, these operations represent changing to different vertices of a
    simplex (which we won't define here), and it is this that gives the algorithm
    its name.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we continue, we''ll provide a brief outline of the process used by the
    simplex method to solve a constrained linear optimization problem. The problem,
    as presented to us, is not a matrix equation problem but a matrix inequality problem.
    We can remedy this problem by introducing **slack variables**, which turn an inequality
    into an equality. For example, the first constraint inequality can be rewritten
    as follows by introducing the slack variable, *s[1]*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/7d8c2f37-dc9d-4c8c-8718-96a71e709d6f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This satisfies the desired inequality, provided that *s[1]* is not negative.
    The second constraint inequality is a greater than or equal to type inequality
    that we must first change so that it''s of the less than or equal to type. We
    do this by multiplying all terms by -1\. This gives us the second row of matrix
    `A` that we defined in the recipe. After introducing a second slack variable,
    *s[2]*, we get the second equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/6aa8a05b-274f-4d44-9eac-9101a8a40105.png)'
  prefs: []
  type: TYPE_IMG
- en: From this, we can construct a matrix whose columns contain the coefficients
    of the two parameter variables, *x[1]* and *x[2,]* and the two slack variables,
    *s[1]* and *s[2.]* The rows of this matrix represent the two bounding equations
    and the objective function*.* This system of equations can now be solved, using
    elementary row operations on this matrix, to obtain the values of*x[1]* and *x[2]*,
    which minimize the objective function. Since solving matrix equations is easy
    and fast, this means that we can minimize linear functions quickly and efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, we don't need to remember how to reduce our system of inequalities
    into a system of linear equations since routines such as `linprog` do this for
    us. We can simply provide the bounding inequalities as a matrix and vector pair,
    consisting of the coefficients of each, and a separate vector that defines the
    objective function. The `linprog` routine takes care of formulating and then solving
    the minimization problem.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, the simplex method is not the algorithm used by the `linprog` routine
    to minimize the function. Instead, `linprog` uses an interior point algorithm,
    which is more efficient. (The method can actually be set to `simplex` or `revised-simplex`
    by providing the `method` keyword argument with the appropriate method name. In
    the printed resulting output, we can see that it only took five iterations to
    reach the solution.) The resulting object that is returned by this routine contains
    the parameter values at which the minimum occurs stored in the `x` attribute,
    the value of the function at this minimum value stored in the `fun` attribute,
    and various other pieces of information about the solving process. If the method
    had failed, then the `status` attribute would have contained a numerical code
    that described why the method failed.
  prefs: []
  type: TYPE_NORMAL
- en: In *step 2* of this recipe, we created a function that represents the objective
    function for this problem. This function takes a single array as input, which
    contains the parameter space values at which the function should be evaluated.
    Here, we used the `tensordot` routine (with `axes=1`) from NumPy to evaluate the
    dot product of the coefficient vector, *c*, with each input, *x*. We have to be
    quite careful here since the values that we pass into the function will be a 2
    × 50 × 50 array in a later step. The ordinary matrix multiplication (`np.dot`)
    would not give the 50 × 50 array output that we desire in this case.
  prefs: []
  type: TYPE_NORMAL
- en: 'In *steps 5* and *6*, we computed the points on the critical lines as those
    points with the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/112c73bc-cd66-44aa-941c-c2d03e5f4bbc.png)'
  prefs: []
  type: TYPE_IMG
- en: We then computed the corresponding *z* values so that we could plot the lines
    that lie on the plane defined by the objective function. We also need to "trim"
    the values so that we only include those that lie in the range specified in the
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This recipe covered the constrained minimization problem and how to solve it
    using SciPy. However, the same method can be used to solve the constrained *maximization*
    problem. This is because maximization and minimization are *dual* to one another
    in the sense that maximizing a function, *f*(*x*), is the same as minimizing the
    function *-f*(*x*), and then taking the negative of this value. In fact, we used
    this fact in this recipe to change the second constraining inequality from ≥ to
    ≤.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we solved a problem with only two parameter variables, but the
    same method will work (except for the plotting steps) for a problem involving
    more than two such variables. We just need to add more rows and columns to each
    of the arrays to account for this increased number of variables – this includes
    the tuple of bounds supplied to the routine. The routine can also be used with
    sparse matrices, where appropriate, for extra efficiency when dealing with very
    large amounts of variables.
  prefs: []
  type: TYPE_NORMAL
- en: The `linprog` routine gets its name from *linear programming*, which is used
    to describe problems of this type – finding values of *x* that satisfy some matrix
    inequalities subject to other conditions. Since there is a very close connection
    to the theory of matrices and linear algebra, there are many very fast and efficient
    techniques available for linear programming problems that are not available in
    a non-linear context.
  prefs: []
  type: TYPE_NORMAL
- en: Minimizing a non-linear function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous recipe, we saw how to minimize a very simple linear function.
    Unfortunately, most functions are not linear and usually don't have nice properties
    that we would like. For these non-linear functions, we cannot use the fast algorithms
    that have been developed for linear problems, so we need to devise new methods
    that can be used in these more general cases. The algorithm that we will use there
    is called the Nelder-Mead algorthim, which is a robust and general-purpose method
    that's used to find the minimum value of a function and does not rely on the gradient
    of the function.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we'll learn how to use the Nelder-Mead simplex method to minimize
    a non-linear function containing two variables.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we will use the NumPy package imported as `np`, the Matplotlib
    `pyplot` module imported as `plt`, the `Axes3D` class imported from `mpl_toolkits.mplot3d`
    to enable 3D plotting, and the SciPy `optimize` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps show you how to use the Nelder-Mead simplex method to find
    the minimum of a general non-linear objective function:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the objective function that we will minimize:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, create a grid of values that we can plot our objective function on:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we evaluate the function on this grid of points:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create a new figure with a `3d` axes object and set the axis labels
    and the title:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can plot the objective function as a surface on the axes we just created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We choose an initial point that our minimization routine will start its iteration
    at and plot this on the surface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot of the objective function''s surface, along with the initial point,
    can be seen in the following image. Here, we can see that the minimum value appears
    to occur at around 0.5 on the x-axis and -0.5 on the y-axis:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/5ab26e54-d0c2-4be6-a1e6-2f3e71f1a30e.png)Figure 9.3: Non-linear
    objective function with a starting value'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we use the `minimize` routine from the `optimize` package to find the
    minimum value and print the `result` object that it produces:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we plot the minimum value found by the `minimize` routine on top of
    the objective function surface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The updated plot of the objective function, including the minimum point found
    by the `minimize` routine, can be seen in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/5d9fcc80-cded-4642-a3b3-60f27b872b09.png)Figure 9.4: Objective function
    with a starting point and a minimum point'
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Nelder-Mead simplex method – not to be confused with the simplex method
    for linear optimization problems – is a simple algorithm for finding the minimum
    values of a non-linear function and works even when the objective function does
    not have a known derivative. (This is not the case for the function in this recipe;
    the only gains from using a gradient-based method is the speed of convergence.)
    The method works by comparing the values of the objective function at the vertices
    of a simplex, which is a triangle in a two-dimensional space. The vertex with
    the largest function value is "reflected" through the opposite edge and performs
    an appropriate expansion or contraction that, in effect, moves the simplex "downhill".
  prefs: []
  type: TYPE_NORMAL
- en: The `minimize` routine from the SciPy `optimize` module is an entry point for
    many non-linear function minimization algorithms. In this recipe, we used the
    Nelder-Mead simplex algorithm, but there are also a number of other algorithms
    available. Many of these algorithms require knowledge of the gradient of the function,
    which might be computed automatically by the algorithm. The algorithm can be used
    by providing the appropriate name to the `method` keyword argument.
  prefs: []
  type: TYPE_NORMAL
- en: The `result` object that's returned by the `minimize` routine contains lots
    of information about the solution that has been found – or not found, if an error
    occurred – by the solver. In particular, the desired parameters that the calculated
    minimum occurs at is stored in the `x`attribute of the result, while the value
    of the function is stored in the `fun`attribute.
  prefs: []
  type: TYPE_NORMAL
- en: The `minimize` routine requires the function and a starting value of `x0`. In
    this recipe, we also provided a tolerance value that the minimum should be computed
    at using the `tol` keyword argument. Changing this value will modify the accuracy
    that the solution is computed with.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Nelder-Mead algorithm is an example of a "gradient-free" minimization algorithm
    since it does not require any information about the gradient (derivative) of the
    objective function. There are several such algorithms, all of which typically
    involve evaluating the objective function at a number of specified points, and
    then using this information to move toward the minimum value. In general, gradient-free
    methods tend to converge more slowly than gradient descent models. However, they
    can be used for almost any objective function, even where it is not easy to compute
    the gradient either exactly or by means of approximation.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing the functions of a single variable is generally easier than the multi-dimensional
    case and has its own special function in the SciPy `optimize` library. The `minimize_scalar`
    routine performs minimization for functions of a single variable and should be
    used instead of `minimize` in this case.
  prefs: []
  type: TYPE_NORMAL
- en: Using gradient descent methods in optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous recipe, we used the Nelder-Mead simplex algorithm to minimize
    a non-linear function containing two variables. This is a fairly robust method
    that works even if very little is known about the objective function. However,
    in many situations, we do know more about the objective function, and this fact
    allows us to devise faster and more efficient algorithms for minimizing the function.
    We can do this by making use of properties such as the gradient of the function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *gradient* of a function of more than one variable describes the rate of
    change of the function in each of its component directions. This is a vector of
    the partial derivatives of the function with respect to each of the variables.
    From this gradient vector, we can deduce the direction in which the function is
    increasing most rapidly and, conversely, the direction in which the function is
    decreasing most rapidly from any given position. This gives us the basis for *gradient
    descent* methods for minimizing a function. The algorithm is very simple: given
    a starting position, **x**, we compute the gradient at this **x** and the corresponding
    direction in which the gradient is most rapidly decreasing, then make a small
    step in that direction. After a few iterations, this will move from the starting
    position to the minimum of the function.'
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to implement an algorithm based on the steepest
    descent algorithm to minimize an objective function within a bounded region.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we will need the NumPy package imported as `np`, the Matplotlib
    `pyplot` module imported as `plt`, and the `Axes3D` object imported from `mpl_toolkits.mplot3d`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the following steps, we will implement a simple gradient descent method
    to minimize an objective function with a known gradient function (we''re actually
    going to use a generator function so that we can see the method as it works):'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start by defining a `descend` routine, which will carry out our algorithm.
    The function declaration is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to implement this routine. We start by defining the variables
    that will hold the iterate values while the method is running:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We then start our loop, which will run the iterations. We immediately check
    whether we are making meaningful progress before continuing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The direction is minus the gradient vector. We compute this once and store
    it in the `direction` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we update the previous and current values, `xnm1` and `xn`, respectively,
    ready for the next iteration. This concludes the code for the `descend` routine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can compute the gradient at the current value and yield all the appropriate
    values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This concludes the definition of the `descend` routine.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now define a sample objective function to minimize:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create a grid that we will evaluate and then plot the objective function
    on:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the grid has been created, we can evaluate our function and store the
    result in the `z` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create a three-dimensional surface plot of the objective function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we can start the minimization process, we need to define an initial
    point, `x0`. We plot this point on the objective function plot we created in the
    previous step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The surface plot of the objective function, along with the initial value, can
    be seen in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/5c4283c9-96a3-4818-8b34-16b400f57003.png)Figure 9.5: Surface of
    the objective function with the initial position'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our `descend` routine requires a function that evaluates the gradient of the
    objective function, so we will define one:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'We will plot the iterations on a contour plot, so we set this up as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we create a variable that holds the bounds in the *x* and *y* directions
    as a tuple of tuples. These are the same bounds from the `linspace` calls in *step
    10*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now use a `for` loop to drive the `descend` generator to produce each
    of the iterations and add the steps to the contour plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the loop is complete, we print the final values to the Terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding print statements is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see that our routine used 37 iterations to find a minimum at approximately
    (0.5, -0.5), which is correct.
  prefs: []
  type: TYPE_NORMAL
- en: 'The contour plot with its iterations plotted can be seen in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/2925d695-1772-420f-b35e-85cac413956f.png)Figure 9.6: Contour plot
    of the objective function with gradient descent iterating to a minimum value'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that the direction of each iteration – shown by the dashed
    lines – is in the direction where the objective function is decreasing most rapidly.
    The final iteration lies at the center of the "bowl" of the objective function,
    which is where the minimum occurs.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The heart of this recipe is the `descend` routine. The process that's defined
    in this routine is a very simple implementation of the gradient descent method.
    Computing the gradient at a given point is handled by the `grad` argument, and
    is then used to deduce the direction of travel for the iteration by taking `direction
    = -grad`. We multiply this direction by a fixed scale factor (sometimes called
    the **learning rate**) with a value of 0.2 to obtain the scaled step, and then
    take this step by adding `0.2*direction` to the current position.
  prefs: []
  type: TYPE_NORMAL
- en: The solution in the recipe took 37 iterations to converge, which is a mild improvement
    on the Nelder-Mead simplex algorithm from the *Minimizing a non-linear function*
    recipe, which took 58 iterations. (This is not a perfect comparison since we changed
    the starting position for this recipe.) This performance is heavily dependent
    on the step size that we choose. In this case, we fixed the maximum step size
    to be 0.2 times the size of the direction vector. This keeps the algorithm simple,
    but it is not particularly efficient.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we chose to implement the algorithm as a generator function
    so that we could see the output of each step and plot this on our contour plot
    as we stepped through the iteration. In practice, we probably wouldn't want to
    do this and instead return the calculated minimum once the iterations have finished.
    To do this, we can simply remove the `yield`statement and replace it with`return
    xn`at the very end of the function, at the main function's indentation (that is,
    not inside the loop). If you want to guard against non-convergence, you can use
    the `else`feature of the `for` loop to catch cases where the loop finishes because
    it has reached the end of its iterator without hitting the `break`keyword. This`else`block
    could raise an exception to indicate that the algorithm has failed to stabilize
    to a solution. The condition we used to end the iteration in this recipe does
    not guarantee that the method has reached a minimum, but this will usually be
    the case.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In practice, you would not usually implement the gradient descent algorithm
    for yourself and instead use a general-purpose routine from a library such as
    the SciPy `optimize` module. We can use the same `minimize` routine that we used
    in the previous recipe to perform minimization with a variety of different algorithms,
    including several gradient descent algorithms. These implementations are likely
    to have much higher performance and be more robust than a custom implementation
    such as this.
  prefs: []
  type: TYPE_NORMAL
- en: 'The gradient descent method we used in this recipe is a very naive implementation
    and can be greatly improved by allowing the routine to choose the step size at
    each step. (Methods that are allowed to choose their own step size are sometimes
    called adaptive methods.) The difficult part of this improvement is choosingthe
    size of the step to take in this direction. For this, we need to consider the
    function of a single variable, which is given by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/be48ec70-e6d7-44a1-968a-30847a25765e.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, **x***[n]*represents the current point, **d**[*n*]represents the current
    direction, and *t* is a parameter. For simplicity, we can use a minimization routine
    called `minimize_scalar` for scalar-valued functions from the SciPy `optimize`module.
    Unfortunately, it is not quite as simple as passing in this auxiliary function
    and finding the minimum value. We have to bound the possible value of *t* so that
    the computed minimizing point, **x**[*n*]+ *t***d**[*n*], lies within the region
    that we are interested in.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand how we bound the values of *t*, we must first look at the construction
    geometrically. The auxiliary function that we introduce evaluates the objective
    function along a single line in the given direction. We can picture this as taking
    a single cross-section through the surface that passes through the current **x***[n]*point
    in the**d**[*n*] direction. The next step of the algorithm is finding the step
    size, *t*, that minimizes the values of the objective function along this line
    – this is a scalar function, which is much easier to minimize. The bounds should
    then be the range of *t*values during which this line lies within the rectangle
    defined by the *x*and *y*boundary values. We determine the four values at which
    this line crosses those *x*and *y*boundary lines, two of which will be negative
    and two of which will be positive. (This is because the current point must lie
    within the rectangle.) We take the minimum of the two positive values and the
    maximum of the two negative values and pass these bounds to the scalar minimization
    routine. This is achieved using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the step size has been chosen, the only remaining step is to update the
    current `xn` value, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Using this adaptive step size increases the complexity of the routine, but the
    performance is massively improved. Using this revised routine, the method converged
    in just three iterations, which is far fewer than the number of iterations used
    by the naive code in this recipe (37 iterations) or by the Nelder-Mead simplex
    algorithm in the previous recipe (58 iterations). This reduction in the number
    of iterations is exactly what we expected by providing the method with more information
    in the form of the gradient function.
  prefs: []
  type: TYPE_NORMAL
- en: We created a function that returned the gradient of the function at a given
    point. We computed this gradient by hand before we started, which will not always
    be easy or even possible. Instead, it is much more common to replace the "analytic"
    gradient used here with a numerically computed gradient that's been estimated
    using finite differences or a similar algorithm. This has an impact on performance
    and accuracy, as all approximations do, but these concerns are usually minor given
    the improvement in the speed of convergence offered by gradient descent methods.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent type algorithms are particularly popular in machine learning
    applications. Most of the popular Python machine learning libraries – including
    PyTorch, TensorFlow, and Theano – offer utilities for automatically computing
    gradients numerically for data arrays. This allows gradient descent methods to
    be used in the background to improve performance.
  prefs: []
  type: TYPE_NORMAL
- en: A popular variation of the gradient descent method is **stochastic gradient
    descent**, where the gradient is estimated by sampling randomly rather than using
    the whole set of data. This can dramatically reduce the computational burden of
    the method – at the cost of slower convergence – especially for high-dimensional
    problems such as those that are common in machine learning applications. Stochastic
    gradient descent methods are often combined with backpropagation to form the basis
    for training artificial neural networks in machine learning applications.
  prefs: []
  type: TYPE_NORMAL
- en: There are several extensions of the basic stochastic gradient descent algorithm.
    For example, the momentum algorithm incorporates the previous increment into the
    calculation of the next increment. Another example is the adaptive gradient algorithm,
    which incorporates per-parameter learning rates to improve the rate of convergence
    for problems that involve a large number of sparse parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Using least squares to fit a curve to data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Least squares is a powerful technique for finding a function from a relatively
    small family of potential functions that best describe a particular set of data.
    This technique is especially common in statistics. For example, least squares
    is used in linear regression problems – here, the family of potential functions
    is the collection of all linear functions. Usually, this family of functions that
    we try to fit has relatively few parameters that can be adjusted to solve the
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: The idea of least squares is relatively simple. For each data point, we compute
    the square of the residual – the difference between the value of the point and
    the expected value given a function – and try to make the sum of these squared
    residuals as small as possible (hence least squares).
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we'll learn how to use least squares to fit a curve to a sample
    set of data.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we will need the NumPy package imported, as usual, as `np`,
    and the Matplotlib `pyplot` module imported as `plt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'We will also need an instance of the default random number generator from the
    NumPy `random` module imported, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we need the `curve_fit` routine form the SciPy `optimize` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps show you how to use the `curve_fit` routine to fit a curve
    to a set of data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to create the sample data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we produce a scatter plot of the data to see if we can identify the underlying
    trend in the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The scatter plot that we have produced can be seen in the following image.
    Here, we can see that the data certainly doesn''t follow a linear trend (straight
    line). Since we know the trend is a polynomial, our next guess would be a quadratic
    trend. This is what we''re using here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3ceb7823-e247-404c-a2d3-f2fe41c0478c.png)Figure 9.7: Scatter plot
    of the sample data. We can see that the data does not follow a linear trend'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we create a function that represents the model that we wish to fit:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can use the `curve_fit` routine to fit the model function to the sample
    data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we plot the best fit curve on top of the scatter plot to evaluate
    how well the fitted curve describes the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The updated scatter plot can be seen in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/dd4d4a24-007e-44fe-be30-d65cbd0cc903.png)Figure 9.8: Scatter plot
    with the curve of best fit found using least-squares superimposed'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that the curve we have found fits the data reasonably well.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `curve_fit` routine performs least-squares fitting to fit the model''s
    curve to the sample data. In practice, this amounts to minimizing the following
    objective function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ba94af51-b092-4000-933f-7e50b33b54ea.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, the pairs (*x[i]*, *y[i]*) are the points from the sample data. In this
    case, we are optimizing over a three-dimensional parameter space, with one dimension
    for each of the parameters. The routine returns the estimated coefficients – the
    point in the parameter space at which the objective function is minimized – and
    a second variable that contains estimates for the covariance matrix for the fit.
    We ignored this in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: The estimated covariance matrix that's returned from the `curve_fit` routine
    can be used to give a confidence interval for the estimated parameters. This is
    done by taking the square root of the diagonal elements divided by sample size
    (100 in this recipe). This gives the standard error for the estimate that, when
    multiplied by the appropriate values corresponding to the confidence, gives us
    the size of the confidence interval. (We discussed confidence intervals in [Chapter
    6](87b0f91d-3086-41a9-995d-27fe7d364e8b.xhtml), *Working with Data and Statistics*.)
  prefs: []
  type: TYPE_NORMAL
- en: You might have noticed that the parameters estimated by the `curve_fit` routine
    are close, but not exactly equal, to the parameters that we used to define the
    sample data in *step 1*. The fact that these are not exactly equal is due to the
    normally distributed noise that we added to the data. In this recipe, we knew
    that the underlying structure of the data was quadratic – that is, a degree 2
    polynomial – and not some other, more esoteric, function. In practice, we are
    unlikely to know so much about the underlying structure of the data, which is
    the reason we added noise to the sample.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is another routine in the SciPy `optimize` module for performing least-squares
    fitting called `least_squares`. This routine has a slightly less intuitive signature
    but does return a results object with more information about the optimization
    process. However, the way this routine is set up is perhaps more similar to the
    way that we constructed the underlying mathematical problem in the *How it works...*
    section. To use this routine, we define the objective function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'We pass this function along with a starting estimate in the parameter space,
    `x0`, such as `(1, 0, 0)`. The additional parameters for the objective function,
    `func`, can be passed using the `args` keyword argument; for example, we could
    use `args=(x_data, y_data)`. These arguments are passed into the `x` and `y` arguments
    of the objective function. To summarize, we could have estimated the parameters
    using the following call to `least_squares`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The `results` object that's returned from the `least_squares` routine is actually
    the same as the one returned by the other optimization routines described in this
    chapter. It contains details such as the number of iterations used, whether the
    process was successful, detailed error messages, the parameter values, and the
    value of the objective function at the minimum value.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing simple two-player games
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Game theory is a branch of mathematics concerned with the analysis of decision-making
    and strategy. It has applications in economics, biology, and behavioral science.
    Many seemingly complex situations can be reduced to a relatively simple mathematical
    game that can be analyzed in a systematic way to find "optimal" solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'A classic problem in game theory is the *prisoner''s dilemma*, which, in its
    original form, is as follows: two co-conspirators are caught and must decide whether
    to remain quiet or to testify against the other. If both remain quiet, they both
    serve a 1-year sentence; if one testifies but the other does not, the testifier
    is released and the other serves a 3-year sentence; and if both testify against
    one another, they both serve a 2-year sentence. What should each conspirator do?
    It turns out that the best choice each conspirator can make, given any reasonable
    distrust of the other, is to testify. Adopting this strategy, they will either
    serve no sentence or a 2-year sentence maximum.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since this book is about Python, we will use a variation of this classic problem
    to illustrate just how universal the idea of this problem is. Consider the following
    problem: you and your colleague have to write some code for a client. You think
    that you could write the code faster in Python, but your colleague thinks that
    they could write it faster in C. The question is, which language should you choose
    for the project?'
  prefs: []
  type: TYPE_NORMAL
- en: 'You think that you could write the Python code 4 times faster than in C, so
    you write C with speed 1 and Python with speed 4\. Your colleague says that they
    can write C slightly faster than Python, so they write C with speed 3 and Python
    with speed 2\. If you both agree on a language, then you write the code at the
    speed you predicted, but if you disagree, then the productivity of the faster
    programmer is reduced by 1\. We can summarize this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Colleague/You** | **C** | **Python** |'
  prefs: []
  type: TYPE_TB
- en: '| C | 3 / 1 | 3 / 2 |'
  prefs: []
  type: TYPE_TB
- en: '| Python | 2 / 1 | 2 / 4 |'
  prefs: []
  type: TYPE_TB
- en: In this recipe, we will learn how to construct an object in Python to represent
    this simple two-player game, and then perform some elementary analysis regarding
    the outcomes of this game.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we will need the NumPy package imported as `np`, and the Nashpy
    package imported as `nash`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps show you how to create and perform some simple analysis
    of a two-player game using Nashpy:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to create matrices that hold the payoff information for each
    player (you and your colleague, in this example):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create a `Game` object that holds the game represented by these payoff
    matrices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'We compute the utility for the given choices using index notation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also compute the expected utilities based on the probabilities of making
    a specific choice:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we built a Python object that represents a very simple two-player
    strategic game. The idea here is that there are two "players" who have decisions
    to make, and each combination of both player's choices gives a specific payoff
    value. What we're aiming to do here is find the best choice that each player can
    make. The players are assumed to make a single move simultaneously, in the sense
    that neither is aware of the other's choice. Each player has a strategy that determines
    the choice they make.
  prefs: []
  type: TYPE_NORMAL
- en: In *step 1,* we create two matrices – one for each player – that are assigned
    to each combination of choices for the payoff value. These two matrices are wrapped
    by the `Game` class from Nashpy, which provides a convenient and intuitive (from
    a game-theoretic point of view) interface for working with games. We can quickly
    calculate the utility of a given combination of choices by passing in the choices
    using index notation.
  prefs: []
  type: TYPE_NORMAL
- en: We can also provide calculate expected utilities based on a strategy where choices
    are chosen at random according to some probability distribution. The syntax is
    the same as for the deterministic case described previously, except we provide
    a vector of probabilities for each choice. We compute the expected utilities based
    on the probability that you choose Python 90% of the time, while your colleague
    chooses Python 50% of the time. The expected speeds are 2.45 and 2.05 for you
    and your colleague, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is an alternative to computational game theory in Python. The Gambit project
    is a collection of tools that's used for computation in game theory that has a
    Python interface ([http://www.gambit-project.org/](http://www.gambit-project.org/)).
    This is a mature project built around C libraries and offers more performance
    than Nashpy.
  prefs: []
  type: TYPE_NORMAL
- en: Computing Nash equilibria
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A *Nash equilibrium* is a two-player strategic game – similar to the one we
    saw in the *Analyzing simple two-player games* recipe – that represents a "steady
    state" in which every player sees the "best possible" outcome. However, this doesn''t
    mean that the outcome linked to a Nash equilibrium is the best overall. Nash equilibria
    are more subtle than this. An informal definition of a Nash equilibrium is as
    follows: an action profile in which no individual player can improve their outcome,
    assuming that all other players adhere to the profile.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will explore the notion of a Nash equilibrium with the classic game of rock-paper-scissors.
    The rules are as follows. Each player can choose one of the options: rock, paper,
    or scissors. Rock beats scissors, but loses to paper; paper beats rock, but loses
    to scissors; scissors beats paper, but loses to rock. Any game in which both players
    make the same choice is a draw. Numerically, we represent a win by +1, a loss
    by -1, and a draw by 0\. From this, we can construct a two-player game and compute
    Nash equilibria for this game.'
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will compute Nash equilibria for the classic game of rock-paper-scissors.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we will need the NumPy package imported as `np`, and the Nashpy
    package imported as `nash`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps show you how to compute Nash equilibria for a simple two-player
    game:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to create a payoff matrix for each player. We will start with
    the first player:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'The payoff matrix for the second player is the transpose of `rps_p1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create the `Game` object to represent the game:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'We compute the Nash equilibria for the game using the support enumeration algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'We iterate over the equilibria and print the profile for each player:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of these print statements is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Nash equilibria are extremely important in game theory because they allow us
    to analyze the outcomes of strategic games and identify advantageous positions.
    They were first described by John F. Nash in 1950, and have played a pivotal role
    in modern game theory. A two-player game may have many Nash equilibria, but any
    finite two-player game must have at least one. The problem is finding all the
    possible Nash equilibria for a given game.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this recipe, we used the support enumeration, which effectively enumerates
    all possible strategies and filters down to those that are Nash equilibria. In
    this recipe, the support enumeration algorithm found just one Nash equilibrium,
    which is a mixed strategy. This means that the only strategy for which there is
    no improvement involves picking one of the choices at random, each with a 1/3
    probability. This is hardly a surprise to anyone who has played rock-paper-scissors
    since for any choice we make, our opponent has a 1 in 3 chance of choosing (at
    random) the move that beats our choice. Equally, we have a 1 in 3 chance of drawing
    or winning the game, so our expected value over all these possibilities is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/e8194320-0a11-4aaa-b6ff-58939c4505f7.png)'
  prefs: []
  type: TYPE_IMG
- en: Without knowing exactly which of the choices our opponent will choose, there
    is no way to improve this expected outcome.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Nashpy package also provides other algorithms for computing Nash equilibria.
    Specifically, the `vertex_enumeration` method, when used on a `Game` object, uses
    the *vertex enumeration* algorithm, while the `lemke_howson_enumeration` method
    uses the *Lemke Howson* algorithm. These alternative algorithms have different
    characteristics and may be more efficient for some problems.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The documentation for the Nashpy package contains more detailed information
    about the algorithms and game theory involved. This includes a number of references
    to texts on game theory. This documentation can be found at [https://nashpy.readthedocs.io/en/latest/](https://nashpy.readthedocs.io/en/latest/).
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As usual, the *Numerical Recipes* book is a good source of numerical algorithms.
    [Chapter 10](169df36b-7160-4fe9-ab59-e20047fc4dc6.xhtml), *Miscellaneous Topics*,
    deals with the maximization and minimization of functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Press, W.H., Teukolsky, S.A., Vetterling, W.T., and Flannery, B.P., 2017\.
    Numerical recipes: the art of scientific computing. 3rd ed. Cambridge: Cambridge
    University Press*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'More specific information on optimization can be found in the following books:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Boyd, S.P. and Vandenberghe, L., 2018\. Convex optimization**. Cambridge:
    Cambridge University Press*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Griva, I., Nash, S., and Sofer, A., 2009\. Linear and nonlinear optimization.**2nd
    ed. Philadelphia: Society for Industrial and Applied Mathematics*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, the following book is a good introduction to game theory:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Osborne, M.J., 2017\. An introduction to game theory**. Oxford: Oxford University
    Press*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL

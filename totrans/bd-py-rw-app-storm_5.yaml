- en: Chapter 5. Persistence Using Redis and MongoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is often necessary to store tuples in a persistent data store, such as a
    NoSQL database or a fast key-value cache, in order to perform additional analysis.
    In this chapter, we will revisit the Twitter trending analysis topology from [Chapter
    4](ch04.html "Chapter 4. Example Topology – Twitter"), *Example Topology – Twitter*
    with the help of two popular persistence media: Redis and MongoDB.'
  prefs: []
  type: TYPE_NORMAL
- en: Redis ([http://redis.io/](http://redis.io/)) is an open source and BSD-licensed
    advanced key-value cache and store. MongoDB is a cross-platform, document-oriented
    database ([https://www.mongodb.org/](https://www.mongodb.org/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the two problems that we will solve in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Finding the top trending tweet topics using Redis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computing hourly aggregates of city mentions using MongoDB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding the top n ranked topics using Redis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The topology will compute a rolling ranking of the most popular words in the
    past 5 minutes. The word counts are stored in individual windows of 60 seconds
    in length. It consists of the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Twitter stream spout (`twitterstream.py`): This reads tweets from the Twitter
    sample stream. This spout is unchanged from [Chapter 4](ch04.html "Chapter 4. Example
    Topology – Twitter"), *Example Topology – Twitter*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Splitter bolt (`splitsentence.py`): This receives tweets and splits them into
    words. This is also identical to the one in [Chapter 4](ch04.html "Chapter 4. Example
    Topology – Twitter"), *Example Topology – Twitter*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rolling word count bolt (`rollingcount.py`): This receives words and counts
    the occurrences. The Redis keys look like `twitter_word_count:<start time of current
    window in seconds>`, and the values are stored in a hash using the following simple
    format:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This bolt uses the Redis `expireat` command to discard old data after 5 minutes.
    These lines of code perform the key work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In this bolt, the following code does the most important work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This bolt computes the top `maxSize` words across the last num_windows periods.
    The `zunionstore()` combines the word counts across the periods. The `zrevrange()`
    sorts the combined counts, returning the top `maxSize` words.
  prefs: []
  type: TYPE_NORMAL
- en: In the original Twitter example, roughly the same logic was implemented in `rollingcount.py`,
    `intermediaterankings.py`, and `totalrankings.py`. With Redis, we can implement
    the same calculations in just a few lines. The design delegates much of the work
    to Redis. Depending on your data volumes, this may not scale as well as the topology
    in the previous chapter. However, it demonstrates that Redis's capabilities go
    far beyond simply storing data.
  prefs: []
  type: TYPE_NORMAL
- en: The topology configuration file – the Redis case
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Coming up is the topology configuration file. Depending on your Redis installation,
    you may need to change the value of `redis_url`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter this code in `topology.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Rolling word count bolt – the Redis case
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The rolling word count bolt is similar to the word count bolt in [Chapter 3](ch03.html
    "Chapter 3. Introducing Petrel"), *Introducing Petrel*. The bolt in the earlier
    chapter simply accumulated the word count indefinitely. This is not good for analyzing
    the top words on Twitter, where the popular topics can change from one moment
    to the next. Rather, we want counts that reflect the latest information. As explained
    earlier, the rolling word count bolt stores data in time-based buckets. Then,
    it periodically discards buckets that exceed 5 minutes in age. Thus, the word
    counts from this bolt only consider the last 5 minutes of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter this code in `rollingcount.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Total rankings bolt – the Redis case
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Enter the following code in `totalrankings.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Defining the topology – the Redis case
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here is the `create.py` script that defines the structure of the topology:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Running the topology – the Redis case
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have a few more small things to address before we run the topology:'
  prefs: []
  type: TYPE_NORMAL
- en: Copy the `logconfig.ini` file from the second example in [Chapter 3](ch03.html
    "Chapter 3. Introducing Petrel"), *Introducing Petrel*, to this topology's directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a file called `setup.sh`. Petrel will package this script with the topology
    and run it at startup. This script installs the third-party Python libraries used
    by the topology. The file looks like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a file called `manifest.txt` with these two lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Install the Redis server on a well-known node. All workers will store state
    here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Install the Python Redis client on all Storm worker machines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Before running the topology, let''s review the list of files that we''ve created.
    Make sure you have created these files correctly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`topology.yaml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`twitterstream.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`splitsentence.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rollingcount.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`totalrankings.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`manifest.txt`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`setup.sh`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Run the topology with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the topology is running, open another terminal in the topology directory.
    Enter this command to see the log file for the total rankings bolt, sorted from
    oldest to newest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'If this is the first time you are running the topology, there will be only
    one log file listed. A new file is created for each run. If there are several
    listed, choose the most recent one. Enter this command to monitor the contents
    of the log file (the exact filename will be different on your system):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Periodically, you will see an output like the following, listing the top 5
    words in descending order of popularity:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Example output from `totalrankings`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Finding the hourly count of tweets by city name using MongoDB
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: MongoDB is a popular database for storing large amounts of data. It is designed
    for easy scalability across many nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run this topology, you first need to install MongoDB and configure some
    database-specific settings. This example uses a MongoDB database called `cities`
    with a collection named `minute`. In order to compute the counts by city and minute,
    we must create a unique index on the `cities.minute` collection. To do this, launch
    the MongoDB command-line client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a unique index on the `cities.minute` collection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This index stores a per minute time series of city counts in MongoDB. After
    running the example topology to capture some data, we'll run a standalone command-line
    script (`city_report.py`) to sum the per minute city counts by hour and city.
  prefs: []
  type: TYPE_NORMAL
- en: This is a variant of the earlier Twitter topology. This example uses the Python
    geotext library ([https://pypi.python.org/pypi/geotext](https://pypi.python.org/pypi/geotext))
    to find city names in tweets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an overview of the topology:'
  prefs: []
  type: TYPE_NORMAL
- en: Read the tweets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Split them into words and find city names.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In MongoDB, count the number of times a city is mentioned each minute.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Twitter stream spout (`twitterstream.py`): This reads tweets from the Twitter
    sample stream.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'City count bolt (`citycount.py`): This finds city names and writes to MongoDB.
    It is similar to the `SplitSentenceBolt` from the Twitter sample, but after splitting
    by words, it looks for city names.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `_get_words()` function here is slightly different from earlier examples.
    This is because geotext does not recognize lowercase strings as city names.
  prefs: []
  type: TYPE_NORMAL
- en: It creates or updates MongoDB records, taking advantage of the unique index
    on minute and city to accumulate the per minute counts.
  prefs: []
  type: TYPE_NORMAL
- en: This is a common pattern for representing time series data in MongoDB. Each
    record also includes an `hour` field. The `city_report.py` script uses this to
    compute the hourly counts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter this code in `citycount.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Defining the topology – the MongoDB case
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Enter the following code in `create.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Running the topology – the MongoDB case
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have a few more small things to address before we run the topology:'
  prefs: []
  type: TYPE_NORMAL
- en: Copy the `logconfig.ini` file from the second example in [Chapter 3](ch03.html
    "Chapter 3. Introducing Petrel"), *Introducing Petrel* to this topology's directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a file called `setup.sh`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Next, create a file called `manifest.txt`. This is identical to the Redis example.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install the MongoDB server. On Ubuntu, you can use the instructions given at
    [http://docs.mongodb.org/manual/tutorial/install-mongodb-on-ubuntu/](http://docs.mongodb.org/manual/tutorial/install-mongodb-on-ubuntu/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Install the Python MongoDB client on all Storm worker machines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'To verify that `pymongo` is installed and the index is created correctly, start
    an interactive Python session by running `python`. Then use this code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output. The second line is the index that we added:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, install `geotext`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Before running the topology, let''s review the list of files that we created.
    Make sure you have created these files correctly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`topology.yaml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`twitterstream.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`citycount.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`manifest.txt`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`setup.sh`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Run the topology with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The `city_report.py` file is a standalone script that generates a simple hourly
    report from the data inserted by the topology. This script uses MongoDB aggregation
    to compute the hourly totals. As noted earlier, the report depends on the presence
    of an `hour` field.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter this code in `city_report.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we saw how to use two popular NoSQL storage engines (Redis
    and MongoDB) with Storm. We also showed you how to create data in a topology and
    access it from other applications, demonstrating that Storm can be an effective
    part of an ETL pipeline.
  prefs: []
  type: TYPE_NORMAL

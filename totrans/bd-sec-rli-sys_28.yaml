- en: Chapter 21\. Building a Culture of Security and Reliability
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第21章。建立安全和可靠性文化
- en: By Heather Adkins
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 作者：Heather Adkins
- en: with Peter Valchev, Felix Gröbert, Ana Oprea, Sergey Simakov, Douglas Colish,
    and Betsy Beyer
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 与Peter Valchev，Felix Gröbert，Ana Oprea，Sergey Simakov，Douglas Colish和Betsy Beyer一起
- en: Effective security and reliability flourish when organizations embrace their
    importance by building a culture around these fundamentals. Organizations that
    explicitly design, implement, and maintain the culture they seek to embody achieve
    success by making culture a team effort—the responsibility of everyone, from the
    CEO and their leadership team, to technical leaders and managers, to the people
    who design, implement, and maintain systems.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 当组织围绕这些基本原则建立文化时，有效的安全和可靠性就会蓬勃发展。明确设计、实施和维护他们希望体现的文化的组织通过使文化成为团队努力的一部分——从CEO及其领导团队，到技术领导和经理，再到设计、实施和维护系统的人员，取得成功。
- en: 'Imagine this scenario: just last week, the CEO told your entire organization
    that getting the next Big Deal was critical to the future of the company. This
    afternoon, you found evidence of an attacker on the company’s systems, and you
    know these systems will have to be taken offline. Customers are going to be angry,
    and the Big Deal may be at risk. You also know that your team may get blamed for
    not applying security patches last month, but a lot of people were on vacation
    and everyone is under tight deadlines for the Big Deal. What kinds of decisions
    does your company culture support employees making in this situation? A healthy
    organization with a strong security culture would encourage employees to report
    the incidents immediately despite the risk of delaying the Big Deal.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下这种情况：就在上周，CEO告诉整个组织，获得下一个重大交易对公司的未来至关重要。今天下午，你发现公司系统中有攻击者的证据，你知道这些系统将不得不被下线。客户将会生气，重大交易可能会受到威胁。你也知道你的团队可能会因为上个月没有应用安全补丁而受到责备，但很多人都在度假，每个人都在为重大交易的紧迫期限而努力。在这种情况下，你的公司文化支持员工做出什么样的决定？一个具有强大安全文化的健康组织会鼓励员工立即报告事故，尽管这可能会延误重大交易。
- en: Suppose that at the same time you’re investigating the malicious interloper,
    the frontend development team accidently pushes a significant change intended
    for staging to the live production system. The error takes the company’s revenue
    stream offline for over an hour, and customers are overwhelming the support helpline.
    The trust of your customer base is quickly eroding. A culture of reliability would
    encourage employees to redesign the process that allowed an accidental frontend
    push, so that teams can manage the needs of customers and the risk of missing
    or delaying the Big Deal.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 假设与此同时，你正在调查恶意闯入者，前端开发团队意外地将一个重大更改推送到了实时生产系统。这个错误导致公司的收入流下线了一个多小时，客户不断打爆了支持热线。你的客户基础的信任正在迅速侵蚀。一个可靠性文化会鼓励员工重新设计允许意外前端推送的流程，以便团队可以管理客户的需求和错过或延误重大交易的风险。
- en: In these situations, cultural norms should encourage blameless postmortems to
    uncover patterns of failure that can be fixed, thereby avoiding harmful conditions
    in the future.^([1](ch21.html#ch21fn1)) Companies with healthy cultures know that
    getting hacked once is very painful, but getting hacked twice is even worse. Similarly,
    they know that 100% is never the right reliability target; using tools like error
    budgets^([2](ch21.html#ch21fn2)) and controls around safe code pushes can keep
    users happy by striking the right balance between reliability and velocity. Finally,
    companies with a healthy security and reliability culture know that in the long
    term, customers appreciate transparency when incidents inevitably occur, and that
    hiding such incidents can erode user trust.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，文化规范应该鼓励无过失的事后分析，以发现可以修复的失败模式，从而避免将来出现有害条件。健康文化的公司知道，被黑客入侵一次是非常痛苦的，但被黑客入侵两次甚至更糟。同样，他们知道100%永远不是正确的可靠性目标；使用诸如错误预算之类的工具以及围绕安全代码推送的控制可以通过在可靠性和速度之间取得正确的平衡来让用户满意。最后，具有健康安全和可靠性文化的公司知道，从长远来看，客户在不可避免地发生事故时会欣赏透明度，并且隐藏此类事故可能会侵蚀用户的信任。
- en: This chapter describes some patterns and anti-patterns for building a culture
    of security and reliability. While we hope that this information will be helpful
    to organizations of all shapes and sizes, culture is a unique element of an organization,
    crafted in the context of its particular challenges and features. No two organizations
    will have the same culture, and not all of the advice we provide here may be applicable
    to everyone. This is a chapter meant to provide a range of ideas on the topic
    of culture, but it’s unlikely that every organization will be able to adopt all
    of the practices we discuss. The somewhat idealized view we present here won’t
    be wholly practical in real-world situations. At Google too, we don’t get culture
    right all the time, and we’re constantly seeking to improve upon the status quo.
    We hope that from among the wide range of viewpoints and options presented here,
    you’ll find some that may work in your environment.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章描述了建立安全和可靠性文化的一些模式和反模式。虽然我们希望这些信息对各种规模和形式的组织都有所帮助，但文化是组织的独特元素，在其特定挑战和特征的背景下塑造。没有两个组织会有相同的文化，我们在这里提供的建议也不一定适用于所有人。这一章旨在提供关于文化主题的一系列想法，但在现实世界的情况下，我们提出的有些理想化观点可能并不完全实用。即使在谷歌，我们也并不总是能够做到文化正确，我们不断努力改进现状。我们希望在这里提出的广泛观点和选择中，你能找到一些适合你的环境的观点。
- en: Defining a Healthy Security and Reliability Culture
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义健康的安全和可靠性文化
- en: Like healthy systems, a healthy team culture can be explicitly designed, implemented,
    and maintained. Throughout this book, we’ve focused on the technical and process
    components of building healthy systems. Design principles for building healthy
    cultures exist as well. In fact, culture is a core component of designing, implementing,
    and maintaining secure and reliable systems.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Culture of Security and Reliability by Default
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we discuss in [Chapter 4](ch04.html#design_tradeoffs), it’s often tempting
    to delay considering security and reliability until the later stages of a project’s
    lifecycle. This postponement appears to accelerate initial velocity, but it does
    so at the expense of sustained velocity and a potentially increased cost of retrofits.
    Over time, these retrofits can increase technical debt or be applied inconsistently,
    leading to failure. To illustrate this point, imagine that when buying a car,
    you had to separately seek out a seat belt vendor, someone to review the safety
    of the car’s windshield, and an inspector to validate the airbags. Addressing
    safety and reliability concerns only *after* manufacturing a car would place a
    high burden on the consumer, who may not be in the best position to assess whether
    the solutions implemented are sufficient. It could also lead to inconsistent practices
    between any two manufactured cars.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: 'This analogy reflects the need for systems to be *secure and reliable by default*.
    When security and reliability choices are made throughout the lifecycle of a project,
    it’s easier to maintain consistency. Also, when these are integrated parts of
    the system, they can become invisible to the consumer. To return to the car analogy:
    consumers don’t need to give much thought to safety mechanisms like seat belts,
    windshields, or rear-view cameras to trust that they do the right thing.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Organizations with healthy cultures of by-default security and reliability encourage
    employees to discuss such topics early in the project lifecycle—for example, during
    the design stage—and throughout each iteration of implementation. As products
    mature, their security and reliability will continue to mature organically as
    well; this is formalized into the software development lifecycle.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Such a culture makes it easier for people designing, maintaining, and implementing
    systems to incorporate the themes of security and reliability automatically and
    transparently. For example, you can introduce automation for continuous builds,
    sanitizers, vulnerability discovery, and testing. Application frameworks and common
    libraries can help developers avoid common vulnerabilities like XSS and SQL injection.
    Guidance around choosing the appropriate programming languages or programming
    language features can help avoid memory corruption errors. This kind of automatic
    security aims to reduce friction (such as slow code audits) and errors (bugs not
    spotted during review), and should be relatively transparent to developers. As
    systems mature within these security and reliability constructs, ideally, employees
    will increasingly trust these implementations.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: We provide some insight into the evolution of creating a culture of security
    and reliability by default at Google in Chapters [12](ch12.html#writing_code),
    [13](ch13.html#onethree_testing_code), and [19](ch19.html#onenine_case_study_chrome_security_team).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Culture of Review
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When a strong review culture is in place, everyone is encouraged to think ahead
    of time about their role in approving changes. This can bolster the ongoing security
    and reliability properties of the system by ensuring that changes take these special
    considerations into account. Peer reviews to ensure the security and reliability
    features of a system apply in a variety of change scenarios, such as these:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Multi-party authorization reviews for access or changes to maintain least privilege
    (see [Chapter 5](ch05.html#design_for_least_privilege))
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Peer reviews to ensure that code changes are appropriate and of high quality,
    including security and reliability considerations (see [Chapter 12](ch12.html#writing_code))
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同行审查以确保代码更改是适当的和高质量的，包括安全性和可靠性考虑
- en: Peer reviews of configuration changes before they are pushed to production systems
    (see [Chapter 14](ch14.html#onefour_deploying_code))
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在将配置更改推送到生产系统之前进行同行审查
- en: Building such a culture requires a broad understanding across the organization
    about the value of the reviews and how to carry them out.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 建立这样的文化需要组织内对审查的价值以及如何进行审查有广泛的理解。
- en: Change review practices should be documented to set clear expectations about
    what will happen during the review. For example, for peer code reviews, you might
    document the organization’s engineering practices related to code review and educate
    all new developers about these expectations.^([3](ch21.html#ch21fn3)) When requiring
    peer review for multi-party authorization schemes (as described in [Chapter 5](ch05.html#design_for_least_privilege)),
    document when access will be granted and under what conditions it might be refused.
    This establishes a common cultural set of expectations across the organization,
    so that only valid approval requests will succeed. Similarly, you should set expectations
    that if an approver denies a request, the reasons are understandable based on
    the documented policy, to avoid hard feelings between people and creating an “us
    versus them” mentality.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 变更审查实践应该被记录下来，以明确期望在审查期间会发生什么。例如，对于同行代码审查，您可以记录组织与代码审查相关的工程实践，并教育所有新开发人员了解这些期望。当要求同行审查多方授权方案时，记录何时将授予访问权限以及在什么条件下可能会被拒绝。这在组织内建立了一套共同的文化期望，因此只有有效的批准请求才会成功。同样，您应该设定期望，如果批准者拒绝请求，原因是可以理解的，基于记录的政策，以避免人与人之间的矛盾和产生“我们与他们”的心态。
- en: The corollary to documentation is to educate reviewers so they understand the
    baseline expectations for being a reviewer. This education can happen early on,
    during onboarding to the organization or a project. Consider onboarding new reviewers
    through an apprenticeship scheme, in which a more experienced or calibrated reviewer
    also looks over the change.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 与文档的相关性是教育审查者，使他们了解成为审查者的基本期望。这种教育可以在组织或项目的入职期间早期进行。考虑通过见习计划来培养新的审查者，其中更有经验或校准的审查者也会审查变更。
- en: A culture of review requires everyone to participate in the review processes.
    While owners are responsible for ensuring the overall direction and standards
    of their respective areas, they too should be individually held accountable for
    the changes they initiate. No one should be able to opt out of a review simply
    because they have a senior role or don’t want to participate. The owner of a code
    tree isn’t exempt from having their code and configuration changes reviewed. In
    the same way, system owners aren’t exempted from participating in multi-party
    authorization for logins.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 审查文化要求每个人都参与审查流程。虽然所有者负责确保其各自领域的整体方向和标准，但他们也应该个别对他们发起的变更负责。没有人应该能够选择退出审查，仅仅因为他们担任高级职位或不想参与。代码树所有者不免于对其代码和配置更改进行审查。同样，系统所有者也不能豁免参与多方登录授权的审批。
- en: Ensure that reviewers have the context necessary to make decisions, and have
    the option to decline or redirect a review if they lack enough context to accurately
    assess whether the change is safe. This is especially important when reviewing
    the security and reliability properties of an access request, such as multi-party
    authorization, or changes to code snippets with safety implications. If the reviewer
    is not familiar with the kinds of pitfalls to look out for, then the review will
    not act as a sufficient control. Automated checks can assist with building this
    context. For example, in [Chapter 13](ch13.html#onethree_testing_code) we discussed
    how Google uses [Tricorder](https://oreil.ly/rdYsN) to automatically raise security
    issues for developers and reviewers in the presubmit phase of code changes.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 确保审查者具有做出决策所需的上下文，并且可以拒绝或重定向审查，如果他们缺乏足够的上下文来准确评估变更是否安全。当审查安全性和可靠性属性时，这一点尤为重要，例如多方授权的访问请求，或者具有安全影响的代码片段的更改。如果审查者不熟悉要注意的陷阱，那么审查将不起到足够的控制作用。自动化检查可以帮助建立这种上下文。例如，在第13章中，我们讨论了Google如何在代码更改的预提交阶段使用Tricorder自动提出开发人员和审查者的安全问题。
- en: Culture of Awareness
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 意识文化
- en: When members of an organization are aware they have security and reliability
    responsibilities, and know how to carry them out, they can be effective in achieving
    good outcomes. For example, an engineer may need to take extra steps to keep their
    account secure because they access sensitive systems. Someone whose job entails
    frequent communication with external parties may receive more phishing emails.
    An executive may be at higher risk when they travel to certain parts of the world.
    Organizations with healthy cultures build awareness of these kinds of conditions
    and reinforce it through educational programs.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 当组织成员意识到他们有安全和可靠性责任，并知道如何履行这些责任时，他们可以有效地实现良好的结果。例如，工程师可能需要采取额外措施来保护他们的帐户安全，因为他们访问敏感系统。那些工作需要频繁与外部方进行沟通的人可能会收到更多的钓鱼邮件。高管在前往世界某些地区时可能面临更高的风险。具有健康文化的组织会增强对这些条件的意识，并通过教育项目加以强化。
- en: Awareness and education strategies are key to building a strong security culture.
    These initiatives should strive to be lighthearted and fun so that learners are
    interested in the content. People retain different types of information at different
    rates depending on how that information is conveyed, their existing familiarity
    with the material, and even personal factors like age and background. In our experience,
    many learners have a higher retention rate with interactive methods of learning
    like hands-on labs than with passive learning methods like watching a video. When
    building awareness, optimize for the best learning experience by carefully considering
    what types of information you want people to retain and how you want them to learn.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: 'Google takes several approaches to educating employees about security and reliability.
    On a broad scale, we provide mandatory annual training for all employees. We then
    reinforce these messages through specialty programs for certain roles. Here are
    some tactics we’ve found useful over years of implementing these programs at Google:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Interactive talks
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Talks that encourage audience participation can be a way of relaying complex
    information in a compelling way. For example, at Google, sharing top root causes
    and mitigations for significant security and reliability incidents has helped
    our employees better understand why we focus on these topics. We’ve found that
    these types of interactive discussions also encourage people to raise issues they
    find, from suspicious activity on their workstations to buggy code that could
    take systems down. This practice helps people feel like they’re part of the team
    that makes the organization more reliable and secure.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Games
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Gamifying security and reliability is another way to build awareness. These
    methods tend to scale more effectively to larger organizations, which may be better
    able to give players flexibility around when they take the training and an option
    to retake it if they want. Our [XSS game](https://xss-game.appspot.com) (shown
    in [Figure 21-1](#a_security_training_game)) has been quite successful in teaching
    developers about this common web application vulnerability.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '![A security training game](assets/bsrs_2101.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
- en: Figure 21-1\. A security training game
  id: totrans-35
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Reference documentation
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Reading documentation may have a lower retention rate for learning than methods
    like hands-on exercises, but we’ve found that it’s critically important to provide
    developers with strong documentation they can reference when needed. As we note
    in [Chapter 12](ch12.html#writing_code), reference documentation is important
    because it’s difficult to keep the numerous nuances of security and reliability
    in one’s mind simultaneously. For guidance on common security problems, Google
    maintains a set of internal security best practices that engineers can search
    for answers to problems as they arise.^([5](ch21.html#ch21fn5)) All documentation
    should have clear ownership and be kept up to date or deprecated when it’s not
    relevant anymore.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Awareness campaigns
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: It can be hard to notify developers about recent security and reliability issues
    and developments. To tackle this, Google publishes weekly engineering advice in
    a one-page format ([Figure 21-2](#an_episode_of_testing_on_the_toilet) shows an
    example). These [“Testing on the Toilet”](https://oreil.ly/cO_P8) episodes are
    distributed to restrooms throughout all Google offices. While initially aimed
    at improving testing, the program also occasionally features security and reliability
    topics. A flyer posted in an unavoidable location is a good way to present tips
    and provide inspiration.^([6](ch21.html#ch21fn6))
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '![An episode of Testing on the Toilet](assets/bsrs_2102.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
- en: Figure 21-2\. An episode of Testing on the Toilet
  id: totrans-41
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Just-in-time notifications
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Especially during procedural steps (like checking in code or upgrading software),
    you may want to remind people of good security and reliability practices. Showing
    just-in-time notifications to people in these situations can help them make better
    risk decisions. At Google, we have experimented with showing pop-ups and hints
    in the moment—for example, when employees are upgrading software from an untrusted
    repository or trying to upload sensitive data to unapproved cloud storage systems.
    When users see alerts in real time when it matters, they can make better decisions
    for themselves and avoid mistakes.^([7](ch21.html#ch21fn7)) On a related note,
    as we discuss in [Chapter 13](ch13.html#onethree_testing_code), presenting developers
    with presubmit security and reliability hints helps them make better choices when
    developing code.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是在程序步骤中（比如检查代码或升级软件），您可能希望提醒人们遵循良好的安全和可靠性实践。在这些情况下向人们显示及时通知可以帮助他们做出更好的风险决策。在谷歌，我们已经尝试在关键时刻向员工显示弹出窗口和提示，例如当员工从不受信任的存储库升级软件或尝试将敏感数据上传到未经批准的云存储系统时。当用户在关键时刻看到警报时，他们可以为自己做出更好的决策，避免错误。另外，正如我们在第13章中讨论的那样，在开发代码时向开发人员提供预提交的安全和可靠性提示有助于他们做出更好的选择。
- en: Culture of Yes
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 肯定文化
- en: 'Over time, organizations can develop a conservative risk culture, especially
    if security breaches or reliability issues have led to revenue loss or other bad
    outcomes. In an extreme form, this mindset can lead to a *culture of no*: the
    inclination to avoid risky changes and the negative consequences they might entail.
    When perpetuated in the name of security or reliability, a culture of no can cause
    an organization to stagnate, and even fail to innovate. We’ve found that healthy
    organizations have a way to work through the challenge of saying “yes” when taking
    advantage of an opportunity requires some amount of risk—that is, to take risks
    deliberately. To embrace risk in this way, you typically need to be able to assess
    and measure it.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，组织可能会形成保守的风险文化，特别是如果安全漏洞或可靠性问题导致收入损失或其他不良结果。在极端情况下，这种心态可能导致“否定文化”：倾向于避免风险变化和可能带来的负面后果。当以安全或可靠性的名义延续时，“否定文化”可能导致组织停滞甚至无法创新。我们发现健康的组织有一种方式来应对在利用机会时需要一定风险的挑战，即有意识地冒险。要以这种方式拥抱风险，通常需要能够评估和衡量风险。
- en: As a concrete example, in [Chapter 8](ch08.html#design_for_resilience) we describe
    the approach used to secure Google App Engine, a platform that proposed running
    third-party unverified code. In this situation, Google’s security team could have
    judged the launch as too risky. After all, running arbitrary untrusted code is
    a fairly well-known security risk. You don’t know, for instance, if the third
    party managing the code might be malicious and try to escape from the platform’s
    execution environment and compromise your infrastructure. To address this risk,
    we embarked on an ambitious collaboration between the product and security teams
    to produce a layered, hardened system, which allowed us to launch a product that
    would have otherwise seemed too dangerous. This kind of collaboration made it
    easier to build additional security into the platform over time, since there was
    an established base of trust between the teams.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个具体的例子，在第8章中，我们描述了用于保护谷歌应用引擎的方法，这是一个提议运行第三方未经验证代码的平台。在这种情况下，谷歌的安全团队可能会认为这次发布过于冒险。毕竟，运行任意不受信任的代码是一个相当众所周知的安全风险。例如，您不知道管理代码的第三方是否可能是恶意的，并尝试逃离平台的执行环境并危害您的基础设施。为了解决这个风险，我们展开了一项雄心勃勃的产品和安全团队之间的合作，制定了一个分层、加固的系统，这使我们能够推出一个在其他情况下看起来太危险的产品。这种合作使得随着时间的推移更容易在平台中构建额外的安全性，因为团队之间建立了信任基础。
- en: Another approach to embracing risk is to use [error budgets](https://oreil.ly/gd3MY),
    which allow for failures up to a certain limit. Once the organization reaches
    a predetermined maximum limit, teams are expected to collaborate to reduce risk
    to normal levels. Because the error budget maintains an emphasis on security and
    reliability throughout the product’s lifecycle, innovators have the freedom to
    introduce a certain number of risky changes.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种拥抱风险的方法是使用错误预算，它允许在一定限制内发生故障。一旦组织达到预定的最大限制，团队就应该合作减少风险至正常水平。由于错误预算在产品的整个生命周期中始终强调安全和可靠性，创新者有自由引入一定数量的风险变化。
- en: Culture of Inevitably
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不可避免的文化
- en: No system is perfect, and any system may eventually fail. At some point, your
    organization will likely experience a service outage or a security incident. Embracing
    this inevitability can help teams have the appropriate frame of mind to build
    secure and reliable systems and respond to failures.^([8](ch21.html#ch21fn8))
    At Google, we assume failure can happen at any time—not because we aren’t diligent
    about proactive measures or because we lack confidence in our systems, but because
    we know that real-world systems can never be 100% secure and reliable.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 没有系统是完美的，任何系统最终都可能失败。在某个时候，您的组织可能会经历服务中断或安全事件。接受这种不可避免性可以帮助团队有适当的心态来构建安全可靠的系统并应对失败。在谷歌，我们假设失败可能随时发生，这不是因为我们不积极采取预防措施或因为我们对系统缺乏信心，而是因为我们知道现实世界的系统永远无法百分之百安全可靠。
- en: '[Chapter 16](ch16.html#onesix_disaster_planning) discusses the need to prepare
    for the inevitable. Teams that embrace a culture of inevitability dedicate time
    to prepare for disasters so they can respond effectively. They talk openly about
    the possibilities for failure and set time aside to simulate these scenarios.
    Incident response skills are effective only when you use them regularly, so it’s
    a good idea to use exercises such as tabletops, Red Team attacks, hands-on recovery
    tests, and [disaster role playing](https://oreil.ly/hyDi_) to test and refine
    your organization’s processes. Organizations that embrace the inevitable also
    study any failures that do occur, including within their peer groups. Internally,
    they use blameless postmortems—discussed in [Chapter 18](ch18.html#oneeight_recovery_and_aftermath)
    of this book and in [Chapter 15 of the SRE book](https://landing.google.com/sre/sre-book/chapters/postmortem-culture/)—to
    reduce the fear of failure and build confidence that repeated events will be unlikely.
    They also make use of after-action reports published by other organizations, both
    within and outside of their industry. These reports provide a broader understanding
    of failure scenarios that may be relevant to the organization.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 第16章讨论了为不可避免的情况做准备的必要性。接受不可避免文化的团队会花时间准备灾难，以便能够有效地做出反应。他们公开讨论可能的失败，并留出时间来模拟这些情景。只有经常使用事故应对技能才有效，因此使用桌面练习、红队攻击、实际恢复测试和灾难角色扮演等练习来测试和完善组织的流程是个好主意。接受不可避免的组织也研究任何发生的失败，包括在同行群体内部。在内部，他们使用无过失的事后分析来减少失败的恐惧，并建立重复事件不太可能发生的信心。他们还利用其他组织发布的事后行动报告，无论是在其行业内部还是外部，这些报告提供了对可能与组织相关的失败情景的更广泛理解。
- en: Culture of Sustainability
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可持续文化
- en: In order to sustain the reliability and security features of a system in the
    long term, your organization must ensure that efforts to improve them are made
    continuously—and dedicate sufficient resources (staff and time) to the task. Sustainability
    requires building the means to handle outages, security incidents, and other emergencies
    on an ongoing basis, using clearly defined processes.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了长期保持系统的可靠性和安全性特性，您的组织必须确保持续努力改进，并投入足够的资源（人员和时间）来完成这项任务。可持续性要求建立处理中断、安全事件和其他紧急情况的手段，并使用明确定义的流程。
- en: To maintain this effort, teams must be able to balance the time spent on reactive
    work versus proactive investments that will pay off over the long term. To recall
    our example of the California Department of Forestry and Fire Protection from
    [Chapter 17](ch17.html#oneseven_crisis_management), effective teams allocate the
    burden of hard work across many people’s shoulders so that no one person is saddled
    with excessive responsibility.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持这种努力，团队必须能够平衡在应对性工作和长期投资之间所花费的时间。回想一下我们在第17章中提到的加利福尼亚州林业和消防局的例子，有效的团队将艰苦的工作分摊到许多人的肩上，以免任何一个人承担过多的责任。
- en: Organizations with a *culture of sustainability* measure the workloads necessary
    to handle operational work (for example, incident response^([10](ch21.html#ch21fn10)))
    as well as the investments required to make improvements over time.^([11](ch21.html#ch21fn11))
    They consider stress, burnout, and morale in their planning, adding sufficient
    resources to sustain long-term efforts or deferring work where necessary through
    prioritization. They avoid the need for heroics by setting up repeatable and predictable
    processes for handling emergencies and rotating the staff who handle emergencies
    regularly. They also proactively handle morale issues by surfacing individuals’
    concerns and continuously motivating people.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有“可持续文化”的组织衡量处理运营工作（例如事故应对）所需的工作量，以及随着时间推移所需的改进投资。他们在规划中考虑压力、倦怠和士气，通过优先级确定足够的资源来支持长期努力或推迟必要的工作。他们通过建立可重复和可预测的应对紧急情况的流程，并定期轮换处理紧急情况的员工，避免了英雄主义的需要。他们还通过提出个人关注并持续激励人们来主动处理士气问题。
- en: Having a culture of sustainably also means knowing that sometimes exceptional
    circumstances can cause temporary deviations from expected workloads, and having
    good processes to handle those deviations. For example, if multiple business-critical
    systems haven’t met their SLOs for a long period of time, or a serious security
    breach results in an extraordinary response effort, you may need an “all hands
    on deck” effort to get things back on track. During this time, teams may be entirely
    devoted to operational work and improving security or reliability. While you might
    have to defer all other organizational work, you may also have to deviate from
    best practices.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有可持续文化的组织也意味着知道有时特殊情况可能会导致暂时偏离预期工作量，并具有处理这些偏差的良好流程。例如，如果多个业务关键系统长时间未达到其SLO，或者严重的安全漏洞导致了非同寻常的应对工作，您可能需要“全员上阵”来使事情重新回到正轨。在这段时间内，团队可能完全致力于运营工作和提高安全性或可靠性。虽然您可能不得不推迟所有其他组织工作，但您也可能不得不偏离最佳实践。
- en: 'In healthy organizations, such extraordinary disruptions of normal business
    operations should be rare. When navigating these situations, the following considerations
    can help maintain a culture of sustainability once the situation is resolved:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在健康的组织中，这种正常业务运营的特殊干扰应该是罕见的。在处理这些情况时，以下考虑因素可以帮助在情况解决后保持可持续文化：
- en: When operating outside of normal operations, be sure to clarify that the situation
    is temporary. For example, if you require all developers to manually supervise
    the changes they push to production (instead of only using automated systems),
    this might cause a lot of toil and unhappiness in the long term. Make clear that
    you expect the situation to return to normal soon, and give an idea of when that
    will happen.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在正常运营之外操作时，一定要澄清情况是暂时的。例如，如果你要求所有开发人员手动监督他们推送到生产环境的更改（而不仅仅使用自动化系统），这可能会在长期内造成很多辛苦和不快乐。明确表示你期望情况很快恢复正常，并给出何时会发生的想法。
- en: Have a dedicated group on standby that has an understanding of the risk landscape
    and the authority to make decisions quickly. For example, this group might grant
    exceptions to standard security and reliability procedures. This will reduce friction
    in execution, while giving the organization some assurance that safety mechanisms
    are still in place. Have a way to flag the times you had to bypass or overturn
    best practices, and be sure to address those one-offs later.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有一个专门的待命小组，他们了解风险情况并有权迅速做出决策。例如，这个小组可能会对标准的安全和可靠性程序进行例外授权。这将减少执行中的摩擦，同时给组织一些保证，即安全机制仍然存在。有一种方法来标记你不得不绕过或推翻最佳实践的时候，并确保以后解决这些一次性事件。
- en: When the event is complete, be sure that your postmortem reviews the reward
    system that may have led to the emergency. Sometimes, cultural issues like prioritizing
    feature launch over reliability or security features can lead to a build-up of
    technical debt. Addressing such issues proactively going forward will help the
    organization return to a cadence of sustainability.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 活动结束后，一定要确保你的事后审查了可能导致紧急情况的奖励制度。有时，像优先考虑功能发布而不是可靠性或安全功能的文化问题可能会导致技术债务的积累。积极解决这些问题将有助于组织恢复到可持续的节奏。
- en: Changing Culture Through Good Practice
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过良好实践改变文化
- en: 'Affecting organizational culture can be difficult, especially if the team or
    project you’re working on is well established. It’s not uncommon for an organization
    to want to make security and reliability improvements, but find that cultural
    obstacles stand in the way. Counterproductive cultures exist for many reasons:
    leadership approaches, starvation of resources, and more.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 影响组织文化可能很困难，特别是如果你正在处理的团队或项目已经很成熟。组织通常希望进行安全和可靠性改进，但发现文化障碍阻碍了前进。文化的反生产存在很多原因：领导方法、资源匮乏等。
- en: A common element of resistance to change—the kind of change necessary for security
    and reliability improvements—is fear. Change can conjure images of chaos, greater
    friction, loss of productivity and control, and increased risk. In particular,
    the topic of friction frequently surfaces in relation to new reliability and security
    controls. New access checks, processes, and procedures can be interpreted as interfering
    with developer or operational productivity. When organizations face tight deadlines
    and high expectations to deliver, either self-imposed or driven by management,
    fear of these new controls can heighten concerns. However, in our opinion, the
    belief that security and reliability improvements have to create friction is a
    myth. If you implement change with certain cultural considerations in mind, we
    believe these changes can actually improve everyone’s experience.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对于改变的抵制的一个常见因素——安全和可靠性改进所必需的改变——是恐惧。改变可能会引发混乱、更大的摩擦、生产力和控制的丧失，以及风险的增加。特别是，摩擦的话题经常与新的可靠性和安全控制相关联。新的访问检查、流程和程序可能被解释为干扰开发人员或运营生产力。当组织面临紧迫的截止日期和高期望交付，无论是自我设定的还是由管理层推动的，对这些新控制的恐惧可能加剧担忧。然而，我们认为，安全和可靠性改进必须造成摩擦的信念是一个谬论。如果你在实施改变时考虑了某些文化因素，我们相信这些改变实际上可以改善每个人的体验。
- en: This section discusses some technical strategies to introduce change that may
    be useful even in the most difficult cultures. You may not be the CEO or a leader
    in your organization, but every developer, SRE, and security professional is an
    instrument of change in their own sphere of influence. By making conscious choices
    about how you design, implement, and maintain systems, it is possible to have
    a positive effect on your organization’s culture; by choosing certain strategies,
    you may find that over time you can turn the tide by building trust and goodwill.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 本节讨论了一些技术策略，介绍了一些即使在最困难的文化中也可能有用的改变。你可能不是你组织中的CEO或领导，但每个开发人员、SRE和安全专业人员都是他们自己影响领域中的变革工具。通过有意识地选择你设计、实施和维护系统的方式，有可能对你组织的文化产生积极影响；通过选择某些策略，你可能会发现随着时间的推移，你可以通过建立信任和善意来扭转局势。
- en: The advice we give in this section is based on that goal—but culture is something
    developed over a long period of time, and it’s highly dependent on the people
    and situations involved. When trying out some of the strategies outlined here
    in your organization, you may find they meet with only limited success, and some
    strategies may not work at all. Some cultures are static and resistant to change.
    Yet having a healthy culture that values security and reliability can be just
    as important as how you design, implement, and maintain your systems, so the fact
    that your efforts might not always work shouldn’t stop you from trying.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节中给出的建议是基于这个目标的——但文化是经过长时间发展的，并且高度依赖于涉及的人和情况。当你在你的组织中尝试这里概述的一些策略时，你可能会发现它们只能取得有限的成功，有些策略可能根本行不通。有些文化是静态的，抵制改变。然而，拥有一个重视安全和可靠性的健康文化和你设计、实施和维护系统一样重要，所以你的努力可能并不总是奏效不应该阻止你尝试。
- en: Align Project Goals and Participant Incentives
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对齐项目目标和参与者激励
- en: It takes hard work to build trust, but it’s quite easy to lose it. In order
    for people who design, implement and maintain systems to collaborate across multiple
    roles, they need to share a common reward system.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 建立信任需要艰苦的工作，但失去信任却很容易。为了让设计、实施和维护系统的人能够跨越多个角色进行合作，他们需要共享一个共同的奖励体系。
- en: On a technical level, the reliability and safety of a project can be evaluated
    regularly through observable metrics like [SLOs](https://oreil.ly/m9rU1) and threat
    modeling (for examples, see Chapters [2](ch02.html#understanding_adversaries)
    and [14](ch14.html#onefour_deploying_code)). On a process and people level, you
    should make sure that career advancement opportunities reward security and reliability.
    Ideally, individuals should be evaluated according to high-level documented expectations.
    These shouldn’t be just a set of checkboxes to tick—they should highlight themes
    and goals that individuals should aspire to meet. For example, the entry-level
    Google software engineering job ladder specifies that engineers should master
    at least one common skill outside of core coding, like adding monitoring to their
    services or writing security tests.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在技术层面上，项目的可靠性和安全性可以通过可观察的指标（如[SLOs](https://oreil.ly/m9rU1)和威胁建模）定期评估（例如，参见[第2章](ch02.html#understanding_adversaries)和[第14章](ch14.html#onefour_deploying_code)）。在流程和人员层面上，你应该确保职业晋升机会奖励安全性和可靠性。理想情况下，个人应该根据高层次的文件化期望进行评估。这些不应该只是一组要勾选的复选框，它们应该突出个人应该努力达到的主题和目标。例如，谷歌的入门级软件工程师职位阶梯规定工程师应该掌握至少一项核心编码之外的常见技能，比如为他们的服务添加监控或编写安全测试。
- en: Aligning project goals with your organization’s strategy without aligning participant
    incentives might result in an unfriendly culture, whereby the people focused on
    improving the security and reliability of your products are not the ones who tend
    to get promoted. Since financial rewards regularly correlate to seniority, it’s
    only fair to keep the employees who contribute to happy users happy by aligning
    project incentives to the reward system.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 将项目目标与组织战略保持一致，而不调整参与者的激励可能会导致一种不友好的文化，即致力于改善产品安全性和可靠性的人并不是那些往往会得到晋升的人。由于财务奖励通常与资历相关，通过将项目激励与奖励制度保持一致，可以让为用户带来快乐的员工保持快乐。
- en: Reduce Fear with Risk-Reduction Mechanisms
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过风险减少机制减少恐惧
- en: 'Have you ever found yourself wanting to make a significant change, such as
    a rollout of new software or a new control, only to find that the organization
    pushes back because of the perceived risk? You can inspire confidence in your
    organization by making good deployment choices. We discuss many of these concepts
    [Chapter 7](ch07.html#design_for_a_changing_landscape), but it’s worth specifically
    noting the impact of culture here. Here are some strategies you might want to
    try:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否曾经发现自己想要进行重大改变，比如推出新软件或新控制，却发现组织因为感知到的风险而反对？通过做出良好的部署选择，你可以激发组织的信心。我们在[第7章](ch07.html#design_for_a_changing_landscape)中讨论了许多这些概念，但在这里特别值得注意的是文化的影响。以下是一些你可能想尝试的策略：
- en: Canaries and staged rollouts
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 金丝雀和分阶段的推出
- en: You can reduce fear by slowly rolling out substantial changes through small
    canary groups of users or systems. That way, the blast radius of an ill-fated
    change is small if something goes wrong. Also consider going one step further,
    and implementing all changes via staged rollouts and canaries (see [Chapter 16
    in the SRE workbook](https://landing.google.com/sre/workbook/chapters/canarying-releases/)).
    In practice, this approach has numerous benefits. For example, in [Chapter 19](ch19.html#onenine_case_study_chrome_security_team)
    we discuss how the staged release cycle for Chrome balances the competing needs
    of speedy updates and reliability. Over time, Chrome’s staged releases have fostered
    its reputation as a secure browser. We’ve also found that by making staged rollouts
    part of a routine change process, over time, an organization comes to expect that
    care and diligence are applied to all changes—which builds confidence in change
    and reduces fear.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通过小金丝雀用户组或系统缓慢推出重大改变，可以减少恐惧。这样，如果出了什么问题，一个不幸的改变的影响范围就会很小。还要考虑更进一步，通过分阶段的推出和金丝雀来实施所有改变（参见[SRE工作手册中的第16章](https://landing.google.com/sre/workbook/chapters/canarying-releases/)）。在实践中，这种方法有许多好处。例如，在[第19章](ch19.html#onenine_case_study_chrome_security_team)中，我们讨论了Chrome的分阶段发布周期如何平衡快速更新和可靠性的竞争需求。随着时间的推移，Chrome的分阶段发布已经培养了它作为一个安全浏览器的声誉。我们还发现，通过将分阶段的推出作为例行改变流程的一部分，随着时间的推移，组织会期望对所有改变都应用谨慎和细心，这增强了对改变的信心并减少了恐惧。
- en: Dogfood
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 自用
- en: By showing users that you’re not afraid of your own changes, you can instill
    confidence in the stability and productivity impact of any particular change.
    *Dogfooding* (or “eating your own dogfood”) involves adopting a change before
    that change affects others. This is especially important if you’re affecting the
    systems and processes that impact people’s daily lives. For example, if you’re
    rolling out a new least privilege mechanism such as multi-factor authorization,
    adopt the stricter control within your own team before you require all employees
    to implement the change. At Google, before we roll out new endpoint security software,
    we test it on some of our most discerning users (the security team) first.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 通过向用户展示你不害怕自己的改变，你可以增强对任何特定改变的稳定性和生产力影响的信心。*自用*（或“吃自己的狗粮”）意味着在改变影响他人之前先采用改变。如果你正在影响影响人们日常生活的系统和流程，这一点尤为重要。例如，如果你正在推出新的最低特权机制，比如多因素授权，先在自己的团队内采用更严格的控制，然后再要求所有员工实施这一改变。在谷歌，我们在推出新的端点安全软件之前，首先在一些最具洞察力的用户（安全团队）上进行测试。
- en: Trusted testers
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 受信任的测试者
- en: Inviting people in your organization to help test a change early in a project’s
    lifecycle can reduce fear of future change. This approach lets stakeholders see
    a change before it becomes final, which allows them to raise concerns early. These
    newly open lines of communication give them a direct channel to deliver feedback
    if something goes wrong. Showing a willingness to gather feedback during testing
    phases can reduce silos between parts of your organization. It’s important to
    make clear to the testers that you trust the feedback they’re giving, and to make
    use of their feedback so they know they’re heard. You can’t always address every
    piece of feedback—not all of it will be valid or actionable—but by explaining
    your decisions to your tester population, you can build a strong coalition of
    trust.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Opt in before mandatory
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: A corollary to the dogfood and trusted tester strategies is making a new control
    optional before it becomes mandatory. This gives teams the opportunity to adopt
    changes on their own timeline. Complicated changes, such as new authorization
    controls or testing frameworks, have a cost; it can take time for an organization
    to fully adopt such changes, and you often need to balance these changes against
    other priorities. If teams know they have time to implement changes at their own
    pace, they may be less resistant to doing so.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Progressive stringency
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have to put into effect a strict new policy for reliability or security,
    consider whether you can ratchet up the stringency over time: perhaps you can
    first introduce a lower-level control that has less impact before teams fully
    adopt a more stringent one with a heavier burden. For example, suppose you want
    to add least privilege controls that require employees to justify their access
    to certain data. Users who don’t justify the access appropriately will be locked
    out of the system. In this scenario, you could start by having the developer team
    integrate the justification framework (such as a library) into the system, but
    keep end user justifications optional. Once you deem the system to be performant
    and secure, you could require justifications to access data without locking out
    users who fail to meet the established criteria. Instead, the system could provide
    detailed error messages when a user enters an inaccurate justification, providing
    a feedback loop to train users and improve use of the system. After a period of
    time, when metrics show a high success rate for proper justifications, you can
    make the stringent control that locks users out of the system mandatory.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Make Safety Nets the Norm
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Reliability and security improvements often require you to remove long-relied-upon
    resources that don’t measure up to the new safety standards you’re introducing.
    For example, imagine you want to change how people in your organization use Unix
    root privileges (or similar highly privileged access), perhaps by implementing
    new proxy systems (see [Chapter 3](ch03.html#case_study_safe_proxies)). Fear of
    substantial changes like these is natural. After all, what if a team suddenly
    loses access to a resource that’s mission-critical? What if the change results
    in downtime?
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: You can reduce fear of change by providing safety nets like breakglass procedures
    (discussed in [Chapter 5](ch05.html#design_for_least_privilege)) that allow users
    to bypass a new stringent control. These emergency procedures should be used sparingly,
    however, and subjected to a high level of audit; they should be viewed as a last
    resort, not a convenient alternative. When implemented properly, breakglass procedures
    can provide nervous teams with the assurance that they can adopt a change or react
    to an incident without completely losing control or productivity. For example,
    suppose you have a staged rollout procedure that requires a long canary process,
    which you’ve implemented as a safety mechanism to prevent reliability issues.
    You can provide a breakglass bypass mechanism to make the push happen immediately
    if absolutely necessary. We discuss these types of situations in [Chapter 14](ch14.html#onefour_deploying_code).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Increase Productivity and Usability
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A fear of increased friction can make organizational changes with regard to
    security and reliability difficult. If people view new controls that slow down
    development and innovation as counterproductive, they may assume that their adoption
    will have a negative impact on the organization. For this reason, it’s often important
    to think carefully about the adoption strategy for new initiatives: consider the
    amount of time necessary to incorporate the change, whether the change might slow
    down productivity, and whether the benefit outweighs the cost of making the change.
    We’ve found that the following techniques help decrease friction:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Build transparent functionality
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: In Chapters [6](ch06.html#design_for_understandability) and [12](ch12.html#writing_code),
    we discuss relieving developers of the responsibility for security and reliability
    by using secure-by-construction APIs, frameworks, and libraries. Making the secure
    choice the default choice helps developers do the right thing without placing
    a heavy burden on them. This approach reduces friction over time because developers
    not only see the benefits of having secure and reliable systems, but also recognize
    your intent to keep these initiatives simple and easy. We’ve found this can build
    trust between teams over time.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Focus on usability
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: A focus on usability positively affects a culture of security and reliability.^([12](ch21.html#ch21fn12))
    If a new control is easier to use than what it’s replacing, it can create positive
    incentives for change.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 7](ch07.html#design_for_a_changing_landscape), we talk about how
    we focused on usability when rolling out security keys for two-factor authentication.
    Users found that touching a security key to authenticate was much easier than
    typing in one-time passwords generated by hardware tokens.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: As an added bonus, the enhanced security of these keys allowed us to require
    less frequent password changes.^([13](ch21.html#ch21fn13)) We performed a risk
    analysis on this topic, considering tradeoffs in usability, security, and auditability.
    We found that security keys negate the efficacy of password theft by a remote
    attacker. When combined with monitoring to detect suspected compromise of passwords,^([14](ch21.html#ch21fn14))
    and enforcement of password changes in such an event, we were able to balance
    security and usability.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: There are other opportunities where security and reliability features can deprecate
    old or unwanted processes and increase usability. Taking advantage of these opportunities
    can build user confidence and trust in security and reliability solutions.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Self-registration and self-resolution
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Self-registration and self-resolution portals empower developers and end users
    to address security and reliability issues directly, without gating on a central
    team that may be overloaded or slow. For example, Google uses deny and allow lists
    to control which applications can run on the systems that employees use. This
    technology is effective in preventing execution of malicious software (such as
    viruses).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: The downside is that if an employee wants to run software not already on the
    allow list, they need to seek approval. To reduce friction for exception requests,
    we developed a self-help portal called [Upvote](https://github.com/google/upvote)
    that enables users to get approval for acceptable software quickly. In some cases,
    we can automatically determine a piece of software to be safe and approve it.
    If we can’t automatically approve the software, we give the user an option to
    have it approved by a set number of peers.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: We’ve found social voting to be a satisfactory control. It’s not perfect—sometimes
    employees approve software that’s not necessarily business-related, such as video
    games—but this approach has had a high rate of effectiveness in preventing malware
    from being executed on our systems. And since it does not gate on a central team,
    friction for the control is kept very low.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Overcommunicate and Be Transparent
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When advocating for change, the means of communication can influence outcomes.
    As we discuss in Chapters [7](ch07.html#design_for_a_changing_landscape) and [19](ch19.html#onenine_case_study_chrome_security_team),
    good communication is key to building buy-in and confidence in success. Giving
    people information and clear insight into how change is happening can reduce fear
    and build trust. We’ve found the following strategies to be successful:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Document decisions
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: When making a change, clearly document why it’s happening, what success looks
    like, how the change will be rolled back if operating conditions deteriorate,
    and who to talk to in case of concerns. Make sure that you clearly communicate
    why you’re making the change, especially if it directly affects employees. For
    example, every Production Excellence SLO at Google requires a documented rationale.
    Since the SRE organization is measured against these SLOs, it’s important that
    SREs understand the meaning behind them.^([15](ch21.html#ch21fn15))
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Create feedback channels
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Make communication bidirectional by creating feedback channels through which
    people can raise concerns. This could be a feedback form, a link to your bug tracking
    system, or even a simple email address. As we mention in the discussion of trusted
    testers (see [“Reduce Fear with Risk-Reduction Mechanisms”](#reduce_fear_with_risk_reduction_mechani)),
    giving partners and stakeholders a more direct involvement in a change can lessen
    fear.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Use dashboards
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: If you’re making a complex change across multiple teams or parts of the infrastructure,
    use dashboards to show clear expectations of what you need people to do and provide
    feedback on how well they’re doing. Dashboards are also helpful in showing the
    big picture of a rollout and keeping the organization in sync on progress.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Write frequent updates
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: If a change takes a long time (some changes at Google have taken several years),
    assign someone to write frequent (for example, monthly) stakeholder updates outlining
    progress. This will build confidence—especially in leadership—that the project
    is progressing and that someone has a watchful eye on the health of the program.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Build Empathy
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can’t understand someone until you’ve walked a mile in their shoes.
  id: totrans-108
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '>'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: —Unknown
  id: totrans-110
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: People begin to understand the challenges others face when they understand the
    ins and out of performing their role. Cross-team empathy is especially important
    when it comes to reliability and security properties of the system, since (as
    discussed in [Chapter 20](ch20.html#twozero_understanding_roles_and_respons))
    these responsibilities should be shared across the organization. Building empathy
    and understanding can help reduce fear in the face of necessary changes.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 19](ch19.html#onenine_case_study_chrome_security_team), we outline
    a few techniques for building cross-team empathy—in particular, how teams can
    share responsibilities for writing, debugging, and fixing code. Similarly, the
    Chrome security team runs fixits not only to improve the security of the product,
    but also as a cross-organization team-building activity. Ideally, teams consistently
    share responsibilities from square one.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Job shadowing or job swapping is another approach to building empathy that doesn’t
    require permanent organizational top-down changes. These engagements can range
    from a few hours (which tend to be less formal exercises) to several months (which
    may require management buy-in). By inviting others to experience your team’s work,
    you can signal that you’re willing to tear down organizational silos and build
    common understanding.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Google’s SRE Security Exchange Program allows an SRE to shadow another SRE or
    security engineer for a week. At the end of the exchange, the SRE writes a report
    with improvement recommendations for both their home team and the host team. When
    conducted in the same office, this program requires a very low investment but
    provides many benefits in terms of knowledge sharing across the organization.
    Google’s [Mission Control program](https://oreil.ly/MSlrf) encourages people to
    join the SRE organization for six months, during which time they learn how to
    think like an SRE and respond to emergencies. In doing so, they directly see the
    impact of software changes initiated in partner organizations. A parallel program
    known as Hacker Camp encourages people to join the security team for six months,
    where they can work on security reviews and response efforts.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Programs like these may begin as small experiments with one or two engineers,
    and grow over time if successful. We’ve found that this type of job swapping both
    builds empathy and inspires exciting new ideas about how to solve challenges.
    Bringing in these new perspectives and building goodwill between teams helps grease
    the cogs of change.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Finally, building in mechanisms to say thank you—from simple emails to more
    elaborate forms—reinforces the positive impact that people have on one another
    and sets the right incentives. At Google, we’ve long had a culture of peer bonuses—small
    amounts of cash that don’t cost the company a lot of money, but build large amounts
    of goodwill. A cash-free version of this called Kudos allows Googlers to formally
    recognize each other in digital form that’s visible to everyone. Some of our offices
    have also experimented with thank-you postcards.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Convincing Leadership
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you work in a large organization, getting buy-in for reliability and security
    changes you want to make may be a challenge. Since many organizations are incentivized
    to spend their limited resources on revenue-generating or mission-forward efforts,
    it can be tough to get buy-in for improvements that are seen as happening behind
    the scenes.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'This section explores some strategies we’ve used at Google, or seen used elsewhere,
    to get buy-in from leadership for security and reliability changes. As with the
    guidance given elsewhere in this chapter, your mileage may vary. Some of these
    strategies will be effective, while others won’t be. Just as every organization’s
    culture is unique, so is every leader and leadership team. It’s worth repeating
    our previous advice here: just because you think one of these strategies won’t
    work doesn’t necessarily mean you shouldn’t try it. The results just might surprise
    you.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Understand the Decision-Making Process
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Suppose you want to make a fairly substantial change to your organization’s
    custom frontend web-serving infrastructure to include DDoS protection; for example,
    referencing the benefits outlined in [Chapter 10](ch10.html#mitigating_denial_of_service_attacks).
    You know this will vastly improve the reliability and security of the system,
    but it also requires multiple teams to incorporate new libraries or restructure
    code. Integrating and testing this change properly could take months. Given the
    high cost but positive impact, who in your organization would make the decision
    to move forward, and how would they make that decision? Understanding the answers
    to these questions is key to knowing how to influence leadership.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Here, the term *leadership* loosely applies to the people who make decisions,
    whether those decisions are around direction setting, resource allocation, or
    resolving conflicts. In short, these are the people who are perceived to have
    authority and accountability. They are the people you want to influence, so you
    need to figure out who they are. If you work in a large company, they could be
    VPs or other senior people in management. Smaller organizations, such as startups
    and nonprofits, often consider the CEO to be the senior decider. In an open source
    project, this could be the project’s founder or top contributor.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: The answer to the question “Who is the decider for this change?” can be tricky
    to determine. The authority to make decisions may indeed lie with someone typically
    considered to be at the top of the leadership hierarchy or in an obvious gatekeeping
    role, such as a lawyer or risk officer. But depending on the nature of the change
    you’re proposing, the decision might also reside in a tech lead, or even with
    you. The decider may not be a single person; it could be a set of stakeholders
    across the organization from different departments such as legal, press relations,
    engineering, and product development.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes the authority to make a decision resides loosely within a group of
    people or, in the extreme form, within a whole community. For example, in [Chapter 7](ch07.html#design_for_a_changing_landscape)
    we describe how the Chrome team participated in increasing HTTPS usage on the
    internet. In this situation, the decision to make a directional change was made
    within the community, and required building an industry-wide consensus.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Determining who is a decider for a change may take some sleuthing, especially
    if you are new to an organization, or if there are no existing processes telling
    you how to get something done. However, you can’t skip this step. Once you understand
    who the deciders are, you then should seek to understand the pressures and demands
    that they face. These might stem from their own management, boards of directors,
    or shareholders, and can even take the form of external influences like customer
    expectations. It’s important to understand these pressures so you can understand
    where your proposed changes fit in. To return to our earlier example of adding
    DDoS protection to the frontend web-serving infrastructure, where would that change
    fit in relative to leadership’s priorities?
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Build a Case for Change
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we’ve mentioned already in this chapter, resistance to change can stem from
    fear or perception of friction, but in many cases it can also stem from not understanding
    the reason for a change. When faced with many priorities, decision makers and
    stakeholders have the difficult task of choosing between different goals that
    they would like to achieve. How will they know your change is valuable? It’s important
    to understand the challenges decision makers face when building a case for your
    change. These are some of the steps in a successful case-building process:^([16](ch21.html#ch21fn16))
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Gather data
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: You know that a change needs to be made. How did you come to that conclusion?
    It’s important to have data to back up your proposed change. For example, if you
    know that building automated test frameworks into the build process will save
    developers time, can you demonstrate how much time this change will save? If you’re
    advocating for continuous builds because the practice creates incentives for developers
    to fix errors, can you show how continuous builds save time in the release processes?
    Conduct research and user studies to produce data-rich reports complete with graphs,
    charts, and anecdotal stories from users; then summarize this data in a way that
    decision makers can digest. For example, if you want to drive down the time it
    takes your team to patch security vulnerabilities or address reliability configuration
    issues, consider creating a dashboard that tracks progress for each of the engineering
    teams. Showing those dashboards to the leaders of those areas can encourage individual
    teams to hit targets. Be mindful of the investments you’ll need to make to gather
    high-quality, relevant data.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Educate others
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Security and reliability issues can be hard to understand unless you’re connected
    to them every day. Get the word out through talks and information sessions. At
    Google, we use Red Team postmortems (see [Chapter 20](ch20.html#twozero_understanding_roles_and_respons))
    to educate leaders at a high level about the kinds of risks we’re facing. While
    Red Teams were not originally created as an educational effort, they can raise
    awareness within all levels of the company. This has been beneficial in convincing
    teams to maintain their SLOs for remediating vulnerabilities.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Align incentives
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Using the data you’ve gathered and your knowledge of the pressures deciders
    face, you may be able to address other concerns in their sphere of influence.
    In our earlier DDoS example, making the proposed change to the framework would
    provide a security benefit, but a more reliable website would also potentially
    help increase sales. This could be a strong argument to present to the company’s
    leadership. For a real-world example, [Chapter 19](ch19.html#onenine_case_study_chrome_security_team)
    discusses how rapid releases of Chrome get security fixes to users faster, with
    the additional benefit of quick deployment for reliability fixes and new features.
    This is great for users and product development stakeholders alike. Don’t forget
    to discuss how you’re reducing the fear and friction that may accompany a change—as
    mentioned earlier in this chapter, Google’s rollout of security keys allowed us
    to eliminate unpopular password change policies and reduce end-user friction for
    two-factor authentication, which were powerful arguments for change.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Find allies
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Chances are, you’re not the only person who knows that a change you’re proposing
    would be beneficial. Finding allies and convincing them to support your change
    can add weight to your argument, especially if those people are organizationally
    close to the decision makers. Allies can also test your assumptions about a change.
    Perhaps they know of different data-based arguments, or understand the organization
    in a way that you don’t. This type of peer review can bolster the strength of
    your argument.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Observe industry trends
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: If you’re adopting a change that other organizations have already adopted, you
    may be able to rely on their experiences to convince your leadership. Do your
    research—articles, books, public talks at conferences, and other materials may
    demonstrate how and why an organization took up a change. There may be additional
    data points you can use directly in building your case for change. You could even
    consider bringing in expert speakers to address your leadership on specific topics
    and industry trends.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Change the zeitgeist
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: If you can change the way people think about your problem over time, it may
    be easier to convince decision makers later on. This applies especially when you
    need broad consensus for a change. We discuss this dynamic briefly in the HTTPS
    case study in [Chapter 7](ch07.html#design_for_a_changing_landscape), where the
    Chrome team and others in the industry changed developer behavior over a long
    period of time, to the point where HTTPS as a default became the norm.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Pick Your Battles
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If your organization is facing many reliability and security challenges, constant
    advocacy can create fatigue and resistance to additional change. It’s important
    to pick your battles carefully: prioritize initiatives that have a chance of succeeding
    and know when to stop advocating for lost causes. This shows leadership and decision
    makers that you’re tackling the most important issues.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Lost causes—that is, proposals you have to shelve—have value too. Even when
    you can’t successfully advocate for change, having data that supports your ideas
    and allies that back your plan, and educating people about the problem, can be
    valuable. At some point, your organization may be ready to tackle a challenge
    you’ve already studied. If you already have a plan waiting in the wings, teams
    can move faster.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Escalations and Problem Resolution
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Despite best efforts, sometimes the need to make decisions on a security or
    reliability change can rise to the surface in an explosive way. Perhaps a serious
    outage or security breach means that you quickly need more resources and staffing.
    Or perhaps two teams have differing opinions on how to solve a problem, and the
    natural course of decision making isn’t working. In these types of situations,
    you may need to seek resolution from the management chain. When dealing with escalations,
    we recommend the following guidelines:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Form a group of colleagues, mentors, tech leads, or managers to provide input
    on the situation from both sides. It’s usually a good idea to walk through the
    situation with someone with an unbiased view before deciding to escalate.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have the group summarize the situation and proposed decision options for management.
    Keep this summary as concise as possible. Maintain a strictly factual tone, and
    include links to any relevant supporting data, conversations, bugs, designs, etc.
    Make the potential impact of each option as clear as possible.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Share the summary with your own team’s leadership to ensure further alignment
    on possible solutions. For example, multiple issues might require simultaneous
    escalation. You may want to either merge escalations or emphasize other aspects
    of corresponding situations.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schedule a session to present the situation to all affected management chains
    and designate appropriate decision makers in each chain. The decision makers should
    then make a formal decision or meet separately to discuss the issue.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a concrete example, sometimes security issues at Google need to be escalated
    when an unresolvable disagreement arises between the product team and the security
    reviewer about the best course of action. In this case, an escalation is initiated
    within the security team. At that point, the two senior leaders within the organizations
    negotiate a compromise or decide to implement one of the options suggested by
    the security team or the product team. Because we integrate these escalations
    into our normal company culture, escalations aren’t seen as confrontational.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just as you design and manage systems, you can design, implement, and maintain
    the culture of an organization over time to support security and reliability goals.
    Reliability and security efforts should be considered just as carefully as engineering
    efforts. There are important cultural elements of engineering that, when taken
    in aggregate, or even on their own, can contribute to more robust systems.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Security and reliability improvements can inspire fear or concern about increased
    friction. There are strategies for addressing these fears and helping achieve
    buy-in from the people these changes affect. Making sure that your goals are well
    aligned with stakeholders—including leadership—is key. Focusing on usability and
    demonstrating empathy for users can encourage people to adopt change more readily.
    Making a small investment in thinking about how others perceive change may lead
    to greater success in convincing them that your changes are sound.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: As we stated in the opening to this chapter, no two cultures are the same, and
    you’ll need to adapt the strategies we’ve outlined to your own organization. In
    doing so, you will also find that you likely can’t implement all of these strategies.
    It may be useful to pick and choose the areas your organization most needs to
    address, and improve those over time—which is the way Google approaches constant
    improvement over the long term.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch21.html#ch21fn1-marker)) See [Chapter 15 of the SRE book](https://landing.google.com/sre/sre-book/chapters/postmortem-culture/).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch21.html#ch21fn2-marker)) This is discussed in [Chapter 3 of the SRE
    book](https://landing.google.com/sre/sre-book/chapters/embracing-risk/).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '^([3](ch21.html#ch21fn3-marker)) Google’s practices for code reviews are documented
    in the [Code Review Developer Guide](https://oreil.ly/mnPdJ). For additional background
    on Google’s code review process and culture, see Sadowski, Caitlin et al. 2018\.
    “Modern Code Review: A Case Study at Google.” [*https://oreil.ly/IfFJ1*](https://oreil.ly/IfFJ1).'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: ^([4](ch21.html#ch21fn4-marker)) A 2018 [study of the modern code review process
    at Google](https://oreil.ly/9FhBV) found that developers valued the low-friction
    workflows provided by their tooling.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: ^([5](ch21.html#ch21fn5-marker)) For example, Google maintains a set of best
    practices for [cross-site scripting](https://oreil.ly/qYpj8).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: ^([6](ch21.html#ch21fn6-marker)) A recent study on the use of the Testing-on-the-Toilet
    program at Google showed that the program increased developer awareness. See Murphy-Hill,
    Emerson et al. 2019\. “Do Developers Learn New Tools on the Toilet?” *Proceedings
    of the 41st International Conference on Software Engineering*. [*https://oreil.ly/ZN18B*.](https://oreil.ly/ZN18B)
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '^([7](ch21.html#ch21fn7-marker)) This topic is closely related to *nudging*,
    a method of changing behavior by subtly encouraging people to do the right thing.
    Nudge theory was developed by Richard Thaler and Cass Sunstein, who were awarded
    a Nobel Prize in Economics for their contribution to behavioral economics. For
    more information, see Thaler, Richard H., and Cass R. Sunstein. 2008\. *Nudge:
    Improving Decisions About Health, Wealth, and Happiness*. New Haven, CT: Yale
    University Press.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: ^([8](ch21.html#ch21fn8-marker)) Dave Rensin, Director of Customer Reliability
    Engineering at Google, considers this topic in greater detail in his talk [“Less
    Risk Through Greater Humanity”](https://oreil.ly/ZrWkS).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: ^([9](ch21.html#ch21fn9-marker)) The final report of the Columbia Disaster Investigation
    Board is preserved [on the NASA website](https://oreil.ly/ew-BA) for the general
    public to read. [Chapter 7](ch07.html#design_for_a_changing_landscape) in particular
    focuses on the culture of safety at NASA and its impact on the disaster. We’ve
    found that the report’s findings can often be extrapolated to organizational culture
    in other types of engineering organizations.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: ^([10](ch21.html#ch21fn10-marker)) See [Chapter 29 of the SRE book](https://landing.google.com/sre/sre-book/chapters/dealing-with-interrupts/).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: ^([11](ch21.html#ch21fn11-marker)) See [Chapter 32 of the SRE book](https://landing.google.com/sre/sre-book/chapters/evolving-sre-engagement-model/).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: ^([12](ch21.html#ch21fn12-marker)) Usable solutions for security and privacy
    have long been recognized as key to successful deployment of technology controls.
    For a flavor of what these conversations look like, you might be interested in
    exploring the proceedings of [SOUPS](https://oreil.ly/8bTuI), a conference dedicated
    to usable security and privacy.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '^([13](ch21.html#ch21fn13-marker)) Studies have shown that users make poor
    choices that put their passwords at risk. For more information on the adverse
    effects of user password choices, see Zhang, Yinqian, Fabian Monrose, and Michael
    K. Reiter. 2010\. “The Security of Modern Password Expiration: An Algorithmic
    Framework and Empirical Analysis.” *Proceedings of the 17th ACM Conference on
    Computer and Communications Security*: 176–186\. [*https://oreil.ly/NbfFj*](https://oreil.ly/NbfFj).
    Standards and compliance regimes are also considering these effects. For example,
    [NIST 800-63](https://oreil.ly/q2Bgw) has been updated to require a password change
    only when there is suspicion that it has been compromised.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: ^([14](ch21.html#ch21fn14-marker)) Password Alert is a Chrome browser extension
    that alerts when a user has typed their Google or GSuite password into a malicious
    website.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: ^([15](ch21.html#ch21fn15-marker)) Production Excellence reviews are carried
    out periodically on SRE teams by senior SRE leaders, assessing them on a number
    of standard measures and providing feedback and encouragement. An SLO of 99.95%
    might be accompanied by a rationale such as, “We previously wanted to reach a
    99.99% success rate, but found this target to be unrealistic in practice. We have
    not discovered a negative impact on developer productivity at 99.95%.”
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '^([16](ch21.html#ch21fn16-marker)) For a practical example of how we successfully
    built a case for change, see [“Example: Increasing HTTPS usage”](ch07.html#example_increasing_https_usage).'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL

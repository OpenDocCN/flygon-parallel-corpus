- en: Scaling Up Serverless Architectures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have learned how to build, monitor, and log serverless functions.
    In this chapter, we will be learning concepts and engineering techniques that
    will help scale up serverless applications to be distributed, and that will also
    enable them to handle heavy workloads with high standards of security and throughput.
    In this chapter, we will also use some third-party tools, such as Ansible, to
    scale up our Lambda functions. We will be scaling up our Lambda functions to spawn
    a distributed serverless architecture, which will involve spawning multiple servers
    (or instances in the AWS environment). You therefore need to keep that in mind
    while following the examples mentioned in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter assumes a working knowledge of a provisioning tool, such as **Ansible**,
    **Chef**, and so on. You can quickly read up on or refresh your knowledge of these
    on their respective sites, where they have quick tutorials. If not, then you can
    safely skip this chapter and move on to the next.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter consists of five sections, which cover all of the basics of scaling
    up serverless architectures and will set you up for building bigger, complex serverless
    architectures:'
  prefs: []
  type: TYPE_NORMAL
- en: Third-party orchestration tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The creation and termination of servers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security best practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Difficulties of scaling up
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling difficulties
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Third-party orchestration tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will learn and become versed in the concept of infrastructure
    provisioning and orchestration. We will be exploring a couple of tools, namely
    Chef and Ansible. Let''s get started by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will begin with getting introduced to Chef. You can visit the official website
    of Chef at [https://www.chef.io/chef/](https://www.chef.io/chef/):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a06338bf-fb28-4b03-810a-82fae062bd39.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Chef has a very good set of tutorials for getting your hands dirty. These are
    organized in the form of mini 10 to 15 minute tutorials for easy consumption.
    Head over to [https://learn.chef.io/](https://learn.chef.io/) to access them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/825c1b56-d209-430e-bbeb-ffc5001d2368.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For getting started with infrastructure provisioning and orchestrating, you
    can refer to the Chef documentation here: [https://docs.chef.io/](https://docs.chef.io/).
    The page looks like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/79e49b87-d2a2-4def-be1d-2621304ed087.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can refer to the AWS Driver Resources page in the documentation to understand
    how to interact with various AWS services via Chef at: [https://docs.chef.io/provisioning_aws.html](https://docs.chef.io/provisioning_aws.html).
    The page looks like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3db9fa23-9e46-4eb9-9f98-8f1040780be7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can also refer to the aws Cookbook for the same purpose, too. This resource
    has very good documentation and APIs for interacting with several AWS services.
    The URL of this documentation is [https://supermarket.chef.io/cookbooks/aws](https://supermarket.chef.io/cookbooks/aws).
    The page looks like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/95c29787-d6ca-49e0-95bc-4ad3fa8ffedb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A detailed description of the cookbook can be seen when you scroll down, directly
    after the title of the cookbook:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2344f475-dc92-44ba-899b-d58d703e6bd6.png)'
  prefs: []
  type: TYPE_IMG
- en: One other good tool for provisioning and orchestrating software resources is
    Ansible. This helps software engineers write code for automating several parts
    of their infrastructure via *yaml scripts*. Similar to the Chef environment, these
    scripts are called **cookbooks**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We will be using this tool for learning how to provision our infrastructure
    in the subsequent sections. The documentation for Ansible can be found at [http://docs.ansible.com/](http://docs.ansible.com/):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c03b9e64-50de-416c-9e94-2764d847eefb.png)'
  prefs: []
  type: TYPE_IMG
- en: The product, ANSIBLE TOWER, is out of scope for this book. We will be learning
    and be working with ANSIBLE CORE, which is the flagship product of Ansible and
    its parent company, Red Hat.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Ansible has a very helpful video for helping you better understand and make
    sense of the tool. It can be accessed when you click on the Quick Start Video
    link in the documentation page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f1e1efa6-0b68-4a68-9649-b7f3c53c5489.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After watching the video, you can proceed to understand the product from the
    documentation itself. The complete documentation of Ansible can be accessed at: [http://docs.ansible.com/ansible/latest/index.html](http://docs.ansible.com/ansible/latest/index.html):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f06582a8-f9bf-41a2-8d05-8ec9f3bd1505.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The EC2 module is the one we will be using for provisioning and orchestrating
    our AWS EC2 instances. This part of the documentation has a very clear explanation
    and demonstration of starting up and terminating EC2 instances, along with adding
    and mounting volumes; it also enables us to provision our EC2 instances into our
    own specific **Virtual Private Cloud** (**VPC**) and/or in our own **Security
    Groups** (**SGs**). The EC2 documentation screen looks like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/dc173ebc-4ff1-4bff-ad37-8cce256003ec.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can find this at the following URL of Ansible Core''s documentation: [http://docs.ansible.com/ansible/latest/ec2_module.html](http://docs.ansible.com/ansible/latest/ec2_module.html).
    When you scroll down further, you can see several examples of how to use the EC2
    module of Ansible for various tasks concerning AWS EC2 instances. Some of them
    can be seen as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/76a160bd-a2dd-4913-8f0e-6fae8b2455dc.png)'
  prefs: []
  type: TYPE_IMG
- en: The creation and termination of servers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn how to use some third-party tools that will
    help us in building the required architecture. Like all of the sections in this
    chapter, the information will be broken down into steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first tool we will be learning about is Ansible. It is a provisioning and
    orchestrating tool, that helps in automating several parts of an infrastructure.
    Depending on when you are reading this book, the Ansible project''s homepage ([https://www.ansible.com/](https://www.ansible.com/))
    will look something like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a5f8df9d-0b00-418c-8257-1a9ec9d33c1b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The installation process for Ansible is different for different operating systems.
    The instructions for some popular operating systems are as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**For Ubuntu**:'
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**For Linux**:'
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**For OS X**:'
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now, we will understand the concept of **nohup**. So, you don't need to have
    a persistent SSH connection to the server for making a `nohup` command run, therefore
    we will be using this technique for running our master–server architecture (to
    know more about nohup refer to: [https://en.wikipedia.org/wiki/Nohup](https://en.wikipedia.org/wiki/Nohup)).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let's look at its definition on Wikipedia (from the time of writing this book), **nohup** is
    a POSIX command to ignore the HUP (hangup) signal. The HUP signal is, by convention,
    the way a terminal warns dependent processes of logout.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now learn how to provision servers from Ansible, SSH into them, run
    a simple `apt-get update` task in them, and terminate them. From this, you will
    learn how to write Ansible scripts, as well as understand how Ansible handles
    the provisioning of cloud resources. The following Ansible script will help you
    understand how to provision an EC2 instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The values in the `{{ }}` brackets need to be filled in as per your convenience
    and specifications. The preceding code will create an EC2 instance in your console
    and name it, as per the specification which is given in the `{{ Instance_Name
    }}` section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ansible.cfg` file should include all of the details which give instructions
    about the control path, the details regarding the forwarding agent, and also the
    path to the EC2 instance key. The `ansible.cfg` file should look like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'When you execute this code using `ansible-playbook -vvv < name-of-playbook
    >.yml`, you can see the EC2 instance being created in your EC2 console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/990b02ae-a1cb-4ada-80dd-6fbb6d11cfa4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we will terminate the instance which we have just created via Ansible.
    This will also be done in an Ansible script, similar to how we provisioned the
    instance. The following code does this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'So, now you can see the instance being terminated in the console. Note that
    the code is the same up until the tasks, such as provisioning and terminating
    instances, so you can copy and paste from the provisioning task:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b3afa19c-951b-4671-af4e-c7bbc7a2d624.png)'
  prefs: []
  type: TYPE_IMG
- en: So, we have successfully learned how to provision and terminate EC2 instances
    via an Ansible script. We will use this knowledge for provisioning and will be
    terminating EC2 instances at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Making a small change to the provisioning code in the yaml script we used previously,
    we can provision multiple servers (EC2 instances) at the same time, by simply
    adding the `count` parameter. The following code will provision the number of
    instances mentioned in the *jinja template*, beside the `count` parameter. In
    our example, it is `ninstances`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Now, as we have our Ansible script ready, we will now use it to start our infrastructure
    from the Lambda function. For that, we will make use of our knowledge of nohup.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In your Lambda function, all you need to do is to write the logic for creating
    a server, and then do some basic installations using the library, `paramiko`,
    and then run the Ansible script in a nohup mode, as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Security best practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ensuring high-level security has always been a major problem for microservices.
    There are multiple levels of software that you need to keep in mind while designing
    the security layers. The engineers need to define the security protocols for each
    of the services and then also define the protocols for the data interaction and
    transfer between each service.
  prefs: []
  type: TYPE_NORMAL
- en: You have to keep all these aspects in mind before architecting distributed serverless
    systems, where (almost) each Ansible task is a microservice. In this section,
    we will understand how to architect the security protocols, and also monitor them
    using some of AWS's built-in services.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will go through a step-by-step understanding of how to write security protocols
    for our serverless architectures:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Firstly, whenever you are creating a session inside your AWS Python scripts
    using **Boto**, try to create temporary credentials using the **AWS Secure Token
    Service** (**STS**), which creates temporary credentials for a specific period of
    time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/98dcd848-36f3-4826-a507-c80f00238c0c.png)'
  prefs: []
  type: TYPE_IMG
- en: You can look at the documentation of the STS at: [https://docs.aws.amazon.com/STS/latest/APIReference/Welcome.html](https://docs.aws.amazon.com/STS/latest/APIReference/Welcome.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'The AssumeRole API of the STS service enables programmers to assumes IAM roles
    into their code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9e6c5386-d7ca-4e42-a57e-ff04caa651ed.png)'
  prefs: []
  type: TYPE_IMG
- en: You can find its documentation on the following page: [https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html](https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html)
  prefs: []
  type: TYPE_NORMAL
- en: 'The Python version of this can be referred to, in the `boto3` documentation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/aee5b2d3-3237-4904-b005-8b7a07fe24bf.png)'
  prefs: []
  type: TYPE_IMG
- en: This documentation can be found here: [http://boto3.readthedocs.io/en/latest/reference/services/sts.html](http://boto3.readthedocs.io/en/latest/reference/services/sts.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'Scrolling down, you can find the usage of the AssumeRole API in Python:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/76e319b3-f47d-46e0-b9e5-645ef255f222.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Proper care should be taken so that the data exchange between microservices
    and/or between the microservices and other AWS resources happens securely with
    authentication. For example, the developer can configure S3 buckets to restrict
    actions such as unencrypted uploads, downloads, and insecure file transfers. The
    bucket policy can be written as follows to ensure all of these things are taken
    care of:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you have finished writing the bucket policy, you can update it in the
    Bucket Policy section of S3:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/332d132a-0366-4b37-b119-3474624a7d2c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'AWS Config provides a very useful interface for monitoring several security
    threats and helps in efficiently avoiding or catching them. The dashboard of AWS
    Config looks like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ea5571d8-5cd9-4bbe-8f44-fab3b7e1c5e5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can see that the dashboard shows 2 non-compliant resource(s) which means
    that two of my AWS resources are not complying with the rules that I have put
    into config. Let''s have a look at these rules:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0703fc51-40ff-47c6-968d-e74dbdbd3861.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This means that we have two AWS S3 buckets which do not have SSL requests turned
    on via the bucket policy. Once you click on the Rules link, you can see more details
    which include the bucket(s) names, and also the timestamps at which these configuration
    changes have been recorded:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c43909d7-bff5-440e-85b2-fc0e407cbe12.png)'
  prefs: []
  type: TYPE_IMG
- en: Identifying and handling difficulties in scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Scaling up distributed serverless systems comes with its own set of engineering
    roadblocks and problems, and the fact that the concept of serverless systems is
    still in a very infantile stage, means that most of those problems are still unsolved.
    But, that shouldn't stop us from trying to solve and work around these roadblocks.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will try and understand some of these roadblocks, and also learn how to
    solve or work around them, as discussed here:'
  prefs: []
  type: TYPE_NORMAL
- en: This is more of an architect's mistake rather than a roadblock. However, it
    is important to address this as one too many architects/software engineers fell
    and fall into the overestimation or the underestimation trap. The problem we will
    try to address is the exact number of instances you have to launch when scaling
    up. In most self-hosted MapReduce-style systems, it is taken care of out of the
    box.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This problem can be taken care of, by properly benchmarking the workloads beforehand
    on different types of instances, and scale accordingly. Let's understand this
    by taking an example of a machine learning pipeline. Thanks to our benchmarking
    efforts, we already know that an *m3.medium* instance can handle 100 files in
    10 minutes. So, if my workload has 202 files and I want it to be completed in
    close to 10 minutes, I would like to have two such instances for handling this.
    Even if we don't know the workloads in advance, we can write a Python script for
    getting that number from wherever the data is, be it an SQS queue pointer, or
    S3, or some other database; and that number can be entered into the Ansible script
    and make the playbook run.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we have already learned about handling security in huge serverless systems,
    we will keep this short. There are several complex data movements happening inside
    a large distributed serverless workload. Using proper security protocols and monitoring
    them, as mentioned in detail in the previous security section, will help in overcoming
    this problem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging is a major problem in distributed serverless systems, which is also
    still unsolved completely. As the systems and containers are destroyed once the
    workload has been completed, logging has been a very difficult task to undertake. There
    are several ways you can log the workflow. The most popular ones are logging every
    Ansible task separately, and one where the last Ansible task is to zip up the
    logs and send the zipped file to a data store, such as S3 or Logstash. The last
    one is the most preferred way as it captures the execution flow better, as the
    entire log trace is in a single file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Monitoring is similar to logging. Monitoring these systems is also mostly an
    unsolved problem. As the servers are all terminated once the workload is run,
    we can''t poll for historic logs from the servers, and latency also will not be
    tolerated, or more precisely, will not be possible. Monitor every task of Ansible
    by having a task after each, that sends a custom metric to CloudWatch upon a condition
    that the previous task has executed successfully or not. This will look something
    like this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/97c4c19a-d7dc-4534-9e9b-366b1df91347.png)'
  prefs: []
  type: TYPE_IMG
- en: Debugging trial runs can also become very frustrating, very fast. This is because,
    if you are not quick, the entire system can be terminated before you even get
    a chance to look at the logs. Also, Ansible emits very verbose logs while debugging,
    which might seem overwhelming when spawning several instances.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some basic Unix hacks can help in handling these problems. The most important
    one is to monitor the tail of the log file, about 50 lines or so. This helps in
    not getting overwhelmed by the huge amount of logs, and it also keeps an eye on
    the execution of the Ansible notebook.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned how to scale up our serverless architecture(s)
    to being massively distributed serverless infrastructure(s). We have learned how
    to build on our existing knowledge of building and deploying Lambda infrastructures
    to handle massive workloads.
  prefs: []
  type: TYPE_NORMAL
- en: We have learned to use the concept of nohup to use our Lambda function as a
    launch board for building a master-worker architecture that takes parallel computing
    into account. We have learned how to leverage configuration and orchestration
    tools, such as Ansible and Chef, to spawn and orchestrate multiple EC2 instances.
  prefs: []
  type: TYPE_NORMAL
- en: The knowledge gained from this chapter will open doors for building many complex
    infrastructures which can handle data and requests, both in terms of size and
    speed. This will allow you to operate multiple microservices closely intertwined
    together. This will also help you to build MapReduce-style systems and interact
    with other AWS services, seamlessly.
  prefs: []
  type: TYPE_NORMAL

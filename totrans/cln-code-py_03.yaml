- en: General Traits of Good Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is a book about software construction with Python. Good software is built
    from a good design. By saying things such as clean code, one might think that
    we will explore good practices that relate only to the implementation details
    of the software, instead of its design. However, this assumption would be wrong
    since the code is not something different from the design—the code is the design.
  prefs: []
  type: TYPE_NORMAL
- en: The code is probably the most detailed representation of the design. In the
    first two chapters, we discussed why structuring the code in a consistent way
    was important, and we have seen idioms for writing more compact and idiomatic
    code. Now it's time to understand that clean code is that, and much more—the ultimate
    goal is to make the code as robust as possible, and to write it in a way that
    minimizes defects or makes them utterly evident, should they occur.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter and the next one are focused on design principles at a higher level
    of abstraction. These ideas not only relate to Python in particular but are instead
    general principles of software engineering.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, for this chapter, we will review different principles that make
    for good software design. Good-quality software should be built around these ideas,
    and they will serve as design tools. This does not mean that all of them should
    always be applied; in fact, some of them represent different points of view (such
    is the case with the **Design by Contract** (**DbC**) approach, as opposed to
    defensive programming). Some of them depend on the context and are not always
    applicable.
  prefs: []
  type: TYPE_NORMAL
- en: A high-quality code is a concept that has multiple dimensions. We can think
    of this similarly to how we think about the quality attributes of a software architecture.
    For example, we want our software to be secure and to have good performance, reliability,
    and maintainability, just to name a few.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goals of this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: To understand the concepts behind robust software
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To learn how to deal with erroneous data during the workflow of the application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To design maintainable software that can easily be extended and adapted to new
    requirements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To design reusable software
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To write effective code that will keep the productivity of the development team
    high
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design by contract
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some parts of the software we are working on are not meant to be called directly
    by users, but instead by other parts of the code. Such is the case when we divide
    the responsibilities of the application into different components or layers, and
    we have to think about the interaction between them.
  prefs: []
  type: TYPE_NORMAL
- en: We will have to encapsulate some functionality behind each component, and expose
    an interface to clients who are going to use that functionality, namely an **Application
    Programming Interface** (**API**). The functions, classes, or methods we write
    for that component have a particular way of working under certain considerations
    that, if they are not met, will make our code crash. Conversely, clients calling
    that code expect a particular response, and any failure of our function to provide
    this would represent a defect.
  prefs: []
  type: TYPE_NORMAL
- en: That is to say that if, for example, we have a function that is expected to
    work with a series of parameters of type integers, and some other function invokes
    our passing strings, it is clear that it should not work as expected, but in reality,
    the function should not run at all because it was called incorrectly (the client
    made a mistake). This error should not pass silently.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, when designing an API, the expected input, output, and side-effects
    should be documented. But documentation cannot enforce the behavior of the software
    at runtime. These rules, what every part of the code expects in order to work
    properly and what the caller is expecting from them, should be part of the design,
    and here is where the concept of a **contract** comes into place.
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind the DbC is that instead of implicitly placing in the code what
    every party is expecting, both parties agree on a contract that, if violated,
    will raise an exception, clearly stating why it cannot continue.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our context, a contract is a construction that enforces some rules that
    must be honored during the communication of software components. A contract entails
    mainly preconditions and postconditions, but in some cases, invariants, and side-effects
    are also described:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Preconditions**: We can say that these are all the checks code will do before
    running. It will check for all the conditions that have to be made before the
    function can proceed. In general, it''s implemented by validating the data set
    provided in the parameters passed, but nothing should stop us from running all
    sorts of validations (for example, validating a set in a database, a file, another
    method that was called before, and so on) if we consider that their side-effects
    are overshadowed by the importance of such a validation. Notice that this imposes
    a constraint on the caller.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Postconditions**: The opposite of preconditions, here, the validations are
    done after the function call is returned. Postcondition validations are run to
    validate what the caller is expecting from this component.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Invariants**: Optionally, it would be a good idea to document, in the docstring
    of a function, the invariants, the things that are kept constant while the code
    of the function is running, as an expression of the logic of the function to be
    correct.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Side-effects**: Optionally, we can mention any side-effects of our code in
    the docstring.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While conceptually all of these items form part of the contract for a software
    component, and this is what should go to the documentation of such piece, only
    the first two (preconditions and postconditions) are to be enforced at a low level
    (code).
  prefs: []
  type: TYPE_NORMAL
- en: The reason why we would design by contract is that if errors occur, they must
    be easy to spot (and by noticing whether it was either the precondition or postcondition
    that failed, we will find the culprit much easily) so that they can be quickly
    corrected. More importantly, we want critical parts of the code to avoid being
    executed under the wrong assumptions. This should help to clearly mark the limits
    for the responsibilities and errors if they occur, as opposed to something saying—this
    part of the application is failing... But the caller code provided the wrong arguments,
    so where should we apply the fix?
  prefs: []
  type: TYPE_NORMAL
- en: The idea is that preconditions bind the client (they have an obligation to meet
    them if they want to run some part of the code), whereas postconditions bind the
    component in question to some guarantees that the client can verify and enforce.
  prefs: []
  type: TYPE_NORMAL
- en: This way, we can quickly identify responsibilities. If the precondition fails,
    we know it is due to a defect on the client. On the other hand, if the postcondition
    check fails, we know the problem is in the routine or class (supplier) itself.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically regarding preconditions, it is important to highlight that they
    can be checked at runtime, and if they occur, the code that is being called should
    not be run at all (it does not make sense to run it because its conditions do
    not hold, and further more, doing so might end up making things worse).
  prefs: []
  type: TYPE_NORMAL
- en: Preconditions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Preconditions are all of the guarantees a function or method expects to receive
    in order to work correctly. In general programming terms, this usually means to
    provide data that is properly formed, for example, objects that are initialized,
    non-null values, and many more. For Python, in particular, being dynamically typed,
    this also means that sometimes we need to check for the exact type of data that
    are provided. This is not exactly the same as type checking, the kind `mypy` would
    do this, but rather verify for exact values that are needed.
  prefs: []
  type: TYPE_NORMAL
- en: Part of these checks can be detected early on by using static analysis tools,
    such as `mypy`, which we already introduced in [Chapter 1](bba62a64-dfe9-478f-9b33-6c3240d75f59.xhtml), *Introduction,
    Code Formatting, and Tools*, but these checks are not enough. A function should
    have proper validation for the information that it is going to handle.
  prefs: []
  type: TYPE_NORMAL
- en: Now, this poses the question of where to place the validation logic, depending
    on whether we let the clients validate all the data before calling the function,
    or allow this one to validate everything that it received prior running its own
    logic. The former corresponds to a tolerant approach (because the function itself
    is still allowing any data, potentially malformed data as well), whereas the latter
    corresponds to a demanding approach.
  prefs: []
  type: TYPE_NORMAL
- en: For the purposes of this analysis, we prefer a demanding approach when it comes
    to DbC, because it is usually the safest choice in terms of robustness, and usually
    the most common practice in the industry.
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of the approach we decide to take, we should always keep in mind
    the non-redundancy principle, which states that the enforcement of each precondition
    for a function should be done by only one of the two parts of the contract, but
    not both. This means that we put the validation logic on the client, or we leave
    it to the function itself, but in no cases should we duplicate it (which also
    relates to the DRY principle, which we will discuss later on in this chapter).
  prefs: []
  type: TYPE_NORMAL
- en: Postconditions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Postconditions are the part of the contract that is responsible for enforcing
    the state after the method or function has returned.
  prefs: []
  type: TYPE_NORMAL
- en: Assuming that the function or method has been called with the correct properties
    (that is, with its preconditions met), then the postconditions will guarantee
    that certain properties are preserved.
  prefs: []
  type: TYPE_NORMAL
- en: The idea is to use postconditions to check and validate for everything that
    a client might need. If the method executed properly, and the postcondition validations
    pass, then any client calling that code should be able to work with the returned
    object without problems, as the contract has been fulfilled.
  prefs: []
  type: TYPE_NORMAL
- en: Pythonic contracts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the time of writing this book, a PEP-316, named Programming by Contract for
    Python, is deferred. This doesn't mean that we cannot implement it in Python,
    because, as introduced at the beginning of the chapter, this is a general design
    principle.
  prefs: []
  type: TYPE_NORMAL
- en: Probably the best way to enforce this is by adding control mechanisms to our
    methods, functions, and classes, and if they rail raise a `RuntimeError` exception
    or `ValueError`. It's hard to devise a general rule for the correct type of exception,
    as that would pretty much depend on the application in particular. These previously
    mentioned exceptions are the most common types of exception, but if they don't
    fit accurately with the problem, creating a custom exception would be the best
    choice.
  prefs: []
  type: TYPE_NORMAL
- en: We would also like to keep the code as isolated as possible. That is, the code
    for the preconditions in one part, the one for the postconditions in another,
    and the core of the function separated. We could achieve this separation by creating
    smaller functions, but in some cases implementing a decorator would be an interesting
    alternative.
  prefs: []
  type: TYPE_NORMAL
- en: Design by contract – conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The main value of this design principle is to effectively identify where the
    problem is. By defining a contract, when something fails at runtime it will be
    clear what part of the code is broken, and what broke the contract.
  prefs: []
  type: TYPE_NORMAL
- en: As a result of following this principle, the code will be more robust. Each
    component is enforcing its own constraints and maintaining some invariants, and
    the program can be proven correct as long as these invariants are preserved.
  prefs: []
  type: TYPE_NORMAL
- en: It also serves the purpose of clarifying the structure of the program better.
    Instead of trying to run ad hoc validations, or trying to surmount all possible
    failure scenarios, the contracts explicitly specify what each function or method
    expects to work properly, and what is expected from them.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, following these principles also adds extra work, because we are not
    just programming the core logic of our main application, but also the contracts.
    In addition, we might also want to consider adding unit tests for these contracts
    as well. However, the quality gained by this approach pays off in the long run;
    hence, it is a good idea to implement this principle for critical components of
    the application.
  prefs: []
  type: TYPE_NORMAL
- en: Nonetheless, for this method to be effective, we should carefully think about
    what are we willing to validate, and this has to be a meaningful value. For example,
    it would not make much sense to define contracts that only check for the correct
    data types of the parameters provided to a function. Many programmers would argue
    that this would be like trying to make Python a statically-typed language. Regardless
    of this, tools such as Mypy, in combination with the use of annotations, would
    serve this purpose much better and with less effort. With that in mind, design
    contracts so that there is actually value on them, checking, for example, the
    properties of the objects being passed and returned, the conditions they have
    to hold, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Defensive programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Defensive programming follows a somewhat different approach than DbC; instead
    of stating all conditions that must be held in a contract, that if unmet will
    raise an exception and make the program fail, this is more about making all parts
    of the code (objects, functions, or methods) able to protect themselves against
    invalid inputs.
  prefs: []
  type: TYPE_NORMAL
- en: Defensive programming is a technique that has several aspects, and it is particularly
    useful if it is combined with other design principles (this means that the fact
    that it follows a different philosophy than DbC does not mean that it is a case
    of either one or the other—it could mean that they might complement each other).
  prefs: []
  type: TYPE_NORMAL
- en: The main ideas on the subject of defensive programming are how to handle errors
    for scenarios that we might expect to occur, and how to deal with errors that
    should never occur (when impossible conditions happen). The former will fall into
    error handling procedures, while the latter will be the case for assertions, both
    topics we will be exploring in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Error handling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our programs, we resort to error handling procedures for situations that
    we anticipate as prone to cause errors. This is usually the case for data input.
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind error handling is to gracefully respond to these expected errors
    in an attempt to either continue our program execution or decide to fail if the
    error turns out to be insurmountable.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are different approaches by which we can handle errors on our programs,
    but not all of them are always applicable. Some of these approaches are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Value substitution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Error logging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exception handling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Value substitution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In some scenarios, when there is an error and there is a risk of the software
    producing an incorrect value or failing entirely, we might be able to replace
    the result with another, safer value. We call this value substitution, since we
    are in fact replacing the actual erroneous result for a value that is to be considered
    non-disruptive (it could be a default, a well-known constant, a sentinel value,
    or simply something that does not affect the result at all, like returning zero
    in a case where the result is intended to be applied to a sum).
  prefs: []
  type: TYPE_NORMAL
- en: Value substitution is not always possible, however. This strategy has to be
    carefully chosen for cases where the substituted value is actually a safe option.
    Making this decision is a trade-off between robustness and correctness. A software
    program is robust when it does not fail, even in the presence of an erroneous
    scenario. But this is not correct either.
  prefs: []
  type: TYPE_NORMAL
- en: This might not be acceptable for some kinds of software. If the application
    is critical, or the data being handled is too sensitive, this is not an option,
    since we cannot afford to provide users (or other parts of the application) with
    erroneous results. In these cases, we opt for correctness, rather than let the
    program explode when yielding the wrong results.
  prefs: []
  type: TYPE_NORMAL
- en: 'A slightly different, and safer, version of this decision is to use default
    values for data that is not provided. This can be the case for parts of the code
    that can work with a default behavior, for example, default values for environment
    variables that are not set, for missing entries in configuration files, or for
    parameters of functions. We can find examples of Python supporting this throughout
    different methods of its API, for example, dictionaries have a `get` method, whose
    (optional) second parameter allows you to indicate a default value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Environment variables have a similar API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In both previous examples, if the second parameter is not provided, `None`
    will be returned, because it''s the default value those functions are defined
    with. We can also define default values for the parameters of our own functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In general, replacing missing parameters with default values is acceptable,
    but substituting erroneous data with legal close values is more dangerous and
    can mask some errors. Take this criterion into consideration when deciding on
    this approach.
  prefs: []
  type: TYPE_NORMAL
- en: Exception handling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the presence of incorrect or missing input data, sometimes it is possible
    to correct the situation with some examples such as the ones mentioned in the
    previous section. In other cases, however, it is better to stop the program from
    continuing to run with the wrong data than to leave it computing under erroneous
    assumptions. In those cases, failing and notifying the caller that something is
    wrong is a good approach, and this is the case for a precondition that was violated,
    as we saw in DbC.
  prefs: []
  type: TYPE_NORMAL
- en: Nonetheless, erroneous input data is not the only possible way in which a function
    can go wrong. After all, functions are not just about passing data around; they
    also have side-effects and connect to external components.
  prefs: []
  type: TYPE_NORMAL
- en: It could be possible that a fault in a function call is due to a problem on
    one of these external components, and not in our function itself. If that is the
    case, our function should communicate this properly. This will make it easier
    to debug. The function should clearly, and unambiguously notify the rest of the
    application about errors that cannot be ignored so that they can be addressed
    accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: The mechanism for accomplishing this is an exception. It is important to emphasize
    that this is what exceptions should be used for—clearly announcing an exceptional
    situation, not altering the flow of the program according to business logic.
  prefs: []
  type: TYPE_NORMAL
- en: If the code tries to use exceptions to handle expected scenarios or business
    logic, the flow of the program will become harder to read. This will lead to a
    situation where exceptions are used as a sort of `go-to` statement, that (to make
    things worse) could span multiple levels on the call stack (up to caller functions),
    violating the encapsulation of the logic into its correct level of abstraction.
    The case could get even worse if these `except` blocks are mixing business logic
    with truly exceptional cases that the code is trying to defend against; in that
    case, it will be harder to distinguish between the core logic we have to maintain
    and errors to be handled.
  prefs: []
  type: TYPE_NORMAL
- en: Do not use exceptions as a `go-to` mechanism for business logic. Raise exceptions
    when there is actually something wrong with the code that callers need to be aware
    of.
  prefs: []
  type: TYPE_NORMAL
- en: This last concept is an important one; exceptions are usually about notifying
    the caller about something that is amiss. This means that exceptions should be
    used carefully because they weaken encapsulation. The more exceptions a function
    has, the more the caller function will have to anticipate, therefore knowing about
    the function it is calling. And if a function raises too many exceptions, this
    means that is not so context-free, because every time we want to invoke it, we
    will have to keep all of its possible side-effects in mind.
  prefs: []
  type: TYPE_NORMAL
- en: This can be used as a heuristic to tell when a function is not cohesive enough
    and has too many responsibilities. If it raises too many exceptions, it could
    be a sign that it has to be broken down into multiple, smaller ones.
  prefs: []
  type: TYPE_NORMAL
- en: Here are some recommendations that relate to exceptions in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Handle exceptions at the right level of abstraction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Exceptions are also part of the principal functions that do one thing, and one
    thing only. The exception the function is handling (or raising) has to be consistent
    with the logic encapsulated on it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we can see what we mean by mixing different levels of abstractions.
    Imagine an object that acts as a transport for some data in our application. It
    connects to an external component where the data is going to be sent upon decoding.
    In the following listing, we will focus on the `deliver_event` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: For our analysis, let's zoom in and focus on how the `deliver_event()` method
    handles exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: What does `ValueError` have to do with `ConnectionError`? Not much. By looking
    at these two highly different types of error, we can get an idea of how responsibilities
    should be divided. The `ConnectionError` should be handled inside the `connect`
    method. This will allow a clear separation of behavior. For example, if this method
    needs to support retries, that would be a way of doing it. Conversely, `ValueError`
    belongs to the `decode` method of the event. With this new implementation, this
    method does not need to catch any exception—the exceptions it was worrying about
    before are either handled by internal methods or deliberately left to be raised.
  prefs: []
  type: TYPE_NORMAL
- en: 'We should separate these fragments into different methods or functions. For
    connection management, a small function should be enough. This function will be
    in charge of trying to establish the connection, catching exceptions (should they
    occur), and logging them accordingly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will call this function in our method. As for the `ValueError` exception
    on the event, we could separate it with a new object and do composition, but for
    this limited case it would be overkill, so just moving the logic to a separate
    method would be enough. With these two considerations in place, the new version
    of the method looks much more compact and easier to read:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Do not expose tracebacks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is a security consideration. When dealing with exceptions, it might be
    acceptable to let them propagate if the error is too important, and maybe even
    let the program fail if this is the decision for that particular scenario and
    correctness was favored over robustness.
  prefs: []
  type: TYPE_NORMAL
- en: When there is an exception that denotes a problem, it's important to log in
    with as much detail as possible (including the traceback information, message,
    and all we can gather) so that the issue can be corrected efficiently. At the
    same time, we want to include as much detail as possible for ourselves—we definitely
    don't want any of this becoming visible to users.
  prefs: []
  type: TYPE_NORMAL
- en: In Python, tracebacks of exceptions contain very rich and useful debugging information.
    Unfortunately, this information is also very useful for attackers or malicious
    users who want to try and harm the application, not to mention that the leak would
    represent an important information disclosure, jeopardizing the intellectual property
    of your organization (parts of the code will be exposed).
  prefs: []
  type: TYPE_NORMAL
- en: If you choose to let exceptions propagate, make sure not to disclose any sensitive
    information. Also, if you have to notify users about a problem, choose generic
    messages (such as Something went wrong, or Page not found). This is a common technique
    used in web applications that display generic informative messages when an HTTP
    error occurs.
  prefs: []
  type: TYPE_NORMAL
- en: Avoid empty except blocks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This was even referred to as the most diabolical Python anti-pattern (REAL 01).
    While it is good to anticipate and defend our programs against some errors, being
    too defensive might lead to even worse problems. In particular, the only problem
    with being too defensive is that there is an empty `except` block that silently
    passes without doing anything.
  prefs: []
  type: TYPE_NORMAL
- en: 'Python is so flexible that it allows us to write code that can be faulty and
    yet, will not raise an error, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The problem with this is that it will not fail, ever. Even when it should. It
    is also non-Pythonic if you remember from the zen of Python that errors should
    never pass silently.
  prefs: []
  type: TYPE_NORMAL
- en: If there is a true exception, this block of code will not fail, which might
    be what we wanted in the first place. But what if there is a defect? We need to
    know if there is an error in our logic to be able to correct it. Writing blocks
    such as this one will mask problems, making things harder to maintain.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two alternatives:'
  prefs: []
  type: TYPE_NORMAL
- en: Catch a more specific exception (not too broad, such as an `Exception`). In
    fact, some linting tools and IDEs will warn you in some cases when the code is
    handling too broad an exception.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do some actual error handling on the `except` block.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The best thing to do would be to apply both items simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: Handling a more specific exception (for example, `AttributeError` or `KeyError`)
    will make the program more maintainable because the reader will know what to expect,
    and can get an idea of the why of it. It will also leave other exceptions free
    to be raised, and if that happens, this probably means a bug, only this time it
    can be discovered.
  prefs: []
  type: TYPE_NORMAL
- en: Handling the exception itself can mean multiple things. In its simplest form,
    it could be just about logging the exception (make sure to use `logger.exception`
    or `logger.error` to provide the full context of what happened). Other alternatives
    could be to return a default value (substitution, only that in this case after
    detecting an error, not prior to causing it), or raising a different exception.
  prefs: []
  type: TYPE_NORMAL
- en: If you choose to raise a different exception, to include the original exception
    that caused the problem, which leads us to the next point.
  prefs: []
  type: TYPE_NORMAL
- en: Include the original exception
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As part of our error handling logic, we might decide to raise a different one,
    and maybe even change its message. If that is the case, it is recommended to include
    the original exception that led to that.
  prefs: []
  type: TYPE_NORMAL
- en: In Python 3 (PEP-3134), we can now use the `raise <e> from <original_exception>`
    syntax. When using this construction, the original traceback will be embedded
    into the new exception, and the original exception will be set in the `__cause__`
    attribute of the resulting one.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if we desire to wrap default exceptions with custom ones internally
    to our project, we could still do that while including information about the root
    exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Always use the `raise <e> from <o>` syntax when changing the type of the exception.
  prefs: []
  type: TYPE_NORMAL
- en: Using assertions in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Assertions are to be used for situations that should never happen, so the expression
    on the `assert` statement has to mean an impossible condition. Should this condition
    happen, it means there is a defect in the software.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast with the error handling approach, here there is (or should not be)
    a possibility of continuing the program. If such an error occurs, the program
    must stop. It makes sense to stop the program because, as commented before, we
    are in the presence of a defect, so there is no way to move forward by releasing
    a new version of the software that corrects this defect.
  prefs: []
  type: TYPE_NORMAL
- en: The idea of using assertions is to prevent the program from causing further
    damage if such an invalid scenario is presented. Sometimes, it is better to stop
    and let the program crash, rather than let it continue processing under the wrong
    assumptions.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this reason, assertions should not be mixed with the business logic, or
    used as control flow mechanisms for the software. The following example is a bad
    idea:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Do not catch the `AssertionError` exception.
  prefs: []
  type: TYPE_NORMAL
- en: Make sure that the program terminates when an assertion fails.
  prefs: []
  type: TYPE_NORMAL
- en: Include a descriptive error message in the assertion statement and log the errors
    to make sure that you can properly debug and correct the problem later on.
  prefs: []
  type: TYPE_NORMAL
- en: Another important reason why the previous code is a bad idea is that besides
    catching `AssertionError`, the statement in the assertion is a function call.
    Function calls can have side-effects, and they aren't always repeatable (we don't
    know if calling `condition.holds()` again will yield the same result). Moreover,
    if we stop the debugger at that line, we might not be able to conveniently see
    the result that causes the error, and, again, even if we call that function again,
    we don't know if that was the offending value.
  prefs: []
  type: TYPE_NORMAL
- en: 'A better alternative requires fewer lines of code and provides more useful
    information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Separation of concerns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is a design principle that is applied at multiple levels. It is not just
    about the low-level design (code), but it is also relevant at a higher level of
    abstraction, so it will come up later when we talk about architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Different responsibilities should go into different components, layers, or modules
    of the application. Each part of the program should only be responsible for a
    part of the functionality (what we call its concerns) and should know nothing
    about the rest.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of separating concerns in software is to enhance maintainability by
    minimizing ripple effects. A **ripple** effect means the propagation of a change
    in the software from a starting point. This could be the case of an error or exception
    triggering a chain of other exceptions, causing failures that will result in a
    defect on a remote part of the application. It can also be that we have to change
    a lot of code scattered through multiple parts of the code base, as a result of
    a simple change in a function definition.
  prefs: []
  type: TYPE_NORMAL
- en: Clearly, we do not want these scenarios to happen. The software has to be easy
    to change. If we have to modify or refactor some part of the code that has to
    have a minimal impact on the rest of the application, the way to achieve this
    is through proper encapsulation.
  prefs: []
  type: TYPE_NORMAL
- en: In a similar way, we want any potential errors to be contained so that they
    don't cause major damage.
  prefs: []
  type: TYPE_NORMAL
- en: This concept is related to the DbC principle in the sense that each concern
    can be enforced by a contract. When a contract is violated, and an exception is
    raised as a result of such a violation, we know what part of the program has the
    failure, and what responsibilities failed to be met.
  prefs: []
  type: TYPE_NORMAL
- en: Despite this similarity, separation of concerns goes further. We normally think
    of contracts between functions, methods, or classes, and while this also applies
    to responsibilities that have to be separated, the idea of separation of concerns
    also applies to Python modules, packages, and basically any software component.
  prefs: []
  type: TYPE_NORMAL
- en: Cohesion and coupling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: These are important concepts for good software design.
  prefs: []
  type: TYPE_NORMAL
- en: On the one hand, **cohesion** means that objects should have a small and well-defined
    purpose, and they should do as little as possible. It follows a similar philosophy
    as Unix commands that do only one thing and do it well. The more cohesive our
    objects are, the more useful and reusable they become, making our design better.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, **coupling** refers to the idea of how two or more objects
    depend on each other. This dependency poses a limitation. If two parts of the
    code (objects or methods) are too dependent on each other, they bring with them
    some undesired consequences:'
  prefs: []
  type: TYPE_NORMAL
- en: '**No code reuse**: If one function depends too much on a particular object,
    or takes too many parameters, it''s coupled with this object, which means that
    it will be really difficult to use that function in a different context (in order
    to do so, we will have to find a suitable parameter that complies with a very
    restrictive interface)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ripple effects**: Changes in one of the two parts will certainly impact the
    other, as they are too close'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Low level of abstraction**: When two functions are so closely related, it
    is hard to see them as different concerns resolving problems at different levels
    of abstraction'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rule of thumb: Well-defined software will achieve high cohesion and low coupling.'
  prefs: []
  type: TYPE_NORMAL
- en: Acronyms to live by
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will review some principles that yield some good design
    ideas. The point is to quickly relate to good software practices by acronyms that
    are easy to remember, working as a sort of mnemonic rule. If you keep these words
    in mind, you will be able to associate them with good practices more easily, and
    finding the right idea behind a particular line of code that you are looking at
    will be faster.
  prefs: []
  type: TYPE_NORMAL
- en: These are by no means formal or academic definitions, but more like empirical
    ideas that emerged from years of working in the software industry. Some of them
    do appear in books, as they were coined by important authors (see the references
    to investigate them in more detail), and others have their roots probably in blog
    posts, papers, or conference talks.
  prefs: []
  type: TYPE_NORMAL
- en: DRY/OAOO
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ideas of **Don't Repeat Yourself** (**DRY**) and **Once and Only Once**
    (**OAOO**) are closely related, so they were included together here. They are
    self-explanatory, you should avoid duplication at all costs.
  prefs: []
  type: TYPE_NORMAL
- en: Things in the code, knowledge, have to be defined only once and in a single
    place. When you have to make a change in the code, there should be only one rightful
    location to modify. Failure to do so is a sign of a poorly designed system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Code duplication is a problem that directly impacts maintainability. It is
    very undesirable to have code duplication because of its many negative consequences:'
  prefs: []
  type: TYPE_NORMAL
- en: '**It''s error prone**: When some logic is repeated multiple times throughout
    the code, and this needs to change, it means we depend on efficiently correcting
    all the instances with this logic, without forgetting of any of them, because
    in that case there will be a bug.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**It''s expensive**: Linked to the previous point, making a change in multiple
    places takes much more time (development and testing effort) than if it was defined
    only once. This will slow the team down.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**It''s unreliable**: Also linked to the first point, when multiple places
    need to be changed for a single change in the context, you rely on the person
    who wrote the code to remember all the instances where the modification has to
    be made. There is no single source of truth.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Duplication is often caused by ignoring (or forgetting) that code represents
    knowledge. By giving meaning to certain parts of the code, we are identifying
    and labeling that knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see what this means with an example. Imagine that, in a study center,
    students are ranked by the following criteria: 11 points per exam passed, minus
    five points per exam failed, and minus two per year in the institution. The following
    is not actual code, but just a representation of how this might be scattered in
    a real code base:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Notice how the lambda which is in the key of the sorted function represents
    some valid knowledge from the domain problem, yet it doesn't reflect it (it doesn't
    have a name, a proper and rightful location, there is no meaning assigned to that
    code, nothing). This lack of meaning in the code leads to the duplication we find
    when the score is printed out while listing the raking.
  prefs: []
  type: TYPE_NORMAL
- en: 'We should reflect our knowledge of our domain problem in our code, and our
    code will then be less likely to suffer from duplication and will be easier to
    understand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'A fair disclaimer: this is just an analysis of one of the traits of code duplication.
    In reality, there are more cases, types, and taxonomies of code duplication, entire
    chapters could be dedicated to this topic, but here we focus on one particular
    aspect to make the idea behind the acronym clear.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we have taken what is probably the simplest approach to eliminating
    duplication: creating a function. Depending on the case, the best solution would
    be different. In some cases, there might be an entirely new object that has to
    be created (maybe an entire abstraction was missing). In other cases, we can eliminate
    duplication with a context manager. Iterators or generators (described in [Chapter
    7](32503c77-5ff2-4d35-af0e-8d9300cfa357.xhtml), *Using Generators*) could also
    help to avoid repetition in the code, and decorators (explained in [Chapter 5](f5d9c7e4-4092-48de-a22c-564df482b021.xhtml), *Using
    Decorators to Improve Our Code), *will also help.'
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, there is no general rule or pattern to tell you which of the
    features of Python are the most suitable to address code duplication, but hopefully,
    after seeing the examples in this book, and how the elements of Python are used,
    the reader will be able to develop his/her own intuition.
  prefs: []
  type: TYPE_NORMAL
- en: YAGNI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**YAGNI** (short for **You Ain''t Gonna Need It**) is an idea you might want
    to keep in mind very often when writing a solution if you do not want to over-engineer
    it.'
  prefs: []
  type: TYPE_NORMAL
- en: We want to be able to easily modify our programs, so we want to make them future-proof.
    In line with that, many developers think that they have to anticipate all future
    requirements and create solutions that are very complex, and so create abstractions
    that are hard to read, maintain, and understand. Sometime later, it turns out
    that those anticipated requirements do not show up, or they do but in a different
    way (surprise!), and the original code that was supposed to handle precisely that
    does not work. The problem is that now it is even harder to refactor and extend
    our programs. What happened was that the original solution did not handle the
    original requirements correctly, and neither do the current ones, simply because
    it is the wrong abstraction.
  prefs: []
  type: TYPE_NORMAL
- en: Having maintainable software is not about anticipating future requirements (do
    not do futurology!). It is about writing software that only addresses current
    requirements in such a way that it will be possible (and easy) to change later
    on. In other words, when designing, make sure that your decisions don't tie you
    down, and that you will be able to keep on building, but do not build more than
    what's necessary.
  prefs: []
  type: TYPE_NORMAL
- en: KIS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**KIS **(stands for **Keep It Simple**) relates very much to the previous point.
    When you are designing a software component, avoid over-engineering it; ask yourself
    if your solution is the minimal one that fits the problem.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Implement minimal functionality that correctly solves the problem and does
    not complicate your solution more than is necessary. Remember: the simpler the
    design, the more maintainable it will be.'
  prefs: []
  type: TYPE_NORMAL
- en: This design principle is an idea we will want to keep in mind at all levels
    of abstraction, whether we are thinking of a high-level design, or addressing
    a particular line of code.
  prefs: []
  type: TYPE_NORMAL
- en: At a high-level, think on the components we are creating. Do we really need
    all of them? Does this module actually require being utterly extensible right
    now? Emphasize the last part—maybe we want to make that component extensible,
    but now is not the right time, or it is not appropriate to do so because we still
    do not have enough information to create the proper abstractions, and trying to
    come up with generic interfaces at this point will only lead to even worse problems.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of code, keeping it simple usually means using the smallest data structure
    that fits the problem. You will most likely find it in the standard library.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes, we might over-complicate code, creating more functions or methods
    than what''s necessary. The following class creates a namespace from a set of
    keyword arguments that have been provided, but it has a rather complicated code
    interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Having an extra class method for initializing the object doesn''t seem really
    necessary. Then, the iteration, and the call to `setattr` inside it, make things
    even more strange, and the interface that is presented to the user is not very
    clear:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The user has to know of the existence of this other method, which is not convenient.
    It would be better to keep it simple, and just initialize the object as we initialize
    any other object in Python (after all, there is a method for that) with the `__init__` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember the zen of Python: simple is better than complex.'
  prefs: []
  type: TYPE_NORMAL
- en: EAFP/LBYL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**EAFP** (stands for **Easier to Ask Forgiveness than Permission**), while **LBYL** (stands
    for **Look Before You Leap**).'
  prefs: []
  type: TYPE_NORMAL
- en: The idea of EAFP is that we write our code so that it performs an action directly,
    and then we take care of the consequences later in case it doesn't work. Typically,
    this means try running some code, expecting it to work, but catching an exception
    if it doesn't, and then handling the corrective code on the except block.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the opposite of **LBYL**. As its name says, in the look before you
    leap approach, we first check what we are about to use. For example, we might
    want to check if a file is available before trying to operate with it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This might be good for other programming languages, but it is not the Pythonic
    way of writing code. Python was built with ideas such as EAFP, and it encourages
    you to follow them (remember, explicit is better than implicit). This code would
    instead be rewritten like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Prefer EAFP over LBYL.
  prefs: []
  type: TYPE_NORMAL
- en: Composition and inheritance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In object-oriented software design, there are often discussions as to how to
    address some problems by using the main ideas of the paradigm (polymorphism, inheritance,
    and encapsulation).
  prefs: []
  type: TYPE_NORMAL
- en: Probably the most commonly used of these ideas is inheritance—developers often
    start by creating a class hierarchy with the classes they are going to need and
    decide the methods each one should implement.
  prefs: []
  type: TYPE_NORMAL
- en: While inheritance is a powerful concept, it does come with its perils. The main
    one is that every time we extend a base class, we are creating a new one that
    is tightly coupled with the parent. As we have already discussed, coupling is
    one of the things we want to reduce to a minimum when designing software.
  prefs: []
  type: TYPE_NORMAL
- en: One of the main uses developers relate inheritance with is code reuse. While
    we should always embrace code reuse, it is not a good idea to force our design
    to use inheritance to reuse code just because we get the methods from the parent
    class for free. The proper way to reuse code is to have highly cohesive objects
    that can be easily composed and that could work on multiple contexts.
  prefs: []
  type: TYPE_NORMAL
- en: When inheritance is a good decision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have to be careful when creating a derived class, because this is a double-edged
    sword—on the one hand, it has the advantage that we get all the code of the methods
    from the parent class for free, but on the other hand, we are carrying all of
    them to a new class, meaning that we might be placing too much functionality in
    a new definition.
  prefs: []
  type: TYPE_NORMAL
- en: 'When creating a new subclass, we have to think if it is actually going to use
    all of the methods it has just inherited, as a heuristic to see if the class is
    correctly defined. If instead, we find out that we do not need most of the methods,
    and have to override or replace them, this is a design mistake that could be caused
    by several reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: The superclass is vaguely defined and contains too much responsibility, instead
    of a well-defined interface
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The subclass is not a proper specialization of the superclass it is trying to
    extend
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A good case for using inheritance is the type of situation when you have a class
    that defines certain components with its behavior that are defined by the interface
    of this class (its public methods and attributes), and then you need to specialize
    this class in order to create objects that do the same but with something else
    added, or with some particular parts of its behavior changed.
  prefs: []
  type: TYPE_NORMAL
- en: You can find examples of good uses of inheritance in the Python standard library
    itself. For example, in the `http.server` package ([https://docs.python.org/3/library/http.server.html#http.server.BaseHTTPRequestHandler](https://docs.python.org/3/library/http.server.html#http.server.BaseHTTPRequestHandler)),
    we can find a base class such as `BaseHTTPRequestHandler`, and subclasses such
    as `SimpleHTTPRequestHandler` that extend this one by adding or changing part
    of its base interface.
  prefs: []
  type: TYPE_NORMAL
- en: Speaking of interface definition, this is another good use for inheritance.
    When we want to enforce the interface of some objects, we can create an abstract
    base class that does not implement the behavior itself, but instead just defines
    the interface—every class that extends this one will have to implement these to
    be a proper subtype.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, another good case for inheritance is exceptions. We can see that the
    standard exception in Python derives from `Exception`. This is what allows you
    to have a generic clause such as `except Exception:`, which will catch every possible
    error. The important point is the conceptual one, they are classes derived from `Exception`
    because they are more specific exceptions. This also works in well-known libraries
    such as `requests`, for instance, in which an `HTTPError` is `RequestException`,
    which in turn is an `IOError`.
  prefs: []
  type: TYPE_NORMAL
- en: Anti-patterns for inheritance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If the previous section had to be summarized into a single word, it would be specialization*. *The
    correct use for inheritance is to specialize objects and create more detailed
    abstractions starting from base ones.
  prefs: []
  type: TYPE_NORMAL
- en: The parent (or base) class is part of the public definition of the new derived
    class. This is because the methods that are inherited will be part of the interface
    of this new class. For this reason, when we read the public methods of a class,
    they have to be consistent with what the parent class defines.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if we see that a class derived from `BaseHTTPRequestHandler` implements
    a method named `handle()`, it would make sense because it is overriding one of
    the parents. If it had any other method whose name relates to an action that has
    to do with an HTTP request, then we could also think that is correctly placed
    (but we would not think that if we found something called `process_purchase()` on
    that class).
  prefs: []
  type: TYPE_NORMAL
- en: The previous illustration might seem obvious, but it is something that happens
    very often, especially when developers try to use inheritance with the sole goal
    of reusing code. In the next example, we will see a typical situation that represents
    a common anti-pattern in Python—there is a domain problem that has to be represented,
    and a suitable data structure is devised for that problem, but instead of creating
    an object that uses such a data structure, the object becomes the data structure
    itself.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see these problems more concretely through an example. Imagine we have
    a system for managing insurance, with a module in charge of applying policies
    to different clients. We need to keep in memory a set of customers that are being
    processed at the time in order to apply those changes before further processing
    or persistence. The basic operations we need are to store a new customer with
    its records as satellite data, apply a change on a policy, or edit some of the
    data, just to name a few. We also need to support a batch operation, that is,
    when something on the policy itself changes (the one this module is currently
    processing), we have to apply these changes overall to customers on the current
    transaction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thinking in terms of the data structure we need, we realize that accessing
    the record for a particular customer in constant time is a nice trait. Therefore,
    something like `policy_transaction[customer_id]` looks like a nice interface.
    From this, we might think that a subscriptable object is a good idea, and further
    on, we might get carried away into thinking that the object we need is a dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'With this code, we can get information about a policy for a customer by its
    identifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Sure, we achieved the interface we wanted in the first place, but at what cost?
    Now, this class has a lot of extra behavior from carrying out methods that weren''t
    necessary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: There are (at least) two major problems with this design. On the one hand, the
    hierarchy is wrong. Creating a new class from a base one conceptually means that
    it's a more specific version of the class it's extending (hence the name). How
    is it that a `TransactionalPolicy` is a dictionary? Does this make sense? Remember,
    this is part of the public interface of the object, so users will see this class,
    their hierarchy, and will notice such an odd specialization, as well as its public
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: This leads us to the second problem—coupling. The interface of the transactional
    policy now includes all methods from a dictionary. Does a transactional policy
    really need methods such as `pop()` or `items()`? However, there they are. They
    are also public, so any user of this interface is entitled to call them, with
    whatever undesired side-effect they may carry. More on this point—we don't really
    gain much by extending a dictionary. The only method it actually needs to update
    for all customers affected by a change in the current policy (`change_in_policy()`)
    is not on the base class, so we will have to define it ourselves either way.
  prefs: []
  type: TYPE_NORMAL
- en: This is a problem of mixing implementation objects with domain objects. A dictionary
    is an implementation object, a data structure, suitable for certain kinds of operation,
    and with a trade-off like all data structures. A transactional policy should represent
    something in the domain problem, an entity that is part of the problem we are
    trying to solve.
  prefs: []
  type: TYPE_NORMAL
- en: Hierarchies like this one are incorrect, and just because we get a few magic
    methods from a base class (to make the object subscriptable by extending a dictionary)
    is not reason enough to create such an extension. Implementation classes should
    be extending solely when creating other, more specific, implementation classes.
    In other words, extend a dictionary if you want to create another (more specific,
    or slightly modified) dictionary. The same rule applies to classes of the domain
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'The correct solution here is to use composition. `TransactionalPolicy` is not
    a dictionary—it uses a dictionary. It should store a dictionary in a private attribute,
    and implement `__getitem__()` by proxying from that dictionary and then only implementing
    the rest of the public method it requires:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This way is not only conceptually correct, but also more extensible. If the
    underlying data structure (which, for now, is a dictionary) is changed in the
    future, callers of this object will not be affected, so long as the interface
    is maintained. This reduces coupling, minimizes ripple effects, allows for better
    refactoring (unit tests ought not to be changed), and makes the code more maintainable.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple inheritance in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python supports multiple inheritance. As inheritance, when improperly used,
    leads to design problems, you could also expect that multiple inheritance will
    also yield even bigger problems when it's not correctly implemented.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple inheritance is, therefore, a double-edged sword. It can also be very
    beneficial in some cases. Just to be clear, there is nothing wrong with multiple
    inheritance—the only problem it has is that when it's not implemented correctly,
    it will multiply the problems.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple inheritance is a perfectly valid solution when used correctly, and
    this opens up new patterns (such as the adapter pattern we discussed in [Chapter
    9](dee5b4ed-34cd-4077-a5b4-83d4853e6e56.xhtml)*, Common Design Patterns)* and
    mixins.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most powerful applications of multiple inheritance is perhaps that
    which enables the creation of mixins. Before exploring mixins, we need to understand
    how multiple inheritance works, and how methods are resolved in a complex hierarchy.
  prefs: []
  type: TYPE_NORMAL
- en: Method Resolution Order (MRO)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some people don't like multiple inheritance because of the constraints it has
    in other programming languages, for instance, the so-called diamond problem. When
    a class extends from two or more, and all of those classes also extend from other
    base classes, the bottom ones will have multiple ways to resolve the methods coming
    from the top-level classes. The question is, which of these implementations is
    used?
  prefs: []
  type: TYPE_NORMAL
- en: Consider the following diagram, which has a structure with multiple inheritance.
    The top-level class has a class attribute and implements the `__str__` method.
    Think of any of the concrete classes, for example, `ConcreteModuleA12`—it extends
    from `BaseModule1` and `BaseModule2`, and each one of them will take the implementation
    of `__str__` from `BaseModule`. Which of these two methods is going to be the
    one for `ConcreteModuleA12`?
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/7ff9f78e-eb12-431a-a8fb-307882151e49.png)'
  prefs: []
  type: TYPE_IMG
- en: 'With the value of the class attribute, this will become evident:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s test this to see what method is being called:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: There is no collision. Python resolves this by using an algorithm called **C3
    linearization** or MRO, which defines a deterministic way in which methods are
    going to be called.
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, we can specifically ask the class for its resolution order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Knowing about how the method is going to be resolved in a hierarchy can be used
    to our advantage when designing classes because we can make use of mixins.
  prefs: []
  type: TYPE_NORMAL
- en: Mixins
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A mixin is a base class that encapsulates some common behavior with the goal
    of reusing code. Typically, a mixin class is not useful on its own, and extending
    this class alone will certainly not work, because most of the time it depends
    on methods and properties that are defined in other classes. The idea is to use
    mixin classes along with other ones, through multiple inheritance, so that the
    methods or properties used on the mixin will be available.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine we have a simple parser that takes a string and provides iteration
    over it by its values separated by hyphens (-):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This is quite straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'But now we want the values to be sent in upper-case, without altering the base
    class. For this simple example, we could just create a new class, but imagine
    that a lot of classes are already extending from `BaseTokenizer`, and we don''t
    want to replace all of them. We can mix a new class into the hierarchy that handles
    this transformation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The new `Tokenizer` class is really simple. It doesn't need any code because
    it takes advantage of the mixin. This type of mixing acts as a sort of decorator.
    Based on what we just saw, `Tokenizer` will take `__iter__` from the mixin, and
    this one, in turn, delegates to the next class on the line (by calling `super()`),
    which is the `BaseTokenizer`, but it converts its values to uppercase, creating
    the desired effect.
  prefs: []
  type: TYPE_NORMAL
- en: Arguments in functions and methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Python, functions can be defined to receive arguments in several different
    ways, and these arguments can also be provided by callers in multiple ways.
  prefs: []
  type: TYPE_NORMAL
- en: There is also an industry-wide set of practices for defining interfaces in software
    engineering that closely relates to the definition of arguments in functions.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will first explore the mechanics of arguments in Python
    functions and afterwards review the general principles of software engineering
    that relate to good practices on this subject to finally relate both concepts.
  prefs: []
  type: TYPE_NORMAL
- en: How function arguments work in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, we will explore the particularities of how arguments are passed to functions
    in Python, and then we will review the general theory of good software engineering
    practices that relate to these concepts.
  prefs: []
  type: TYPE_NORMAL
- en: By first understanding the possibilities that Python offers for handling parameters,
    we will be able to assimilate general rules more easily, and the idea is that
    after having done so, we can easily draw conclusions on what good patterns or
    idioms are when handling arguments. Then, we can identify in which scenarios the
    Pythonic approach is the correct one, and in which cases we might be abusing the
    features of the language.
  prefs: []
  type: TYPE_NORMAL
- en: How arguments are copied to functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first rule in Python is that all arguments are passed by a value. Always.
    This means that when passing values to functions, they are assigned to the variables
    on the signature definition of the function to be later used on it. You will notice
    that a function changing arguments might depend on the type arguments—if we are
    passing `mutable` objects, and the body of the function modifies this, then, of
    course, we have side-effect that they will have been changed by the time the function
    returns.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following we can see the difference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This might look like an inconsistency, but it's not. When we pass the first
    argument, a string, this is assigned to the argument on the function. Since string
    objects are immutable, a statement like `"argument += <expression>"` will in fact
    create the new object, `"argument + <expression>"`, and assign that back to the
    argument. At that point, an `argument` is just a local variable inside the scope
    of the function and has nothing to do with the original one in the caller.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, when we pass `list`, which is a `mutable` object, then that
    statement has a different meaning (it's actually equivalent to calling `.extend()`
    on that `list`). This operator acts by modifying the `list` in-place over a variable
    that holds a reference to the original `list` object, hence modifying it.
  prefs: []
  type: TYPE_NORMAL
- en: We have to be careful when dealing with these types of parameter because it
    can lead to unexpected side-effects. Unless you are absolutely sure that it is
    correct to manipulate mutable arguments in this way, we would recommend avoiding
    it and going for alternatives without these problems.
  prefs: []
  type: TYPE_NORMAL
- en: Don't `mutate` function arguments. In general, try to avoid side-effects in
    functions as much as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Arguments in Python can be passed by position, as in many other programming
    languages, but also by keyword. This means that we can explicitly tell the function
    which values we want for which of its parameters. The only caveat is that after
    a parameter is passed by keyword, the rest that follow must also be passed this
    way, otherwise, `SyntaxError` will be raised.
  prefs: []
  type: TYPE_NORMAL
- en: Variable number of arguments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python, as well as other languages, has built-in functions and constructions
    that can take a variable number of arguments. Consider for example string interpolation
    functions (whether it be by using the `%` operator or the `format` method for
    strings), which follow a similar structure to the `printf` function in C, a first
    positional parameter with the string format, followed by any number of arguments
    that will be placed on the markers of that formatting string.
  prefs: []
  type: TYPE_NORMAL
- en: Besides taking advantage of these functions that are available in Python, we
    can also create our own, which will work in a similar fashion. In this section,
    we will cover the basic principles of functions with a variable number of arguments,
    along with some recommendations, so that in the next section, we can explore how
    to use these features to our advantage when dealing with common problems, issues,
    and constraints that functions might have if they have too many arguments.
  prefs: []
  type: TYPE_NORMAL
- en: For a variable number of positionalarguments, the star symbol (`*`) is used,
    preceding the name of the variable that is packing those arguments. This works
    through the packing mechanism of Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say there is a function that takes three positional arguments. In one
    part of the code, we conveniently happen to have the arguments we want to pass
    to the function inside a list, in the same order as they are expected by the function.
    Instead of passing them one by one by the position (that is, `list[0]` to the
    first element, `list[1]` to the second, and so on), which would be really un-Pythonic,
    we can use the packing mechanism and pass them all together in a single instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The nice thing about the packing mechanism is that it also works the other
    way around. If we want to extract the values of a list to variables, by their
    respective position, we can assign them like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Partial unpacking is also possible. Let''s say we are just interested in the
    first values of a sequence (this can be a list, tuple, or something else), and
    after some point we just want the rest to be kept together. We can assign the
    variables we need and leave the rest under a packaged list. The order in which
    we unpack is not limited. If there is nothing to place in one of the unpacked
    subsections, the result will be an empty list. The reader is encouraged to try
    examples such as those presented in the following listing on a Python terminal,
    and also to explore that unpacking works with generators as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'One of the best uses for unpacking variables can be found in iteration. When
    we have to iterate over a sequence of elements, and each element is, in turn,
    a sequence, it is a good idea to unpack at the same time each element is being
    iterated over. To see an example of this in action, we are going to pretend that
    we have a function that receives a list of database rows, and that it is in charge
    of creating users out of that data. The first implementation takes the values
    to construct the user with from the position of each column in the row, which
    is not idiomatic at all. The second implementation uses unpacking while iterating:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the second version is much easier to read. In the first version
    of the function (`bad_users_from_rows`), we have data expressed in the form `row[0]`,
    `row[1]`, and `row[2]`, which doesn't tell us anything about what they are. On
    the other hand, variables such as `user_id`, `first_name`, and `last_name` speak
    for themselves.
  prefs: []
  type: TYPE_NORMAL
- en: We can leverage this kind of functionality to our advantage when designing our
    own functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of this that we can find in the standard library lies in the `max`
    function, which is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: There is a similar notation, with two stars (`**`) for keyword arguments. If
    we have a dictionary and we pass it with a double star to a function, what it
    will do is pick the keys as the name for the parameter, and pass the value for
    that `key` as the `value` for that parameter in that function.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, check this out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'It is the same as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Conversely, if we define a function with a parameter starting with two-star
    symbols, the opposite will happen—keyword-provided parameters will be packed into
    a dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: The number of arguments in functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we agree on the idea that having functions or methods that
    take too many arguments is a sign of bad design (a code smell). Then, we propose
    ways of dealing with this issue.
  prefs: []
  type: TYPE_NORMAL
- en: The first alternative is a more general principle of software design—**reification**
    (creating a new object for all of those arguments that we are passing, which is
    probably the abstraction we are missing). Compacting multiple arguments into a
    new object is not a solution specific to Python, but rather something that we
    can apply in any programming language.
  prefs: []
  type: TYPE_NORMAL
- en: Another option would be to use the Python-specific features we saw in the previous
    section, making use of variable positional and keyword arguments to create functions
    that have a dynamic signature. While this might be a Pythonic way of proceeding,
    we have to be careful not to abuse the feature, because we might be creating something
    that is so dynamic that it is hard to maintain. In this case, we should take a
    look at the body of the function. Regardless of the signature, and whether the
    parameters seem to be correct, if the function is doing too many different things
    responding to the values of the parameters, then it is a sign that it has to be
    broken down into multiple smaller functions (remember, functions should do one
    thing, and one thing only!).
  prefs: []
  type: TYPE_NORMAL
- en: Function arguments and coupling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The more arguments a function signature has, the more likely this one is going
    to be tightly coupled with the caller function.
  prefs: []
  type: TYPE_NORMAL
- en: Let's say we have two functions, `f1`, and `f2`, and the latter takes five parameters.
    The more parameters `f2` takes, the more difficult it would be for anyone trying
    to call that function to gather all that information and pass it along so that
    it can work properly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, `f1` seems to have all of this information because it can call it correctly.
    From this, we can derive two conclusions: first, `f2` is probably a leaky abstraction,
    which means that since `f1` knows everything that `f2` requires, it can pretty
    much figure out what it is doing internally and will be able to do it by itself.
    So, all in all, `f2` is not abstracting that much. Second, it looks like `f2`
    is only useful to `f1`, and it is hard to imagine using this function in a different
    context, making it harder to reuse.'
  prefs: []
  type: TYPE_NORMAL
- en: When functions have a more general interface and are able to work with higher-level
    abstractions, they become more reusable.
  prefs: []
  type: TYPE_NORMAL
- en: This applies to all sort of functions and object methods, including the `__init__`
    method for classes. The presence of a method like this could generally (but not
    always) mean that a new higher-level abstraction should be passed instead, or
    that there is a missing object.
  prefs: []
  type: TYPE_NORMAL
- en: If a function needs too many parameters to work properly, consider it a code
    smell.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, this is such a design problem that static analysis tools such as `pylint`
    (discussed in [Chapter 1](bba62a64-dfe9-478f-9b33-6c3240d75f59.xhtml), *Introduction,
    Code Formatting, and Tools*) will, by default, raise a warning about when they
    encounter such a case. When this happens, don't suppress the warning—refactor
    it instead.
  prefs: []
  type: TYPE_NORMAL
- en: Compact function signatures that take too many arguments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Suppose we find a function that requires too many parameters. We know that we
    cannot leave the code base like that, and a refactor is imperative. But, what
    are the options?
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the case, some of the following rules might apply. This is by no
    means extensive, but it does provide an idea of how to solve some scenarios that
    occur quite often.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes, there is an easy way to change parameters if we can see that most
    of them belong to a common object. For example, consider a function call like
    this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Now, the function might or might not take additional arguments, but something
    is really obvious here: all of the parameters depend upon `request`, so why not
    pass the `request` object instead? This is a simple change, but it significantly
    improves the code. The correct function call should be `track_request(request)`—not
    to mention that, semantically, it also makes much more sense.
  prefs: []
  type: TYPE_NORMAL
- en: While passing around parameters like this is encouraged, in all cases where
    we pass mutable objects to functions, we must be really careful about side-effects.
    The function we are calling should not make any modifications to the object we
    are passing because that will mutate the object, creating an undesired side-effect.
    Unless this is actually the desired effect (in which case, it must be made explicit),
    this kind of behavior is discouraged. Even when we actually want to change something
    on the object we are dealing with, a better alternative would be to copy it and
    return a (new) modified version of it.
  prefs: []
  type: TYPE_NORMAL
- en: Work with immutable objects, and avoid side-effects as much as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'This brings us to a similar topic: grouping parameters. In the previous example,
    the parameters were already grouped, but the group (in this case, the request
    object) was not being used. But other cases are not as obvious as that one, and
    we might want to group all the data in the parameters in a single object that
    acts as a container. Needless to say, this grouping has to make sense. The idea
    here is to *reify*: create the abstraction that was missing from our design.'
  prefs: []
  type: TYPE_NORMAL
- en: If the previous strategies don't work, as a last resort we can change the signature
    of the function to accept a variable number of arguments. If the number of arguments
    is too big, using `*args` or `**kwargs` will make things harder to follow, so
    we have to make sure that the interface is properly documented and correctly used,
    but in some cases this is worth doing.
  prefs: []
  type: TYPE_NORMAL
- en: It's true that a function defined with `*args` and `**kwargs` is really flexible
    and adaptable, but the disadvantage is that it loses its signature, and with that,
    part of its meaning, and almost all of its legibility. We have seen examples of
    how names for variables (including function arguments) make the code much easier
    to read. If a function will take any number of arguments (positional or keyword),
    we might find out that when we want to take a look at that function in the future,
    we probably won't know exactly what it was supposed to do with its parameters,
    unless it has a very good docstring.
  prefs: []
  type: TYPE_NORMAL
- en: Final remarks on good practices for software design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A good software design involves a combination of following good practices of
    software engineering and taking advantage of most of the features of the language.
    There is a great value in using everything that Python has to offer, but there
    is also a great risk of abusing this and trying to fit complex features into simple
    designs.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to this general principle, it would be good to add some final recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: Orthogonality in software
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This word is very general and can have multiple meanings or interpretations.
    In math, orthogonal means that two elements are independent. If two vectors are
    orthogonal, their scalar product is zero. It also means they are not related at
    all: a change in one of them doesn''t affect the other one at all. That''s the
    way we should think about our software.'
  prefs: []
  type: TYPE_NORMAL
- en: Changing a module, class, or function should have no impact on the outside world
    to that component that is being modified. This is of course highly desirable,
    but not always possible. But even for cases where it's not possible, a good design
    will try to minimize the impact as much as possible. We have seen ideas such as
    separation of concerns, cohesion, and isolation of components.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of the runtime structure of software, orthogonality can be interpreted
    as the fact that makes changes (or side-effects) local. This means, for instance,
    that calling a method on an object should not alter the internal state of other
    (unrelated) objects. We have already (and will continue to do so) emphasized in
    this book the importance of minimizing side-effects in our code.
  prefs: []
  type: TYPE_NORMAL
- en: In the example with the mixin class, we created a `tokenizer` object that returned
    an iterable. The fact that the `__iter__` method returned a new generator increases
    the chances that all three classes (the base, the mixing, and the concrete class)
    are orthogonal. If this had returned something in concrete (a list, let's say),
    this would have created a dependency on the rest of the classes, because when
    we changed the list to something else, we might have needed to update other parts
    of the code, revealing that the classes were not as independent as they should
    be.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s show you a quick example. Python allows passing functions by parameter
    because they are just regular objects. We can use this feature to achieve some
    orthogonality. We have a function that calculates a price, including taxes and
    discounts, but afterward we want to format the final price that''s obtained:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that the top-level function is composing two orthogonal functions. One
    thing to notice is how we calculate the price, which is how the other one is going
    to be represented. Changing one does not change the other. If we don''t pass anything
    in particular, it will use string conversion as the default representation function,
    and if we choose to pass a custom function, the resulting string will change.
    However, changes in `show_price` do not affect `calculate_price`. We can make
    changes to either function, knowing that the other one will remain as it was:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: There is an interesting quality aspect that relates to orthogonality. If two
    parts of the code are orthogonal, it means one can change without affecting the
    other. This implies that the part that changed has unit tests that are also orthogonal
    to the unit tests of the rest of the application. Under this assumption, if those
    tests pass, we can assume (up to a certain degree) that the application is correct
    without needing full regression testing.
  prefs: []
  type: TYPE_NORMAL
- en: More broadly, orthogonality can be thought of in terms of features. Two functionalities
    of the application can be totally independent so that they can be tested and released
    without having to worry that one might break the other (or the rest of the code,
    for that matter). Imagine that the project requires a new authentication mechanism
    (`oauth2`, let's say, but just for the sake of the example), and at the same time
    another team is also working on a new report. Unless there is something fundamentally
    wrong in that system, neither of those features should impact the other. Regardless
    of which one of those gets merged first, the other one should not be affected
    at all.
  prefs: []
  type: TYPE_NORMAL
- en: Structuring the code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The way code is organized also impacts the performance of the team and its maintainability.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, having large files with lots of definitions (classes, functions,
    constants, and so on) is a bad practice and should be discouraged. This doesn't
    mean going to the extreme of placing one definition per file, but a good code
    base will structure and arrange components by similarity.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, most of the time, changing a large file into smaller ones is not a
    hard task in Python. Even if multiple other parts of the code depend on definitions
    made on that file, this can be broken down into a package, and will maintain total
    compatibility. The idea would be to create a new directory with a `__init__.py`
    file on it (this will make it a Python package). Alongside this file, we will
    have multiple files with all the particular definitions each one requires (fewer
    functions and classes grouped by a certain criterion). Then, the `__init__.py`
    file will import from all the other files the definitions it previously had (which
    is what guarantees its compatibility). Additionally, these definitions can be
    mentioned in the `__all__` variable of the module to make them exportable.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many advantages of this. Other than the fact that each file will
    be easier to navigate, and things will be easier to find, we could argue that
    it will be more efficient because of the following reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: It contains fewer objects to parse and load into memory when the module is imported
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The module itself will probably be importing fewer modules because it needs
    fewer dependencies, like before
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It also helps to have a convention for the project. For example, instead of
    placing `constants` in all of the files, we can create a file specific to the
    constant values to be used in the project, and import it from there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Centralizing information like this makes it easier to reuse code and helps to
    avoid inadvertent duplication.
  prefs: []
  type: TYPE_NORMAL
- en: More details about separating modules and creating Python packages will be discussed
    in [Chapter 10](87530c54-bf97-48c2-a557-de448cd690d4.xhtml), *Clean Architecture*,
    when we explore this in the context of software architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have explored several principles to achieve a clean design.
    Understanding that the code is part of the design is key to achieving high-quality
    software. This and the following chapter are focused precisely on that.
  prefs: []
  type: TYPE_NORMAL
- en: With these ideas, we can now construct more robust code. For example, by applying
    DbC, we can create components that are guaranteed to work under their constraints.
    More importantly, if errors occur, this will not happen out of the blue, but instead,
    we will have a clear idea of who the offender is and which part of the code broke
    the contract. This compartmentalization is clear to effective debugging.
  prefs: []
  type: TYPE_NORMAL
- en: Along similar lines, each component can be made more robust if it defends itself
    from malicious intent or incorrect input. Although this idea goes in a different
    direction from design by contract, it might complement it very well. Defensive
    programming is a good idea, especially for critical parts of the application.
  prefs: []
  type: TYPE_NORMAL
- en: For both approaches (design by contract and defensive programming), it's important
    to correctly handle assertions. Keep in mind how they should be used in Python,
    and don't use assertions as part of the control flow logic of the program. Don't
    catch this exception, either.
  prefs: []
  type: TYPE_NORMAL
- en: Speaking of exceptions, it's important to know how and when to use them, and
    the most important concept here is to avoid using exception as a control flow
    (go-to) kind of construction.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have explored a recurrent topic in object-oriented design: deciding between
    using inheritance or composition. The main lesson here is not to use one over
    the other, but to use whichever option is better; we should also avoid some common
    anti-patterns, which we might often see in Python (especially given its highly
    dynamic nature).'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we discussed the number of arguments in functions, along with heuristics
    for a clean design, always with the particularities of Python in mind.
  prefs: []
  type: TYPE_NORMAL
- en: These concepts are fundamental design ideas that lay the foundations for what's
    coming in the next chapter. We need to first understand these ideas so that we
    can move on to more advanced topics, such as SOLID principles.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here is a list of information you can refer to:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Object-Oriented Software Construction, Second Edition*, written by Bertrand
    Meyer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The Pragmatic Programmer: From Journeyman to Master*, by Andrew Hunt and David
    Thomas published by Addison-Wesley, 2000.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PEP-316*: Programming by Contract for Python ([https://www.python.org/dev/peps/pep-0316/](https://www.python.org/dev/peps/pep-0316/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*REAL 01*: The Most Diabolical Python Antipattern: [https://realpython.com/blog/python/the-most-diabolical-python-antipattern/](https://realpython.com/blog/python/the-most-diabolical-python-antipattern/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PEP-3134:* Exception Chaining and Embedded Tracebacks ([https://www.python.org/dev/peps/pep-3134/](https://www.python.org/dev/peps/pep-3134/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Idiomatic Python: EAFP versus LBYL* ([https://blogs.msdn.microsoft.com/pythonengineering/2016/06/29/idiomatic-python-eafp-versus-lbyl/](https://blogs.msdn.microsoft.com/pythonengineering/2016/06/29/idiomatic-python-eafp-versus-lbyl/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Composition vs. Inheritance: How to Choose?* ([https://www.thoughtworks.com/insights/blog/composition-vs-inheritance-how-choose](https://www.thoughtworks.com/insights/blog/composition-vs-inheritance-how-choose))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python HTTP ([https://docs.python.org/3/library/http.server.html#http.server.BaseHTTPRequestHandler](https://docs.python.org/3/library/http.server.html#http.server.BaseHTTPRequestHandler))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Source reference for exceptions in the `requests` library ([http://docs.python-requests.org/en/master/_modules/requests/exceptions/](http://docs.python-requests.org/en/master/_modules/requests/exceptions/))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Code Complete: A Practical Handbook of Software Construction, Second Edition*,
    written by Steve McConnell'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL

- en: Using Generators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generators are another of those features that makes Python a peculiar language
    over more traditional ones. In this chapter, we will explore their rationale,
    why they were introduced in the language, and the problems they solve. We will
    also cover how to address problems idiomatically by using generators, and how
    to make our generators (or any iterable, for that matter) Pythonic.
  prefs: []
  type: TYPE_NORMAL
- en: We will understand why iteration (in the form of the iterator pattern) is automatically
    supported in the language. From there, we will take another journey and explore
    how generators became such a fundamental feature of Python in order to support
    other functionality, such as coroutines and asynchronous programming.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goals for this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: To create generators that improve the performance of our programs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To study how iterators (and the iterator pattern, in particular) are deeply
    embedded in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To solve problems that involve iteration idiomatically
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To understand how generators work as the basis for coroutines and asynchronous
    programming
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To explore the syntactic support for coroutines—`yield from`, `await`, and `async
    def`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The examples in this chapter will work with any version of Python 3.6 on any
    platform.
  prefs: []
  type: TYPE_NORMAL
- en: The code used in this chapter can be found at [https://github.com/PacktPublishing/Clean-Code-in-Python.](https://github.com/PacktPublishing/Clean-Code-in-Python)
  prefs: []
  type: TYPE_NORMAL
- en: The instructions are available in the `README` file.
  prefs: []
  type: TYPE_NORMAL
- en: Creating generators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generators were introduced in Python a long time ago (PEP-255), with the idea
    of introducing iteration in Python while improving the performance of the program
    (by using less memory) at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: The idea of a generator is to create an object that is iterable, and, while
    it's being iterated, will produce the elements it contains, one at a time. The
    main use of generators is to save memory—instead of having a very large list of
    elements in memory, holding everything at once, we have an object that knows how
    to produce each particular element, one at a time, as they are required.
  prefs: []
  type: TYPE_NORMAL
- en: This feature enables lazy computations or heavyweight objects in memory, in
    a similar manner to what other functional programming languages (Haskell, for
    instance) provide. It would even be possible to work with infinite sequences because
    the lazy nature of generators allows for such an option.
  prefs: []
  type: TYPE_NORMAL
- en: A first look at generators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's start with an example. The problem at hand now is that we want to process
    a large list of records and get some metrics and indicators over them. Given a
    large data set with information about purchases, we want to process it in order
    to get the lowest sale, highest sale, and the average price of a sale.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the simplicity of this example, we will assume a CSV with only two fields,
    in the following format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We are going to create an object that receives all the purchases, and this will
    give us the necessary metrics. We could get some of these values out of the box
    by simply using the `min()` and `max()` built-in functions, but that would require
    iterating all of the purchases more than once, so instead, we are using our custom
    object, which will get these values in a single iteration.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code that will get the numbers for us looks rather simple. It''s just an
    object with a method that will process all prices in one go, and, at each step,
    will update the value of each particular metric we are interested in. First, we
    will show the first implementation in the following listing, and, later on in
    this chapter (once we have seen more about iteration), we will revisit this implementation
    and get a much better (and compact) version of it. For now, we are settling on
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This object will receive all the totals for the `purchases` and process the
    required values. Now, we need a function that loads these numbers into something
    that this object can process. Here is the first version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This code works; it loads all the numbers of the file into a list that, when
    passed to our custom object, will produce the numbers we want. It has a performance
    issue, though. If you run it with a rather large dataset, it will take a while
    to complete, and it might even fail if the dataset is large enough as to not fit
    into the main memory.
  prefs: []
  type: TYPE_NORMAL
- en: If we take a look at our code that consumes this data, it is processing the
    `purchases`, one at a time, so we might be wondering why our producer fits everything
    in memory at once. It is creating a list where it puts all of the content of the
    file, but we know we can do better.
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution is to create a generator. Instead of loading the entire content
    of the file in a list, we will produce the results one at a time. The code will
    now look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: If you measure the process this time, you will notice that the usage of memory
    has dropped significantly. We can also see how the code looks simpler—there is
    no need to define the list (therefore, there is no need to append to it), and
    that the `return` statement also disappeared.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the `load_purchases` function is a generator function, or simply
    a generator.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, the mere presence of the keyword `yield` in any function makes it
    a generator, and, as a result, when calling it, nothing other than creating an
    instance of the generator will happen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: A generator object is an iterable (we will revisit iterables in more detail
    later on), which means that it can work with `for` loops. Notice how we did not
    have to change anything on the consumer code—our statistics processor remained
    the same, with the `for` loop unmodified, after the new implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Working with iterables allows us to create these kinds of powerful abstractions
    that are polymorphic with respect to `for` loops. As long as we keep the iterable
    interface, we can iterate over that object transparently.
  prefs: []
  type: TYPE_NORMAL
- en: Generator expressions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generators save a lot of memory, and since they are iterators, they are a convenient
    alternative to other iterables or containers that require more space in memory such
    as lists, tuples, or sets.
  prefs: []
  type: TYPE_NORMAL
- en: Much like these data structures, they can also be defined by comprehension,
    only that it is called a generator expression (there is an ongoing argument about
    whether they should be called generator comprehensions. In this book, we will
    just refer to them by their canonical name, but feel free to use whichever you
    prefer).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the same way, we would define a list comprehension. If we replace the square
    brackets with parenthesis, we get a generator that results from the expression.
    Generator expressions can also be passed directly to functions that work with
    iterables, such as `sum()`, and, `max()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Always pass a generator expression, instead of a list comprehension, to functions
    that expect iterables, such as `min()`, `max()`, and `sum()`. This is more efficient
    and pythonic.
  prefs: []
  type: TYPE_NORMAL
- en: Iterating idiomatically
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will first explore some idioms that come in handy when we
    have to deal with iteration in Python. These code recipes will help us get a better
    idea of the types of things we can do with generators (especially after we have
    already seen generator expressions), and how to solve typical problems in relation
    to them.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have seen some idioms, we will move on to exploring iteration in Python
    in more depth, analyzing the methods that make iteration possible, and how iterable
    objects work.
  prefs: []
  type: TYPE_NORMAL
- en: Idioms for iteration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are already familiar with the built-in `enumerate()` function that, given
    an iterable, will return another one on which the element is a tuple, whose first
    element is the enumeration of the second one (corresponding to the element in
    the original iterable):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We wish to create a similar object, but in a more low-level fashion; one that
    can simply create an infinite sequence. We want an object that can produce a sequence
    of numbers, from a starting one, without any limits.
  prefs: []
  type: TYPE_NORMAL
- en: 'An object as simple as the following one can do the trick. Every time we call
    this object, we get the next number of the sequence *ad infinitum*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Based on this interface, we would have to use this object by explicitly invoking
    its `next()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'But with this code, we cannot reconstruct the `enumerate()` function as we
    would like to, because its interface does not support being iterated over a regular
    Python `for` loop, which also means that we cannot pass it as a parameter to functions
    that expect something to iterate over. Notice how the following code fails:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The problem lies in the fact that `NumberSequence` does not support iteration.
    To fix this, we have to make the object an iterable by implementing the magic
    method `__iter__()`. We have also changed the previous `next()` method, by using
    the magic method `__next__`, which makes the object an iterator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This has an advantage—not only can we iterate over the element, we also don''t
    even need the `.next()` method any more because having `__next__()` allows us
    to use the `next()` built-in function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The next() function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `next()` built-in function will advance the iterable to its next element
    and return it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'If the iterator does not have more elements to produce, the `StopIteration`
    exception is raised:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This exception signals that the iteration is over and that there are no more
    elements to consume.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we wish to handle this case, besides catching the `StopIteration` exception,
    we could provide this function with a default value in its second parameter. Should
    this be provided, it will be the return value in lieu of throwing `StopIteration`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Using a generator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The previous code can be simplified significantly by simply using a generator.
    Generator objects are iterators. This way, instead of creating a class, we can
    define a function that `yield` the values as needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember that from our first definition, the `yield` keyword in the body of
    the function makes it a generator. Because it is a generator, it''s perfectly
    fine to create an infinite loop like this, because, when this generator function
    is called, it will run all the code until the next `yield `statement is reached.
    It will produce its value and suspend there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Itertools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working with iterables has the advantage that the code blends better with Python
    itself because iteration is a key component of the language. Besides that, we
    can take full advantage of the `itertools` module (ITER-01). Actually, the `sequence()`
    generator we just created is fairly similar to `itertools.count()`. However, there
    is more we can do.
  prefs: []
  type: TYPE_NORMAL
- en: One of the nicest things about iterators, generators, and itertools, is that
    they are composable objects that can be chained together.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, getting back to our first example that processed `purchases`
    in order to get some metrics, what if we want to do the same, but only for those
    values over a certain threshold? The naive approach of solving this problem would
    be to place the condition while iterating:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This is not only non-Pythonic, but it's also rigid (and rigidity is a trait
    that denotes bad code). It doesn't handle changes very well. What if the number
    changes now? Do we pass it by parameter? What if we need more than one? What if
    the condition is different (less than, for instance)? Do we pass a lambda?
  prefs: []
  type: TYPE_NORMAL
- en: These questions should not be answered by this object, whose sole responsibility
    is to compute a set of well-defined metrics over a stream of purchases represented
    as numbers. And, of course, the answer is no. It would be a huge mistake to make
    such a change (once again, clean code is flexible, and we don't want to make it
    rigid by coupling this object to external factors). These requirements will have
    to be addressed elsewhere.
  prefs: []
  type: TYPE_NORMAL
- en: It's better to keep this object independent of its clients. The less responsibility
    this class has, the more useful it will be for more clients, hence enhancing its
    chances of being reused.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of changing this code, we're going to keep it as it is and assume that
    the new data is filtered according to whatever requirements each customer of the
    class has.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, if we wanted to process only the first `10` `purchases` that
    amount to more than `1,000`, we would do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: There is no memory penalization for filtering this way because since they all
    are generators, the evaluation is always lazy. This gives us the power of thinking
    as if we had filtered the entire set at once and then passed it to the object,
    but without actually fitting everything in memory.
  prefs: []
  type: TYPE_NORMAL
- en: Simplifying code through iterators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we will briefly discuss some situations that can be improved with the help
    of iterators, and occasionally the `itertools` module. After discussing each case,
    and its proposed optimization, we will close each point with a corollary.
  prefs: []
  type: TYPE_NORMAL
- en: Repeated iterations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have seen more about iterators, and introduced the `itertools` module,
    we can show you how one of the first examples of this chapter (the one for computing
    statistics about some purchases), can be dramatically simplified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: In this example, `itertools.tee`will split the original iterable into three
    new ones. We will use each of these for the different kinds of iterations that
    we require, without needing to repeat three different loops over `purchases`*.*
  prefs: []
  type: TYPE_NORMAL
- en: The reader can simply verify that if we pass an iterable object as the `purchases`
    parameter, this one is traversed only once (thanks to the `itertools.tee` function
    [see references]), which was our main requirement. It is also possible to verify
    how this version is equivalent to our original implementation. In this case, there
    is no need to manually raise `ValueError` because passing an empty sequence to
    the `min()` function will do the same.
  prefs: []
  type: TYPE_NORMAL
- en: If you are thinking about running a loop over the same object more than one
    time, stop and think if `itertools.tee` can be of any help.
  prefs: []
  type: TYPE_NORMAL
- en: Nested loops
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In some situations, we need to iterate over more than one dimension, looking
    for a value, and nested loops come as the first idea. When the value is found,
    we need to stop iterating, but the `break` keyword doesn't work entirely because
    we have to escape from two (or more) `for` loops, not just one.
  prefs: []
  type: TYPE_NORMAL
- en: What would be the solution for this? A flag signaling escape? No. Raising an
    exception? No, this would be the same as the flag, but even worse because we know
    that exceptions are not to be used for control flow logic. Moving the code to
    a smaller function and return it? Close, but not quite.
  prefs: []
  type: TYPE_NORMAL
- en: The answer is, whenever possible, flat the iteration to a single `for` loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the kind of code we would like to avoid:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'And here is a simplified version of it that does not rely on flags to signal
    termination, and has a simpler, more compact structure of iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: It's worth mentioning how the auxiliary generator that was created works as
    an abstraction for the iteration that's required. In this case, we just need to
    iterate over two dimensions, but if we needed more, a different object could handle
    this without the client needing to know about it. This is the essence of the iterator
    design pattern, which, in Python, is transparent, since it supports iterator objects
    automatically, which is the topic covered in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Try to simplify the iteration as much as possible with as many abstractions
    as are required, flatting the loops whenever possible.
  prefs: []
  type: TYPE_NORMAL
- en: The iterator pattern in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here, we will take a small detour from generators to understand iteration in
    Python more deeply. Generators are a particular case of iterable objects, but
    iteration in Python goes beyond generators, and being able to create good iterable
    objects will give us the chance to create more efficient, compact, and readable
    code.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous code listings, we have been seeing examples of iterable objects
    that are also iterators, because they implement both the `__iter__()` and `__next__()`magic
    methods. While this is fine in general, it's not strictly required that they always
    have to implement both methods, and here we'll show the subtle differences between
    an iterable object (one that implements `__iter__`) and an iterator (that implements `__next__`).
  prefs: []
  type: TYPE_NORMAL
- en: We also explore other topics related to iterations, such as sequences and container
    objects.
  prefs: []
  type: TYPE_NORMAL
- en: The interface for iteration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An iterable is an object that supports iteration, which, at a very high level,
    means that we can run a `for .. in ...` loop over it, and it will work without
    any issues. However, iterable does not mean the same as iterator*.*
  prefs: []
  type: TYPE_NORMAL
- en: Generally speaking, an iterable is just something we can iterate, and it uses
    an iterator to do so. This means that in the `__iter__` magic method, we would
    like to return an iterator, namely, an object with a `__next__()` method implemented.
  prefs: []
  type: TYPE_NORMAL
- en: An iterator is an object that only knows how to produce a series of values,
    one at a time, when it's being called by the already explored built-in `next()`
    function. While the iterator is not called, it's simply frozen, sitting idly by
    until it's called again for the next value to produce. In this sense, generators
    are iterators.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Python concept** | **Magic method** | **Considerations** |'
  prefs: []
  type: TYPE_TB
- en: '| Iterable | `__iter__` | They work with an iterator to construct the iteration
    logic.These objects can be iterated in a `for ... in ...:` loop |'
  prefs: []
  type: TYPE_TB
- en: '| Iterator | `__next__` | Define the logic for producing values one at the
    time.The `StopIteration` exception signals that the iteration is over.The values
    can be obtained one by one via the built-in `next()` function. |'
  prefs: []
  type: TYPE_TB
- en: 'In the following code, we will see an example of an iterator object that is
    not iterable—it only supports invoking its values, one at a time. Here, the name
    `sequence` refers just to a series of consecutive numbers, not to the sequence
    concept in Python, which will we explore later on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that we can get the values of the sequence one at a time, but we can''t
    iterate over this object (this is fortunate because it would otherwise result
    in an endless loop):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The error message is clear, as the object doesn't implement `__iter__()`.
  prefs: []
  type: TYPE_NORMAL
- en: Just for explanatory purposes, we can separate the iteration in another object
    (again, it would be enough to make the object implement both `__iter__` and `__next__`,
    but doing so separately will help clarify the distinctive point we're trying to
    make in this explanation).
  prefs: []
  type: TYPE_NORMAL
- en: Sequence objects as iterables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have just seen, if an object implements the `__iter__()` magic method,
    it means it can be used in a `for` loop. While this is a great feature, it's not
    the only possible form of iteration we can achieve. When we write a `for` loop,
    Python will try to see if the object we're using implements `__iter__`, and, if
    it does, it will use that to construct the iteration, but if it doesn't, there
    are fallback options.
  prefs: []
  type: TYPE_NORMAL
- en: If the object happens to be a sequence (meaning that it implements `__getitem__()`
    and `__len__()` magic methods), it can also be iterated. If that is the case,
    the interpreter will then provide values in sequence, until the `IndexError`exception
    is raised, which,  analogous to the aforementioned `StopIteration`, also signals
    the stop for the iteration.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the sole purpose of illustrating such a behavior, we run the following
    experiment that shows a sequence object that implements `map()` over a range of
    numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Keep in mind that this example is only designed to illustrate that an object
    such as this one can be iterated with a regular `for` loop. There is a logging
    line placed in the `__getitem__` method to explore what values are passed while
    the object is being iterated, as we can see from the following test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: As a word of caution, it's important to highlight that while it is useful to
    know this, it's also a fallback mechanism for when the object doesn't implement `__iter__`,
    so most of the time we'll want to resort to these methods by thinking in creating
    proper sequences, and not just objects we want to iterate over.
  prefs: []
  type: TYPE_NORMAL
- en: When thinking about designing an object for iteration, favor a proper iterable
    object (with `__iter__`), rather than a sequence that can coincidentally also
    be iterated.
  prefs: []
  type: TYPE_NORMAL
- en: Coroutines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we already know, generator objects are iterables. They implement `__iter__()`
    and `__next__()`. This is provided by Python automatically so that when we create
    a generator object function, we get an object that can be iterated or advanced
    through the `next()` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides this basic functionality, they have more methods so that they can work
    as coroutines (PEP-342). Here, we will explore how generators evolved into coroutines
    to support the basis of asynchronous programming before we go into more detail
    in the next section, where we explore the new features of Python and the syntax
    that covers programming asynchronously. The basic methods added in (PEP-342) to
    support coroutines are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`.close()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.throw(ex_type[, ex_value[, ex_traceback]])`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.send(value)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The methods of the generator interface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will explore what each of the aforementioned methods does,
    how it works, and how it is expected to be used. By understanding how to use these
    methods, we will be able to make use of simple coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: Later on, we will explore more advanced uses of coroutines, and how to delegate
    to sub-generators (coroutines) in order to refactor code, and how to orchestrate
    different coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: close()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When calling this method, the generator will receive the `GeneratorExit` exception.
    If it's not handled, then the generator will finish without producing any more
    values, and its iteration will stop.
  prefs: []
  type: TYPE_NORMAL
- en: This exception can be used to handle a finishing status. In general, if our
    coroutine does some sort of resource management, we want to catch this exception
    and use that control block to release all resources being held by the coroutine.
    In general, it is similar to using a context manager or placing the code in the
    `finally` block of an exception control, but handling this exception specifically
    makes it more explicit.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we have a coroutine that makes use of a database
    handler object that holds a connection to a database, and runs queries over it,
    streaming data by pages of a fixed length (instead of reading everything that
    is available at once):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'At each call to the generator, it will return `10` rows obtained from the database
    handler, but when we decide to explicitly finish the iteration and call `close()`,
    we also want to close the connection to the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Use the `close()` method on generators to perform finishing-up tasks when needed.
  prefs: []
  type: TYPE_NORMAL
- en: throw(ex_type[, ex_value[, ex_traceback]])
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This method will `throw` the exception at the line where the generator is currently
    suspended. If the generator handles the exception that was sent, the code in that
    particular `except` clause will be called, otherwise, the exception will propagate
    to the caller.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we are modifying the previous example slightly to show the difference
    when we use this method for an exception that is handled by the coroutine, and
    when it''s not:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Now, it is a part of the control flow to receive a `CustomException`, and, in
    such a case, the generator will log an informative message (of course, we can
    adapt this according to our business logic on each case), and move on to the next
    `yield` statement, which is the line where the coroutine reads from the database
    and returns that data.
  prefs: []
  type: TYPE_NORMAL
- en: 'This particular example handles all exceptions, but if the last block (`except
    Exception:`) wasn''t there, the result would be that the generator is raised at
    the line where the generator is paused (again, the `yield`*),* and it will propagate
    from there to the caller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: When our exception from the domain was received, the generator continued. However,
    when it received another exception that was not expected, the default block caught
    where we closed the connection to the database and finished the iteration, which
    resulted in the generator being stopped. As we can see from the `StopIteration`
    that was raised, this generator can't be iterated further.
  prefs: []
  type: TYPE_NORMAL
- en: send(value)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous example, we created a simple generator that reads rows from
    a database, and when we wished to finish its iteration, this generator released
    the resources linked to the database. This is a good example of using one of the
    methods that generators provide (close), but there is more we can do.
  prefs: []
  type: TYPE_NORMAL
- en: An obvious of such a generator is that it was reading a fixed number of rows
    from the database.
  prefs: []
  type: TYPE_NORMAL
- en: We would like to parametrize that number (`10`) so that we can change it throughout
    different calls. Unfortunately, the `next()` function does not provide us with
    options for that. But luckily, we have `send()`*:*
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The idea is that we have now made the coroutine able to receive values from
    the caller by means of the `send()` method. This method is the one that actually
    distinguishes a generator from a coroutine because when it's used, it means that
    the `yield` keyword will appear on the right-hand side of the statement, and its
    return value will be assigned to something else.
  prefs: []
  type: TYPE_NORMAL
- en: 'In coroutines, we generally find the `yield` keyword to be used in the following
    form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The `yield`, in this case, will do two things. It will send `produced` back
    to the caller, which will pick it up on the next round of iteration (after calling
    `next()`*,* for example), and it will suspend there. At a later point, the caller
    will want to send a value back to the coroutine by using the `send()` method.
    This value will become the result of the `yield` statement, assigned in this case
    to the variable named `receive`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sending values to the coroutine only works when this one is suspended at a
    `yield` statement, waiting for something to produce. For this to happen, the coroutine
    will have to be advanced to that status. The only way to do this is by calling
    `next()` on it. This means that before sending anything to the coroutine, this
    has to be advanced at least once via the `next()` method. Failure to do so will
    result in an exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Always remember to advance a coroutine by calling `next()` before sending any
    values to it.
  prefs: []
  type: TYPE_NORMAL
- en: Back to our example. We are changing the way elements are produced or streamed
    to make it able to receive the length of the records it expects to read from the
    database.
  prefs: []
  type: TYPE_NORMAL
- en: The first time we call `next()`, the generator will advance up to the line containing
    `yield`; it will provide a value to the caller (`None`, as set in the variable),
    and it will suspend there). From here, we have two options. If we choose to advance
    the generator by calling `next()`, the default value of `10` will be used, and
    it will go on with this as usual. This is because `next()` is technically the
    same as `send(None)`, but this is covered in the `if` statement that will handle
    the value that we previously set.
  prefs: []
  type: TYPE_NORMAL
- en: If, on the other hand, we decide to provide an explicit value via `send(<value>)`,
    this one will become the result of the `yield` statement, which will be assigned
    to the variable containing the length of the page to use, which, in turn, will
    be used to read from the database.
  prefs: []
  type: TYPE_NORMAL
- en: Successive calls will have this logic, but the important point is that now we
    can dynamically change the length of the data to read in the middle of the iteration,
    at any point.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we understand how the previous code works, most Pythonistas would
    expect a simplified version of it (after all, Python is also about brevity and
    clean and compact code):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: This version is not only more compact, but it also illustrates the idea better.
    The parenthesis around the `yield` makes it clearer that it's a statement (think
    of it as if it were a function call), and that we are using the result of it to
    compare it against the previous value.
  prefs: []
  type: TYPE_NORMAL
- en: This works as we expect it does, but we always have to remember to advance the
    coroutine before sending any data to it. If we forget to call the first `next()`,
    we'll get a `TypeError`. This call could be ignored for our purposes because it
    doesn't return anything we'll use.
  prefs: []
  type: TYPE_NORMAL
- en: 'It would be good if we could use the coroutine directly, right after it is
    created without having to remember to call `next()` the first time, every time
    we are going to use it. Some authors (PYCOOK) devised an interesting decorator
    to achieve this. The idea of this decorator is to advance the coroutine, so the
    following definition works automatically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Let's take an example we create the `prepare_coroutine()`, decorator.
  prefs: []
  type: TYPE_NORMAL
- en: More advanced coroutines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have a better understanding of coroutines, and we are able to create
    simple ones to handle small tasks. We can say that these coroutines are, in fact,
    just more advanced generators (and that would be right, coroutines are just fancy
    generators), but, if we actually want to start supporting more complex scenarios,
    we usually have to go for a design that handles many coroutines concurrently,
    and that requires more features.
  prefs: []
  type: TYPE_NORMAL
- en: When handling many coroutines, we find new problems. As the control flow of
    our application becomes more complex, we want to pass values up and down the stack
    (as well as exceptions), be able to capture values from sub-coroutines we might
    call at any level, and finally schedule multiple coroutines to run toward a common
    goal.
  prefs: []
  type: TYPE_NORMAL
- en: To make things simpler, generators had to be extended once again. This is what
    PEP-380 addressed—by changing the semantic of generators so that they are able
    to return values, and introducing the new `yield from` construction.
  prefs: []
  type: TYPE_NORMAL
- en: Returning values in coroutines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As introduced at the beginning of this chapter, the iteration is a mechanism
    that calls `next()` on an iterable object many times until a `StopIteration` exception
    is raised.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have been exploring the iterative nature of generators—we produce
    values one at a time, and, in general, we only care about each value as it's being
    produced at every step of the `for` loop. This is a very logical way of thinking
    about generators, but coroutines have a different idea; even though they are technically
    generators, they weren't conceived with the idea of iteration in mind, but with
    the goal of suspending the execution of a code until it's resumed later on.
  prefs: []
  type: TYPE_NORMAL
- en: This is an interesting challenge; when we design a coroutine, we usually care
    more about suspending the state rather than iterating (and iterating a coroutine
    would be an odd case). The challenge lies in that it is easy to mix them both.
    This is because of a technical implementation detail; the support for coroutines
    in Python was built upon generators.
  prefs: []
  type: TYPE_NORMAL
- en: If we want to use coroutines to process some information and suspend its execution,
    it would make sense to think of them as lightweight threads (or green threads,
    as they are called in other platforms). In such a case, it would make sense if
    they could return values, much like calling any other regular function.
  prefs: []
  type: TYPE_NORMAL
- en: But let's remember that generators are not regular functions, so in a generator,
    the construction `value = generator()` will do nothing other than create a `generator`
    object. What would be the semantics for making a generator return a value? It
    will have to be after the iteration is done.
  prefs: []
  type: TYPE_NORMAL
- en: When a generator returns a value, it iteration is immediately stopped (it can't
    be iterated any further). To preserve the semantics, the `StopIteration` exception
    is still raised, and the value to be returned is stored inside the `exception`
    object. It's the responsibility of the caller to catch it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we are creating a simple `generator` that produces
    two values and then returns a third. Notice how we have to catch the exception
    in order to get this `value`, and how it''s stored precisely inside the exception
    under the attribute named `value`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Delegating into smaller coroutines – the yield from syntax
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous feature is interesting in the sense that it opens up a lot of new
    possibilities with coroutines (generators), now that they can return values. But
    this feature, by itself, would not be so useful without proper syntax support,
    because catching the returned value this way is a bit cumbersome.
  prefs: []
  type: TYPE_NORMAL
- en: This is one of the main features of the `yield from` syntax. Among other things
    (that we'll review in detail), it can collect the value returned by a sub-generator.
    Remember that we said that returning data in a generator was nice, but that, unfortunately,
    writing statements as `value = generator()` wouldn't work? Well, writing it as `value
    = yield from generator()` would.
  prefs: []
  type: TYPE_NORMAL
- en: The simplest use of yield from
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In its most basic form, the new `yield from` syntax can be used to chain generators
    from nested `for` loops into a single one, which will end up with a single string
    of all the values in a continuous stream.
  prefs: []
  type: TYPE_NORMAL
- en: The canonical example is about creating a function similar to `itertools.chain()`
    from the `standard` library. This is a very nice function because it allows you
    to pass any number of `iterables`, and will return them all together in one stream.
  prefs: []
  type: TYPE_NORMAL
- en: 'The naive implementation might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: It receives a variable number of `iterables`, traverses through all of them,
    and since each value is `iterable`, it supports a `for... in..` construction,
    so we have another `for` loop to get every value inside each particular iterable,
    which is produced by the caller function. This might be helpful in multiple cases,
    such as chaining generators together or trying to iterate things that it wouldn't
    normally be possible to compare in one go (such as lists with tuples, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the `yield from` syntax allows us to go further and avoid the nested
    loop because it''s able to produce the values from a sub-generator directly. In
    this case, we could simplify the code like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that for both implementations, the behavior of the generator is exactly
    the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: This means that we can use `yield from` over any other iterable, and it will
    work as if the top-level generator (the one the `yield from` is using) were generating
    those values itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'This works with any iterable, and even generator expressions aren''t the exception.
    Now that we''re familiar with its syntax, let''s see how we could write a simple
    generator function that will produce all the powers of a number (for instance,
    if provided with `all_powers(2, 3)`, it will have to produce `2^0, 2^1,... 2^3`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: While this simplifies the syntax a bit, saving one line of a `for` statement
    isn't a big advantage, and it wouldn't justify adding such a change to the language.
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, this is actually just a side effect and the real raison d'être of the `yield
    from` construction is what we are going to explore in the following two sections.
  prefs: []
  type: TYPE_NORMAL
- en: Capturing the value returned by a sub-generator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following example, we have a generator that calls another two nested
    generators, producing values in a sequence. Each one of these nested generators
    returns a value, and we will see how the top-level generator is able to effectively
    capture the return value since it''s calling the internal generators through `yield
    from`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a possible execution of the code in main while it''s being iterated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: The first line of main delegates into the internal generator, and produces the
    values, extracting them directly from it. This is nothing new, as we have already
    seen. Notice, though, how the `sequence()` generator function returns the end
    value, which is assigned in the first line to the variable named `step1`, and
    how this value is correctly used at the start of the following instance of that
    generator.
  prefs: []
  type: TYPE_NORMAL
- en: In the end, this other generator also returns the second end value (`10`), and
    the main generator, in turn, returns the sum of them (`5+10=15`), which is the
    value we see once the iteration has stopped.
  prefs: []
  type: TYPE_NORMAL
- en: We can use `yield from` to capture the last value of a coroutine after it has
    finished its processing.
  prefs: []
  type: TYPE_NORMAL
- en: Sending and receiving data to and from a sub-generator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we will see the other nice feature of the `yield from` syntax, which is
    probably what gives it its full power. As we have already introduced when we explored
    generators acting as coroutines, we know that we can send values and throw exceptions
    at them, and, in such cases, the coroutine will either receive the value for its
    internal processing, or it will have to handle the exception accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: If we now have a coroutine that delegates into other ones (such as in the previous
    example), we would also like to preserve this logic. Having to do so manually
    would be quite complex (you can take a look at the code described in PEP-380 if
    we didn't have this handled by `yield from` automatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to illustrate this, let''s keep the same top-level generator (main)
    unmodified with respect to the previous example (calling other internal generators),
    but let''s modify the internal generators to make them able to receive values
    and handle exceptions. The code is probably not idiomatic, only for the purposes
    of showing how this mechanism works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will call the `main` coroutine, not only by iterating it, but also
    by passing values and throwing exceptions at it to see how they are handled inside `sequence`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: This example is showing us a lot of different things. Notice how we never send
    values to `sequence`, but only to `main`, and even so, the code that is receiving
    those values is the nested generators. Even though we never explicitly send anything
    to `sequence`, it's receiving the data as it's being passed along by `yield from`.
  prefs: []
  type: TYPE_NORMAL
- en: The `main` coroutine calls two other coroutines internally, producing their
    values, and it will be suspended at a particular point in time in any of those.
    When it's stopped at the first one, we can see the logs telling us that it is
    that instance of the coroutine that received the value we sent. The same happens
    when we throw an exception to it. When the first coroutine finishes, it returns
    the value that was assigned in the variable named `step1`, and passed as input
    for the second coroutine, which will do the same (it will handle the `send()`
    and `throw()` calls, accordingly).
  prefs: []
  type: TYPE_NORMAL
- en: The same happens for the values that each coroutine produces. When we are at
    any given step, the return from calling `send()` corresponds to the value that
    the subcoroutine (the one that `main` is currently suspended at) has produced.
    When we throw an exception that is being handled, the `sequence` coroutine produces
    the value `OK`, which is propagated to the called (`main`), and which in turn
    will end up at main's caller.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the constructions we have seen so far, we are able to create asynchronous
    programs in Python. This means that we can create programs that have many coroutines,
    schedule them to work in a particular order, and switch between them when they're
    suspended after a `yield from` has been called on each of them.
  prefs: []
  type: TYPE_NORMAL
- en: The main advantage that we can take out of this is the possibility of parallelizing
    I/O operations in a non-blocking way. What we would need is a low-level generator
    (usually implemented by a third-party library) that knows how to handle the actual
    I/O while the coroutine is suspended. The idea is for the coroutine to effect
    suspension so that our program can handle another task in the meantime. The way
    the application would retrieve the control back is by means of the `yield from` statement,
    which will suspend and produce a value to the caller (as in the examples we saw
    previously when we used this syntax to alter the control flow of the program).
  prefs: []
  type: TYPE_NORMAL
- en: This is roughly the way asynchronous programming had been working in Python
    for quite a few years, until it was decided that better syntactic support was
    needed.
  prefs: []
  type: TYPE_NORMAL
- en: The fact that coroutines and generators are technically the same causes some
    confusion. Syntactically (and technically), they are the same, but semantically,
    they are different. We create generators when we want to achieve efficient iteration.
    We typically create coroutines with the goal of running non-blocking I/O operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'While this difference is clear, the dynamic nature of Python would still allow
    developers to mix these different type of objects, ending up with a runtime error
    at a very late stage of the program. Remember that in the simplest and most basic
    form of the `yield from`syntax, we used this construction over iterables (we created
    a sort of `chain` function applied over strings, lists, and so on). None of these
    objects were coroutines, and it still worked. Then, we saw that we can have multiple
    coroutines, use `yield from` to send the value (or exceptions), and get some results
    back. These are clearly two very different use cases, however, if we write something along
    the lines of the following statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: It's not clear what `iterable_or_awaitable` returns. It can be a simple iterable
    such as a string, and it might still be syntactically correct. Or, it might be
    an actual coroutine. The cost of this mistake will be paid much later.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, the typing system in Python had to be extended. Before Python
    3.5, coroutines were just generators with a `@coroutine` decorator applied, and
    they were to be called with the `yield from` syntax. Now, there is a specific
    type of object, that is, a coroutine.
  prefs: []
  type: TYPE_NORMAL
- en: This change heralded, syntax changes as well. The `await` and `async def` syntax
    were introduced. The former is intended to be used instead of `yield from,` and
    it only works with `awaitable` objects (which coroutines conveniently happen to
    be). Trying to call `await` with something that doesn't respect the interface
    of an `awaitable` will raise an exception. The `async def` is the new way of defining
    coroutines, replacing the aforementioned decorator, and this actually creates
    an object that, when called, will return an instance of a coroutine.
  prefs: []
  type: TYPE_NORMAL
- en: Without going into all the details and possibilities of asynchronous programming
    in Python, we can say that despite the new syntax and the new types, this is not
    doing anything fundamentally different from concepts we have covered in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The idea of programming asynchronously in Python is that there is an `event`
    loop (typically `asyncio` because it's the one that is included in the `standard`
    library, but there are many others that will work just the same) that manages
    a series of coroutines. These coroutines belong to the event loop, which is going
    to call them according to its scheduling mechanism. When each one of these runs,
    it will call our code (according to the logic we have defined inside the coroutine
    we programmed), and when we want to get control back to the event loop, we call `await
    <coroutine>`*,* which will process a task asynchronously. The event loop will
    resume and another coroutine will take place while that operation is left running.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, there are more particularities and edge cases that are beyond the
    scope of this book. It is, however, worth mentioning that these concepts are related
    to the ideas introduced in this chapter and that this arena is another place where
    generators demonstrate being a core concept of the language, as there are many
    things constructed on top of them.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generators are everywhere in Python. Since their inception in Python a long
    time ago, they proved to be a great addition that makes programs more efficient
    and iteration much simpler.
  prefs: []
  type: TYPE_NORMAL
- en: As time moved on, and more complex tasks needed to be added to Python, generators
    helped again in supporting coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: And, while in Python, coroutines are generators, we still don't have to forget
    that they're semantically different. Generators are created with the idea of iteration,
    while coroutines have the goal of asynchronous programming (suspending and resuming
    the execution of a part of our program at any given time). This distinction became
    so important that it made Python's syntax (and type system) evolve.
  prefs: []
  type: TYPE_NORMAL
- en: Iteration and asynchronous programming constitute the last of the main pillars
    of Python programming. Now, it's time to see how everything fits together and
    to put all of these concepts we have been exploring over the past few chapters
    into action.
  prefs: []
  type: TYPE_NORMAL
- en: The following chapters will describe other fundamental aspects of Python projects,
    such as testing, design patterns, and architecture.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here is a list of information you can refer to:'
  prefs: []
  type: TYPE_NORMAL
- en: '*PEP-234*: Iterators ([https://www.python.org/dev/peps/pep-0234/](https://www.python.org/dev/peps/pep-0234/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PEP-255*: Simple Generators ([https://www.python.org/dev/peps/pep-0255/](https://www.python.org/dev/peps/pep-0255/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ITER-01*: Python''s itertools module ([https://docs.python.org/3/library/itertools.html](https://docs.python.org/3/library/itertools.html))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*GoF*: The book written by Erich Gamma, Richard Helm, Ralph Johnson, John Vlissides
    named *Design Patterns: Elements of Reusable Object-Oriented Software*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PEP-342*: Coroutines via Enhanced Generators([https://www.python.org/dev/peps/pep-0342/](https://www.python.org/dev/peps/pep-0342/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PYCOOK*: The book  written by Brian Jones, David Beazley named *Python Cookbook:
    Recipes for Mastering Python 3, Third Edition*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PY99*: Fake threads (generators, coroutines, and continuations) ([https://mail.python.org/pipermail/python-dev/1999-July/000467.html](https://mail.python.org/pipermail/python-dev/1999-July/000467.html))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*CORO-01*: Co Routine ([http://wiki.c2.com/?CoRoutine](http://wiki.c2.com/?CoRoutine))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*CORO-02*: Generators Are Not Coroutines ([http://wiki.c2.com/?GeneratorsAreNotCoroutines](http://wiki.c2.com/?GeneratorsAreNotCoroutines))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*TEE*: The `itertools.tee` function ([https://docs.python.org/3/library/itertools.html#itertools.tee](https://docs.python.org/3/library/itertools.html#itertools.tee))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL

- en: Exploring the Largest-Scale Deployments
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索最大规模的部署
- en: In earlier chapters, we covered many different aspects of deploying Docker containers,
    but if we are to turn our examples into a global service that would withstand
    the throughput of many millions of requests a second, a few things will still
    need to be addressed and this chapter was specifically written to go over the
    most important ones in some detail. Since implementations of topics covered here
    would involve enough material to be books on their own and infrastructure would
    differ wildly depending on a multitude of factors, the text here will be mostly
    on the theory side, but the previous understanding of services we gained in the
    text leading up to this chapter should be good enough to give you ideas on how
    you can proceed with the least amount of pain.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们涵盖了部署Docker容器的许多不同方面，但是如果我们要将我们的例子转化为一个全球服务，能够承受每秒数百万请求的吞吐量，仍然有一些事情需要解决，这一章特别写作是为了详细讨论其中最重要的一些。由于这里涉及的主题实施将涉及足够的材料，可以单独成书，并且基础设施会根据多种因素大相径庭，因此这里的文本大部分将是理论性的，但是在本章之前我们对服务的理解应该足够好，可以给你一些关于如何以最少的痛苦进行下一步操作的想法。
- en: 'In its core, the topics we will cover revolve around choosing the right technologies
    and then following three basic ideas:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在其核心，我们将要讨论的主题围绕选择合适的技术，然后遵循三个基本理念：
- en: Automate everything!
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一切都要自动化！
- en: Really, automate it all!
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真的，一切都要自动化！
- en: Yes, automate even those one-off things you do every few weeks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是的，甚至自动化那些你每隔几周做一次的事情
- en: It might be a joke, but hopefully by now it should be clear that one of the
    main points of all of this work (besides isolation) is to remove any human interaction
    from your system in regards to keeping your services running so that you and your
    team can focus on actually developing services and not wasting time on deployments.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是一个玩笑，但希望到现在为止应该清楚，所有这些工作的主要目的之一（除了隔离）是从你的系统中消除任何人为干预，以保持你的服务运行，这样你和你的团队就可以专注于实际开发服务，而不是浪费时间在部署上。
- en: Maintaining quorums
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 维护法定人数
- en: In our previous examples, we mostly worked with a single-node manager but if
    you want resilience, you must ensure that there are minimal points of failure
    that will take your whole infrastructure down and a single orchestration management
    node is absolutely not enough for production services regardless of whether you
    use Swarm, Kubernetes, Marathon, or something else as your orchestration tooling.
    From the best practices perspective, you would want to have at least three or
    more management nodes in your cluster that are spread across three or more of
    your cloud's **Availability Zones** (**AZ**) or equivalent grouping to really
    ensure stability at scales since data center outages have been known to happen
    and have caused serious issues to companies that did not mitigate these types
    of circumstances.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的例子中，我们大多数时间都是使用单节点管理器，但是如果你想要弹性，你必须确保最小的故障点不会导致整个基础架构崩溃，而单个编排管理节点绝对不足以支持生产服务，无论你使用Swarm、Kubernetes、Marathon还是其他编排工具。从最佳实践的角度来看，你至少需要在集群中拥有三个或更多的管理节点，这些节点分布在云的三个或更多的**可用区**（**AZ**）或等效的分组中，以确保在规模上真正实现稳定性，因为数据中心的故障已经被证明会发生，并且给那些没有减轻这类情况的公司造成严重问题。
- en: While in most orchestration platforms you can have any number of backing management
    nodes (or backing key-value stores in some cases), you will always have to balance
    resiliency vs speed due to the fact that with more nodes comes better capability
    to handle failures of larger parts of the system, but changes to this system (such
    as node additions and removals) must reach more points that will all have to agree,
    thus making it slower to process data. In most cases where this 3+ availability
    zone topology is required, we will need to go in details about quorums—the concept
    we lightly covered earlier, which is the backbone of all **high availability**
    (**HA**) systems.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Quorums in their basic sense are a grouping of the majority of management nodes,
    which together can decide whether updates to the cluster are going to be allowed
    or not. If the quorum is lost by the fact that half or more management nodes are
    unavailable, all changes to the cluster will be stopped to prevent your cluster
    infrastructure from having effectively split clusters. To properly divide your
    network topology for scale in this respect, you must make sure that you have a
    minimum of three nodes and/or availability zones as the quorum majority is lost
    with a single failure with less than that number. Taking this further, you will
    generally also want an odd number of nodes and availability zones since even numbers
    do not provide much additional protection for maintaining quorum, as we will see
    in a moment.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: To start off, let's say that you have five management nodes. To maintain a quorum
    of this number, you must have three or more nodes available, but if you have only
    two availability zones, the best split you can do is *3-2*, which will work fine
    if a connection is broken or the **AZ** with two management nodes goes down, but
    if the **AZ** with three nodes goes down, a quorum cannot be established since
    two is less than half of the total node count.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/feae7e99-8ae3-4908-be7d-713000fe7308.png) ![](assets/1f054a31-0e01-4b62-a99a-380baa499533.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
- en: 'Let us now see what kind of resilience we can get with three availability zones.
    The optimal layout of this grouping with five management nodes would be *2-2-1*
    and if you take a closer look at what happens when any one of the zones goes out,
    you will see that the quorum is always maintained since we will either have *3
    (2+1)* or *4 (2+2)* nodes still available from the rest of the cluster, ensuring
    that our services run without issues:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/d0bb04d0-17b7-43d7-8740-b047fd872717.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
- en: 'Of course, it is also good to show what kind of effect even numbers have on
    the effectiveness since we mentioned that they may be a bit troublesome. With
    four AZs, the best split that we can make would be *2-1-1-1* across them and with
    those numbers we can only tolerate two zones being unavailable if they both contain
    only one node. With this setup, we have a 50/50 chance that two zones being unavailable
    will include the zone with two nodes within it, putting the number of total nodes
    unavailable to over 3, and thus the cluster will be completely offline:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/8afaa925-f216-4b68-b3e6-58dc2560d26e.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
- en: '![](assets/f48bc1dc-a1b2-4515-b900-c8bf945aafb3.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
- en: This spread of management nodes across higher counts of AZs for clusters gets
    much more stable if you have more availability zones and managers, but for our
    simple example here, we can see this effect if we have five management nodes and
    five availability zones (*1-1-1-1-1* layout). With such a split, due to the quorum
    requiring at least three nodes, we will still be fully operational if any two
    of the five zones are unavailable, increasing your failure tolerance by 100 percent
    from the 3-AZ topology; but you can assume that communication between possibly
    wildly disparate geographical regions will add plenty of latency to any updates.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, with these examples, it should now be clear what kind of considerations
    and calculations you would use when trying to keep your cluster resilient and
    it is able to maintain quorum. While the tooling may differ depending on the orchestration
    tooling (that is `etcd` nodes versus Zookeeper nodes), the principles remain relatively
    the same in almost all of them, so this section should be relatively portable.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Node automation
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have worked on making **Amazon Machine Images** (**AMIs**) with Packer,
    we have seen what kind of thing we can do with pre-baked instance images, but
    their true power is only fully harnessed when the whole infrastructure is comprised
    of them. If your orchestration management nodes and worker nodes have their own
    system images, with a couple of startup scripts also baked-in though the init
    system (for example, `systemd` startup services), you can make instances launched
    with those images auto-join your cluster during boot in their predefined roles.
    Taking this further to a conceptual level, if we extract all stateful configuration
    into the image configurations and all dynamic configurations into a separate service
    accessible to all nodes such as EC2 `user-data` or HashiCorp Vault, your cluster
    will be almost fully self-configuring besides the initial deployment and image
    building.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用Packer制作Amazon Machine Images（AMIs）时，我们已经看到了我们可以使用预先烘焙的实例映像做什么，但是只有当整个基础设施由它们组成时，它们的真正力量才能得到充分发挥。如果您的编排管理节点和工作节点有自己的系统映像，并且还有一些启动脚本通过init系统（例如，systemd启动服务）烘焙进去，您可以使使用这些映像启动的实例在其预定义角色中在启动时自动加入到集群中。将这进一步提升到概念层面，如果我们将所有有状态的配置提取到映像配置中，将所有动态配置提取到一个对所有节点可访问的单独服务中，例如EC2
    `user-data`或HashiCorp Vault，除了初始部署和映像构建之外，您的集群几乎完全自我配置。
- en: 'By having this powerful auto-join capability, you are eliminating most of the
    manual work related to scaling your cluster up or down since there is no need
    for interacting with the VM instance other than starting it. A rather simple illustration
    of this architecture is depicted in the following figure, where orchestration
    and worker nodes have their own respective images and self-configure on startup
    using a shared configuration data provider within the **VPC** itself:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 通过拥有这种强大的自动加入功能，您可以消除与扩展集群的手动工作大部分相关的工作，因为除了启动它之外，无需与VM实例进行交互。这种架构的一个相当简单的示例如下图所示，其中编排和工作节点有各自的映像，并在启动时使用VPC内的共享配置数据提供程序进行自我配置：
- en: '![](assets/9fdaeb81-160f-41d5-bdd1-0e5b8aba0619.png)CAUTION! To prevent serious
    security breaches make sure to separate and isolate any sensitive information
    to be accessible only by the desired systems in this configuration service layout.
    As we mentioned in one of the early chapters, following security best practices
    by using need-to-know practices will ensure that a compromise of a single point
    (most likely a worker node) will not be able to spread easily to the rest of your
    cluster. As a simple example here, this would include making sure that management
    secrets are not readable by worker nodes or their network.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/9fdaeb81-160f-41d5-bdd1-0e5b8aba0619.png)注意！为了防止严重的安全漏洞，请确保将任何敏感信息分离和隔离，只能由此配置服务布局中的所需系统访问。正如我们在早期的章节中提到的，通过使用需要知道的最佳实践，可以确保单个点（很可能是工作节点）的妥协不会轻易传播到集群的其余部分。举个简单的例子，这将包括确保管理秘密对工作节点或其网络不可读。'
- en: Reactive auto-scaling
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 反应式自动扩展
- en: With automated self-configuration implemented, we can start looking even bigger
    by starting the instances automatically. If you remember auto-scaling groups from
    earlier chapters, even that can be automated in most cloud offerings. By using
    launch configurations and pre-configured images, like the ones we just talked
    about, adding or removing nodes with this setup would be as easy as dialing the
    desired nodes setting. The auto-scaling group would increase or decrease the worker
    instance count and because the images are self-configuring, that would be the
    full extent of input needed from you. With such a simple input, you can make scaling
    changes to your infrastructure extremely easy and done through many different
    ways.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Something to consider here as an even further step in automation is that with
    some cloud providers you can trigger these actions in your auto-scaling groups
    based on their metrics or even a `cron`-like schedule as well. In principle, if
    you have increased load on your cluster you could trigger a node count increase,
    and conversely, if the load on either the cluster or an individual node drops
    below a pre-defined value you can activate a service drain and shutdown of a fraction
    of your nodes to scale the system as needed. For periodic but predictable demand
    variations (see [https://en.wikipedia.org/wiki/Internet_Rush_Hour](https://en.wikipedia.org/wiki/Internet_Rush_Hour)
    for more info), the scheduled scaling changes we mentioned can make sure that
    you have enough resources to handle the expected demand.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Predictive auto-scaling
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you manually dial up and down the node counts and auto-scale on schedule
    or metric triggers, you still will have some issues bringing up services you need
    at exactly the time you want them to run since services take a bit of time to
    get online, self-configure, and start getting propagated to various load balancers
    in your network. With that type of architecture, it is likely that your users
    will be the one discovering that you do not have enough capacity and your system
    then reacting to compensate. If you are really striving for all-out best user
    experience from your services sometimes you may also need to add one more layer
    to your auto-scaling triggers that can predict when your service will need more
    resources before they are even actually needed, aptly called **predictive scaling**.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: In extremely broad terms, what you would do to add this predictive layer to
    your infrastructure is to funnel some fraction of your metrics collected over
    the last `x` amount of time to a **machine learning** (**ML**) tool such as TensorFlow
    ([https://www.tensorflow.org/](https://www.tensorflow.org/)) and generate a training
    set that would be able to make the tooling you are using able to predict with
    some certainty whether you will need more nodes or not. By using this method,
    your services can scale before they will even be needed to do so (!) and in a
    much smarter way than simple schedule-based approaches. Systems such as these
    are pretty difficult to integrate properly into your pipeline, but if you are
    working on global scales with crazy throughput and simple reactive auto-scaling
    comes up short, it is an avenue possibly worth exploring.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Training set in machine learning means just a set of training data (in our case
    it would be a chunk of our long-term metrics) that you can use to teach a neural
    network about how to correctly predict the demand that you will need.Like many
    of the topics in recent chapters, there are actual books written on this material
    (machine learning) that would eclipse the content of this one by volume many times
    over and would provide only marginal utility for you here. If you would like to
    learn more about machine learning in detail, this Wikipedia page has a good primer
    on it at [https://en.wikipedia.org/wiki/Machine_learning](https://en.wikipedia.org/wiki/Machine_learning)
    and you can give TensorFlow a whirl at [https://www.tensorflow.org/get_started/get_started](https://www.tensorflow.org/get_started/get_started).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: In the end, if you manage to implement some or all of these techniques together,
    you will barely need any interventions with your clusters to handle scaling in
    either direction. As an added bonus to being able to sleep soundly, you will also
    save resources since you will be able to closely match your processing resources
    with the actual usage of your services making you, your budget, and your users
    all happy.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Any service that you rely on in your service delivery should ideally have a
    way to notify you if something has gone wrong with it, and I do not mean user
    feedback here. Most service development nowadays is moving at incredible speeds
    and monitoring is one of those things like backups that most developers do not
    think about until something catastrophic happens, so it is something that we should
    cover a little bit. The big question that really should determine how you approach
    this topic is if your users can handle the downtimes that you will not see without
    monitoring.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 您在服务交付中依赖的任何服务理想情况下都应该有一种方式来通知您它是否出现了问题，我指的不是用户反馈。大多数服务开发现在都以令人难以置信的速度发展，监控就像备份一样，大多数开发人员在发生灾难性事件之前都不会考虑，因此我们应该稍微涉及一下。真正应该决定您如何处理这个问题的重要问题是，如果您的用户能够处理您在没有监控的情况下看不到的停机时间。
- en: Most tiny services might be OK with some outages, but for everything else, this
    would be at a bare minimum a couple of angry emails from users and at worst your
    company losing a huge percentage of your users, so monitoring at all scales is
    greatly encouraged.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数小型服务可能对一些中断没有太大问题，但对于其他所有情况，这至少会导致用户发来一些愤怒的电子邮件，最坏的情况是您的公司失去了大部分用户，因此强烈鼓励在各个规模上进行监控。
- en: While it is true that monitoring is maybe considered one of those boring pieces
    of your infrastructure to implement, having a way to gain insights into what your
    cloud is doing at all times is an absolutely essential part of managing the multitude
    of disparate systems and services. By adding monitoring to your **Key Performance
    Indicators** (**KPIs**) you can ensure that, as a whole, your system is performing
    as expected and by adding triggers to your critical monitoring targets you can
    be instantly alerted to any activity that can potentially impact your users. Having
    these type of insights into the infrastructure can both help reduce user turnover
    and drive better business decisions.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管监控可能被认为是基础设施中那些无聊的部分之一，但在任何时候都能获得对云端正在进行的工作的洞察力绝对是管理多样化系统和服务的绝对必要部分。通过将监控添加到您的关键绩效指标（KPIs）中，您可以确保整个系统的性能符合预期，并通过向关键监控目标添加触发器，您可以立即收到可能影响用户的任何活动的警报。对基础设施的这种洞察力既可以帮助减少用户流失，也可以推动更好的业务决策。
- en: 'As we worked through our examples, you may have already come up with ideas
    of what you would monitor, but here are some common ones that consistently pop
    up as the most useful ones:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们通过示例进行工作时，您可能已经想到了要监控的内容，但以下是一些常见的内容，它们一直被认为是最有用的：
- en: '**Node RAM utilization**: If you notice that your nodes aren''t using all the
    RAM allocated, you can move to smaller ones and vice versa. This generally gets
    less useful if you use memory-constrained Docker containers, but it is still a
    good metric to keep as you want to make sure you never hit a system-level max
    memory utilization on a node or your containers will run with much slower swap
    instead.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点RAM利用率**：如果您注意到您的节点没有使用分配的所有RAM，您可以切换到较小的节点，反之亦然。如果您使用受内存限制的Docker容器，这个指标通常会变得不那么有用，但仍然是一个很好的指标，因为您希望确保您的节点从未达到系统级最大内存利用率，否则您的容器将以更慢的交换方式运行。'
- en: '**Node CPU utilization**: You can see from this metric if your service density
    is too low or too high or if there are spikes in service demands.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点CPU利用率**：通过这个指标，您可以看到服务密度是否过低或过高，或者服务需求是否出现波动。'
- en: '**Node unexpected terminations**: This one is good to track to ensure that
    your CI/CD pipeline is not creating bad images, that your configuration services
    are online, and a multitude of other issues that could take down your services.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点意外终止**：这个指标很好地跟踪确保您的CI/CD流水线没有创建错误的镜像，您的配置服务是在线的，以及可能导致服务中断的其他问题。'
- en: '**Service unexpected terminations**: Finding out why a service is unexpectedly
    terminating is critical to ironing out bugs out of any system. Seeing an increase
    or a decrease in this value can be good indicators of codebase quality though
    they can also indicate a multitude of other problems, both internal and external
    to your infrastructure.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务意外终止：找出服务为何意外终止对于消除任何系统中的错误至关重要。看到这个值的增加或减少可能是代码质量的良好指标，尽管它们也可能表明一系列其他问题，无论是内部的还是外部的。
- en: '**Messaging queue sizes**: We covered this in a bit of detail before but ballooning
    queue sizes indicate that your infrastructure is unable to process data as quickly
    as it is generated, so this metric is always good to have.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消息队列大小：我们之前详细介绍了这一点，但膨胀的队列大小表明您的基础设施无法快速处理生成的数据，因此这个指标总是很有用的。
- en: '**Connection throughputs**: Knowing exactly how much data you are dealing with
    can be a good indicator of service load. Comparing this to other collected stats
    can also tell you if the problems you are seeing are internally or externally
    caused.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连接吞吐量：准确了解您正在处理的数据量可以很好地指示服务负载。将其与其他收集的统计数据进行比较，还可以告诉您所见问题是内部还是外部造成的。
- en: '**Service latencies**: Just because there are no failures does not mean that
    the service is unusable. By tracking latencies you can see in detail what could
    use improving or what is not performing to your expectations.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务延迟：仅仅因为没有故障并不意味着服务不可用。通过跟踪延迟，您可以详细了解需要改进的地方，或者哪些性能不符合您的期望。
- en: '**Kernel panics**: Rare but extremely deadly, kernel panics can be a really
    disruptive force on your deployed services. Even though it is pretty tricky to
    monitor these, keeping track of kernel panics will alert you if there is an underlying
    kernel or hardware problem that you will need to start addressing.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核恐慌：虽然罕见但极其致命，内核恐慌可能对部署的服务造成严重影响。尽管监控这些情况相当棘手，但跟踪内核恐慌将在出现潜在的内核或硬件问题时向您发出警报，这将需要您开始解决。
- en: This obviously is not an exhaustive list, but it covers some of the more useful
    ones. As you develop your infrastructure, you will find that adding monitoring
    everywhere leads to better turnarounds on issues and discovery of scalability
    bugs with your services. So once you have monitoring added to your infrastructure,
    don't be afraid to plug it into as many pieces of your system that you can. At
    the end of the day, by gaining visibility and transparency of your whole infrastructure
    through monitoring, you can make wiser decisions and build better services, which
    is exactly what we want.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这并不是一个详尽的列表，但它涵盖了一些更有用的内容。随着基础设施的发展，您会发现在各处添加监控会更快地解决问题，并发现服务的可扩展性问题。因此，一旦将监控添加到基础设施中，不要害怕将其连接到系统的尽可能多的部分。最终，通过监控整个基础设施获得可见性和透明度，您可以做出更明智的决策并构建更好的服务，这正是我们想要的。
- en: Evaluating next-gen technologies
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估下一代技术
- en: Something that I personally have been feeling has been left out of most documentation
    and learning material about containers (and most other tech topics) is proper
    evaluation and risk assessment of emerging technologies. While the risk of choosing
    a fundamentally flawed music player is trivial, choosing a fundamentally flawed
    cloud technology could tie you up in years of pain and development that you would
    otherwise not have needed. With the speed of tooling creation and development
    in the cloud space increasing at break-neck speed, good evaluation techniques
    are something that you might want to have in your toolbox of skills as they can
    save you effort, time, and money in the long run. Hunches are great but having
    a solid, repeatable, and deterministic way of evaluating technologies is a much
    more likely way to cause long-term success.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Please note that while the advice given here has had a pretty good track record
    for me and other people I have talked to over my career, you can never fully predict
    the course that a disparate landscape of technologies will take, especially when
    most tech start-ups can close their doors at a moment's notice (i.e. ClusterHQ).
    So keep in mind that these are all just points of interest and not a magical list
    that will make the most common problems with choosing technologies disappear.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Technological needs
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This should be a pretty obvious one, but it needs to be written down. If you
    have a need for a feature that is provided by a tool that you do not want to develop
    in-house, you will not have much of a choice but to go with it and hope for the
    best. Luckily, in most cloud technologies and the tooling modules that supports
    them, there are usually at least two competing options fighting for the same users
    so things are not as dire as they may seem today even though just a single year
    back almost everything in this space had a version number below `1.0`. As you
    evaluate how competing tools fit your needs, also keep in mind that not every
    tool is geared towards the same purpose even if they solve the same issues. If
    we take an example of current Kubernetes versus Marathon, even though they can
    both be used to solve the same service deployment problems, Kubernetes is mostly
    geared towards that single purpose but Marathon, for example, can also be used
    to do scheduling and cluster management as an additional functionality so we are
    in the proverbial sense really comparing apples and oranges.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: In broad strokes, your service infrastructure needs will drive your tooling
    needs so you will not often end up dealing with your favorite programming language,
    having easy integration points, or working with a sane tooling codebase, but integrating
    a tool that will save you hundreds or thousands of man-hours is something not
    to be taken lightly. Sometimes it might be possible to completely skirt around
    a technological requirement by changing pieces of your system's architecture to
    avoid adding complexity to the system, but in my personal experience this was
    almost never easy to do so your mileage may vary.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Popularity
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is probably the most controversial dimension to consider, but also one
    of the most important ones to pay attention to when dealing with new technologies.
    While it is absolutely true that popularity does not equate to technical merit,
    it can be assumed that:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: More people using a particular tool will be able to provide better integration
    help.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solutions to problems will be easier to find.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the codebase is open source, the project will be more likely to have fixes
    and features added to it.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In another way of describing the problem, can you afford to risk weeks/months/years
    of integration work on a tool that is unproven or on track to be abandoned in
    the next couple of years? If you are a really big shop with massive budgets this
    might not be an issue but in most cases, you will not have the opportunity to
    play with integrating different competing technologies to see which one is the
    best. While there are times that there are perfectly valid cases where taking
    a calculated chance with a new tool is warranted and desired, in the majority
    of cases due to the sheer complexity and longevity of cloud systems the cost of
    failure is extremely high, so a pragmatic approach is generally recommended but
    your individual requirements may vary, so choose accordingly.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: To evaluate this aspect of a project there is a variety of tooling that can
    be used, but the simplest and the easiest are the GitHub project forks/stars (for
    OSS projects), Google Trends ([https://trends.google.com](https://trends.google.com))
    projections, and general social media feedback from people that have used said
    technology. By looking at movements and shifts in these values, extrapolation
    of long-term viability can be made with a relatively good accuracy and combined
    together with comparisons against existing tooling can create a good picture of
    the general pulse of a project as well. Upwardly-mobile projects generally have
    been indicative of superior technological base but in some cases, this was spurred
    by rejection of existing tooling or a big marketing push, so don't always think
    the popular option is better when evaluating a tool.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '**![](assets/fac939d5-87a1-4de2-80f1-a8b5fbc11d9f.png)**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding screenshot, you can see a distinct increase over time in interest
    in Kubernetes that somewhat mirrors community adoption and acceptance of that
    orchestration tooling. If we were to implement this technology ourselves, we could
    be reasonably sure that for some period of time that we would be using a tool
    that will be easier to work with and get support for.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'When comparing Kubernetes against Marathon and using the same technique, things
    get very messy as Marathon is also a very common long-distance running activity,
    so the results get muddled with unrelated Google queries. In the following screenshot,
    we overlaid the results versus a couple of other cloud-related keywords and you
    can see that there''s something wrong with our data:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/f9e6c5e8-01cf-4e88-b1a1-4f87c0199812.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
- en: 'However, taking a look at the top-right side of their GitHub pages and the
    forks/stars we can see how they compare (**3,483** stars and **810** forks versus **28,444**
    stars and **10,167** forks):'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ad45d9ff-4388-4ece-a644-aff9600199c8.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
- en: 'Compare the preceding GitHub page with the following page:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/9b4d4d63-a545-4a67-875d-639c8fb138df.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
- en: In this particular example, though, it is very hard to see long-term trends
    and we've mentioned that these two do not solve the same kind of problems, on
    top of which these two tools have vastly different setup complexity, so proper
    evaluation is really difficult.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'Something that is really important that we should mention before moving on
    to the next dimension: a common and highly-recommended risk mitigation for immature
    tooling (this scenario is much more likely than you might think) is that your
    own developers can be used to fix bugs and add features to relevant upstream projects
    if they are capable and allowed to work on them. If a tool is such a good fit
    for your infrastructure and you can throw development resources behind it, it
    will not make much of a difference if it is popular or not as long as you can
    make it work for you in the way that you are satisfied with.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: As a reference data point, countless times during the development of cloud implementations,
    the teams that I worked on have found bugs and issues in upstream projects that
    we fixed rather quickly and in the process also helped all the other users of
    that software instead of potentially waiting days or weeks for the upstream developers
    to make time to fix them. I would highly encourage this type of approach to contributing
    back being applied to your workplace if possible since it helps the whole project's
    community and indirectly prevents loss of project momentum due to unfixed bugs.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: A team's technical competency
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: New tooling often has a great initial idea, but due to poor execution or architecture,
    it quickly turns into spaghetti code that is un-maintainable and prone to bugs.
    If design and implementation are kept to high standards, you can have a better
    assurance that you will not get unexpected breakages or at least that the bugs
    can be easier to find and fix. The competency of the core project developers plays
    a huge part in this aspect and since most of the newer tooling is open-source,
    taking a look at the codebase can often be very helpful in this respect.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: 'It is near impossible to put exact guidelines for evaluating projects that
    span all sorts of technologies and systems, but there are some red flags that
    should be treated as warning signs of potential troubles in the future for the
    tooling that is used in critical applications:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '**Lack of tests**: Without tests, assurance that the code works is pretty much
    eliminated and you are hoping that the developer making changes was careful enough
    when implementing new features and that they did not break current functionality.
    I have only seen a handful of developers in my life that can be as mindful of
    all the edge cases as a test harness, but I would not hold my breath that the
    project you are looking into has one of them.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clever code**: From time to time, a project will have one or more developers
    that are more concerned about showing their skills off than the maintainability
    of the project they are working on and they will almost always turn files they
    touch into code that only they can work on, causing future problems with adding
    features or fixing bugs. Almost always this type of change is one-directional
    and after a long enough period of time it usually ends up in the death of the
    project (more often than not in my experience).'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A high count of critical bugs open for extended periods of time**: For any
    project, there will come a time where you will encounter a critical bug that must
    be fixed as soon as possible, and by seeing trends in how long fixes take, you
    can see whether the team is capable of quickly fixing an issue or whether it pays
    attention to the wider community. While more of a subjective metric, it becomes
    extremely important as the profile or security posture of your service increases.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can also use any other metrics for evaluation such as: old and un-merged
    pull requests, arbitrarily closed bug reports, and many more as long as you get
    the right notion of the codebase''s quality. With that knowledge in hand, you
    can properly evaluate what the future might hold for your candidate tooling and
    how your infrastructure can evolve with it.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: And with that, we have reached the end of our book! In this chapter, we have
    covered various things that you will need to take your small service and make
    it global through aggressive automation, splitting things into multiple availability
    zones, and adding monitoring to your infrastructure. Since cloud technologies
    are also relatively young, we have more importantly included some tips on how
    to evaluate emerging tooling as objectively as you can to ensure that your projects
    have the greatest likelihood of success with the tooling ecosystem changes that
    will be common for the foreseeable future. By assuming that things will change
    in the future and having the tools to handle those changes, we can be ready to
    embrace anything that gets thrown at us.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL

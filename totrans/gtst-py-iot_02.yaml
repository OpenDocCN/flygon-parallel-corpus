- en: Dividing Text Data and Building Text Classifiers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter presents the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Building a text classifier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preprocessing data using tokenization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stemming text data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dividing text using chunking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a bag-of-words model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applications of text classifiers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter presents recipes to build text classifiers. This includes extracting
    vital features from the database, training, testing, and validating the text classifier.
    Initially, a text classifier is trained using commonly used words. Later, the
    trained text classifier is used for prediction. Building a text classifier includes
    preprocessing the data using tokenization, stemming text data, dividing text using
    chunking, and building a bag-of-words model.
  prefs: []
  type: TYPE_NORMAL
- en: Building a text classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Classifier units are normally considered to separate a database into various
    classes. The Naive Bayes classifier scheme is widely considered in literature
    to segregate the texts based on the trained model. This section of the chapter
    initially considers a text database with keywords; feature extraction extracts
    the key phrases from the text and trains the classifier system. Then, **term frequency-inverse
    document frequency** (**tf-idf**) transformation is implemented to specify the
    importance of the word. Finally, the output is predicted and printed using the
    classifier system.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Include the following lines in a new Python file to add datasets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Perform feature extraction to extract the main words from the text:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Train the classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the Multinomial Naive Bayes classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Predict the output categories:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Print the output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot provides examples of predicting the object based on
    the input from the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/14d70abf-d300-4e88-9ece-6318c2e1abb0.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous section of this chapter provided insight regarding the implemented
    classifier section and some sample results. The classifier section works based
    on a comparison between the previous text in the trained Naive Bayes with the
    key test in the test sequence*.*
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Please refer to the following articles:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Sentiment analysis algorithms and applications: A survey *at [https://www.sciencedirect.com/science/article/pii/S2090447914000550](https://www.sciencedirect.com/science/article/pii/S2090447914000550).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'S*entiment classification of online reviews: using sentence-based language
    model* to learn how sentiment prediction works at [https://www.tandfonline.com/doi/abs/10.1080/0952813X.2013.782352?src=recsys&journalCode=teta20](https://www.tandfonline.com/doi/abs/10.1080/0952813X.2013.782352?src=recsys&journalCode=teta20).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Sentiment analysis using product review data* and *Sentence-level sentiment
    analysis in the presence of modalities* to learn more about various metrics used
    in recommendation systems at [https://journalofbigdata.springeropen.com/articles/10.1186/s40537-015-0015-2](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-015-0015-2)
    and ;[https://link.springer.com/chapter/10.1007/978-3-642-54903-8_1](https://link.springer.com/chapter/10.1007/978-3-642-54903-8_1).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pre-processing data using tokenization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The pre-processing of data involves converting the existing text into acceptable
    information for the learning algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Tokenization is the process of dividing text into a set of meaningful pieces.
    These pieces are called tokens.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Introduce sentence tokenization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Form a new text tokenizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Form a new word tokenizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Introduce a new WordPunct tokenizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The result obtained by the tokenizer is shown here. It divides a sentence into
    word groups:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/fb4eb393-47a2-496c-a3cb-a2f99a36dfa6.png)'
  prefs: []
  type: TYPE_IMG
- en: Stemming text data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The stemming procedure involves creating a suitable word with reduced letters
    for the words of the tokenizer.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Initialize the stemming process with a new Python file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s describe some words to consider, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Identify a group of `stemmers` to be used:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize the necessary tasks for the chosen `stemmers`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Format a table to print the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Repeatedly check the list of words and arrange them using chosen `stemmers`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The result obtained from the stemming process is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/c6b683e2-a8d2-4273-89f8-7b841628e28b.png)'
  prefs: []
  type: TYPE_IMG
- en: Dividing text using chunking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The chunking procedure can be used to divide the large text into small, meaningful
    words.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Develop and import the following packages using Python:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Describe a function that divides text into chunks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize the following programming lines to get the assigned variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Start the iteration using words:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'After getting the essential amount of words, reorganize the variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Attach the chunks to the output variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Import the data of `Brown corpus` and consider the first `10000` words:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Describe the word size in every chunk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Initiate a pair of significant variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Print the result by calling the `splitter` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The result obtained after chunking is shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/e33566a4-1380-4420-91db-00b582161836.png)'
  prefs: []
  type: TYPE_IMG
- en: Building a bag-of-words model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When working with text documents that include large words, we need to switch
    them to several types of arithmetic depictions. We need to formulate them to be
    suitable for machine learning algorithms. These algorithms require arithmetical
    information so that they can examine the data and provide significant details.
    The bag-of-words procedure helps us to achieve this. Bag-of-words creates a text
    model that discovers vocabulary using all the words in the document. Later, it
    creates the models for every text by constructing a histogram of all the words
    in the text.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Initialize a new Python file by importing the following file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the `main` function and read the input data from `Brown corpus`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Split the text content into chunks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Build a vocabulary based on these `text` chunks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract a document word matrix, which effectively counts the amount of incidences
    of each word in the document:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Extract the document term `matrix:`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract the vocabulary and print it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Print the document term `matrix`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Iterate throughout the words, and print the reappearance of every word in various
    chunks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The result obtained after executing the bag-of-words model is shown as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/be04e751-2b4b-4148-a279-59415d35db0a.png)![](Images/c0088dd1-48ad-4485-b29b-14b920f4998e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In order to understand how it works on a given sentence, refer to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Introduction to Sentiment Analysis*, explained here: [https://blog.algorithmia.com/introduction-sentiment-analysis/](https://blog.algorithmia.com/introduction-sentiment-analysis/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applications of text classifiers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Text classifiers are used to analyze customer sentiments, in product reviews,
    when searching queries on the internet, in social tags, to predict the novelty
    of research articles, and so on.
  prefs: []
  type: TYPE_NORMAL

- en: The Iterator Pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''ve discussed how many of Python''s built-ins and idioms seem, at first
    blush, to fly in the face of object-oriented principles, but are actually providing
    access to real objects under the hood. In this chapter, we''ll discuss how the
    `for` loop, which seems so structured, is actually a lightweight wrapper around
    a set of object-oriented principles. We''ll also see a variety of extensions to
    this syntax that automatically create even more types of object. We will cover
    the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What design patterns are
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The iterator protocol—one of the most powerful design patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: List, set, and dictionary comprehensions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generators and coroutines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design patterns in brief
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When engineers and architects decide to build a bridge, or a tower, or a building,
    they follow certain principles to ensure structural integrity. There are various
    possible designs for bridges (suspension and cantilever, for example), but if
    the engineer doesn't use one of the standard designs, and doesn't have a brilliant
    new design, it is likely the bridge he/she designs will collapse.
  prefs: []
  type: TYPE_NORMAL
- en: Design patterns are an attempt to bring this same formal definition for correctly
    designed structures to software engineering. There are many different design patterns
    to solve different general problems. Design patterns typically solve a specific
    common problem faced by developers in some specific situation. The design pattern
    is then a suggestion as to the ideal solution for that problem, in terms of object-oriented
    design.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing a design pattern and choosing to use it in our software does not, however,
    guarantee that we are creating a *correct* solution. In 1907, the Québec Bridge
    (to this day, the longest cantilever bridge in the world) collapsed before construction
    was completed, because the engineers who designed it grossly underestimated the
    weight of the steel used to construct it. Similarly, in software development,
    we may incorrectly choose or apply a design pattern, and create software that
    *collapses* under normal operating situations or when stressed beyond its original
    design limits.
  prefs: []
  type: TYPE_NORMAL
- en: Any one design pattern proposes a set of objects interacting in a specific way
    to solve a general problem. The job of the programmer is to recognize when they
    are facing a specific version of such a problem, then to choose and adapt the
    general design in their precise needs.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll be covering the iterator design pattern. This pattern
    is so powerful and pervasive that the Python developers have provided multiple
    syntaxes to access the object-oriented principles underlying the pattern. We will
    be covering other design patterns in the next two chapters. Some of them have
    language support and some don't, but none of them is so intrinsically a part of
    the Python coder's daily life as the iterator pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Iterators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In typical design pattern parlance, an iterator is an object with a `next()`
    method and a `done()` method; the latter returns `True` if there are no items
    left in the sequence. In a programming language without built-in support for iterators,
    the iterator would be looped over like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In Python, iteration is a special feature, so the method gets a special name,
    `__next__`. This method can be accessed using the `next(iterator)` built-in. Rather
    than a `done` method, Python's iterator protocol raises `StopIteration` to notify
    the loop that it has completed. Finally, we have the much more readable `foriteminiterator`
    syntax to actually access items in an iterator instead of messing around with
    a `while` loop. Let's look at these in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: The iterator protocol
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `Iterator` abstract base class, in the `collections.abc` module, defines
    the iterator protocol in Python. As mentioned, it must have a `__next__` method
    that the `for` loop (and other features that support iteration) can call to get
    a new element from the sequence. In addition, every iterator must also fulfill
    the `Iterable` interface. Any class that provides an `__iter__` method is iterable.
    That method must return an `Iterator` instance that will cover all the elements
    in that class.
  prefs: []
  type: TYPE_NORMAL
- en: 'This might sound a bit confusing, so have a look at the following example,
    but note that this is a very verbose way to solve this problem. It clearly explains
    iteration and the two protocols in question, but we''ll be looking at several
    more readable ways to get this effect later in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This example defines an `CapitalIterable` class whose job is to loop over each
    of the words in a string and output them with the first letter capitalized. Most
    of the work of that iterable is passed to the `CapitalIterator` implementation.
    The canonical way to interact with this iterator is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This example first constructs an iterable and retrieves an iterator from it.
    The distinction may need explanation; the iterable is an object with elements
    that can be looped over. Normally, these elements can be looped over multiple
    times, maybe even at the same time or in overlapping code. The iterator, on the
    other hand, represents a specific location in that iterable; some of the items
    have been consumed and some have not. Two different iterators might be at different
    places in the list of words, but any one iterator can mark only one place.
  prefs: []
  type: TYPE_NORMAL
- en: Each time `next()` is called on the iterator, it returns another token from
    the iterable, in order. Eventually, the iterator will be exhausted (won't have
    any more elements to return), in which case `Stopiteration` is raised, and we
    break out of the loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, we already know a much simpler syntax for constructing an iterator
    from an iterable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the `for` statement, in spite of not looking remotely object-oriented,
    is actually a shortcut to some obviously object-oriented design principles. Keep
    this in mind as we discuss comprehensions, as they, too, appear to be the polar
    opposite of an object-oriented tool. Yet, they use the exact same iteration protocol
    as `for` loops and are just another kind of shortcut.
  prefs: []
  type: TYPE_NORMAL
- en: Comprehensions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Comprehensions are simple, but powerful, syntaxes that allow us to transform
    or filter an iterable object in as little as one line of code. The resultant object
    can be a perfectly normal list, set, or dictionary, or it can be a generator expression
    that can be efficiently consumed while keeping just one element in memory at a
    time.
  prefs: []
  type: TYPE_NORMAL
- en: List comprehensions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: List comprehensions are one of the most powerful tools in Python, so people
    tend to think of them as advanced. They're not. Indeed, I've taken the liberty
    of littering previous examples with comprehensions, assuming you would understand
    them. While it's true that advanced programmers use comprehensions a lot, it's
    not because they're advanced. It's because they're trivial, and handle some of
    the most common operations in software development.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s have a look at one of those common operations; namely, converting a
    list of items into a list of related items. Specifically, let''s assume we just
    read a list of strings from a file, and now we want to convert it to a list of
    integers. We know every item in the list is an integer, and we want to do some
    activity (say, calculate an average) on those numbers. Here''s one simple way
    to approach it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This works fine and it''s only three lines of code. If you aren''t used to
    comprehensions, you may not even think it looks ugly! Now, look at the same code
    using a list comprehension:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We're down to one line and, importantly for performance, we've dropped an `append`
    method call for each item in the list. Overall, it's pretty easy to tell what's
    going on, even if you're not used to comprehension syntax.
  prefs: []
  type: TYPE_NORMAL
- en: The square brackets indicate, as always, that we're creating a list. Inside
    this list is a `for` loop that iterates over each item in the input sequence.
    The only thing that may be confusing is what's happening between the list's opening
    brace and the start of the `for` loop. Whatever happens here is applied to *each*
    of the items in the input list. The item in question is referenced by the `num`
    variable from the loop. So, it's calling the `int` function for each element and
    storing the resulting integer in the new list.
  prefs: []
  type: TYPE_NORMAL
- en: That's all there is to a basic list comprehension. Comprehensions are highly
    optimized C code; list comprehensions are far faster than `for` loops when looping
    over a large number of items. If readability alone isn't a convincing reason to
    use them as much as possible, speed should be.
  prefs: []
  type: TYPE_NORMAL
- en: 'Converting one list of items into a related list isn''t the only thing we can
    do with a list comprehension. We can also choose to exclude certain values by
    adding an `if` statement inside the comprehension. Have a look:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: All that's different between this example and the previous one is the `if len(num)
    < 3` part. This extra code excludes any strings with more than two characters.
    The `if` statement is applied to each element **before** the `int` function, so
    it's testing the length of a string. Since our input strings are all integers
    at heart, it excludes any number over 99.
  prefs: []
  type: TYPE_NORMAL
- en: List comprehensions are used to map input values to output values, applying
    a filter along the way to include or exclude any values that meet a specific condition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Any iterable can be the input to a list comprehension. In other words, anything
    we can wrap in a `for` loop can also be placed inside a comprehension. For example,
    text files are iterable; each call to `__next__` on the file''s iterator will
    return one line of the file. We could load a tab-delimited file where the first
    line is a header row into a dictionary using the `zip` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This time, I've added some whitespace to make it more readable (list comprehensions
    don't *have* to fit on one line). This example creates a list of dictionaries
    from the zipped header and split lines for each line in the file.
  prefs: []
  type: TYPE_NORMAL
- en: Er, what? Don't worry if that code or explanation doesn't make sense; it's confusing.
    One list comprehension is doing a pile of work here, and the code is hard to understand,
    read, and ultimately, maintain. This example shows that list comprehensions aren't
    always the best solution; most programmers would agree that a `for` loop would
    be more readable than this version.
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember: the tools we are provided with should not be abused! Always pick
    the right tool for the job, which is always to write maintainable code.'
  prefs: []
  type: TYPE_NORMAL
- en: Set and dictionary comprehensions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Comprehensions aren't restricted to lists. We can use a similar syntax with
    braces to create sets and dictionaries as well. Let's start with sets. One way
    to create a set is to wrap a list comprehension in the `set()` constructor, which
    converts it to a set. But why waste memory on an intermediate list that gets discarded,
    when we can create a set directly?
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example that uses a named tuple to model author/title/genre triads,
    and then retrieves a set of all the authors that write in a specific genre:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The highlighted set comprehension sure is short in comparison to the demo-data
    setup! If we were to use a list comprehension, of course, Terry Pratchett would
    have been listed twice. As it is, the nature of sets removes the duplicates, and
    we end up with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Still using braces, we can introduce a colon to create a dictionary comprehension.
    This converts a sequence into a dictionary using *key:value* pairs. For example,
    it may be useful to quickly look up the author or genre in a dictionary if we
    know the title. We can use a dictionary comprehension to map titles to `books`
    objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Now, we have a dictionary, and can look up books by title using the normal syntax.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, comprehensions are not advanced Python, nor are they *non-object-oriented* tools
    that should be avoided. They are simply a more concise and optimized syntax for
    creating a list, set, or dictionary from an existing sequence.
  prefs: []
  type: TYPE_NORMAL
- en: Generator expressions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes we want to process a new sequence without pulling a new list, set,
    or dictionary into system memory. If we're just looping over items one at a time,
    and don't actually care about having a complete container (such as a list or dictionary)
    created, creating that container is a waste of memory. When processing one item
    at a time, we only need the current object available in memory at any one moment.
    But when we create a container, all the objects have to be stored in that container
    before we start processing them.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, consider a program that processes log files. A very simple log
    might contain information in this format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Log files for popular web servers, databases, or email servers can contain many
    gigabytes of data (I once had to clean nearly 2 terabytes of logs off a misbehaving
    system). If we want to process each line in the log, we can't use a list comprehension;
    it would create a list containing every line in the file. This probably wouldn't
    fit in RAM and could bring the computer to its knees, depending on the operating
    system.
  prefs: []
  type: TYPE_NORMAL
- en: If we used a `for` loop on the log file, we could process one line at a time
    before reading the next one into memory. Wouldn't be nice if we could use comprehension
    syntax to get the same effect?
  prefs: []
  type: TYPE_NORMAL
- en: This is where generator expressions come in. They use the same syntax as comprehensions,
    but they don't create a final container object. To create a generator expression,
    wrap the comprehension in `()` instead of `[]` or `{}`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code parses a log file in the previously presented format and
    outputs a new log file that contains only the `WARNING` lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This program takes the two filenames on the command line, uses a generator
    expression to filter out the warnings (in this case, it uses the `if` syntax and
    leaves the line unmodified), and then outputs the warnings to another file. If
    we run it on our sample file, the output looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Of course, with such a short input file, we could have safely used a list comprehension,
    but if the file is millions of lines long, the generator expression will have
    a huge impact on both memory and speed.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping a `for` expression in parenthesis creates a generator expression, not
    a tuple.
  prefs: []
  type: TYPE_NORMAL
- en: Generator expressions are frequently most useful inside function calls. For
    example, we can call `sum`, `min`, or `max` on a generator expression instead
    of a list, since these functions process one object at a time. We're only interested
    in the aggregate result, not any intermediate container.
  prefs: []
  type: TYPE_NORMAL
- en: In general, of the four options, a generator expression should be used whenever
    possible. If we don't actually need a list, set, or dictionary, but simply need
    to filter or convert items in a sequence, a generator expression will be most
    efficient. If we need to know the length of a list, or sort the result, remove
    duplicates, or create a dictionary, we'll have to use the comprehension syntax.
  prefs: []
  type: TYPE_NORMAL
- en: Generators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generator expressions are actually a sort of comprehension too; they compress
    the more advanced (this time it really is more advanced!) generator syntax into
    one line. The greater generator syntax looks even less object-oriented than anything
    we've seen, but we'll discover that once again, it is a simple syntax shortcut
    to create a kind of object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take the log file example a little further. If we want to delete the
    `WARNING` column from our output file (since it''s redundant: this file contains
    only warnings), we have several options at various levels of readability. We can
    do it with a generator expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'That''s perfectly readable, though I wouldn''t want to make the expression
    much more complicated than that. We could also do it with a normal `for` loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: That's clearly maintainable, but so many levels of indent in so few lines is
    kind of ugly. More alarmingly, if we wanted to do something other than printing
    the lines out, we'd have to duplicate the looping and conditional code, too.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s consider a truly object-oriented solution, without any shortcuts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'No doubt about it: that is so ugly and difficult to read that you may not even
    be able to tell what''s going on. We created an object that takes a file object
    as input, and provides a `__next__` method like any iterator.'
  prefs: []
  type: TYPE_NORMAL
- en: This `__next__` method reads lines from the file, discarding them if they are
    not `WARNING` lines. When we encounter a `WARNING` line, we modify and return
    it. Then our `for` loop calls `__next__` again to process the subsequent `WARNING`
    line. When we run out of lines, we raise `StopIteration` to tell the loop we're
    finished iterating. It's pretty ugly compared to the other examples, but it's
    also powerful; now that we have a class in our hands, we can do whatever we want
    with it.
  prefs: []
  type: TYPE_NORMAL
- en: 'With that background behind us, we finally get to see true generators in action.
    This next example does *exactly* the same thing as the previous one: it creates
    an object with a `__next__` method that raises `StopIteration` when it''s out
    of inputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: OK, that's pretty readable, maybe... at least it's short. But what on earth
    is going on here? It makes no sense whatsoever. And what is `yield`, anyway?
  prefs: []
  type: TYPE_NORMAL
- en: In fact, `yield` is the key to generators. When Python sees `yield` in a function,
    it takes that function and wraps it up in an object not unlike the one in our
    previous example. Think of the `yield` statement as similar to the `return` statement;
    it exits the function and returns a line. Unlike `return`, however, when the function
    is called again (via `next()`), it will start where it left off—on the line after
    the `yield` statement—instead of at the beginning of the function.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, there is no line *after* the `yield` statement, so it jumps
    to the next iteration of the `for` loop. Since the `yield` statement is inside
    an `if` statement, it only yields lines that contain `WARNING`.
  prefs: []
  type: TYPE_NORMAL
- en: 'While it looks like this is just a function looping over the lines, it is actually
    creating a special type of object, a generator object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: I passed an empty list into the function to act as an iterator. All the function does
    is create and return a generator object. That object has `__iter__` and `__next__`
    methods on it, just like the one we created in the previous example. (You can
    call the `dir` built-in function on it to confirm.) Whenever `__next__` is called,
    the generator runs the function until it finds a `yield` statement. It then returns
    the value from `yield`, and the next time `__next__` is called, it picks up where
    it left off.
  prefs: []
  type: TYPE_NORMAL
- en: This use of generators isn't that advanced, but if you don't realize the function
    is creating an object, it can seem like magic. This example was quite simple,
    but you can get really powerful effects by making multiple calls to `yield` in
    a single function; on each loop, the generator will simply pick up at the most
    recent `yield` and continue to the next one.
  prefs: []
  type: TYPE_NORMAL
- en: Yield items from another iterable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Often, when we build a generator function, we end up in a situation where we
    want to yield data from another iterable object, possibly a list comprehension
    or generator expression we constructed inside the generator, or perhaps some external
    items that were passed into the function. This has always been possible by looping
    over the iterable and individually yielding each item. However, in Python version
    3.3, the Python developers introduced a new syntax to make it a little more elegant.
  prefs: []
  type: TYPE_NORMAL
- en: Let's adapt the generator example a bit so that instead of accepting a sequence
    of lines, it accepts a filename. This would normally be frowned upon as it ties
    the object to a particular paradigm. When possible we should operate on iterators
    as input; this way the same function could be used regardless of whether the log
    lines came from a file, memory, or the web.
  prefs: []
  type: TYPE_NORMAL
- en: 'This version of the code illustrates that your generator can do some basic
    setup before yielding information from another iterable (in this case, a generator
    expression):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This code combines the `for` loop from the previous example into a generator
    expression. Notice that this transformation didn't help anything; the previous
    example with a `for` loop was more readable.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let''s consider an example that is more readable than its alternative.
    It can be useful to construct a generator that yields data from multiple other
    generators. The `itertools.chain` function, for example, yields data from iterables
    in sequence until they have all been exhausted. This can be implemented far too
    easily using the `yield from` syntax, so let''s consider a classic computer science
    problem: walking a general tree.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A common implementation of the general tree data structure is a computer''s
    filesystem. Let''s model a few folders and files in a Unix filesystem so we can
    use `yield from` to walk them effectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This setup code looks like a lot of work, but in a real filesystem, it would
    be even more involved. We''d have to read data from the hard drive and structure
    it into the tree. Once in memory, however, the code that outputs every file in
    the filesystem is quite elegant:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: If this code encounters a directory, it recursively asks `walk()` to generate
    a list of all files subordinate to each of its children, and then yields all that
    data plus its own filename. In the simple case that it has encountered a normal
    file, it just yields that name.
  prefs: []
  type: TYPE_NORMAL
- en: As an aside, solving the preceding problem without using a generator is tricky
    enough that it is a common interview question. If you answer it as shown like
    this, be prepared for your interviewer to be both impressed and somewhat irritated
    that you answered it so easily. They will likely demand that you explain exactly
    what is going on. Of course, armed with the principles you've learned in this
    chapter, you won't have any problem. Good luck!
  prefs: []
  type: TYPE_NORMAL
- en: The `yield from` syntax is a useful shortcut when writing chained generators.
    It was added to the language for a different reason, to support coroutines. It
    is not used all that much anymore, however, because it's usage has been replaced
    with `async` and `await` syntax. We'll see examples of both in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Coroutines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Coroutines are extremely powerful constructs that are often confused with generators.
    Many authors inappropriately describe coroutines as *generators with a bit of
    extra syntax*. This is an easy mistake to make, as, way back in Python 2.5, when
    coroutines were introduced, they were presented as *we added a* `send` *method
    to the generator syntax*. The difference is actually a lot more nuanced and will
    make more sense after you've seen a few examples.
  prefs: []
  type: TYPE_NORMAL
- en: Coroutines are pretty hard to understand. Outside the `asyncio` module, they
    are not used all that often in the wild. You can definitely skip this section
    and happily develop in Python for years without ever encountering coroutines.
    There are a couple of libraries that use coroutines extensively (mostly for concurrent
    or asynchronous programming), but they are normally written such that you can
    use coroutines without actually understanding how they work! So, if you get lost
    in this section, don't despair.
  prefs: []
  type: TYPE_NORMAL
- en: 'If I haven''t scared you off, let''s get started! Here''s one of the simplest
    possible coroutines; it allows us to keep a running tally that can be increased
    by arbitrary values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This code looks like black magic that couldn''t possibly work, so let''s prove
    it works before going into a line-by-line description. This simple object could
    be used by a scoring application for a baseball team. Separate tallies could be
    kept for each team, and their score could be incremented by the number of runs
    accumulated at the end of every half-innings. Look at this interactive session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: First, we construct two `tally` objects, one for each team. Yes, they look like
    functions, but as with the generator objects in the previous section, the fact
    that there is a `yield` statement inside the function tells Python to put a great
    deal of effort into turning the simple function into an object.
  prefs: []
  type: TYPE_NORMAL
- en: We then call `next()` on each of the coroutine objects. This does the same thing
    as calling next on any generator, which is to say, it executes each line of code
    until it encounters a `yield` statement, returns the value at that point, and
    then *pauses* until the next `next()` call.
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, then, there''s nothing new. But look back at the `yield` statement
    in our coroutine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Unlike with generators, this `yield` function looks like it's supposed to return
    a value and assign it to a variable. In fact, this is exactly what's happening.
    The coroutine is still paused at the `yield` statement and waiting to be activated
    again by another call to `next()`.
  prefs: []
  type: TYPE_NORMAL
- en: Except we don't call `next()`. As you see in the interactive session, we instead
    call to a method called `send()`. The `send()` method does *exactly* the same
    thing as `next()` except that in addition to advancing the generator to the next
    `yield` statement, it also allows you to pass in a value from outside the generator.
    This value is what gets assigned to the left side of the `yield` statement.
  prefs: []
  type: TYPE_NORMAL
- en: 'The thing that is really confusing for many people is the order in which this
    happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '`yield` occurs and the generator pauses'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`send()` occurs from outside the function and the generator wakes up'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The value sent in is assigned to the left side of the `yield` statement
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The generator continues processing until it encounters another `yield` statement
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'So, in this particular example, after we construct the coroutine and advance
    it to the `yield` statement with a single call to `next()`, each successive call
    to `send()` passes a value into the coroutine. We add this value to its score.
    Then we go back to the top of the `while` loop, and keep processing until we hit
    the `yield` statement. The `yield` statement returns a value, which becomes the
    return value of our most recent call to `send`. Don''t miss that: like `next()`,
    the `send()` method does not just submit a value to the generator, it also returns
    the value from the upcoming `yield` statement. This is how we define the difference
    between a generator and a coroutine: a generator only produces values, while a
    coroutine can also consume them.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The behavior and syntax of `next(i)`, `i.__next__()`, and `i.send(value)` are
    rather unintuitive and frustrating. The first is a normal function, the second
    is a special method, and the last is a normal method. But all three do the same
    thing: advance the generator until it yields a value and pause. Further, the `next()`
    function and associated method can be replicated by calling `i.send(None)`. There
    is value to having two different method names here, since it helps the reader
    of our code easily see whether they are interacting with a coroutine or a generator.
    I just find the fact that in one case it''s a function call and in the other it''s
    a normal method somewhat irritating.'
  prefs: []
  type: TYPE_NORMAL
- en: Back to log parsing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Of course, the previous example could easily have been coded using a couple
    of integer variables and calling `x += increment` on them. Let's look at a second
    example where coroutines actually save us some code. This example is a somewhat
    simplified (for pedagogical reasons) version of a problem I had to solve while
    working at Facebook.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Linux kernel log contains lines that look almost, but not quite entirely,
    unlike this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: There are a whole bunch of interspersed kernel log messages, some of which pertain
    to hard disks. The hard disk messages might be interspersed with other messages,
    but they occur in a predictable format and order. For each, a specific drive with
    a known serial number is associated with a bus identifier (such as `0:0:0:0`).
    A block device identifier (such as `sda`) is also associated with that bus. Finally,
    if the drive has a corrupt filesystem, it might fail with an XFS error.
  prefs: []
  type: TYPE_NORMAL
- en: Now, given the preceding log file, the problem we need to solve is how to obtain
    the serial number of any drives that have XFS errors on them. This serial number
    might later be used by a data center technician to identify and replace the drive.
  prefs: []
  type: TYPE_NORMAL
- en: We know we can identify the individual lines using regular expressions, but
    we'll have to change the regular expressions as we loop through the lines, since
    we'll be looking for different things depending on what we found previously. The
    other difficult bit is that if we find an error string, the information about
    which bus contains that string as well as the serial number have already been
    processed. This can easily be solved by iterating through the lines of the file
    in reverse order.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before you look at this example, be warned—the amount of code required for
    a coroutine-based solution is scarily small:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This code neatly divides the job into two separate tasks. The first task is
    to loop over all the lines and spit out any lines that match a given regular expression.
    The second task is to interact with the first task and give it guidance as to
    what regular expression it is supposed to be searching for at any given time.
  prefs: []
  type: TYPE_NORMAL
- en: Look at the `match_regex` coroutine first. Remember, it doesn't execute any
    code when it is constructed; rather, it just creates a coroutine object. Once
    constructed, someone outside the coroutine will eventually call `next()` to start
    the code running. Then it stores the state of two variables `filename` and `regex`.
    It then reads all the lines in the file and iterates over them in reverse. Each
    line is compared to the regular expression that was passed in until it finds a
    match. When the match is found, the coroutine yields the first group from the
    regular expression and waits.
  prefs: []
  type: TYPE_NORMAL
- en: At some point in the future, other code will send in a new regular expression
    to search for. Note that the coroutine never cares what regular expression it
    is trying to match; it's just looping over lines and comparing them to a regular
    expression. It's somebody else's responsibility to decide what regular expression
    to supply.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, that somebody else is the `get_serials` generator. It doesn't
    care about the lines in the file; in fact, it isn't even aware of them. The first
    thing it does is create a `matcher` object from the `match_regex` coroutine constructor,
    giving it a default regular expression to search for. It advances the coroutine
    to its first `yield` and stores the value it returns. It then goes into a loop
    that instructs the `matcher` object to search for a bus ID based on the stored
    device ID, and then a serial number based on that bus ID.
  prefs: []
  type: TYPE_NORMAL
- en: It idly yields that serial number to the outside `for` loop before instructing
    the matcher to find another device ID and repeat the cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Basically, the coroutine's job is to search for the next important line in the
    file, while the generator's (`get_serial`, which uses the `yield` syntax without
    assignment) job is to decide which line is important. The generator has information
    about this particular problem, such as what order lines will appear in the file.
  prefs: []
  type: TYPE_NORMAL
- en: The coroutine, on the other hand, could be plugged into any problem that required
    searching a file for given regular expressions.
  prefs: []
  type: TYPE_NORMAL
- en: Closing coroutines and throwing exceptions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Normal generators signal their exit from inside by raising `StopIteration`.
    If we chain multiple generators together (for example, by iterating over one generator
    from inside another), the `StopIteration` exception will be propagated outward.
    Eventually, it will hit a `for` loop that will see the exception and know that
    it's time to exit the loop.
  prefs: []
  type: TYPE_NORMAL
- en: Even though they use a similar syntax, coroutines don't normally follow the
    iteration mechanism. Instead of pulling data through one until an exception is
    encountered, data is usually pushed into it (using `send`). The entity doing the
    pushing is normally the one in charge of telling the coroutine when it's finished.
    It does this by calling the `close()` method on the coroutine in question.
  prefs: []
  type: TYPE_NORMAL
- en: When called, the `close()` method will raise a `GeneratorExit` exception at
    the point the coroutine was waiting for a value to be sent in. It is normally
    good policy for coroutines to wrap their `yield` statements in a `try`...`finally`
    block so that any cleanup tasks (such as closing associated files or sockets)
    can be performed.
  prefs: []
  type: TYPE_NORMAL
- en: If we need to raise an exception inside a coroutine, we can use the `throw()`
    method in a similar way. It accepts an exception type with optional `value` and
    `traceback` arguments. The latter is useful when we encounter an exception in
    one coroutine and want to cause an exception to occur in an adjacent coroutine
    while maintaining the traceback.
  prefs: []
  type: TYPE_NORMAL
- en: The previous example could be written without coroutines and would be about
    equally readable. The truth is, correctly managing all the state between coroutines
    is pretty difficult, especially when you take things like context managers and
    exceptions into account. Luckily, the Python standard library contains a package
    called `asyncio` that can manage all of this for you. In general, I recommend
    you avoid using bare coroutines unless you are specifically coding for asyncio.
    The logging example could almost be considered an *anti-pattern*; a design pattern
    that should be avoided rather than embraced.
  prefs: []
  type: TYPE_NORMAL
- en: The relationship between coroutines, generators, and functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've seen coroutines in action, so now let's go back to that discussion of
    how they are related to generators. In Python, as is so often the case, the distinction
    is quite blurry. In fact, all coroutines are generator objects, and authors often
    use the two terms interchangeably. Sometimes, they describe coroutines as a subset
    of generators (only generators that return values from yield are considered coroutines).
    This is technically true in Python, as we've seen in the previous sections.
  prefs: []
  type: TYPE_NORMAL
- en: However, in the greater sphere of theoretical computer science, coroutines are
    considered the more general principles, and generators are a specific type of
    coroutine. Further, normal functions are yet another distinct subset of coroutines.
  prefs: []
  type: TYPE_NORMAL
- en: A coroutine is a routine that can have data passed in at one or more points
    and get it out at one or more points. In Python, the point where data is passed
    in and out is the `yield` statement.
  prefs: []
  type: TYPE_NORMAL
- en: A function, or subroutine, is the simplest type of coroutine. You can pass data
    in at one point, and get data out at one other point when the function returns.
    While a function can have multiple `return` statements, only one of them can be
    called for any given invocation of the function.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, a generator is a type of coroutine that can have data passed in at
    one point, but can pass data out at multiple points. In Python, the data would
    be passed out at a `yield` statement, but you can't pass data back in. If you
    called `send`, the data would be silently discarded.
  prefs: []
  type: TYPE_NORMAL
- en: So, in theory, generators are types of coroutines, functions are types of coroutines,
    and there are coroutines that are neither functions nor generators. That's simple
    enough, eh? So, why does it feel more complicated in Python?
  prefs: []
  type: TYPE_NORMAL
- en: In Python, generators and coroutines are both constructed using a syntax that
    **looks** like we are constructing a function. But the resulting object is not
    a function at all; it's a totally different kind of object. Functions are, of
    course, also objects. But they have a different interface; functions are callable
    and return values, generators have data pulled out using `next()`, and coroutines
    have data pushed in using `send`.
  prefs: []
  type: TYPE_NORMAL
- en: There is an alternate syntax for coroutines using the `async` and `await` keywords. The
    syntax makes it clearer that the code is a coroutine and further breaks the deceiving
    symmetry between coroutines and generators.
  prefs: []
  type: TYPE_NORMAL
- en: Case study
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the fields in which Python is the most popular these days is data science.
    In honor of that fact, let's implement a basic machine learning algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning is a huge topic, but the general idea is to make predictions
    or classifications about future data by using knowledge gained from past data.
    Uses of such algorithms abound, and data scientists are finding new ways to apply
    machine learning every day. Some important machine learning applications include
    computer vision (such as image classification or facial recognition), product
    recommendation, identifying spam, and self-driving cars.
  prefs: []
  type: TYPE_NORMAL
- en: 'So as not to digress into an entire book on machine learning, we''ll look at
    a simpler problem: given an RGB color definition, what name would humans identify
    that color as?'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are more than 16 million colors in the standard RGB color space, and
    humans have come up with names for only a fraction of them. While there are thousands
    of names (some quite ridiculous; just go to any car dealership or paint store),
    let''s build a classifier that attempts to divide the RGB space into the basic
    colors:'
  prefs: []
  type: TYPE_NORMAL
- en: Red
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Purple
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Green
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yellow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orange
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gray
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pink
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (In my testing, I classified whitish and blackish colors as gray, and brownish
    colors as orange.)
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we need is a dataset to train our algorithm on. In a production
    system, you might scrape a *list of colors* website or survey thousands of people.
    Instead, I created a simple application that renders a random color and asks the
    user to select one of the preceding eight options to classify it. I implemented
    it using `tkinter`, the user interface toolkit that ships with Python. I''m not
    going to go into the details of what this script does, but here it is in its entirety
    for completeness (it''s a trifle long, so you may want to pull it from Packt''s
    GitHub repository with the examples for this book instead of typing it in):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: You can easily add more buttons for other colors if you like. You may get tripped
    up on the layout; the second and third argument to `create_color_button` represent
    the row and column of a two column grid that the button goes in. Once you have
    all your colors in place, you will want to move the **Quit** button to the last
    row.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the purposes of this case study, the important thing to know about this
    application is the output. It creates a **C****omma-Separated Value** (**CSV**)
    file named `colors.csv`. This file contains two CSVs: the label the user assigned
    to the color, and the hex RGB value for the color. Here''s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: I made over 250 datapoints before I got bored and decided it was time to start
    machine learning on my dataset. My datapoints are shipped with the examples for
    this chapter if you would like to use it (nobody's ever told me I'm colorblind,
    so it should be somewhat reasonable).
  prefs: []
  type: TYPE_NORMAL
- en: We'll be implementing one of the simpler machine learning algorithms, referred
    to as *k-nearest neighbor*. This algorithm relies on some kind of *distance* calculation
    between points in the dataset (in our case, we can use a three-dimensional version
    of the Pythagorean theorem). Given a new datapoint, it finds a certain number
    (referred to as *k*, which is the *k* in *k-nearest*) of datapoints that are closest
    to it when measured by that distance calculation. Then it combines those datapoints
    in some way (an average might work for linear calculations; for our classification
    problem, we'll use the mode), and returns the result.
  prefs: []
  type: TYPE_NORMAL
- en: We won't go into too much detail about what the algorithm does; rather, we'll
    focus on some of the ways we can apply the iterator pattern or iterator protocol
    to this problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now write a program that performs the following steps in order:'
  prefs: []
  type: TYPE_NORMAL
- en: Load the sample data from the file and construct a model from it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate 100 random colors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Classify each color and output it to a file in the same format as the input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The first step is a fairly simple generator that loads CSV data and converts
    it into a format that is amenable to our needs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: We haven't seen the `csv.reader` function before. It returns an iterator over
    the lines in the file. Each value returned by the iterator is a list of strings,
    as separated by commas. So, the line `Green,#6edd13` is returned as `["Green",
    "#6edd13"]`.
  prefs: []
  type: TYPE_NORMAL
- en: The `load_colors` generator then consumes that iterator, one line at a time,
    and yields a tuple of RGB values as well as the label. It is quite common for
    generators to be chained in this way, where one iterator calls another that calls
    another and so on. You may want to look at the `itertools` module in the Python
    Standard Library for a whole host of such ready-made generators waiting for you.
  prefs: []
  type: TYPE_NORMAL
- en: 'The RGB values in this case are tuples of integers between 0 and 255\. The
    conversion from hex to RGB is a bit tricky, so we pulled it out into a separate
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: This generator expression is doing a lot of work. It takes a string such as `"#12abfe"`
    as input and returns a tuple such as `(18, 171, 254)`. Let's break it down from
    back to front.
  prefs: []
  type: TYPE_NORMAL
- en: The `range` call will return the numbers `[1, 3, 5]`. These represent the indexes
    of the three color channels in the hex string. The index, `0`, is skipped, since
    it represents the character `"#"`, which we don't care about. For each of the
    three numbers, it extracts the two character string between `i` and `i+2`. For
    the preceding example string , that would be `12`, `ab`, and `fe`. Then it converts
    this string value to an integer. The `16` passed as the second argument to the
    `int` function tells the function to use base-16 (hexadecimal) instead of the
    usual base-10 (decimal) for the conversion.
  prefs: []
  type: TYPE_NORMAL
- en: Given how difficult the generator expression is to read, do you think it should
    have been represented in a different format? It could be created as a sequence
    of multiple generator expressions, for example, or be unrolled into a normal generator
    function with `yield` statements. Which would you prefer?
  prefs: []
  type: TYPE_NORMAL
- en: In this case, I am comfortable trusting the function name to explain what the
    ugly line of code is doing.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've loaded the *training data* (manually classified colors, we need
    some new data to test how well the algorithm is working. We can do this by generating
    a hundred random colors, each composed of three random numbers between 0 and 255.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are so many ways this can be done:'
  prefs: []
  type: TYPE_NORMAL
- en: A list comprehension with a nested generator expression: ``[tuple(randint(0,255)
    for c in range(3)) for r in range(100)]``
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A basic generator function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A class that implements the `__iter__` and `__next__` protocols
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Push the data through a pipeline of coroutines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even just a basic `for` loop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The generator version seems to be most readable, so let''s add that function
    to our program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Notice how we parameterize the number of colors to generate. We can now reuse
    this function for other color-generating tasks in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, before we do the classification step, we need a function to calculate
    the *distance* between two colors. Since it''s possible to think of colors as
    being three dimensional (red, green, and blue could map to the *x*, *y*, and *z*
    axes, for example), let''s use a little basic math:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This is a pretty basic-looking function; it doesn't look like it's even using
    the iterator protocol. There's no `yield` function, no comprehensions. However,
    there is a `for` loop, and that call to the `zip` function is doing some real
    iteration as well (if you aren't familiar with it, `zip` yields tuples, each containing
    one element from each input iterator).
  prefs: []
  type: TYPE_NORMAL
- en: 'This distance calculation is the three-dimensional version of the Pythagorean
    theorem you may remember from school: *a² + b² = c²*. Since we are using three
    dimensions, I guess it would actually be *a² + b² + c² = d²*. The distance is
    technically the square root of *a² + b² + c²*, but there isn''t any need to perform
    the somewhat expensive `sqrt` calculation since the squared distances are all
    the same relative size to each other.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have some plumbing in place, let''s do the actual k-nearest neighbor
    implementation. This routine can be thought of as consuming and combining the
    two generators we''ve already seen (`load_colors` and `generate_colors`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: We first convert the `model_colors` generator to a list because it has to be
    consumed multiple times, once for each of the `target_colors`.  If we didn't do
    this, we would have to load the colors from the source file repeatedly, which
    would perform a lot of unnecessary disk reads.
  prefs: []
  type: TYPE_NORMAL
- en: The downside of this decision is that the entire list has to be stored in memory
    all at once. If we had a massive dataset that didn't fit in memory, it would actually
    be necessary to reload the generator from disk each time (though we'd actually
    be looking at different machine learning algorithms in that case).
  prefs: []
  type: TYPE_NORMAL
- en: The `nearest_neighbors` generator loops over each target color (a three-tuple,
    such as `(255, 14, 168)`) and calls the `color_distance` function on it inside
    a generator expression. The `sorted` call surrounding that generator expression
    then sorts the results by their first element, which is the distance. It is a
    complicated piece of code and isn't object-oriented at all. You may want to break
    it down into a normal `for` loop to ensure you understand what the generator expression
    is doing.
  prefs: []
  type: TYPE_NORMAL
- en: The `yield` statement is a bit less complicated. For each RGB three-tuple from
    the `target_colors` generator, it yields the target, and a list comprehension
    of the `num_neighbors` (that's the *k* in *k-nearest*, by the way. Many mathematicians
    and, by extension, data scientists, have a horrible tendency to use unintelligible
    one-letter variable names) closest colors.
  prefs: []
  type: TYPE_NORMAL
- en: 'The contents of each element in the list comprehension is an element from the
    `model_colors` generator; that is, a tuple of a tuple of three RGB values and
    the string name that was manually entered for that color. So, one element might
    look like this: `((104, 195, 77), ''Green'')`. The first thing I think when I
    see nested tuples like that is, *that is not the right datastructure*. The RGB
    color should probably be represented as a named tuple, and the two attributes
    should maybe go on a dataclass.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now add *another* generator to the chain to figure out what name we
    should give this target color:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: This generator is unpacking the tuple returned by `nearest_neighbors` into the
    three-tuple target and the five nearest datapoints. It uses a `Counter` to find
    the name that appears most often among the colors that were returned. There is
    yet another generator expression in the `Counter` constructor; this one extracts
    the second element (the color name) from each datapoint. Then it yields a tuple
    RGB value and the guessed name. An example of the return value is `(91, 158, 250)
    Blue`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can write a function that accepts the output from the `name_colors` generator
    and writes it to a CSV file, with the RGB colors represented as hex values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: This is a function, not a generator. It's consuming the generator in a `for`
    loop, but it's not yielding anything. It constructs a CSV writer and outputs rows
    of name, hex value (for example, `Purple,#7f5f95`) pairs for each of the target
    colors. The only thing that might be confusing in here is the contents of the
    format string. The `:02x` modifier used with each of the `r`,`g`, and `b` channels
    outputs the number as a zero-padded two-digit hexadecimal number.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now all we have to do is connect these various generators and pipelines together,
    and kick off the process with a single function call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: So, this function, unlike almost every other function we've defined, is a perfectly
    normal function without any `yield` statements or `for` loops. It doesn't do any
    iteration at all.
  prefs: []
  type: TYPE_NORMAL
- en: 'It does, however, construct three generators. Can you see all three?:'
  prefs: []
  type: TYPE_NORMAL
- en: '`load_colors` returns a generator'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generate_colors` returns a generator'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`name_guess` returns a generator'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `name_guess` generator consumes the first two generators. It, in turn, is
    then consumed by the `write_results` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'I wrote a second Tkinter app to check the accuracy of the algorithm. It is
    similar to the first app, except it renders each color and the label associated
    with that color. Then you have to manually click Yes or No if the label matches
    the color. For my example data, I got around 95% accuracy. This could be improved
    by implementing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Adding more color names
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding more training data by manually classifying more colors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tweaking the value of `num_neighbors`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a more advanced machine learning algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here''s the code for the output checking app, though I recommend downloading
    the example code instead. This would be tedious to type in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: You might be wondering, *what does any of this have to do with object-oriented
    programming? There isn't even one class in this code!*. In some ways, you'd be
    right; generators are not commonly considered object-oriented. However, the functions
    that create them return objects; in fact, you could think of those functions as
    constructors. The constructed object has an appropriate `__next__()` method. Basically,
    the generator syntax is a syntax shortcut for a particular kind of object that
    would be quite verbose to create without it.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you don't use comprehensions in your daily coding very often, the first thing
    you should do is search through some existing code and find some `for` loops.
    See whether any of them can be trivially converted to a generator expression or
    a list, set, or dictionary comprehension.
  prefs: []
  type: TYPE_NORMAL
- en: Test the claim that list comprehensions are faster than `for` loops. This can
    be done with the built-in `timeit` module. Use the help documentation for the
    `timeit.timeit` function to find out how to use it. Basically, write two functions
    that do the same thing, one using a list comprehension, and one using a `for`
    loop to iterate over several thousand items. Pass each function into `timeit.timeit`,
    and compare the results. If you're feeling adventurous, compare generators and
    generator expressions as well. Testing code using `timeit` can become addictive,
    so bear in mind that code does not need to be hyperfast unless it's being executed
    an immense number of times, such as on a huge input list or file.
  prefs: []
  type: TYPE_NORMAL
- en: Play around with generator functions. Start with basic iterators that require
    multiple values (mathematical sequences are canonical examples; the Fibonacci
    sequence is overused if you can't think of anything better). Try some more advanced
    generators that do things such as take multiple input lists and somehow yield
    values that merge them. Generators can also be used on files; can you write a
    simple generator that shows lines that are identical in two files?
  prefs: []
  type: TYPE_NORMAL
- en: Coroutines abuse the iterator protocol but don't actually fulfill the iterator
    pattern. Can you build a non-coroutine version of the code that gets a serial
    number from a log file? Take an object-oriented approach so that you can store
    an additional state on a class. You'll learn a lot about coroutines if you can
    create an object that is a drop-in replacement for the existing coroutine.
  prefs: []
  type: TYPE_NORMAL
- en: The case study for this chapter has a lot of odd tuples of tuples being passed
    around that are hard to keep track of. See whether you can replace those return
    values with more object-oriented solutions. Also, experiment with moving some
    of the functions that share data (for example, `model_colors` and `target_colors`)
    into a class. That should reduce the number of arguments that have to be passed
    into most of the generators since they can look them up on `self`.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned that design patterns are useful abstractions that
    provide best-practice solutions for common programming problems. We covered our
    first design pattern, the iterator, as well as numerous ways that Python uses
    and abuses this pattern for its own nefarious purposes. The original iterator
    pattern is extremely object-oriented, but it is also rather ugly and verbose to
    code around. However, Python's built-in syntax abstracts the ugliness away, leaving
    us with a clean interface to these object-oriented constructs.
  prefs: []
  type: TYPE_NORMAL
- en: Comprehensions and generator expressions can combine container construction
    with iteration in a single line. Generator objects can be constructed using the
    `yield` syntax. Coroutines look like generators on the outside but serve a much
    different purpose.
  prefs: []
  type: TYPE_NORMAL
- en: We'll cover several more design patterns in the next two chapters.
  prefs: []
  type: TYPE_NORMAL

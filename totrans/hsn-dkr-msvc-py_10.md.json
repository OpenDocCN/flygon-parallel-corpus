["```\n$ aws configure\nAWS Access Key ID [None]: <your Access Key>\nAWS Secret Access Key [None]: <your Secret Key>\nDefault region name [us-west-2]: <EKS region>\nDefault output format [None]:\n```", "```\n$ aws sts get-caller-identity\n{\n \"UserId\": \"<Access Key>\",\n \"Account\": \"<account ID>\",\n \"Arn\": \"arn:aws:iam::XXXXXXXXXXXX:user/jaime\"\n}\n```", "```\n$ aws ecr get-login --no-include-email\n<command>\n$ docker login -u AWS -p <token>\nLogin Succeeded\n```", "```\n$ docker tag thoughts_frontend 033870383707.dkr.ecr.us-west-2.amazonaws.com/frontend\n$ docker push 033870383707.dkr.ecr.us-west-2.amazonaws.com/frontend\nThe push refers to repository [033870383707.dkr.ecr.us-west-2.amazonaws.com/frontend]\n...\nlatest: digest: sha256:21d5f25d59c235fe09633ba764a0a40c87bb2d8d47c7c095d254e20f7b437026 size: 2404\n```", "```\n$ eksctl get clusters\nNo clusters found\n```", "```\n$ eksctl create cluster -n Example\n[i] using region us-west-2\n[i] setting availability zones to [us-west-2d us-west-2b us-west-2c]\n...\n[\u2714]  EKS cluster \"Example\" in \"us-west-2\" region is ready\n\n```", "```\n$ kubectl get nodes\nNAME                    STATUS ROLES AGE VERSION\nip-X.us-west-2.internal Ready <none> 11m v1.13.7-eks-c57ff8\nip-Y.us-west-2.internal Ready <none> 11m v1.13.7-eks-c57ff8\n```", "```\n$ eksctl get nodegroups --cluster Example\nCLUSTER NODEGROUP CREATED MIN SIZE MAX SIZE DESIRED CAPACITY INSTANCE TYPE IMAGE ID\nExample ng-fa5e0fc5 2019-07-16T13:39:07Z 2 2 0 m5.large ami-03a55127c613349a7\n$ eksctl scale nodegroup --cluster Example --name ng-fa5e0fc5 -N 1\n[i] scaling nodegroup stack \"eksctl-Example-nodegroup-ng-fa5e0fc5\" in cluster eksctl-Example-cluster\n[i] scaling nodegroup, desired capacity from to 1, min size from 2 to 1\n```", "```\n$ kubectl get svc\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\nkubernetes ClusterIP 10.100.0.1 <none> 443/TCP 7m31s\n```", "```\ncontainers:\n- name: frontend-service\n  image: XXX.dkr.ecr.us-west-2.amazonaws.com/frontend:latest\n  imagePullPolicy: Always\n```", "```\n$ kubectl create namespace example\nnamespace/example created\n$ kubectl apply -f frontend/deployment.yaml\ndeployment.apps/frontend created\n```", "```\n$ kubectl get pods -n example\nNAME                      READY STATUS  RESTARTS AGE\nfrontend-58898587d9-4hj8q 1/1   Running 0        13s\n```", "```\napiVersion: v1\nkind: Service\nmetadata:\n    namespace: example\n    labels:\n        app: frontend-service\n    name: frontend-service\nspec:\n    ports:\n        - name: frontend\n          port: 80\n          targetPort: 8000\n    selector:\n        app: frontend\n    type: LoadBalancer\n```", "```\n$ kubectl apply --recursive -f .\ndeployment.apps/frontend unchanged\ningress.extensions/frontend created\nservice/frontend-service created\ndeployment.apps/thoughts-backend created\ningress.extensions/thoughts-backend-ingress created\nservice/thoughts-service created\ndeployment.apps/users-backend created\ningress.extensions/users-backend-ingress created\nservice/users-service created\n```", "```\n$ kubectl get pods -n example\nNAME                              READY STATUS  RESTARTS AGE\nfrontend-58898587d9-dqc97         1/1   Running 0        3m\nthoughts-backend-79f5594448-6vpf4 2/2   Running 0        3m\nusers-backend-794ff46b8-s424k     2/2   Running 0        3m\n```", "```\n$ kubectl get svc -n example\nNAME             TYPE         CLUSTER-IP EXTERNAL-IP AGE\nfrontend-service LoadBalancer 10.100.152.177 a28320efca9e011e9969b0ae3722320e-357987887.us-west-2.elb.amazonaws.com 3m\nthoughts-service NodePort 10.100.52.188 <none> 3m\nusers-service    NodePort 10.100.174.60 <none> 3m\n```", "```\nfrontend haproxynode\n    bind *:80\n    mode http\n    default_backend backendnodes\n\nbackend backendnodes\n    balance roundrobin\n    option forwardfor\n    server aws a28320efca9e011e9969b0ae3722320e-357987887\n               .us-west-2.elb.amazonaws.com:80 check\n    server example www.example.com:80 check\n\nlisten stats\n    bind *:8001\n    stats enable\n    stats uri /\n    stats admin if TRUE\n```", "```\n$ docker-compose up --build proxy\n...\n```", "```\noption httpchk HEAD / HTTP/1.1\\r\\nHost:\\ example.com\n```", "```\nspec:\n  containers:\n  - name: frontend-service\n    livenessProbe:\n      exec:\n        command:\n        - curl\n        - http://localhost:8000/\n        initialDelaySeconds: 5\n        periodSeconds: 30\n```", "```\nspec:\n  containers:\n  - name: frontend-service\n    readinessProbe:\n      exec:\n        command:\n        - curl\n        - http://localhost:8000/\n        initialDelaySeconds: 5\n        periodSeconds: 10\n```", "```\nspec:\n    replicas: 4\n    strategy:\n      type: RollingUpdate\n      rollingUpdate:\n        maxUnavailable: 25%\n        maxSurge: 1\n```", "```\n$ tar -xzf metrics-server-0.3.3.tar.gz\n$ cd metrics-server-0.3.3/deploy/1.8+/\n$ kubectl apply -f .\nclusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created\nclusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created\nrolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created\napiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created\nserviceaccount/metrics-server created\ndeployment.extensions/metrics-server created\nservice/metrics-server created\nclusterrole.rbac.authorization.k8s.io/system:metrics-server created\nclusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created\n```", "```\n$ kubectl get pods -n kube-system\nNAME                            READY STATUS  RESTARTS AGE\n...\nmetrics-server-56ff868bbf-cchzp 1/1   Running 0        42s\n```", "```\n$ kubectl top node\nNAME                    CPU(cores) CPU% MEM(bytes) MEMORY%\nip-X.us-west-2.internal 57m        2%   547Mi      7%\nip-Y.us-west-2.internal 44m        2%   534Mi      7%\n$ kubectl top pods -n example\n$ kubectl top pods -n example\nNAME                              CPU(cores) MEMORY(bytes)\nfrontend-5474c7c4ff-d4v77         2m         51Mi\nfrontend-5474c7c4ff-dlq6t         1m         50Mi\nfrontend-5474c7c4ff-km2sj         1m         51Mi\nfrontend-5474c7c4ff-rlvcc         2m         51Mi\nthoughts-backend-79f5594448-cvdvm 1m         54Mi\nusers-backend-794ff46b8-m2c6w     1m         54Mi\n```", "```\nspec:\n    containers:\n    - name: frontend-service\n      image: 033870383707.dkr.ecr.us-west-2\n                 .amazonaws.com/frontend:latest\n      imagePullPolicy: Always\n      ...\n      resources:\n          requests:\n              memory: \"64M\"\n              cpu: \"60m\"\n          limits:\n              memory: \"128M\"\n              cpu: \"70m\"\n```", "```\n$ kubectl autoscale deployment frontend --cpu-percent=10 --min=2 --max=8 -n example\nhorizontalpodautoscaler.autoscaling/frontend autoscaled\n```", "```\n$ kubectl get hpa -n example\nNAME     REFERENCE           TARGETS  MIN MAX REPLICAS AGE\nfrontend Deployment/frontend 2%/10%   2   8   4        80s\n```", "```\n$ ab -n 100 http://<LOADBALANCER>.elb.amazonaws.com/load\nBenchmarking <LOADBALANCER>.elb.amazonaws.com (be patient)....\n```", "```\nNAME     REFERENCE           TARGETS MIN MAX REPLICAS AGE\nfrontend Deployment/frontend 47%/10% 2   8   8        15m\n```", "```\n$ eksctl get nodegroup --cluster Example\nCLUSTER NODEGROUP   MIN  MAX  DESIRED INSTANCE IMAGE ID\nExample ng-74a0ead4 2    2    2       m5.large ami-X\n```", "```\n$ eksctl scale nodegroup --cluster Example --name ng-74a0ead4 --nodes 4\n[i] scaling nodegroup stack \"eksctl-Example-nodegroup-ng-74a0ead4\" in cluster eksctl-Example-cluster\n[i] scaling nodegroup, desired capacity from to 4, max size from 2 to 4\n```"]
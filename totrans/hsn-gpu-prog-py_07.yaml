- en: Using the CUDA Libraries with Scikit-CUDA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will be taking a tour of three of the standard CUDA libraries
    intended for streamlined numerical and scientific computation. The first that
    we will look at is **cuBLAS**, which is NVIDIA's implementation of the **Basic
    Linear Algebra Subprograms** (**BLAS**) specification for CUDA. (cuBLAS is NVIDIA's
    answer to various optimized, CPU-based implementations of BLAS, such as the free/open
    source OpenBLAS or Intel's proprietary Math Kernel Library.) The next library
    that we will look at is **cuFFT**, which can perform virtually every variation
    of the **fast Fourier transform** (**FFT**) on the GPU. We'll look at how we can
    use cuFFT for filtering in image processing in particular. We will then look at **cuSolver**,
    which can perform more involved linear algebra operations than those featured
    in cuBLAS, such as **singular value decomposition** (**SVD**) or Cholesky factorization.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have been primarily dealing with one single Python module that acted
    as our gateway to CUDA—PyCUDA. While PyCUDA is a very powerful and versatile Python
    library, its main purpose is to provide a gateway to program, compile, and launch
    CUDA kernels, rather than provide an interface to the CUDA libraries. To this
    end, fortunately, there is a free Python module available that provides a user-friendly
    wrapper interface to these libraries. This is called Scikit-CUDA.
  prefs: []
  type: TYPE_NORMAL
- en: While you don't have to know PyCUDA or even understand GPU programming to appreciate
    Scikit-CUDA, it is conveniently compatible with PyCUDA; Scikit-CUDA, for instance,
    can operate easily with PyCUDA's `gpuarray` class, and this allows you to easily
    pass data between our own CUDA kernel routines and Scikit-CUDA. Additionally,
    most routines will also work with PyCUDA's stream class, which will allow us to
    properly synchronize our own custom CUDA kernels with Scikit-CUDA's wrappers.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that, besides these three listed libraries, Scikit-CUDA also provides
    wrappers for the proprietary CULA library, as well as for the open source MAGMA
    library. Both have a lot of overlap with the functionality provided by the official
    NVIDIA libraries. Since these libraries are not installed by default with a standard
    CUDA installation, we will opt to not cover them in this chapter. Interested readers
    can learn more about CULA and MAGMA at [http://www.culatools.com](http://www.culatools.com) and [http://icl.utk.edu/magma/](http://icl.utk.edu/magma/),
    respectively. It is suggested that readers take a look at the official documentation
    for Scikit-CUDA, which is available here: [https://media.readthedocs.org/pdf/scikit-cuda/latest/scikit-cuda.pdf](https://media.readthedocs.org/pdf/scikit-cuda/latest/scikit-cuda.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: 'The learning outcomes for this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: To learn how to install Scikit-CUDA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To understand the basic purposes and differences between the standard CUDA libraries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To learn how to use low-level cuBLAS functions for basic linear algebra
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To learn how to use the SGEMM and DGEMM operations to measure the performance
    of a GPU in FLOPS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To learn how to use cuFFT to perform 1D or 2D FFT operations on the GPU
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To learn how to create a 2D convolutional filter using the FFT, and apply it
    to simple image processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To understand how to perform a Singular Value Decomposition (SVD) with cuSolver
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To learn how to use cuSolver's SVD algorithm to perform basic principal component
    analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Linux or Windows 10 PC with a modern NVIDIA GPU (2016—onward) is required
    for this chapter, with all of the necessary GPU drivers and the CUDA Toolkit (9.0–onward)
    installed. A suitable Python 2.7 installation (such as Anaconda Python 2.7) that
    includes the PyCUDA module is also required.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter's code is also available on GitHub, and can be found at [https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA](https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA).
  prefs: []
  type: TYPE_NORMAL
- en: For more information about the prerequisites, check out the preface of this
    book. For more information about the software and hardware requirements, check
    out the README file at [https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA](https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA).
  prefs: []
  type: TYPE_NORMAL
- en: Installing Scikit-CUDA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is suggested that you install the latest stable version of Scikit-CUDA directly
    from GitHub: [https://github.com/lebedov/scikit-cuda](https://github.com/lebedov/scikit-cuda).
  prefs: []
  type: TYPE_NORMAL
- en: Unzip the package into a directory, and then open up the command line here and
    install the module by typing `python setup.py install` into the command line.
    You may then run the unit tests to ensure that a correct installation has been
    performed with `python setup.py test`. (This method is suggested for both Windows
    and Linux users.) Alternatively, Scikit-CUDA can be installed directly from the
    PyPI repository with `pip install scikit-cuda`.
  prefs: []
  type: TYPE_NORMAL
- en: Basic linear algebra with cuBLAS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will start this chapter by learning how to use Scikit-CUDA's cuBLAS wrappers.
    Let's spend a moment discussing BLAS. BLAS (Basic Linear Algebra Subroutines)
    is a specification for a basic linear algebra library that was first standardized
    in the 1970s. BLAS functions are broken down into several categories, which are
    referred to as *levels*.
  prefs: []
  type: TYPE_NORMAL
- en: Level 1 BLAS functions consist of operations purely on vectors—vector-vector
    addition and scaling (also known as *ax+y* operations, or AXPY), dot products,
    and norms. Level 2 BLAS functions consist of general matrix-vector operations
    (GEMV), such as matrix multiplication of a vector, while level 3 BLAS functions
    consist of "general matrix-matrix" (GEMM) operations, such as matrix-matrix multiplication. Originally,
    these libraries were written entirely in FORTRAN in the 1970s, so you should take
    into account that there are some seemingly archaic holdovers in usage and naming
    that may seem cumbersome to new users today.
  prefs: []
  type: TYPE_NORMAL
- en: cuBLAS is NVIDIA's own implementation of the BLAS specification, which is of
    course optimized to make full use of the GPU's parallelism. Scikit-CUDA provides
    wrappers for cuBLAS that are compatible with PyCUDA `gpuarray` objects, as well
    as with PyCUDA streams. This means that we can couple and interface these functions
    with our own custom CUDA-C kernels by way of PyCUDA, as well as synchronize these
    operations over multiple streams.
  prefs: []
  type: TYPE_NORMAL
- en: Level-1 AXPY with cuBLAS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's start with a basic level-1 *ax + y* (or AXPY) operation with cuBLAS. Let's
    stop for a moment and review a bit of linear algebra and think about what this
    means. Here, *a* is considered to be a scalar; that is, a real number, such as
    -10, 0, 1.345, or 100. *x* and *y* are considered to be vectors in some vector
    space, ![](assets/47a6873c-3e1b-4b3c-95e8-d1a3a4f796eb.png). This means that *x*
    and *y* are n-tuples of real numbers, so in the case of ![](assets/d0e81dc7-0fa8-4bce-a264-941fee2e3ad7.png),
    these could be values such as `[1,2,3]` or `[-0.345, 8.15, -15.867]`. *ax* means
    the scaling of *x* by *a*, so if a is 10 and *x* is the first prior value, then
    *ax* is each individual value of *x* multiplied by *a;* that is, `[10, 20, 30]`.
    Finally, the sum *ax + y* means that we add each individual value in each slot
    of both vectors to produce a new vector, which would be as follows (assuming that *y*
    is the second vector given)—`[9.655, 28.15, 14.133]`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s do this in cuBLAS now. First, let''s import the appropriate modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s import cuBLAS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now set up our vector arrays and copy them to the GPU. Note that we
    are using 32-bit (single precision) floating point numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have to create a **cuBLAS context**. This is similar in nature to CUDA
    contexts, which we discussed in [Chapter 5](ea648e20-8c72-44a9-880d-11469d0e291f.xhtml),
    *Streams, Events, Contexts, and Concurrency*, only this time it is used explicitly
    for managing cuBLAS sessions. The `cublasCreate` function creates a cuBLAS context
    and gives a handle to it as its output. We will need to hold onto this handle
    for as long as we intend to use cuBLAS in this session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now use the `cublasSaxpy` function. The `S` stands for single precision,
    which is what we will need since we are working with 32-bit floating point arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Let's discuss what we just did. Also, let's keep in mind that this is a direct
    wrapper to a low-level C function, so the input may seem more like a C function
    than a true Python function. In short, this performed an "AXPY" operation, ultimately
    putting the output data into the `y_gpu` array. Let's go through each input parameter
    one by one.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first input is always the CUDA context handle. We then have to specify
    the size of the vectors, since this function will be ultimately operating on C
    pointers; we can do this by using the `size` parameter of a gpuarray. Having typecasted
    our scalar already to a NumPy `float32` variable, we can pass the `a` variable
    right over as the scalar parameter. We then hand the underlying C pointer of the
    `x_gpu` array to this function using the `gpudata` parameter. Then we specify
    the **stride** of the first array as 1: the stride specifies how many steps we
    should take between each input value. (In contrast, if you were using a vector
    from a column in a row-wise matrix, you would set the stride to the width of the
    matrix.) We then put in the pointer to the `y_gpu` array, and set its stride to
    1 as well.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We are done with our computation; now we have to explicitly destroy our cuBLAS
    context:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now verify whether this is close with NumPy''s `allclose` function,
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Again, notice that the final output was put into the `y_gpu` array, which was
    also an input.
  prefs: []
  type: TYPE_NORMAL
- en: Always remember that BLAS and CuBLAS functions act in-place to save time and
    memory from a new allocation call. This means that an input array will also be
    used as an output!
  prefs: []
  type: TYPE_NORMAL
- en: We just saw how to perform an `AXPY` operation using the `cublasSaxpy` function.
  prefs: []
  type: TYPE_NORMAL
- en: Let's discuss the prominent upper case S. Like we mentioned previously, this
    stands for single precision that is, 32-bit real floating point values (`float32`).
    If we want to operate on arrays of 64-bit real floating point values, (`float64`
    in NumPy and PyCUDA), then we would use the `cublasDaxpy` function; for 64-bit
    single precision complex values (`complex64`), we would use `cublasCaxpy`, while
    for 128-bit double precision complex values (`complex128`), we would use `cublasZaxpy`.
  prefs: []
  type: TYPE_NORMAL
- en: We can tell what type of data a BLAS or CuBLAS function operates on by checking
    the letter preceding the rest of the function name. Functions that use single
    precision reals are always preceded with S, double precision reals with D, single
    precision complex with C, and double precision complex with Z.
  prefs: []
  type: TYPE_NORMAL
- en: Other level-1 cuBLAS functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s look at a few other level-1 functions. We won''t go over their operation
    in depth, but the steps are similar to the ones we just covered: create a cuBLAS
    context, call the function with the appropriate array pointers (which is accessed
    with the `gpudata` parameter from a PyCUDA `gpuarray`), and set the strides accordingly.
    Another thing to keep in mind is that if the output of a function is a single
    value as opposed to an array (for example, a dot product function), the function
    will directly output this value to the host rather than within an array of memory
    that has to be pulled off the GPU. (We will only cover the single precision real
    versions here, but the corresponding versions for other datatypes can be used
    by replacing the S with the appropriate letter.)'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can perform a dot product between two single precision real `gpuarray`s,
    `v_gpu`, and `w_gpu`. Again, the 1s are there to ensure that we are using stride-1
    in this calculation! Again, recall that a dot product is the sum of the point-wise
    multiple of two vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also perform the L2-norm of a vector like so (recall that for a vector, *x*, this
    is its L2-norm, or length, which is calculated with the ![](assets/839337d6-db29-481e-8467-bcd415a2ad7c.png) formula):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Level-2 GEMV in cuBLAS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s look at how to do a `GEMV` matrix-vector multiplication. This is defined
    as the following operation for an *m* x *n* matrix *A*, an n-dimensional vector
    *x*, a *m*-dimensional vector *y*, and for the scalars *alpha* and *beta*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/0b6277ff-e027-45fe-ad2e-d312ea1a38f5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now let''s look at how the function is laid out before we continue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s go through these inputs one-by-one:'
  prefs: []
  type: TYPE_NORMAL
- en: '`handle` refers to the cuBLAS context handle.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trans` refers to the structure of the matrix—we can specify whether we want
    to use the original matrix, a direct transpose, or a conjugate transpose (for
    complex matrices). This is important to keep in mind because this function will
    expect that the matrix `A` is stored in **column-major** format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`m` and `n` are the number of rows and columns of the matrix `A` that we want
    to use.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`alpha` is the floating-point value for *α.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`A` is the *m x n* matrix *A.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lda` indicates the leading dimension of the matrix, where the total size of
    the matrix is actually `lda` x `n`. This is important in the column-major format
    because if `lda` is larger than `m`, this can cause problems for cuBLAS when it
    tries to access the values of `A` since its underlying structure of this matrix
    is a one-dimensional array.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We then have `x` and its stride, `incx`; `x` is the underlying C pointer of
    the vector being multiplied by `A`. Remember, `x` will have to be of size `n`; that
    is, the number of columns of `A`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`beta`, which is the floating-point value for *β*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we have `y` and its stride `incy` as the last parameters. We should
    remember that `y` should be of size `m`, or the number of rows of `A`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s test this by generating a 10 x 100 matrix of random values `A`, and
    a vector `x` of 100 random values. We''ll initialize `y` as a matrix of 10 zeros.
    We will set alpha to 1 and beta to 0, just to get a direct matrix multiplication
    with no scaling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now have to get `A` into **column-major** (or column-wise) format.
    NumPy stores matrices as **row-major** (or row-wise) by default, meaning that
    the underlying one-dimensional array that is used to store a matrix iterates through
    all of the values of the first row, then all of the values of the second row,
    and so on. You should remember that a transpose operation swaps the columns of
    a matrix with its rows. However, the result will be that the new one-dimensional
    array underlying the transposed matrix will represent the original matrix in a
    column-major format. We can make a copy of the transposed matrix of `A` with `A.T.copy()` like
    so, and copy this as well as `x` and `y` to the GPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we now have the column-wise matrix stored properly on the GPU, we can
    set the `trans` variable to not take the transpose by using the `_CUBLAS_OP` dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the size of the matrix is exactly the same as the number of rows that
    we want to use, we now set `lda` as `m`. The strides for the *x* and *y* vectors
    are, again, 1\. We now have all of the values we need set up, and can now create
    our CuBLAS context and store its handle, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now launch our function. Remember that `A`, `x`, and `y` are actually
    PyCUDA `gpuarray` objects, so we have to use the `gpudata` parameter to input
    into this function. Other than doing this, this is pretty straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now destroy our cuBLAS context and check the return value to ensure
    that it is correct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Level-3 GEMM in cuBLAS for measuring GPU performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will now look at how to perform a **general matrix-matrix multiplication**
    (**GEMM**) with CuBLAS. We will actually try to make something a little more utilitarian
    than the last few examples we saw in cuBLAS—we will use this as a performance
    metric for our GPU to determine the number of **Floating Point Operations Per
    Second** (**FLOPS**) it can perform, which will be two separate values: the case
    of single precision, and that of double precision. Using GEMM is a standard technique
    for evaluating the performance of computing hardware in FLOPS, as it gives a much
    better understanding of sheer computational power than using pure clock speed
    in MHz or GHz.'
  prefs: []
  type: TYPE_NORMAL
- en: If you need a brief review, recall that we covered matrix-matrix multiplication
    in depth in the last chapter. If you forgot how this works, it's strongly suggested
    that you review this chapter before you move on to this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s see how a GEMM operation is defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/6732ed55-6eea-497a-adcb-95731cc211b9.png)'
  prefs: []
  type: TYPE_IMG
- en: This means that we perform a matrix multiplication of *A* and *B*, scale the
    result by *alpha*, and then add this to the *C* matrix that we have scaled by
    *beta, *placing the final result in *C*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s think about how many floating point operations are executed to get the
    final result of a real-valued GEMM operation, assuming that *A* is an *m* x *k*
    (where *m* is rows and* k* is columns)matrix, *B* is a *k* x *n* matrix, and C
    is an *m* x *n* matrix. First, let''s figure out how many operations are required
    for computing *AB*. Let''s take a single column of *A* and multiply it by *B*:
    this will amount to *k* multiplies and *k - 1* adds for each of the *m* rows in
    *A*, which means that this is *km + (k-1)m* total operations over *m* rows. There
    are *n* columns in *B*, so computing *AB* will total to *kmn + (k-1)mn = 2kmn
    - mn* operations. Now, we use *alpha* to scale *AB*, which will be *m**n* operations,
    since that is the size of the matrix *AB*; similarly, scaling *C* by *beta* is
    another *m**n* operation. Finally, we add these two resulting matrices, which
    is yet another *mn* operation. This means that we will have a total of *2kmn -
    mn + 3mn = 2kmn + 2mn = 2mn(k+1)* floating point operations in a given GEMM operation.'
  prefs: []
  type: TYPE_NORMAL
- en: Now the only thing we have to do is run a timed GEMM operation, taking note
    of the different sizes of the matrices, and divide *2kmn + 2mn* by the total time
    duration to calculate the FLOPS of our GPU. The resulting number will be very
    large, so we will represent this in terms of GFLOPS – that is, how many billions
    (10⁹) of operations that can be computed per second. We can compute this by multiplying
    the FLOPS value by 10^(-9).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we are ready to start coding this up. Let''s start with our import statements,
    as well as the `time` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we will set the `m`, `n`, and `k` variables for our matrix sizes. We want
    our matrices to be relatively big so that the time duration is sufficiently large
    so as to avoid divide by 0 errors. The following values should be sufficient for
    any GPU released up to mid-2018 or earlier; users with newer cards may consider
    increasing these values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now write a function that computes the GFLOPS for both single and double
    precision. We will set the input value to `''D''` if we wish to use double precision,
    or `''S''` otherwise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Now let's generate some random matrices that are of the appropriate precision
    that we will use for timing. The GEMM operations act similarly to the GEMV operation
    we saw before, so we will have to transpose these before we copy them to the GPU.
    (Since we are just doing timing, this step isn't necessary, but it's good practice
    to remember this.)
  prefs: []
  type: TYPE_NORMAL
- en: 'We will set up some other necessary variables for GEMM, whose purpose should
    be self-explanatory at this point (`transa`, `lda`, `ldb`, and so on):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now start the timer! First, we will create a cuBLAS context:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now launch GEMM. Keep in mind that there are two versions for the real
    case: `cublasSgemm` for single precision and `cublasDgemm` for double precision.
    We can execute the appropriate function using a little Python trick: we will write
    a string with `cublas%sgemm` with the appropriate parameters, and then replace
    the `%s` with D or S by appending `% precision` to the string. We will then execute
    this string as Python code with the `exec` function, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now destroy the cuBLAS context and get the final time for our computation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we need to compute the GFLOPS using the equation we derived and return
    it as the output of this function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can set up our main function. We will output the GFLOPS in both the
    single and double precision cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s do a little homework before we run this program—go to [https://www.techpowerup.com](https://www.techpowerup.com)
    and search for your GPU, and then take note of two things—the single precision
    floating point performance and the double precision floating point performance.
    I am using a GTX 1050 right now, and it''s listing claims that it has 1,862 GFLOPS
    performance in single precision, and 58.20 GFLOPS performance in double precision.
    Let''s run this program right now and see if this aligns with the truth:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/0d014970-b902-4cd8-804a-433bf0b83d77.png)'
  prefs: []
  type: TYPE_IMG
- en: Lo and behold, it does!
  prefs: []
  type: TYPE_NORMAL
- en: This program is also available as the `cublas_gemm_flops.py` file under the
    directory in this book's repository.
  prefs: []
  type: TYPE_NORMAL
- en: Fast Fourier transforms with cuFFT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now let''s look at how we can do some basic **fast Fourier transforms** (**FFT**)
    with cuFFT.  First, let''s briefly review what exactly a Fourier transform is.
    If you have taken an advanced Calculus or Analysis class, you might have seen
    the Fourier transform defined as an integral formula, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/d1c79c32-6eab-4a52-a2ef-4af0bc192f5c.png)'
  prefs: []
  type: TYPE_IMG
- en: What this does is take *f* as a time domain function over *x*. This gives us
    a corresponding frequency domain function over "ξ".  This turns out to be an incredibly
    useful tool that touches virtually all branches of science and engineering.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s remember that the integral can be thought of as a sum; likewise, there
    is a corresponding discrete, finite version of the Fourier Transform called the
    **discrete Fourier transform** (**DFT**). This operates on vectors of a finite
    length and allows them to be analyzed or modified in the frequency domain. The
    DFT of an *n*-dimensional vector *x* is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/8b60bac2-8488-4c5f-9d90-3ac7eb73bd62.png)'
  prefs: []
  type: TYPE_IMG
- en: In other words, we can multiply a vector, *x*, by the complex *N* x *N* matrix ![](assets/96b3a1fb-9202-44fa-8b1d-381398412504.png)
  prefs: []
  type: TYPE_NORMAL
- en: '(here, *k* corresponds to row number, while *n* corresponds to column number)
    to find its DFT. We should also note the inverse formula that lets us retrieve *x*
    from its DFT (replace *y* with the DFT of *x* here, and the output will be the
    original *x*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/25229fe6-66c3-4ca5-b8d7-96ba5e639917.png)'
  prefs: []
  type: TYPE_IMG
- en: Normally, computing a matrix-vector operation is of computational complexity
    O(*N²*) for a vector of length *N*. However, due to symmetries in the DFT matrix,
    this can always be reduced to O(*N log N*) by using an FFT. Let's look at how
    we can use an FFT with CuBLAS, and then we will move on to a more interesting
    example.
  prefs: []
  type: TYPE_NORMAL
- en: A simple 1D FFT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's start by looking at how we can use cuBLAS to compute a simple 1D FFT.
    First, we will briefly discuss the cuFFT interface in Scikit-CUDA.
  prefs: []
  type: TYPE_NORMAL
- en: There are two submodules here that we can access the cuFFT library with, `cufft`
    and `fft`. `cufft` consists of a collection of low-level wrappers for the cuFFT
    library, while `fft` provides a more user-friendly interface; we will be working
    solely with `fft` in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with the appropriate imports, remembering to include the Scikit-CUDA
    `fft` submodule:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We now will set up some random array and copy it to the GPU. We will also set
    up an empty GPU array that will be used to store the FFT (notice that we are using
    a real float32 array as an input, but the output will be a complex64 array, since
    the Fourier transform is always complex-valued):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now set up a cuFFT plan for the forward FFT transform. This is an object
    that cuFFT uses to determine the shape, as well as the input and output data types
    of the transform:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'We will also set up a plan for the inverse FFT plan object. Notice that this
    time we go from `complex64` to real `float32`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we must take the forward FFT from `x_gpu` into `x_hat`, and the inverse
    FFT from `x_hat` back into `x_gpu`. Notice that we set `scale=True` in the inverse
    FFT; we do this to indicate to cuFFT to scale the inverse FFT by 1/N:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'We now will check `x_hat` against a NumPy FFT of `x`, and `x_gpu` against `x`
    itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: If you run this, you will see that `x_hat` does not match `y`, yet, inexplicably,
    `x_gpu` matches `x`. How is this possible? Well, let's remember that `x` is real;
    if you look at how the Discrete Fourier Transform is computed, you can prove mathematically
    that the outputs of a real vector will repeat as their complex conjugates after
    N/2\. While the NumPy FFT fully computes these values anyway, cuFFT saves time
    by only computing the first half of the outputs when it sees that the input is
    real, and it sets the remaining outputs to `0`. You should verify that this is
    the case by checking the preceding variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, if we change the first print statement in the preceding code to only
    compare the first N/2 outputs between CuFFT and NumPy, then this will return true:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Using an FFT for convolution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will now look at how we can use an FFT to perform **convolution**. Let''s
    review what exactly convolution is, first: given two one-dimensional vectors,
    *x* and *y*, their convolution is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/34574397-830b-446f-8e5f-34b468e76b3e.png)'
  prefs: []
  type: TYPE_IMG
- en: This is of interest to us because if *x* is some long, continuous signal, and
    *y* only has a small amount of localized non-zero values, then *y* will act as
    a filter on *x*; this has many applications in itself. First, we can use a filter
    to smooth the signal *x* (as is common in digital signal processing and image
    processing). We can also use it to collect samples of the signal *x* so as to
    represent the signal or compress it (as is common in the field of data compression
    or compressive sensing), or use filters to collect features for signal or image
    recognition in machine learning. This idea forms the basis for convolutional neural
    networks).
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, computers cannot handle infinitely long vectors (at least, not yet),
    so we will be considering **circular convolution**. In circular convolution, we
    are dealing with two length *n*-vectors whose indices below 0 or above n-1 will
    wrap around to the other end; that is to say, *x*[-1] = *x*[n-1], *x*[-2] = *x*[n-2],
    *x*[n] = *x*[0], *x*[n+1] = *x*[1], and so on. We define circular convolution
    of *x* and *y* like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/69ee6cc9-5c17-40f2-a4f5-675f5a0a9ee2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It turns out that we can perform a circular convolution using an FFT quite
    easily; we can do this by performing an FFT on *x* and *y*, point-wise-multiplying
    the outputs, and then performing an inverse FFT on the final results. This result
    is known as the **convolution theorem**, which can also be expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/d4a9eaac-c5fb-4ec2-8544-35b8e7388209.png)'
  prefs: []
  type: TYPE_IMG
- en: We will be doing this over two dimensions, since we wish to apply the result
    to signal processing. While we have only seen the math for FFTs and convolution
    along one dimension, two-dimensional convolution and FFTs work very similarly
    to their one-dimensional counterparts, only with some more complex indexing. We
    will opt to skip over this, however, so that we can get directly into the application.
  prefs: []
  type: TYPE_NORMAL
- en: Using cuFFT for 2D convolution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we are going to make a small program that performs **Gaussian filtering**
    on an image using cuFFT-based two-dimensional convolution. Gaussian filtering
    is an operation that smooths a rough image using what is known as a Gaussian filter.
    This is named as such because it is based on the Gaussian (normal) distribution
    in statistics. This is how the Gaussian filter is defined over two dimensions
    with a standard deviation of σ:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/06f381b9-2e9d-48aa-95e7-265b988f144d.png)'
  prefs: []
  type: TYPE_IMG
- en: When we convolve a discrete image with a filter, we sometimes refer to the filter
    as a **convolution kernel**. Oftentimes, image processing engineers will just
    call this a plain kernel, but since we don't want to confuse these with CUDA kernels,
    we will always use the full term, convolution kernel. We will be using a discrete
    version of the Gaussian filter as our convolution kernel here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with the appropriate imports; notice that we will use the Scikit-CUDA
    submodule `linalg` here. This will provide a higher-level interface for us than
    cuBLAS. Since we''re working with images here, we will also import Matplotlib''s
    `pyplot` submodule. Also note that we will use Python 3-style division here, from
    the first line; this means that if we divide two integers with the `/` operator,
    then the return value will be a float without typecasting (we perform integer
    division with the `//` operator):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s jump right in and start writing the convolution function. This will
    take in two NumPy arrays of the same size, `x` and `y`. We will typecast these
    to complex64 arrays, and then return `-1` if they are not of the same size:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now set up our FFT plan and inverse FFT plan objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can copy our arrays to the GPU. We will also set up some empty arrays
    of the appropriate sizes to hold the FFTs of these arrays, plus one additional
    array that will hold the output of the final convolution, `out_gpu`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'We now can perform our FFTs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now perform pointwise (Hadamard) multiplication between `x_fft` and
    `y_fft` with the `linalg.multiply` function. We will set `overwrite=True` so as
    to write the final value into `y_fft`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we will call the inverse FFT, outputting the final result into `out_gpu`.
    We transfer this value to the host and return it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: We are not done yet. Our convolution kernel will be much smaller than our input
    image, so we will have to adjust the sizes of our two 2D arrays (both the convolution
    kernel and the image) so that they are equal and perform the pointwise multiplication
    between them. Not only should we ensure that they are equal, but we also need
    to ensure that we perform **zero padding** on the arrays and that we appropriately
    center the convolution kernel. Zero padding means that we add a buffer of zeros
    on the sides of the images so as to prevent a wrap-around error. If we are using
    an FFT to perform our convolution, remember that it is a circular convolution,
    so the edges will literally always wrap-around. When we are done with our convolution,
    we can remove the buffer from the outside of the image to get the final output
    image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a new function called `conv_2d` that takes in a convolution kernel, `ker`,
    and an image, `img`. The padded image size will be (`2*ker.shape[0] + img.shape[0]`,
    `2*ker.shape[1] + img.shape[1]`). Let''s set up the padded convolution kernel
    first. We will create a 2D array of zeros of this size, and then set the upper-left
    submatrix as our convolution kernel, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now have to shift our convolution kernel so that its center is precisely
    at the coordinate (0,0). We can do this with the NumPy `roll` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we need to pad the input image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we have two arrays of the same size that are appropriately formatted. We
    can now use our `cufft_conv` function that we just wrote here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'We now can remove the zero buffer outside of our image. We then return the
    result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'We are not yet done. Let''s write some small functions to set up our Gaussian
    filter, and then we can move on to applying this to an image. We can write the
    basic filter itself with a single line using a lambda function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now write a function that uses this filter to output a discrete convolution
    kernel. The convolution kernel will be of height and length `2*sigma + 1`, which
    is fairly standard:'
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we normalize the values of our Gaussian kernel by summing its values
    into `total_` and dividing it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: We are now ready to test this on an image! As our test case, we will use Gaussian
    filtering to blur a color JPEG image of this book's editor, *Akshada Iyer*. (This
    image is available under the `Chapter07` directory in the GitHub repository with
    the file name `akshada.jpg`.) We will use Matplotlib's `imread` function to read
    the image; this is stored as an array of unsigned 8-bit integers ranging from
    0 to 255 by default. We will typecast this to an array of floats and normalize
    it so that all of the values will range from 0 to 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note to the readers of the print edition of this text: although the print edition
    of this text is in greyscale, this a color image.We will then set up an empty
    array of zeros that will store the blurred image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s set up our convolution kernel. Here, a standard deviation of 15 should
    be enough:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now blur the image. Since this is a color image, we will have to apply
    Gaussian filtering to each color layer (red, green, and blue) individually; this
    is indexed by the third dimension in the image arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s look at the Before and After images side-by-side by using some Matplotlib
    tricks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now run the program and observe the effects of Gaussian filtering:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ae723dc0-ccbd-4163-9c08-bb7caad3aa74.png)'
  prefs: []
  type: TYPE_IMG
- en: This program is available in the `Chapter07` directory in a file called `conv_2d.py`
    in the repository for this book.
  prefs: []
  type: TYPE_NORMAL
- en: Using cuSolver from Scikit-CUDA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now look at how we can use cuSolver from Scikit-CUDA's `linalg` submodule.
    Again, this provides a high-level interface for both cuBLAS and cuSolver, so we
    don't have to get caught up in the small details.
  prefs: []
  type: TYPE_NORMAL
- en: As we noted in the introduction, cuSolver is a library that's used for performing
    more advanced linear algebra operations than cuBLAS, such as the Singular Value
    Decomposition, LU/QR/Cholesky factorization, and eigenvalue computations. Since
    cuSolver, like cuBLAS and cuFFT, is another vast library, we will only take the
    time to look at one of the most fundamental operations in data science and machine
    learning—SVD.
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to NVIDIA's official documentation on cuSOLVER if you would like
    further information on this library: [https://docs.NVIDIA.com/cuda/cusolver/index.html](https://docs.nvidia.com/cuda/cusolver/index.html).
  prefs: []
  type: TYPE_NORMAL
- en: Singular value decomposition (SVD)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: SVD takes any *m* x *n* matrix *A*, and then returns three matrices in return—*U*, *Σ*,
    and *V*. Here, *U* is an *m* x *m* unitary matrix, *Σ* is an *m* x *n* diagonal
    matrix, and *V* is an *n* x *n* unitary matrix. By *unitary*, we mean that a matrix's
    columns form an orthonormal basis; by *diagonal*, we mean that all values in the
    matrix are zero, except for possibly the values along its diagonal.
  prefs: []
  type: TYPE_NORMAL
- en: The significance of the SVD is that this decomposes *A* into these matrices
    so that we have *A = UΣV^T* ; moreover, the values along the diagonal of *Σ* will
    all be positive or zero, and are known as the singular values. We will see some
    applications of this soon, but you should keep in mind that the computational
    complexity of SVD is of the order O(*mn²*)—for large matrices, it is definitely
    a good idea to use a GPU, since this algorithm is parallelizable.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll now look at how we can compute the SVD of a matrix. Let''s make the
    appropriate import statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now generate a relatively large random matrix and transfer it to the
    GPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now execute the SVD. This will have three outputs corresponding to the
    matrices that we just described. The first parameter will be the matrix array
    we just copied to the GPU. Then we need to specify that we want to use cuSolver
    as our backend for this operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s copy these arrays from the GPU to the host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '`s` is actually stored as a one-dimensional array; we will have to create a
    zero matrix of size 1000 x 5000 and copy these values along the diagonal. We can
    do this with the NumPy `diag` function, coupled with some array slicing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now matrix-multiply these values on the host with the NumPy `dot` function
    to verify that they match up to our original array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: Since we are using only float32s and our matrix is relatively large, a bit of
    numerical error was introduced; we had to set the "tolerance" level (`atol`) a
    little higher than usual here, but it's still small enough to verify that the
    two arrays are sufficiently close.
  prefs: []
  type: TYPE_NORMAL
- en: Using SVD for Principal Component Analysis (PCA)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Principal Component Analysis** (**PCA**) is a tool that''s used primarily
    for dimensionality reduction. We can use this to look at a dataset and find which
    dimensions and linear subspaces are the most salient. While there are several
    ways to implement this, we will show you how to perform PCA using SVD.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll do this as follows—we will work with a dataset that exists in 10 dimensions.
    We will start by creating two vectors that are heavily weighted in the front,
    and 0 otherwise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'We will then add 9,000 additional vectors: 6,000 of these will be the same
    as the first two vectors, only with a little added random white noise, and the
    remaining 3,000 will just be random white noise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now typecast the `vals` list to a `float32` NumPy array. We take the
    mean over the rows and subtract this value from each row. (This is a necessary
    step for PCA.) We then transpose this matrix, since cuSolver requires that input
    matrices have fewer or equal rows compared to the columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now run cuSolver, just like we did previously, and copy the output
    values off of the GPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we are ready to begin our investigative work. Let''s open up IPython and
    take a closer look at `u` and `s`. First, let''s look at s; its values are actually
    the square roots of the **principal values**, so we will square them and then
    take a look:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/28321a31-a6fb-49e8-974f-1b2caecfe01b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You will notice that the first two principal values are of the order 10⁵, while
    the remaining components are of the order 10^(-3). This tells us there is only
    really a two-dimensional subspace that is even relevant to this data at all, which
    shouldn''t be surprising. These are the first and second values, which will correspond
    to the first and second principal components that is, the corresponding vectors.
    Let''s take a look at these vectors, which will be stored in `U`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/9d685877-5a4c-4449-8da4-68b1b21d1e66.png)'
  prefs: []
  type: TYPE_IMG
- en: You will notice that these two vectors are very heavily weighted in the first
    two entries, which are of the order 10^(-1); the remaining entries are all of
    the order 10^(-6) or lower, and are comparably irrelevant. This is what we should
    have expected, considering how biased we made our data in the first two entries.
    That, in a nutshell, is the idea behind PCA.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We started this chapter by looking at how to use the wrappers for the cuBLAS
    library from Scikit-CUDA; we have to keep many details in mind here, such as when
    to use column-major storage, or if an input array will be overwritten in-place.
    We then look at how to perform one- and two-dimensional FFTs with cuFFT from Scikit-CUDA,
    and how to create a simple convolutional filter. We then showed you how to apply
    this for a simple Gaussian blurring effect on an image. Finally, we looked at
    how to perform a singular value decomposition (SVD) on the GPU with cuSolver,
    which is normally a very computationally onerous operation, but which parallelizes
    fairly well onto the GPU. We ended this chapter by looking at how to use the SVD
    for basic PCA.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Suppose you get a job translating some old legacy FORTRAN BLAS code to CUDA.
    You open a file and see a function called SBLAH, and another called ZBLEH. Can
    you tell what datatypes these two functions use without looking them up?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can you alter the cuBLAS level-2 GEMV example to work by directly copying the
    matrix `A` to the GPU, without taking the transpose on the host to set it column-wise?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use cuBLAS 32-bit real dot-product (`cublasSdot`) to implement matrix-vector
    multiplication using one row-wise matrix and one stride-1 vector.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implement matrix-matrix multiplication using `cublasSdot`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can you implement a method to precisely measure the GEMM operations in the performance
    measurement example?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the example of the 1D FFT, try typecasting `x` as a `complex64` array, and
    then switching the FFT and inverse FFT plans to be `complex64` valued in both
    directions. Then confirm whether `np.allclose(x, x_gpu.get())` is true without
    checking the first half of the array. Why do you think this works now?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Notice that there is a dark edge around the blurred image in the convolution
    example. Why is this in the blurred image but not in the original? Can you think
    of a method that you can use to mitigate this?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL

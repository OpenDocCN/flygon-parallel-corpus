- en: Where to Go from Here
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book has been a journey, much like a daring mountain hike… but now, at
    last, we have arrived at the end of our trek. We now stand upon the summit of
    mount introductory-GPU-programming, and we stand proud as we gaze back upon our
    native village of serial-programming-ville and smile as we think about the quaint
    naivity of our old one-dimensional programming traditions, where we considered
    *forking* a process in Unix to be our entire understanding of the notion of *parallel
    programming*. We have braved many pitfalls and dangers to arrive at this point,
    and we may have even made such mishaps as installing a broken NVIDIA driver module
    in Linux, or maybe downloading the wrong Visual Studio version over a slow 100k
    connection while visiting our parents for vacation. But these setbacks were only
    temporary, leaving wounds that developed into calluses that made us even stronger
    against the forces of (GPU) nature.
  prefs: []
  type: TYPE_NORMAL
- en: But, in the corner of our eye, we can see two wooden signs a few meters away
    from where we are standing; we avert our gaze from the little village of our past
    and now take a look at them. The first has an arrow pointing in the direction
    from which we are currently faced, with only one word on it—PAST. The other is
    pointing in the opposite direction, also with only one word—FUTURE. We turn around
    in the direction pointing to FUTURE, and we see a large glimmering metropolis
    strewn out before us to the horizon, beckoning us. Now that we have finally caught
    our breath, we can start walking into the future…
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will go over some of the options that you now have so that
    you can continue your education and career in fields related to GPU programming.
    Whether you are trying to build a career, a hobbyist doing this for fun, an engineering
    student studying GPUs for a class, a programmer or engineer trying to enhance
    your technical background, or an academic scientist trying to apply GPUs to a
    research project, there are many, many options that you now have at this point.
    Much like our metaphorical metropolis, it is easy to get lost, and it is difficult
    to determine where we should go. We hope to provide something akin to a brief
    tour guide in this final chapter, providing you with some of the options for where
    you can go next.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now take a look at the following paths in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Advanced CUDA and GPGPU programming
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graphics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning and computer vision
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blockchain technology
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Furthering your knowledge of CUDA and GPGPU programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first option you have is, of course, to learn more about CUDA and **General-Purpose
    GPU** (**GPGPU**) programming in particular. In this case, you have probably already
    found a good application of this and want to write even more advanced or optimized
    CUDA code. You may find it interesting for its own sake, or perhaps you want to
    get a job as a CUDA/GPU programmer. With a strong GPU programming foundation in
    place (which was provided by this book), we will now look at some of the advanced
    topics in this field that we are now prepared to learn about.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-GPU systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first major topic that comes to mind would be to learn how to program systems
    with more than one GPU installed. Many professional workstations and servers contain
    several GPUs that have been installed with the intention of processing far more
    data that requires not one, but several top-of-the-line GPUs. To this end, there
    exists a subfield called Multi-GPU programming. Much of the work is focused on
    load balancing, which is the art of using each GPU at its peak capacity, ensuring
    that no GPU gets saturated with too much work while the other goes without being
    fully utilized. Another topic here is Inter-GPU Communication, which is generally
    concerned about the issue of one GPU directly copying memory arrays to or from
    another using CUDA's GPUDirect **peer-to-peer** (**P2P**) memory access.
  prefs: []
  type: TYPE_NORMAL
- en: NVIDIA provides a brief introduction to Multi-GPU programming here: [https://www.nvidia.com/docs/IO/116711/sc11-multi-gpu.pdf](https://www.nvidia.com/docs/IO/116711/sc11-multi-gpu.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: Cluster computing and MPI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another topic is cluster computing, that is, writing programs that make collective
    use of a multitude of servers containing GPUs. These are the *server farms* that
    populate the data-processing facilities of well-known internet companies such
    as Facebook and Google, as well as the scientific supercomputing facilities used
    by governments and militaries. Clusters are generally programmed with a programming
    paradigm called **message-passing interface** (**MPI**), which is an interface
    used with languages such as C++ or Fortran that allows you to program many computers
    that are connected to the same network.
  prefs: []
  type: TYPE_NORMAL
- en: More information about using CUDA with MPI is available here: [https://devblogs.nvidia.com/introduction-cuda-aware-mpi/](https://devblogs.nvidia.com/introduction-cuda-aware-mpi/).
  prefs: []
  type: TYPE_NORMAL
- en: OpenCL and PyOpenCL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CUDA isn't the only language that can be used to program a GPU. CUDA's most
    major competitor is called Open Computing Language, or OpenCL. Where CUDA is a
    closed and proprietary system that will work exclusively on only NVIDIA hardware,
    OpenCL is an open standard that's developed and supported by the nonprofit Khronos
    Group. OpenCL can be used to program not only an NVIDIA GPU, but also AMD Radeon
    GPUs and even Intel HD GPUs—most major technology companies have committed to
    supporting OpenCL in their products. Additionally, the author of PyCUDA, Professor
    Andreas Kloeckner of UIUC, has written another excellent (and free) Python library
    called PyOpenCL, which provides an equally user-friendly interface to OpenCL,
    with nearly the same syntax and notions as PyCUDA.
  prefs: []
  type: TYPE_NORMAL
- en: Information on OpenCL is provided by NVIDIA here: [https://developer.nvidia.com/opencl](https://developer.nvidia.com/opencl).
  prefs: []
  type: TYPE_NORMAL
- en: 'Information on the free PyOpenCL library is available from Andreas Kloeckner’s
    website here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://mathema.tician.de/software/pyopencl/](https://mathema.tician.de/software/pyopencl/).'
  prefs: []
  type: TYPE_NORMAL
- en: Graphics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Obviously, the **G** in GPU stands for **graphics**, which we really haven't
    seen much of in this book. Even though machine learning applications are now NVIDIA's
    bread and butter, it all started with rendering nice-looking graphics. We will
    provide some resources to get you started here, whether you want to develop video
    game engines, render CGI movies, or develop CAD software. CUDA can actually be
    used hand in hand with graphics applications, and is actually used in professional
    software such as Adobe's Photoshop and After Effects, as well as in many recent
    video games such as the *Mafia* and *Just Cause* series. We will briefly cover
    some of the major APIs you might consider starting with here.
  prefs: []
  type: TYPE_NORMAL
- en: OpenGL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Open Graphics Language, or OpenGL, is an industry open standard that has
    existed since the early 90's. While in some ways it is showing its age, it is
    a stable API that enjoys widespread support, and if you write a program that makes
    use of this, it is pretty much guaranteed to work on any relatively modern GPU
    in existence. The CUDA samples folder actually contains many examples of how OpenGL
    can interface with CUDA (particularly in the `2_Graphics` subdirectory), so interested
    readers may consider going over these examples. (The default location is `C:\ProgramData\NVIDIA
    Corporation\CUDA Samples` in Windows, and `/usr/local/cuda/samples` in Linux.)
  prefs: []
  type: TYPE_NORMAL
- en: Information about OpenGL is available directly from NVIDIA here: [https://developer.nvidia.com/opengl](https://developer.nvidia.com/opengl).
  prefs: []
  type: TYPE_NORMAL
- en: 'PyCUDA also provides an interface for the NVIDIA OpenGL driver. Information
    is available here: [https://documen.tician.de/pycuda/gl.html](https://documen.tician.de/pycuda/gl.html).'
  prefs: []
  type: TYPE_NORMAL
- en: DirectX 12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DirectX 12 is the latest iteration of Microsoft's well-known and well-supported
    graphics API. While this is proprietary for Windows PCs and Microsoft Xbox game
    consoles, these systems obviously have a wide install base of hundreds of millions
    of users. Furthermore, a variety of GPUs are supported on Windows PCs besides
    NVIDIA cards, and the Visual Studio IDE provides a great ease of use. DirectX
    12 actually supports low-level GPGPU programming-type concepts and can utilize
    multiple GPUs.
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft's DirectX 12 Programming Guide is available here: [https://docs.microsoft.com/en-us/windows/desktop/direct3d12/directx-12-programming-guide](https://docs.microsoft.com/en-us/windows/desktop/direct3d12/directx-12-programming-guide).
  prefs: []
  type: TYPE_NORMAL
- en: Vulkan
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Vulkan can be thought of as the open equivalent of DirectX 12, which was developed
    by the Khronos Group as the *next-gen* successor of OpenGL. Along with Windows,
    Vulkan is also supported on macOS and Linux, as well as on the Sony PlayStation
    4, Nintendo Switch, and Xbox One consoles. Vulkan has many of the same features
    as DirectX 12, such as quasi-GPGPU programming. Vulkan is providing some serious
    competition to DirectX 12, with video games such as the 2016 *DOOM* remake.
  prefs: []
  type: TYPE_NORMAL
- en: The *Beginner's Guide to Vulkan* is available from the Khronos Group here: [https://www.khronos.org/blog/beginners-guide-to-vulkan](https://www.khronos.org/blog/beginners-guide-to-vulkan).
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning and computer vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Of course, the elephant in the room of this chapter is machine learning and
    its fraternal twin computer vision. It goes without saying that machine learning
    (particularly the subfields of deep neural networks and convolutional neural networks)
    is what is keeping a roof over NVIDIA CEO Jensen Huang's head these days. (Okay,
    we admit that was the understatement of the decade...) If you need a reminder
    as to why GPUs are so applicable and useful in this field, please take another
    look at [Chapter 9](3562f1e0-a53d-470f-9b4d-94fa41b1b2fa.xhtml), *Implementation
    of a Deep Neural Network*. A large number of parallel computations and mathematical
    operations, as well as the user-friendly mathematical libraries, have made NVIDIA GPUs
    the hardware backbone of the machine learning industry.
  prefs: []
  type: TYPE_NORMAL
- en: The basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While you now know many of the intricacies of low-level GPU programming, you
    won't be able to apply this knowledge to machine learning immediately. If you
    don't have the basic skills in this field, like how to do a basic statistical
    analysis of a dataset, you really should stop and familiarize yourself with them.
    Stanford Professor Andrew Ng, the founder of Google Brain, provides many materials
    that are available for free on the web and on YouTube. Professor Ng's work is
    generally considered to be the gold standard of educational material on machine
    learning.
  prefs: []
  type: TYPE_NORMAL
- en: Professor Ng provides a free introductory machine learning class on the web
    here: [http://www.ml-class.org](http://www.ml-class.org).
  prefs: []
  type: TYPE_NORMAL
- en: cuDNN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: NVIDIA provides an optimized GPU library for deep neural network primitives
    called cuDNN. These primitives include operations such as forward propagation,
    convolutions, back propagation, activation functions (such as sigmoid, ReLU, and
    tanh), and gradient descent. cuDNN is what most of the mainstream deep neural
    network frameworks such as Tensorflow use as a backend for NVIDIA GPUs. This is
    provided for free by NVIDIA , but has to be downloaded separately from the CUDA
    Toolkit.
  prefs: []
  type: TYPE_NORMAL
- en: More information on cuDNN is available here: [https://developer.nvidia.com/cudnn](https://developer.nvidia.com/cudnn).
  prefs: []
  type: TYPE_NORMAL
- en: Tensorflow and Keras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tensorflow is, of course, Google's well-known neural network framework. This
    is a free and open source framework that is usable with Python and C++, and has
    been available to the general public since 2015.
  prefs: []
  type: TYPE_NORMAL
- en: Tutorials on Tensorflow are available from Google here: [https://www.tensorflow.org/tutorials/](https://www.tensorflow.org/tutorials/).
  prefs: []
  type: TYPE_NORMAL
- en: Keras is a higher level library that provides a more *user-friendly* interface
    to Tensorflow, which was originally written by Google Brain's Francois Chollet.
    Readers may actually consider starting with Keras before moving on to Tensorflow.
  prefs: []
  type: TYPE_NORMAL
- en: Information on Keras is available here: [https://keras.io/](https://keras.io/).
  prefs: []
  type: TYPE_NORMAL
- en: Chainer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chainer is another neural network API that was developed by Seiya Tokui, who
    is currently a PhD student at the University of Tokyo in Japan. While it is less
    mainstream than Tensorflow, it is very well-respected due to its incredible speed
    and efficiency. Moreover, readers may find Chainer of particular interest, since
    this was originally developed using PyCUDA. (This was later switched to CuPy,
    which is a PyCUDA branch that was developed to provide an interface that is more
    similar to NumPy.)
  prefs: []
  type: TYPE_NORMAL
- en: Information on Chainer is available here: [https://chainer.org/](https://chainer.org/).
  prefs: []
  type: TYPE_NORMAL
- en: OpenCV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Open Source computer vision Library (OpenCV) has been around since 2001\.
    This library provides many of the tools from classical computer vision and image
    processing, which are still extremely useful in this age of the deep neural network.
    Most of the algorithms in OpenCV have been ported to CUDA in recent years, and
    it interfaces very easily with PyCUDA.
  prefs: []
  type: TYPE_NORMAL
- en: Information on OpenCV is here: [https://opencv.org/](https://opencv.org/).
  prefs: []
  type: TYPE_NORMAL
- en: Blockchain technology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Last, but certainly not least, is **blockchain technology**. This is the underlying
    cryptographic technology that powers cryptocurrencies such as Bitcoin and Ethereum.
    This is, of course, a very new field, which was first described by Bitcoin's mysterious
    creator, Satoshi Nakamoto, in a white paper published in 2008\. GPUs were applied
    to this field almost immediately after its invention—generating a unit of currency
    comes down to brute-force cracking a cryptographic puzzle, and a GPU can attempt
    to brute-force crack more combinations in parallel than any other piece of hardware
    available to the general public today. This process is known as **mining**.
  prefs: []
  type: TYPE_NORMAL
- en: Those who are interested in blockchain technology are suggested to read Satoshi
    Nakamoto's original white paper on Bitcoin, which is available here: [https://bitcoin.org/bitcoin.pdf](https://bitcoin.org/bitcoin.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: GUIMiner, an open source, CUDA-based Bitcoin miner, is available here: [https://guiminer.org/](https://guiminer.org/).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we went over some of the options and paths for those that are
    interested in furthering their background in GPU programming, which is beyond
    the scope of this book. The first path we covered was expanding your background
    in pure CUDA and GPGPU programming—some of the things you can learn about that
    weren't covered in this book include programming systems with multiple GPUs and
    networked clusters. We also looked at some of the parallel programming languages/APIs
    besides CUDA, such as MPI and OpenCL. Next, we discussed some of the well-known
    APIs available to those who are interested in applying GPUs to rendering graphics,
    such as Vulkan and DirectX 12\. We then looked at machine learning and went into
    some of the basic backgrounds that you should have as well as some of the major
    frameworks available for developing deep neural networks. Finally, we ended by
    taking a brief look at blockchain technology and GPU-based cryptocurrency mining.
  prefs: []
  type: TYPE_NORMAL
- en: As the author, I would like to say *thank you* to everyone who has pushed through
    this book and made it here, to the end. GPU programming is one of the trickiest
    subfields of programming that I have encountered, and I hope my text has helped
    you come to grips with the essentials. As the reader, you should now feel free
    to indulge in a slice of the richest, most calorie-laden slice of chocolate cake
    you can find—just know that you've *earned* it. (But only one slice!)
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Use Google or some other search engine to find at least one application of GPU
    programming that is not featured in this chapter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try to find at least one programming language or API that can be used to program
    a GPU that is not featured in this chapter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Look up Google's new Tensor Processing Unit (TPU) chips. How do these differ
    from GPUs?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do you think it is a better idea to connect computers together into a cluster
    using Wi-Fi or wired Ethernet cables?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL

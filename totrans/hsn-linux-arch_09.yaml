- en: Understanding the Core Components of a Kubernetes Cluster
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解Kubernetes集群的核心组件
- en: 'In this chapter, we will be going through a 10,000-foot view of the main Kubernetes
    components, from what each controller is composed of to how a container in a pod
    is deployed and scheduled across each of the workers. It is crucial to understand
    the ins and outs of the Kubernetes cluster in order to be able to deploy and design
    a solution based on Kubernetes as an orchestrator for your containerized applications:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将从每个控制器的组成到如何部署和调度pod中的容器，对主要的Kubernetes组件进行一个全面的了解。了解Kubernetes集群的方方面面对于能够基于Kubernetes作为容器化应用程序的编排器部署和设计解决方案至关重要：
- en: Control plane components
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制平面组件
- en: The Kubernetes workers' components
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes工作节点的组件
- en: Pods as basic building blocks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pod作为基本构建块
- en: Kubernetes services, load balancers, and Ingress controllers
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes服务、负载均衡器和Ingress控制器
- en: Kubernetes deployments and DaemonSets
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes部署和DaemonSets
- en: Persistent storage in Kubernetes
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes中的持久存储
- en: The Kubernetes control plane
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes控制平面
- en: The Kubernetes master nodes are where the core control plane services live;
    not all services have to reside on the same node; however, for centralization
    and practicality, they are often deployed this way. This obviously raises services
    availability questions; however, they can easily be overcome by having several
    nodes and providing load balancing requests to achieve a highly available set
    of **master nodes**.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes主节点是核心控制平面服务所在的地方；并非所有服务都必须驻留在同一节点上；然而，出于集中和实用性的考虑，它们通常以这种方式部署。这显然引发了服务可用性的问题；然而，通过拥有多个节点并提供负载平衡请求，可以轻松克服这些问题，从而实现高度可用的**主节点**集。
- en: 'The master nodes are composed of four basic services:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 主节点由四个基本服务组成：
- en: The kube-apiserver
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: kube-apiserver
- en: The kube-scheduler
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: kube-scheduler
- en: The kube-controller-manager
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: kube-controller-manager
- en: The etcd database
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: etcd数据库
- en: Master nodes can either run on bare metal servers, virtual machines, or a private
    or public cloud, but it is not recommended to run container workloads on them.
    We will see more on this later.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 主节点可以在裸金属服务器、虚拟机或私有或公共云上运行，但不建议在其上运行容器工作负载。我们稍后会详细了解更多。
- en: 'The following diagram shows the Kubernetes master nodes components:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了Kubernetes主节点的组件：
- en: '![](img/7e921f9a-af2e-4baf-932e-7c58ac02a1ab.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7e921f9a-af2e-4baf-932e-7c58ac02a1ab.png)'
- en: The kube-apiserver
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: kube-apiserver
- en: The API server is what ties everything together. It is the frontend REST API
    of the cluster that receives manifests to create, update, and delete API objects
    such as services, pods, Ingress, and others.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: API服务器是将所有内容联系在一起的东西。它是集群的前端REST API，接收清单以创建、更新和删除诸如服务、pod、Ingress等API对象。
- en: The **kube-apiserver** is the only service that we should be talking to; it
    is also the only one that writes and talks to the `etcd` database for registering
    the cluster state. With the `kubectl` command, we will send commands to interact
    with it. This will be our Swiss Army knife when it comes to Kubernetes.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**kube-apiserver**是我们应该与之交谈的唯一服务；它也是唯一一个写入并与`etcd`数据库交谈以注册集群状态的服务。通过`kubectl`命令，我们将发送命令与其交互。这将是我们在处理Kubernetes时的瑞士军刀。'
- en: The kube-controller-manager
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: kube-controller-manager
- en: 'The **kube-controller-manager** daemon, in a nutshell, is a set of infinite
    control loops that is shipped for simplicity in a single binary. It watches for
    the defined desired state of the cluster and it makes sure that it is accomplished
    and satisfied by moving all the bits and pieces necessary to achieve it. The kube-controller-manager
    is not just one controller; it contains several different loops that watch different
    components in the cluster. Some of them are the service controller, the namespace
    controller, the service account controller, and many others. You can find each
    controller and its definition in the Kubernetes GitHub repository:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**kube-controller-manager**守护程序，简而言之，是一组无限控制循环，以简单的单个二进制文件的形式进行交付。它监视集群的定义期望状态，并确保通过移动实现所需的所有组件来实现和满足它。kube-controller-manager不仅仅是一个控制器；它包含了集群中监视不同组件的几个不同循环。其中一些是服务控制器、命名空间控制器、服务账户控制器等。您可以在Kubernetes
    GitHub存储库中找到每个控制器及其定义：'
- en: '[https://github.com/kubernetes/kubernetes/tree/master/pkg/controller](https://github.com/kubernetes/kubernetes/tree/master/pkg/controller).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/kubernetes/kubernetes/tree/master/pkg/controller](https://github.com/kubernetes/kubernetes/tree/master/pkg/controller)。'
- en: The kube-scheduler
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: kube-scheduler
- en: 'The **kube-scheduler** schedules your newly created pods to nodes with enough
    space to satisfy the pods'' resource needs. It basically listens to the kube-apiserver
    and the kube-controller-manager for newly created pods that are put into a queue
    and then scheduled to an available node by the scheduler. The kube-scheduler definition
    can be found here:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**kube-scheduler**将您新创建的pod调度到具有足够空间满足pod资源需求的节点上。它基本上监听kube-apiserver和kube-controller-manager，以获取新创建的pod，并将其放入队列，然后由调度程序安排到可用节点上。kube-scheduler的定义可以在这里找到：'
- en: '[https://github.com/kubernetes/kubernetes/blob/master/pkg/scheduler](https://github.com/kubernetes/kubernetes/blob/master/pkg/scheduler/scheduler.go).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/kubernetes/kubernetes/blob/master/pkg/scheduler](https://github.com/kubernetes/kubernetes/blob/master/pkg/scheduler/scheduler.go)。'
- en: Besides compute resources, the kube-scheduler also reads the nodes' affinity
    and anti-affinity rules to find out whether a node can or cannot run that pod.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 除了计算资源外，kube-scheduler还会读取节点的亲和性和反亲和性规则，以确定节点是否能够运行该pod。
- en: The etcd database
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: etcd数据库
- en: The **etcd** **database** is a very reliable consistent key-value store that's
    used to store the state of the Kubernetes cluster. It contains the current status
    of the pods in which the node is running on, how many nodes the cluster currently
    has, what the state of those nodes is, how many replicas of a deployment are running,
    services names, and others.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**etcd**数据库是一个非常可靠的一致性键值存储，用于存储Kubernetes集群的状态。它包含了节点正在运行的pod的当前状态，集群当前有多少个节点，这些节点的状态是什么，部署有多少个副本正在运行，服务名称等。'
- en: As we mentioned before, only the kube-apiserver talks to the `etcd` database.
    If the kube-controller-manager needs to check the state of the cluster, it will
    go through the API server in order to get the state from the `etcd` database,
    instead of querying the `etcd` store directly. The same happens with the kube-scheduler,
    if the scheduler needs to make it known that a pod has been stopped or allocated
    to another node; it will inform the API server, and the API server will store
    the current state in the etcd database.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，只有kube-apiserver与etcd数据库通信。如果kube-controller-manager需要检查集群的状态，它将通过API服务器获取etcd数据库的状态，而不是直接查询etcd存储。kube-scheduler也是如此，如果调度程序需要通知某个pod已停止或分配到另一个节点，它将通知API服务器，API服务器将在etcd数据库中存储当前状态。
- en: With etcd, we have covered all the main components for our Kubernetes master
    nodes so that we are ready to manage our cluster. But a cluster is not only composed
    of masters; we still require the nodes that will be performing the heavy lifting
    by running our applications.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 通过etcd，我们已经涵盖了Kubernetes主节点的所有主要组件，因此我们已经准备好管理我们的集群。但是，集群不仅由主节点组成；我们仍然需要执行重型工作并运行我们的应用程序的节点。
- en: Kubernetes worker nodes
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes工作节点
- en: The worker nodes that do this task in Kubernetes are simply called nodes. Previously,
    around 2014, they were called **minions**, but this term was later replaced with
    just nodes, as the name was confusing with Salt's terminologies and made people
    think that Salt was playing a major role in Kubernetes.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中执行此任务的工作节点简单地称为节点。在2014年左右，它们曾被称为minions，但后来这个术语被替换为节点，因为这个名称与Salt的术语混淆，并让人们认为Salt在Kubernetes中扮演了重要角色。
- en: These nodes are the only place that you will be running workloads, as it is
    not recommended to have containers or loads on the master nodes, as they need
    to be available to manage the entire cluster.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这些节点是您将运行工作负载的唯一位置，因为不建议在主节点上运行容器或负载，因为它们需要可用于管理整个集群。
- en: 'The nodes are very simple in terms of components; they only require three services
    to fulfill their task:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 节点在组件方面非常简单；它们只需要三个服务来完成任务：
- en: Kubelet
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: kubelet
- en: Kube-proxy
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: kube-proxy
- en: Container runtime
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器运行时
- en: Let's explore these three components in a little bit more depth.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地探讨这三个组件。
- en: Container runtime
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器运行时
- en: To be able to spin up containers, we require a **container runtime**. This is
    the base engine that will create the containers in the nodes kernel for our pods
    to run. The kubelet will be talking to this runtime and will spin up or stop our
    containers on demand.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够启动容器，我们需要一个容器运行时。这是将在节点内核中为我们的pod创建容器的基本引擎。kubelet将与此运行时进行通信，并根据需要启动或停止我们的容器。
- en: Currently, Kubernetes supports any OCI-compliant container runtime, such as
    Docker, `rkt`, `runc`, `runsc`, and so on.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，Kubernetes支持任何符合OCI规范的容器运行时，例如Docker、rkt、runc、runsc等。
- en: You can learn more about all the specifications from the OCI GitHub page: [https://github.com/opencontainers/runtime-spec](https://github.com/opencontainers/runtime-spec).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从OCI GitHub页面了解有关所有规范的更多信息：[https://github.com/opencontainers/runtime-spec](https://github.com/opencontainers/runtime-spec)。
- en: The kubelet
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: kubelet
- en: The **kubelet** is a low-level Kubernetes component and one of the most important
    ones after the kube-apiserver; both of these components are essential for the
    provisioning of pods/containers in the cluster. The kubelet is a service that
    runs on the Kubernetes nodes and listens to the API server for pod creation. The
    kubelet is only in charge of starting/stopping and making sure that containers
    in pods are healthy; the kubelet will not be able to manage any containers that
    were not created by it.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: kubelet是Kubernetes的一个低级组件，是继kube-apiserver之后最重要的组件之一；这两个组件对于在集群中提供pod/容器至关重要。kubelet是在Kubernetes节点上运行的一个服务，它监听API服务器以创建pod。kubelet只负责启动/停止并确保pod中的容器健康；kubelet将无法管理未由其创建的任何容器。
- en: The kubelet achieves the goals by talking to the container runtime via something
    called the **container runtime interface** (**CRI**). The CRI provides pluggability
    to the kubelet via a gRPC client, which is able to talk to different container
    runtimes. As we mentioned earlier, Kubernetes supports multiple container runtimes
    to deploy containers, and this is how it achieves such diverse support for different
    engines.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: kubelet通过与容器运行时进行通信来实现目标，这是通过所谓的容器运行时接口（CRI）实现的。CRI通过gRPC客户端为kubelet提供可插拔性，可以与不同的容器运行时进行通信。正如我们之前提到的，Kubernetes支持多个容器运行时来部署容器，这就是它如何实现对不同引擎的多样化支持的方式。
- en: You can check the kubelet's source code via the following GitHub link: [https://github.com/kubernetes/kubernetes/tree/master/pkg/kubelet](https://github.com/kubernetes/kubernetes/tree/master/pkg/kubelet).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过以下GitHub链接检查kubelet的源代码：[https://github.com/kubernetes/kubernetes/tree/master/pkg/kubelet](https://github.com/kubernetes/kubernetes/tree/master/pkg/kubelet)。
- en: The kube-proxy
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: kube-proxy
- en: The **kube-proxy** is a service that resides on each node of the cluster, and
    is the one that makes communications between pods, containers, and nodes possible.
    This service watches the kube-apiserver for changes on defined services (a service
    is a sort of logical load balancer in Kubernetes; we will dive deeper into services
    later on in this chapter) and keeps the network up to date via `iptables` rules
    that forward traffic to the correct endpoints. Kube-proxy also sets up rules in
    `iptables` that do random load balancing across pods behind a service.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: kube-proxy是集群中每个节点上的一个服务，它使得pod、容器和节点之间的通信成为可能。该服务监视kube-apiserver以获取定义的服务的更改（服务是Kubernetes中一种逻辑负载均衡器；我们将在本章后面更深入地了解服务），并通过iptables规则保持网络最新，以将流量转发到正确的端点。Kube-proxy还在iptables中设置规则，对服务后面的pod进行随机负载平衡。
- en: 'Here is an example of an `iptables` rule that was made by the kube-proxy:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是kube-proxy创建的一个iptables规则的示例：
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This is a service with no endpoints (no pods behind it).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个没有端点的服务（没有pod在其后面）。
- en: Now that we have gone through all the core components that form a cluster, we
    can talk about what we can do with them and how Kubernetes is going to help us
    orchestrate and manage our containerized applications.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了构成集群的所有核心组件，我们可以谈谈我们可以如何使用它们以及Kubernetes将如何帮助我们编排和管理我们的容器化应用程序。
- en: Kubernetes objects
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes对象
- en: '**Kubernetes** **objects** are exactly that: they are logical persistent objects
    or abstractions that will represent the state of your cluster. You are the one
    in charge of telling Kubernetes what your desired state of that object is so that
    it can work to maintain it and make sure that the object exists.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubernetes对象**就是这样：它们是逻辑持久对象或抽象，将代表您集群的状态。您负责告诉Kubernetes您对该对象的期望状态，以便它可以努力维护它并确保该对象存在。'
- en: 'To create an object, there are two things that it needs to have: a status and
    its spec. The status is provided by Kubernetes, and it is the current state of
    the object. Kubernetes will manage and update that status as needed to be in accordance
    to your desired state. The `spec` field, on the other hand, is what you provide
    to Kubernetes, and is what you tell it to describe the object you desire, for
    example, the image that you want the container to be running, the number of containers
    of that image that you want to run, and so on. Each object has specific `spec`
    fields for the type of task that they perform, and you will be providing these
    specifications on a YAML file that is sent to the kube-apiserver with `kubectl`,
    which that transforms it into JSON and sends it as an API request. We will dive
    deeper into each object and its spec fields later in this chapter.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个对象，它需要具备两个要素：状态和规范。状态由Kubernetes提供，并且它是对象的当前状态。Kubernetes将根据需要管理和更新该状态，以符合您的期望状态。另一方面，`spec`字段是您提供给Kubernetes的内容，并且是您告诉它描述您所需对象的内容，例如，您希望容器运行的图像，您希望运行该图像的容器数量等。每个对象都有特定的`spec`字段，用于执行其任务类型，并且您将在发送到kube-apiserver的YAML文件中提供这些规范，该文件将使用`kubectl`将其转换为JSON并将其发送为API请求。我们将在本章后面更深入地了解每个对象及其规范字段。
- en: 'Here is an example of a YAML that was sent to `kubectl`:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是发送到`kubectl`的YAML的示例：
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The basic fields of the object definition are the very first ones, and these
    ones will not vary from object to object and are very self-explanatory. Let''s
    take a quick look at them:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对象定义的基本字段是最初的字段，这些字段不会因对象而异，并且非常直观。让我们快速浏览一下它们：
- en: '`kind`: The `kind` field tells Kubernetes what type of object you are defining:
    a pod, a service, a deployment, and so on'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kind`：`kind`字段告诉Kubernetes您正在定义的对象类型：pod、服务、部署等'
- en: '`apiVersion`: Because Kubernetes supports multiple API versions, we need to
    specify a REST API path that we want to send our definition to'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`apiVersion`：因为Kubernetes支持多个API版本，我们需要指定一个REST API路径，以便将我们的定义发送到该路径'
- en: '`metadata`: This is a nested field, which means that you have several more
    subfields to metadata, where you will write basic definitions such as the name
    of your object, assigning it to a specific namespace, and also tag a label to
    it to relate your object to other Kubernetes objects'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metadata`：这是一个嵌套字段，这意味着您有更多的子字段可以写入metadata，您可以在其中编写基本定义，例如对象的名称，将其分配给特定命名空间，并为其标记一个标签，以将您的对象与其他Kubernetes对象相关联'
- en: 'So, we have now been through the most-used fields and their contents; you can
    learn more about the Kuberntes API conventions at the following GitHub page:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们现在已经了解了最常用的字段及其内容；您可以在以下GitHub页面了解有关Kuberntes API约定的更多信息：
- en: '[https://github.com/kubernetes/community/blob/master/contributors/devel/api-conventions.md](https://github.com/kubernetes/community/blob/master/contributors/devel/api-conventions.md).'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/kubernetes/community/blob/master/contributors/devel/api-conventions.md](https://github.com/kubernetes/community/blob/master/contributors/devel/api-conventions.md)。'
- en: Some of the fields of the object can later be modified after the object has
    been created, but that will depend on the object and the field that you want to
    modify.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对象的某些字段在创建对象后可以进行修改，但这将取决于对象和您要修改的字段。
- en: 'The following is a short list of the various Kubernetes objects that you can
    create:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是您可以创建的各种Kubernetes对象的简短列表：
- en: Pod
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pod
- en: Volume
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷
- en: Service
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务
- en: Deployment
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署
- en: Ingress
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 入口
- en: Secret
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 秘钥
- en: ConfigMap
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置映射
- en: And there are many more.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他内容。
- en: Let's take a closer look at each one of these items.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看这些项目中的每一个。
- en: Pods – the basis of Kubernetes
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pods - Kubernetes的基础
- en: Pods are the most basic objects in Kubernetes and also the most important ones.
    Everything revolves around them; we can say that Kubernetes is for the pods! All
    of the other objects are here to serve them, and all the tasks that they do are
    to make the pods achieve your desired state.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Pod是Kubernetes中最基本且最重要的对象。一切都围绕它们展开；我们可以说Kubernetes是为了pod！所有其他对象都是为了服务它们，它们所做的所有任务都是为了使pod达到您期望的状态。
- en: So, what is a pod and why are pods so important?
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，什么是pod，为什么pod如此重要？
- en: A pod is a logical object that runs one or more containers together on the same
    network namespace, the same **inter-process communication** (**IPC**) and, sometimes,
    depending on the version of Kubernetes, the same **process ID** (**PID**) namespace.
    This is because they are the ones that are going to run our containers and hence
    will be the center of attention. The whole point of Kubernetes is to be a container
    orchestrator, and with pods, we make orchestration possible.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Pod是一个逻辑对象，在同一网络命名空间上运行一个或多个容器，相同的**进程间通信**（**IPC**），有时，根据Kubernetes的版本，还在相同的**进程ID**（**PID**）命名空间上运行。这是因为它们将运行我们的容器，因此将成为关注的中心。Kubernetes的整个目的是成为一个容器编排器，而通过pod，我们使编排成为可能。
- en: As we mentioned before, containers on the same pod live in a "bubble" where
    they can talk to one another via localhost, as they are local to one another.
    One container in a pod has the same IP address as the other container because
    they are sharing a network namespace, but in most cases, you will be running on
    a one-on-one basis, that is to say, a single container per pod. Multiple containers
    per pod are only used on very specific scenarios, such as when an application
    requires a helper such as a data pusher or a proxy that needs to communicate in
    a fast and resilient way with the primary application.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，同一pod上的容器生活在一个“泡泡”中，它们可以通过localhost相互通信，因为它们彼此之间是本地的。一个pod中的一个容器与另一个容器具有相同的IP地址，因为它们共享网络命名空间，但在大多数情况下，您将以一对一的方式运行，也就是说，一个pod中只有一个容器。在非常特定的情况下才会在一个pod中运行多个容器，比如当一个应用程序需要一个数据推送器或需要以快速和有弹性的方式与主要应用程序通信的代理时。
- en: 'The way you define a pod is the same way you would do so for any other Kubernetes
    object: via a YAML that contains all the pod specs and definitions:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 定义pod的方式与定义任何其他Kubernetes对象的方式相同：通过包含所有pod规范和定义的YAML：
- en: '[PRE2]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let''s go through the basic pod definitions needed under the `spec` field to
    create our pod:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看在`spec`字段下创建我们的pod所需的基本pod定义：
- en: '**Containers:** Containers is an array; therefore, we have a set of several
    subfields under it. Basically, it''s what defines the containers that are going
    to be running on the pod. We can specify a name for the container, the image that
    is going to be spin-off from, and the arguments or command that we need it to
    run. The difference between arguments and commands is the same as the difference
    between `CMD` and `ENTRYPOINT` that we went through in [Chapter 6](6da53f60-978c-43a4-9dc9-f16b14405709.xhtml), *Creating
    a Highly Available Self-Healing Architecture,* when we talked about creating Docker
    images. Take note that all the fields that we just went through are for the `containers`
    array. They are not directly part of the `spec` of the pod.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容器：**容器是一个数组；因此，在它下面有一系列子字段。基本上，它定义了将在pod上运行的容器。我们可以为容器指定一个名称，要从中启动的图像，以及我们需要它运行的参数或命令。参数和命令之间的区别与我们在[第6章](6da53f60-978c-43a4-9dc9-f16b14405709.xhtml)中讨论的`CMD`和`ENTRYPOINT`的区别相同，当时我们讨论了创建Docker镜像。请注意，我们刚刚讨论的所有字段都是针对`containers`数组的。它们不是pod的`spec`的直接部分。'
- en: '**restartPolicy:** This field is exactly that: it tells Kubernetes what to
    do with a container, and it applies to all the containers in the pod in the case
    of a zero or non-zero exit code. You can choose from either option, Never, OnFailure
    or Always. Always will be the default in case a restartPolicy is not defined.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**restartPolicy:** 这个字段就是这样：它告诉Kubernetes如何处理容器，在零或非零退出代码的情况下，它适用于pod中的所有容器。您可以从Never、OnFailure或Always中选择。如果未定义restartPolicy，Always将是默认值。'
- en: 'These are the most basic specs that you are going to declare on a pod; other
    specs will require that you have a little bit more background knowledge on how
    to use them and how they interact with various other Kubernetes objects. We will
    revisit them later on this chapter, some of them are as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是您将在pod上声明的最基本的规范；其他规范将要求您对如何使用它们以及它们如何与各种其他Kubernetes对象进行交互有更多的背景知识。我们将在本章后面重新讨论它们，其中一些如下：
- en: Volume
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷
- en: Env
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Env
- en: Ports
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端口
- en: dnsPolicy
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: dnsPolicy
- en: initContainers
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: initContainers
- en: nodeSelector
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: nodeSelector
- en: Resource limits and requests
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 资源限制和请求
- en: 'To view the pods that are currently running in your cluster, you can run `kubectl
    get pods`:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看当前在集群中运行的pod，可以运行`kubectl get pods`：
- en: '[PRE3]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Alternatively, you can run `kubectl describe pods` without specifying any pod.
    This will print out a description of every pod running in the cluster. In this
    case, it will be only the `busybox` pod, as it is the only one that''s currently
    running:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以运行`kubectl describe pods`，而不指定任何pod。这将打印出集群中运行的每个pod的描述。在这种情况下，只会有`busybox`
    pod，因为它是当前唯一正在运行的pod：
- en: '[PRE4]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Pods are mortal, and this is the clue in knowing how to manage your application.
    You have to understand that once a pod dies or is deleted, there is no way to
    bring it back. Its IP and the containers that were running on it will be gone;
    they are totally ephemeral. The data on the pods that is mounted as a volume may
    or may not survive, depending on how you set it up; however, this is a discussion
    that we will have later in this chapter. If our pods die and we lose them, how
    do we ensure that all our microservices are running? Well, deployments are the
    answer.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Pods是有生命期的，这是了解如何管理应用程序的关键。您必须明白，一旦pod死亡或被删除，就无法将其恢复。它的IP和在其上运行的容器将消失；它们是完全短暂的。作为卷挂载的pod上的数据可能会存活，也可能不会，这取决于您如何设置；然而，这是我们将在本章后面讨论的问题。如果我们的pod死亡并且我们失去它们，我们如何确保所有的微服务都在运行？嗯，部署就是答案。
- en: Deployments
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署
- en: Pods by themselves are not very useful, since it is not very efficient to have
    more than a single instance of our application running in a single pod. Provisioning
    hundreds of copies of our application on different pods without having a method
    to look for them all will get out of hand really quickly.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 单独的pod并不是很有用，因为在单个pod中运行我们的应用程序的实例超过一个是不太有效率的。在没有一种方法来查找它们的情况下，在不同的pod上为我们的应用程序提供数百个副本将会很快失控。
- en: 'This is where deployments come into play. With deployments, we can manage our
    pods with a controller. This allows us to not only decide how many we want to
    run, but we can also manage updates by changing the image version or the image
    itself that our containers are running. Deployments are what you will be working
    with most of the time. With deployments as well as pods and any other objects
    that we mentioned before, they have their own definition inside a YAML file:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是部署发挥作用的地方。通过部署，我们可以使用控制器来管理我们的pod。这不仅允许我们决定要运行多少个，还可以通过更改容器正在运行的图像版本或图像本身来管理更新。部署是您大部分时间将要处理的内容。除了pod和我们之前提到的任何其他对象，它们在YAML文件中都有自己的定义：
- en: '[PRE5]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Let's start exploring their definition.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始探索它们的定义。
- en: At the beginning of the YAML, we have more general fields, such as `apiVersion`,
    `kind`, and `metadata`. But under `spec` is where we will find the specific options
    for this API Object.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在YAML的开头，我们有更一般的字段，如`apiVersion`，`kind`和`metadata`。但在`spec`下，我们将找到此API对象的特定选项。
- en: 'Under `spec`, we can add the following fields:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在`spec`下，我们可以添加以下字段：
- en: '**Selector**: With the Selector field, the deployment will know which pods
    to target when changes are applied. There are two fields that you will be using
    under the selector: `matchLabels` and `matchExpressions`. With `matchLabels`,
    the selector will use the labels of the pods (key/value pairs). It is important
    to note that all the labels that you specify here will be `ANDed`. This means
    that the pod will require that it has all the labels that you specify under `matchLabels`.
    `matchExpressions` is rarely used, but you can learn more about by reading our
    recommended books in the *Further reading* section.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选择器**：使用选择器字段，部署将知道在应用更改时要针对哪些pod。在选择器下有两个字段：`matchLabels`和`matchExpressions`。使用`matchLabels`，选择器将使用pod的标签（键/值对）。重要的是要注意，您在这里指定的所有标签都将被`ANDed`。这意味着pod将要求具有您在`matchLabels`下指定的所有标签。`matchExpressions`很少使用，但您可以通过阅读我们在*进一步阅读*部分推荐的书籍来了解更多信息。'
- en: '**Replicas**: This will state the number of pods that the deployment needs
    to keep running via the replication controller; for example, if you specify three
    replicas, and one of the pods dies, the replication controller will watch the
    replicas spec as the desired state and inform the scheduler to schedule a new
    pod, as the current status is now 2 since the pod died.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**副本**：这将说明部署需要通过复制控制器保持运行的pod数量；例如，如果指定了三个副本，并且其中一个pod死亡，复制控制器将监视副本规范作为期望的状态，并通知调度程序安排一个新的pod，因为当前状态现在是2，因为pod死亡。'
- en: '**RevisionHistoryLimit**: Every time you make a change to a deployment, this
    change is saved as a revision of the deployment, which you can later either revert
    to that previous state or keep a record of what was changed. You can consult your
    history with `kubectl` rollout history deployment/<name of deployment>. With `revisionHistoryLimit`,
    you can set up a number stating how many records you want to save.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RevisionHistoryLimit**：每次对部署进行更改，此更改都将保存为部署的修订版本，您稍后可以恢复到以前的状态，或者保留更改的记录。您可以使用`kubectl`
    rollout history deployment/<部署名称>来查看历史记录。使用`revisionHistoryLimit`，您可以设置一个数字，指定要保存多少条记录。'
- en: '**Strategy**: This will let you decide how you want to handle any update or
    horizontal pod scale. To overwrite the default, which is `rollingUpdate`, you
    need to write the `type` key, where you can choose between two values: `recreate`
    or `rollingUpdate`. While `recreate` is a fast way to update your deployment,
    it will delete all the pods and replace them with new ones, but it will imply
    that you will have to take into consideration that a system downtime will be in
    place for this type of strategy. The `rollingUpdate`, on the other hand, is smoother
    and slower, and is ideal for stateful applications that can rebalance their data.
    The `rollingUpdate` opens the door for two more fields, which are `maxSurge` and
    `maxUnavailable`. The first one will be how many pods above your total amount
    you want when performing an update; for example, a deployment with 100 pods and
    a 20% `maxSurge` will grow up to a maximum of 120 pods while updating. The next
    option will let you select how many pods in the percentage you are willing to
    kill in order to replace them with new ones in a 100 pod scenario. In cases where
    there is 20% `maxUnavailable`, only 20 pods will be killed and replaced with new
    ones before continuing to replace the rest of the deployment.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**策略**：这将让您决定如何处理任何更新或水平pod扩展。要覆盖默认值（即`rollingUpdate`），您需要编写`type`键，您可以在两个值之间进行选择：`recreate`或`rollingUpdate`。虽然`recreate`是更新部署的快速方式，它将删除所有pod并用新的替换它们，但这意味着您必须考虑到这种策略将导致系统停机。另一方面，`rollingUpdate`更加平稳和缓慢，非常适合可以重新平衡其数据的有状态应用程序。`rollingUpdate`为另外两个字段打开了大门，这些字段是`maxSurge`和`maxUnavailable`。第一个字段将是在执行更新时您希望超出总数的pod数量；例如，具有100个pod和20%`maxSurge`的部署将在更新时增长到最多120个pod。下一个选项将让您选择在100个pod场景中愿意杀死多少百分比的pod以用新的替换它们。在存在20%`maxUnavailable`的情况下，只有20个pod将被杀死并用新的替换，然后继续替换部署的其余部分。'
- en: '**Template**: This is just a nested pod spec field where you will include all
    the specs and metadata of the pods that the deployment is going to manage.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模板**：这只是一个嵌套的pod spec字段，您将在其中包含部署将要管理的pod的所有规范和元数据。'
- en: We have seen that, with deployments, we manage our pods, and they help us maintain
    them in a state that we desire. All these pods are still in something called the
    **cluster network**, which is a closed network in which only the Kubernetes cluster
    components can talk to one another, even having their own set of IP ranges. How
    do we talk to our pods from the outside? How do we reach our application? This
    is where services come into play.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，通过部署，我们管理我们的pod，并帮助我们将它们保持在我们期望的状态。所有这些pod仍然处于所谓的**集群网络**中，这是一个封闭的网络，其中只有Kubernetes集群组件可以相互通信，甚至有自己的一组IP范围。我们如何从外部与我们的pod通信？我们如何访问我们的应用程序？这就是服务发挥作用的地方。
- en: Services
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务
- en: The name *service* doesn't fully describe what services actually do in Kubernetes.
    Kubernetes services are what route traffic to our pods. We can say that services
    are what tie pods together.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 名称*service*并不能完全描述Kubernetes中服务的实际作用。Kubernetes服务是将流量路由到我们的pod的东西。我们可以说服务是将pod联系在一起的东西。
- en: Let's imagine that we have a typical frontend/backend type of application where
    we have our frontend pods talking to our backend ones via the IP addresses of
    the pods. If a pod in the backend dies, we know that pods are ephemeral and therefore
    we lose communication with our backend, and so now we are in a world of hurt.
    This is not only because the new pod will not have the same IP address of the
    pod that died, but now we also have to reconfigure our app to use the new IP address.
    This issue and similar issues are solved with services.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: A service is a logical object that tells the kube-proxy to create iptables rules
    based on which pods are behind the service. Services configure their endpoints,
    which is how the pods behind a service are called, the same way as deployments
    know which pods to control, the selector field, and the pods' labels.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'This diagram shows you how services use labels to manage traffic:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1a03e05d-be3b-4a05-a7ff-7808314eb329.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
- en: Services will not only make kube-proxy create rules to route traffic; it will
    also trigger something called **kube-dns**.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'Kube-dns is a set of pods with `SkyDNS` containers that run on the cluster that
    provides a DNS server and forwarder, which will create records for services and
    sometimes pods for ease of use. Whenever you create a service, a DNS record pointing
    to the service''s internal cluster ipaddress will be created with the form `service-name.namespace.svc.cluster.local`.
    You can learn more about the Kubernetes DNS specifications on the Kubernetes GitHub
    page: [https://github.com/kubernetes/dns/blob/master/docs/specification.md](https://github.com/kubernetes/dns/blob/master/docs/specification.md).'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Going back to our example, we will now only have to configure our application
    to talk to the service **fully qualified domain name** (**FQDN**) in order to
    talk to our backend pods. This way, it will not matter what IP address the pods
    and services have. If a pod behind the service dies, the service will take care
    of everything by using the A record, as we will be able to tell our frontend to
    route all traffic to my-svc. The logic of the service will take care of everything
    else.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several types of service that you can create whenever you are declaring
    the object to be created in Kubernetes. Let''s go through them to see which one
    will be best suited for the type of work we need:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '**ClusterIP**: This is the default service. Whenever you create a ClusterIP
    service, it will create a service with a cluster-internal IP address that will
    only be routable inside the Kubernetes cluster. This type is ideal for pods that
    only need to talk to one another and not go outside the cluster.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NodePort**: When you create this type of service, by default a random port
    from `30000` to `32767` will be allocated to forward traffic to the endpoint pods
    of the service. You can override this behavior by specifying a node port in the
    `ports` array. Once this is defined you will be able to access your pods via `<Nodes-IP>`:`<Node-Port>`.
    This is useful to access your pods from outside the cluster via the Node IP address.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**LoadBalancer**: Most of the time, you will be running Kubernetes on a cloud
    provider. The LoadBalancer type is ideal for these situations, as you will be
    able to allocate public IP addresses to your service via your cloud provider''s
    API. This is the ideal service for when you want to communicate with your pods
    from outside your cluster. With LoadBalancer, you will be able to not only allocate
    a publicIP address but also, using Azure, allocate a private IP address from your
    virtual private network. So, you can talk to your pods from the internet or internally
    on your private subnet.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s review YAML''s definition of a service:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'A service''s YAML is very simple, and the specs will vary, depending on the
    type of service that you are creating. But the most important thing you have to
    take into account is port definitions. Let''s take a look at these:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '`port`: This is the service port that is exposed'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`port`：这是暴露的服务端口'
- en: '`targetPort`: This is the port on the pods to where the service is sending
    traffic'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`targetPort`：这是服务发送流量到Pod的端口'
- en: '`nodePort`: This is the port that will be exposed'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nodePort`：这是将被暴露的端口。'
- en: Although we now understand how we can communicate with the pods in our cluster,
    we still need to understand how we are going to manage the problem of losing our
    data every time a pod is terminated. This is where **Persistent Volumes** (**PV**)
    comes into play.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们现在了解了如何与集群中的Pods进行通信，但我们仍然需要了解每次Pod终止时我们如何管理丢失数据的问题。这就是**持久卷**（**PV**）发挥作用的地方。
- en: Kubernetes and persistent storage
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes和持久存储
- en: '**Persistent storage** in the container world is a serious issue. When we studied
    Docker images, we learned that the only storage that is persistent across container
    runs are the layers of the image, and they are read-only. The layer where the
    container runs is read/write, but all data in this layer is deleted when the container
    stops. With pods, this is the same. When a container dies, the data written to
    it is gone.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器世界中，**持久存储**是一个严重的问题。当我们学习Docker镜像时，我们了解到唯一持久跨容器运行的存储是镜像的层，而且它们是只读的。容器运行的层是读/写的，但当容器停止时，该层中的所有数据都会被删除。对于Pods来说也是一样的。当容器死掉时，写入其中的数据也会消失。
- en: Kubernetes has a set of objects to handle storage across pods. The first one
    that we will discuss is volumes.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes有一组对象来处理跨Pod的存储。我们将讨论的第一个对象是卷。
- en: Volumes
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷
- en: '**Volumes** solve one of the biggest problems when it comes to persistent storage.
    First of all, volumes are not actually objects, but a definition of a pod''s spec.
    When you create a pod, you can define a volume under the pod''s spec field. Containers
    in this pod will be able to mount the volume on their mount namespace, and the
    volume will be available across container restarts or crashes. Volumes are tied
    to the pods, though, and if the pod is deleted, the volume will be gone as well.
    The data on the volume is another story; data persistence will depend on the backend
    of that volume.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷**解决了持久存储时的最大问题之一。首先，卷实际上不是对象，而是Pod规范的定义。当您创建一个Pod时，您可以在Pod规范字段下定义一个卷。此Pod中的容器将能够在其挂载命名空间上挂载卷，并且卷将在容器重新启动或崩溃时可用。但是，卷与Pod绑定，如果删除Pod，卷也将消失。卷上的数据是另一回事；数据持久性将取决于该卷的后端。'
- en: Kubernetes supports several types of volumes or volume sources and how they
    are called in the API specifications, which range from filesystem maps from the
    local node, cloud providers' virtual disks, and software-defined storage-backed
    volumes. Local filesystem mounts are the most common ones that you will see when
    it comes to regular volumes. It's important to note that the disadvantage of using
    local node filesystems is that the data will not be available across all the nodes
    of the cluster, and just on that node where the pod was scheduled.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes支持多种类型的卷或卷源以及它们在API规范中的称呼，这些类型包括来自本地节点的文件系统映射、云提供商的虚拟磁盘以及软件定义的存储支持的卷。当涉及到常规卷时，本地文件系统挂载是最常见的。需要注意的是使用本地节点文件系统的缺点是数据将不会在集群的所有节点上可用，而只在调度Pod的节点上可用。
- en: 'Let''s examine how a pod with a volume is defined in YAML:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下如何在YAML中定义一个带有卷的Pod：
- en: '[PRE7]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note how there is a field called `volumes` under `spec` and then there is another
    one called `volumeMounts`.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意`spec`下有一个名为`volumes`的字段，然后另一个名为`volumeMounts`。
- en: The first field (`volumes`) is where you define the volume you want to create
    for that pod. This field will always require a name and then a volume source.
    Depending on the source, the requirements will be different. In this example,
    the source would be `hostPath`, which is a node's local filesystem. `hostPath`
    supports several types of mappings, ranging from directories, files, block devices,
    and even Unix sockets.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个字段（`volumes`）是您为该Pod定义要创建的卷的位置。该字段将始终需要一个名称，然后是一个卷源。根据源的不同，要求也会有所不同。在这个例子中，源将是`hostPath`，这是节点的本地文件系统。`hostPath`支持多种类型的映射，从目录、文件、块设备，甚至Unix套接字。
- en: Under the second field, `volumeMounts`, we have `mountPath,` which is where
    you define the path inside the container where you want to mount your volume to.
    The `name` parameter is how you specify to the pod which volume to use. This is
    important because you can have several types of volumes defined under `volumes`,
    and the name will be the only way for the pod to know which volumes mount to which
    container.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二个字段`volumeMounts`下，我们有`mountPath`，这是您在容器内定义要将卷挂载到的路径。`name`参数是您指定给Pod要使用哪个卷的方式。这很重要，因为您可以在`volumes`下定义多种类型的卷，而名称将是Pod知道哪些卷挂载到哪个容器的唯一方式。
- en: We will not be going through all the different types of volumes because it is
    irrelevant to know about them unless you are going to use a specific one. The
    important part is to know that they exist and what type of sources we can have.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会详细介绍所有不同类型的卷，因为除非你要使用特定的卷，否则了解它们是无关紧要的。重要的是要知道它们的存在以及我们可以拥有什么类型的来源。
- en: You can learn more about the different types of volumes in the volume definitions
    in the Kubernetes website ([https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes](https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes))
    and in the Kubernetes API reference document ([https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#volume-v1-core](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#volume-v1-core)).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在Kubernetes网站的卷定义中了解更多关于不同类型的卷（[https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes](https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes)）以及Kubernetes
    API参考文档中的卷定义（[https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#volume-v1-core](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#volume-v1-core)）。
- en: Having volumes die with the pods is not ideal. We require storage that persists,
    and this is how the need for PVs came to be.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 让卷随Pod一起消失并不理想。我们需要持久存储，这就是PV的需求产生的原因。
- en: Persistent Volumes, Persistent Volume Claims, and Storage Classes
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 持久卷、持久卷索赔和存储类别
- en: The main difference between volumes and PVs is that, unlike volumes, PVs are
    actually Kubernetes API objects, so you can manage them individually like separate
    entities, and therefore they persist even after a pod is deleted.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 卷和PV之间的主要区别在于，与卷不同，PV实际上是Kubernetes API对象，因此您可以像单独的实体一样单独管理它们，因此它们甚至在删除pod后仍然存在。
- en: You might be wondering why this subsection has PV, **persistent volume claims**
    (**PVCs**), and storage classes all mixed in. This is because we can't talk about
    one without talking about the others; all of them depend on one another, and it
    is crucial to understand how they interact among one another to provision storage
    for our pods.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能想知道为什么这个小节中混合了PV、持久卷索赔（PVC）和存储类别。这是因为我们不能谈论其中一个而不谈论其他；它们都彼此依赖，了解它们如何相互作用以为我们的pod提供存储是至关重要的。
- en: Let's begin with PVs and PVCs. Like volumes, PVs have a storage source, so the
    same mechanism that volumes have applies here. You will either have a software-defined
    storage cluster providing **logical unit number** (**LUNs**), a cloud provider
    giving virtual disks, or even a local filesystem to the Kubernetes node, but here,
    instead of being called volume sources, they are called **persistent volume types **instead.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从PV和PVC开始。与卷一样，PV具有存储源，因此卷具有的相同机制在这里也适用。您可以有一个软件定义的存储集群提供**逻辑单元号**（**LUNs**），云提供商提供虚拟磁盘，甚至是本地文件系统提供给Kubernetes节点，但是这里，它们被称为**持久卷类型**而不是卷源。
- en: 'PVs are pretty much like LUNs in a storage array: you create them, but without
    a mapping; they are just a bunch of allocated storage waiting to be used. Here
    is where PVCs come into play. PVCs are like LUN mappings: they are backed or bound
    to a PV and also are what you actually define, relate, and make available to the
    pod that it can then use for its containers.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: PV基本上就像存储阵列中的LUN：您创建它们，但没有映射；它们只是一堆已分配的存储，等待使用。这就是PVC发挥作用的地方。PVC就像LUN映射：它们支持或绑定到PV，也是您实际定义、关联和提供给pod以供其容器使用的东西。
- en: 'The way you use PVCs on pods is exactly the same as with normal volumes. You
    have two fields: one to specify which PVC you want to use, and the other one to
    tell the pod on which container to use that PVC.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 您在pod上使用PVC的方式与普通卷完全相同。您有两个字段：一个用于指定要使用的PVC，另一个用于告诉pod要在哪个容器上使用该PVC。
- en: 'The YAML for a PVC API object definition should have the following code:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: PVC API对象定义的YAML应该包含以下代码：
- en: '[PRE8]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The YAML for `pod` should have the following code:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '`pod`的YAML应该包含以下代码：'
- en: '[PRE9]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'When a Kubernetes administrator creates a PVC, there are two ways that this
    request is satisfied:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 当Kubernetes管理员创建PVC时，有两种方式可以满足此请求：
- en: '**Static**: Several PVs have already been created, and then when a user creates
    a PVC, any available PV that can satisfy the requirements will be bound to that
    PVC.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**静态**：已经创建了几个PV，然后当用户创建PVC时，可以满足要求的任何可用PV都将绑定到该PVC。'
- en: '**Dynamic**: Some PV types can create PVs based on PVC definitions. When a
    PVC is created, the PV type will dynamically create a PV object and allocate the
    storage in the backend; this is dynamic provisioning. The catch with dynamic provisioning
    is that you require a third type of Kubernetes storage object, called a **storage
    class**.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动态**：某些PV类型可以根据PVC定义创建PV。创建PVC时，PV类型将动态创建PV对象并在后端分配存储；这就是动态配置。动态配置的关键在于您需要第三种Kubernetes存储对象，称为**存储类别**。'
- en: Storage classes are like a way of **tiering** your storage. You can create a
    class that provisions slow storage volumes, or another one with hyper-fast SSD
    drives. However, storage classes are a little bit more complex than just tiering.
    As we mentioned in the two ways of creating a PVC, storage classes are what make
    dynamic provisioning possible. When working on a cloud environment, you don't
    want to be manually creating every backend disk for every PV. Storage classes
    will set up something called a **provisioner**, which invokes the volume plugin
    that's necessary to talk to your cloud provider's API. Every provisioner has its
    own settings so that it can talk to the specified cloud provider or storage provider.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 存储类别就像是对存储进行**分层**的一种方式。您可以创建一个类别，用于提供慢速存储卷，或者另一个类别，其中包含超快速SSD驱动器。但是，存储类别比仅仅分层要复杂一些。正如我们在创建PVC的两种方式中提到的，存储类别是使动态配置成为可能的关键。在云环境中工作时，您不希望手动为每个PV创建每个后端磁盘。存储类别将设置一个称为**提供程序**的东西，它调用必要的卷插件以与您的云提供商的API进行通信。每个提供程序都有自己的设置，以便它可以与指定的云提供商或存储提供商进行通信。
- en: 'You can provision storage classes in the following way; this is an example
    of a storage class using Azure-disk as a disk provisioner:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以按以下方式配置存储类别；这是一个使用Azure-disk作为磁盘提供程序的存储类别的示例：
- en: '[PRE10]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Each storage class provisioner and PV type will have different requirements
    and parameters, as well as volumes, and we have already had a general overview
    of how they work and what we can use them for. Learning about specific storage
    classes and PV types will depend on your environment; you can learn more about
    each one of them by clicking on the following links:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 每个存储类别的提供程序和PV类型都有不同的要求和参数，以及卷，我们已经对它们的工作原理和用途有了一个总体概述。了解特定的存储类别和PV类型将取决于您的环境；您可以通过点击以下链接了解它们中的每一个：
- en: '[https://kubernetes.io/docs/concepts/storage/storage-classes/#provisioner](https://kubernetes.io/docs/concepts/storage/storage-classes/#provisioner)'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://kubernetes.io/docs/concepts/storage/storage-classes/#provisioner](https://kubernetes.io/docs/concepts/storage/storage-classes/#provisioner)'
- en: '[https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes)'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes)'
- en: Summary
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about what Kubernetes is, its components, and what
    the advantages of using orchestration are.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了Kubernetes是什么，它的组件，以及使用编排的优势。
- en: You should now be able to identify each of the Kubernetes API objects, their
    purpose, and their use cases. You should be able to understand how the master
    nodes control the cluster and the scheduling of the containers in the worker nodes.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您应该能够识别每个Kubernetes API对象，它们的目的和用例。您应该能够理解主节点如何控制集群以及工作节点中容器的调度。
- en: Questions
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is Kubernetes?
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是Kubernetes？
- en: What are the components of Kubernetes?
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes的组件是什么？
- en: What are Kubernetes's API objects?
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes的API对象是什么？
- en: What can we do with Kubernetes?
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以用Kubernetes做什么？
- en: What is a container orchestrator?
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是容器编排器？
- en: What is a pod?
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是Pod？
- en: What is a deployment?
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是部署？
- en: Further reading
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*Mastering Kubernetes*, by Packt Publishing: [https://prod.packtpub.com/in/virtualization-and-cloud/mastering-kubernetes](https://prod.packtpub.com/in/virtualization-and-cloud/mastering-kubernetes)'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*精通Kubernetes*，由Packt Publishing出版：[https://prod.packtpub.com/in/virtualization-and-cloud/mastering-kubernetes](https://prod.packtpub.com/in/virtualization-and-cloud/mastering-kubernetes)'
- en: '*Kubernetes for Developers*, by Packt Publishing: [https://prod.packtpub.com/in/virtualization-and-cloud/kubernetes-developers](https://prod.packtpub.com/in/virtualization-and-cloud/kubernetes-developers)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*面向开发人员的Kubernetes*，由Packt Publishing出版：[https://prod.packtpub.com/in/virtualization-and-cloud/kubernetes-developers](https://prod.packtpub.com/in/virtualization-and-cloud/kubernetes-developers)'
- en: '*Getting Started with Kubernetes*, by Packt Publishing: [https://prod.packtpub.com/in/virtualization-and-cloud/getting-started-kubernetes-third-edition](https://prod.packtpub.com/in/virtualization-and-cloud/getting-started-kubernetes-third-edition)'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*开始使用Kubernetes*，由Packt Publishing出版：[https://prod.packtpub.com/in/virtualization-and-cloud/getting-started-kubernetes-third-edition](https://prod.packtpub.com/in/virtualization-and-cloud/getting-started-kubernetes-third-edition)'

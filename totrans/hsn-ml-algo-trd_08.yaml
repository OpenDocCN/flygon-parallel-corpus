- en: Time Series Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列模型
- en: In the last chapter, we focused on linear models tailored to cross-sectional
    data where the input data belongs to the same time period as the output they aim
    to explain or predict. In this chapter, we will focus on time series data where
    observations differ by period, which also creates a natural ordering. Our goal
    will be to identify historical patterns in data and leverage these patterns to
    predict how the time series will behave in the future.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们专注于适用于横截面数据的线性模型，其中输入数据属于与其旨在解释或预测的输出相同的时间段。在本章中，我们将专注于时间序列数据，其中观察值因期间而异，这也产生了自然的排序。我们的目标将是识别数据中的历史模式，并利用这些模式来预测时间序列在未来的行为。
- en: We already encountered panel data with both a cross-sectional and a time series
    dimension in the last chapter and learned how the Fama-Macbeth regression estimates
    the value of taking certain factor risks over time and across assets. However,
    the relationship between returns across time is typically fairly low, so this
    procedure could largely ignore the time dimension. The models in this chapter
    focus on time series models where past values contain predictive signals about
    future developments. Time series models can also predict features that are then
    used in cross-sectional models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们已经遇到了具有横截面和时间序列维度的面板数据，并学习了Fama-Macbeth回归如何估计随时间和跨资产采取某些因子风险的价值。然而，随时间的回报之间的关系通常相当低，因此这个过程可能会大部分忽略时间维度。本章的模型侧重于时间序列模型，其中过去的值包含有关未来发展的预测信号。时间序列模型还可以预测然后用于横截面模型的特征。
- en: More specifically, in this chapter, we focus on models that extract signals
    from previously observed data to predict future values for the same time series. The
    time dimension of trading makes the application of time series models to market,
    fundamental, and alternative data very popular. Time series data will become even
    more prevalent as an ever broader array of connected devices collects regular
    measurements that may contain predictive signals. Key applications include the
    prediction of asset returns, correlations or covariances, or volatility.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，在本章中，我们将重点放在从先前观察到的数据中提取信号以预测相同时间序列的未来值的模型上。交易的时间维度使得将时间序列模型应用于市场、基本和替代数据非常受欢迎。随着越来越广泛的连接设备收集可能包含预测信号的定期测量，时间序列数据将变得更加普遍。关键应用包括资产回报、相关性或协方差、波动性的预测。
- en: We focus on linear time series models in this chapter as a baseline for non-linear
    models like recurrent or convolutional neural networks that we apply to time series
    data in part 4 of this book. We being by introducing tools to diagnose time series
    characteristics, including stationarity, and extract features that capture potential
    patterns. Then we introduce univariate and multivariate time series models and
    apply them to forecast macro data and volatility patterns. We conclude with the
    concept of cointegration and how to apply it to develop a pairs trading strategy.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将线性时间序列模型作为基线，用于本书第4部分中应用于时间序列数据的非线性模型，如循环或卷积神经网络。我们首先介绍诊断时间序列特征的工具，包括平稳性，并提取捕捉潜在模式的特征。然后我们介绍单变量和多变量时间序列模型，并将它们应用于预测宏观数据和波动模式。最后，我们介绍协整概念以及如何应用它来开发配对交易策略。
- en: 'In particular, we will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，我们将涵盖以下主题：
- en: How to use time series analysis to diagnose diagnostic statistics that inform
    the modeling process
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用时间序列分析来诊断信息建模过程的诊断统计
- en: How to estimate and diagnose autoregressive and moving-average time series models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何估计和诊断自回归和移动平均时间序列模型
- en: How to build Autoregressive Conditional Heteroskedasticity (ARCH) models to
    predict volatility
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何构建自回归条件异方差（ARCH）模型来预测波动性
- en: How to build vector autoregressive models
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何构建向量自回归模型
- en: How to use cointegration for a pairs trading strategy
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用协整来进行配对交易策略
- en: Analytical tools for diagnostics and feature extraction
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 诊断和特征提取的分析工具
- en: Time series data is a sequence of values separated by discrete time intervals
    that are typically even-spaced (except for missing values). A time series is often
    modeled as a stochastic process consisting of a collection of random variables,
    y(t[1]), ..., y(t[T]), with one variable for each point in time, t[i ], i=1, ...,
    T. A univariate time series consists of a single value, y, at each point in time,
    whereas a multivariate time series consists of several observations that can be
    represented by a vector.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据是一系列由离散时间间隔分隔的值，通常是均匀间隔的（除了缺失值）。时间序列通常被建模为由一组随机变量组成的随机过程，y(t[1]), ...,
    y(t[T])，每个时间点t[i]都有一个变量，i=1, ..., T。单变量时间序列由每个时间点上的单个值y组成，而多变量时间序列由几个观测值组成，可以用向量表示。
- en: The number of periods, Δt= t[i] - t[j], between distinct points in time, t[i], t[j],
    is called lag, with T-1 lags for each time series. Just as relationships between
    different variables at a given point in time is key for cross-sectional models,
    relationships between data points separated by a given lag are fundamental to
    analyzing and exploiting patterns in time series. For cross-sectional models,
    we distinguished between input and output variables, or target and predictors,
    with the labels y and x, respectively. In a time series context, the lagged values
    of the outcome play the role of the input or x values in the cross-section context.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 不同时间点t[i]，t[j]之间的周期数Δt= t[i] - t[j]称为滞后，每个时间序列有T-1个滞后。就像在给定时间点上不同变量之间的关系对于横截面模型至关重要一样，由给定滞后分隔的数据点之间的关系对于分析和利用时间序列中的模式至关重要。对于横截面模型，我们区分输入和输出变量，或目标和预测变量，分别用y和x标签。在时间序列环境中，结果的滞后值扮演了横截面环境中输入或x值的角色。
- en: A time series is called white noiseif it is a sequence of independent and identically-distributed
    random variables, ε[t], with finite mean and variance. In particular, the series
    is called a Gaussian white noise if the random variables are normally distributed
    with a mean of zero and a constant variance of σ.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果时间序列是独立同分布的随机变量ε[t]序列，并且具有有限的均值和方差，则称为白噪声时间序列。特别地，如果随机变量服从均值为零、方差为σ的正态分布，则称为高斯白噪声。
- en: 'A time series is linear if it can be written as a weighted sum of past disturbances,
    ε[t], that are also called innovations, and are here assumed to represent white
    noise, and the mean of the series, μ:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果时间序列可以被写成过去扰动ε[t]的加权和，ε[t]也称为创新，并且在这里假定代表白噪声，以及系列的均值μ，则时间序列是线性的。
- en: '![](img/fbe56b58-d93c-4878-ba0a-b61e2e545898.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fbe56b58-d93c-4878-ba0a-b61e2e545898.png)'
- en: A key goal of time series analysis is to understand the dynamic behavior driven
    by the coefficients, a[i]. The analysis of time series offers methods tailored
    to this type of data with the goal of extracting useful patterns that, in turn,
    help us to build predictive models. We will introduce the most important tools
    for this purpose, including the decomposition into key systematic elements, the
    analysis of autocorrelation, and rolling window statistics such as moving averages.
    Linear time series models often make certain assumptions about the data, such
    as stationarity, and we will also introduce both the concept, diagnostic tools,
    and typical transformations to achieve stationarity.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列分析的一个关键目标是理解由系数a[i]驱动的动态行为。时间序列分析提供了针对这种类型数据量身定制的方法，旨在提取有用的模式，进而帮助我们构建预测模型。我们将介绍实现这一目的的最重要工具，包括分解为关键系统元素、自相关分析和移动平均等滚动窗口统计。线性时间序列模型通常对数据做出某些假设，例如平稳性，我们还将介绍该概念、诊断工具和实现平稳性的典型转换。
- en: For most of the examples in this chapter, we work with data provided by the
    Federal Reserve that you can access using the `pandas datareader` that we introduced
    in [Chapter 2](e7bd6fc7-7ef7-4c4e-acec-ac1d083f8902.xhtml), *Market and Fundamental
    Data*. The code examples for this section are available in the notebook `tsa_and_arima` notebook.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的大多数示例中，我们使用美联储提供的数据，您可以使用我们在[第2章](e7bd6fc7-7ef7-4c4e-acec-ac1d083f8902.xhtml)介绍的`pandas
    datareader`来访问。本节的代码示例可在`tsa_and_arima`笔记本中找到。
- en: How to decompose time series patterns
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何分解时间序列模式
- en: Time series data typically contains a mix of various patterns that can be decomposed
    into several components, each representing an underlying pattern category. In
    particular, time series often consist of the systematic components trend, seasonality
    and cycles, and unsystematic noise. These components can be combined in an additive,
    linear model, in particular when fluctuations do not depend on the level of the
    series, or in a non-linear, multiplicative model.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据通常包含各种模式的混合，可以将其分解为几个组件，每个组件代表一个基础模式类别。特别是，时间序列通常由系统组件趋势、季节性和周期性以及非系统噪声组成。这些组件可以以加法线性模型的形式组合，特别是当波动不依赖于系列水平时，或者以非线性乘法模型的形式组合。
- en: 'These components can be split up automatically. `statsmodels` includes a simple
    method to split the time series into a trend, seasonal, and residual component
    using moving averages. We can apply it to monthly data on industrial manufacturing
    production with both a strong trend and seasonality component, as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这些组件可以自动拆分。`statsmodels`包括一种简单的方法，使用移动平均将时间序列拆分为趋势、季节和残差组件。我们可以将其应用于工业制造生产的月度数据，该数据具有强劲的趋势和季节性组件，如下所示：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The resulting charts show the additive components. The residual component would
    be the focus of additional modeling, assuming that the trend and seasonality components
    are more deterministic and amenable to simple extrapolation:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图表显示了加法组件。残差组件将成为额外建模的重点，假设趋势和季节性组件更具决定性，并且易于简单外推：
- en: '![](img/088daf58-8022-4521-ad95-6bb39e843681.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/088daf58-8022-4521-ad95-6bb39e843681.png)'
- en: There are more sophisticated, model-based approaches that are included in the
    references available on GitHub.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub上提供了更复杂的基于模型的方法。
- en: How to compute rolling window statistics
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何计算滚动窗口统计
- en: Given the sequential ordering of time series data, it is natural to compute
    familiar descriptive statistics for periods of a given length to detect stability
    or changes in behavior and obtain a smoothed representation that captures systematic
    aspects while filtering out the noise.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于时间序列数据的顺序排列，自然而然地计算给定长度的周期的熟悉描述性统计量，以检测行为的稳定性或变化，并获得捕捉系统方面的平滑表示，同时滤除噪声。
- en: 'Rolling window statistics serve this process: they produce a new time series
    where each data point represents a summary statistic computed for a certain period
    of the original data. Moving averages are the most familiar example. The original
    data points can enter the computation with equal weights, or using weights to,
    for example, emphasize more recent data points. Exponential moving averages recursively
    compute weights that shrink or decay, for data points further away from the present.
    The new data points are typically a summary of all preceding data points, but
    they can also be computed from a surrounding window.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动窗口统计有助于这一过程：它们生成一个新的时间序列，其中每个数据点代表原始数据的一定期间内计算的摘要统计量。移动平均是最熟悉的例子。原始数据点可以以相等的权重进入计算，也可以使用权重，例如，强调更近期的数据点。指数移动平均递归地计算权重，使得距离现在更远的数据点权重缩小或衰减。新的数据点通常是所有先前数据点的摘要，但也可以从周围的窗口计算得出。
- en: The `pandas` library includes very flexible functionality to define various
    window types, including rolling, exponentially weighted and expanding windows.
    In a second step, you can apply computations to each data captured by a window.
    These computations include built-in standard computations for individual series,
    such as the mean or the sum, the correlation or covariance for several series,
    as well as user-defined functions. The moving average and exponential smoothing
    examples in the following section make use of these tools.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`库包括非常灵活的功能，可以定义各种窗口类型，包括滚动窗口、指数加权窗口和扩展窗口。在第二步中，可以对窗口捕获的每个数据应用计算。这些计算包括内置的用于单个系列的标准计算，如均值或总和，多个系列的相关性或协方差，以及用户定义的函数。以下部分中的移动平均和指数平滑示例利用了这些工具。'
- en: Moving averages and exponential smoothing
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '![](img/4e519202-2131-436c-91f7-b965dc3cc44e.png)'
- en: Early forecasting models included moving-average models with exponential weights called exponential
    smoothing models. We will encounter moving averages again as key building blocks
    for linear time series.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 自相关（也称为串行相关）将相关性的概念应用到时间序列的上下文中：正如相关系数衡量两个变量之间线性关系的强度一样，自相关系数ρ[k]衡量相隔给定滞后k的时间序列值之间线性关系的程度。
- en: Forecasts that rely on exponential smoothing methods use weighted averages of
    past observations, where the weights decay exponentially as the observations get
    older. Hence, a more recent observation receives a higher associated weight. These
    methods are popular for time series that do not have very complicated or abrupt
    patterns.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖指数平滑方法的预测使用过去观察的加权平均，其中权重随着观察变老而呈指数衰减。因此，较新的观察获得更高的相关权重。这些方法在没有非常复杂或突然模式的时间序列中很受欢迎。
- en: Exponential smoothing is a popular technique based on weighted averages of past
    observations, with the weights decaying exponentially as the observations get
    older. In other words, the more recent the observation, the higher the associated
    weight. This framework generates reliable forecasts quickly and for a wide range
    of time series, which is a great advantage and of major importance to applications
    in industry.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 指数平滑是一种基于过去观察的加权平均的流行技术，权重随着观察变老而呈指数衰减。换句话说，观察越近，相关权重越高。这个框架可以快速生成可靠的预测，适用于广泛的时间序列，这是一个巨大的优势，对于工业应用来说非常重要。
- en: How to measure autocorrelation
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何诊断和实现平稳性
- en: 'Autocorrelation (also called serial correlation) adapts the concept of correlation
    to the time series context: just as the correlation coefficient measures the strength
    of a linear relationship between two variables, the autocorrelation coefficient,
    ρ[k], measures the extent of a linear relationship between time series values
    separated by a given lag, k:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如何测量自相关
- en: '![](img/4e519202-2131-436c-91f7-b965dc3cc44e.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: 早期的预测模型包括带有指数权重的移动平均模型，称为指数平滑模型。我们将再次遇到移动平均作为线性时间序列的关键构建模块。
- en: Hence, we can calculate one autocorrelation coefficient for each of the T-1
    lags in a time series; T is the length of the series. The autocorrelation function
    (ACF) computes the correlation coefficients as a function of the lag.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以计算时间序列中T-1个滞后的每个自相关系数；T是序列的长度。自相关函数（ACF）计算滞后的相关系数。
- en: The autocorrelation for a lag larger than 1 (that is, between observations more
    than one time step apart) reflects both the direct correlation between these observations
    and the indirect influence of the intervening data points. The partial autocorrelation
    removes this influence and only measures the linear dependence between data points
    at the given lag distance. The **partial autocorrelation function** (**PACF**)
    provides all the correlations that result once the effects of a correlation at
    shorter lags have been removed.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 滞后大于1的自相关（即相隔一个以上时间步的观察之间）反映了这些观察之间的直接相关性以及中间数据点的间接影响。偏自相关去除了这种影响，只测量给定滞后距离处数据点之间的线性依赖关系。**偏自相关函数**（PACF）提供了一旦较短滞后的相关性效应被移除后的所有相关性。
- en: There are algorithms that estimate the partial autocorrelation from the sample
    autocorrelation based on the exact theoretical relationship between the PACF and
    the ACF.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 有算法可以根据样本自相关来估计偏自相关，这是基于偏自相关函数（PACF）和自相关函数（ACF）之间的精确理论关系。
- en: A correlogram is simply a plot of the ACF or PACF for sequential lags, k=0,1,...,n.
    It allows us to inspect the correlation structure across lags at one glance. The
    main usage of correlograms is to detect any autocorrelation after the removal
    of the effects of deterministic trend or seasonality. Both the ACF and the PACF
    are key diagnostic tools for the design of linear time series models and we will
    review examples of ACF and PACF plots in the following section on time series
    transformations.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 移动平均和指数平滑
- en: How to diagnose and achieve stationarity
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个**自相关图**简单地是顺序滞后k=0,1,...,n的ACF或PACF的绘图。它允许我们一目了然地检查各个滞后的相关结构。自相关图的主要用途是在去除确定性趋势或季节性效应后检测任何自相关。ACF和PACF都是线性时间序列模型设计的关键诊断工具，我们将在以下时间序列转换部分中回顾ACF和PACF图的示例。
- en: The statistical properties, such as the mean, variance, or autocorrelation,
    of a stationary time series are independent of the period, that is, they don't
    change over time. Hence, stationarity implies that a time series does not have
    a trend or seasonal effects and that descriptive statistics, such as the mean
    or the standard deviation, when computed for different rolling windows, are constant
    or do not change much over time. It reverts to its mean, and the deviations have
    constant amplitude, while short-term movements always look the same in the statistical
    sense.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: More formally, strict stationarity requires the joint distribution of any subset
    of time series observations to be independent of time with respect to all moments.
    So, in addition to the mean and variance, higher moments such as skew and kurtosis,
    also need to be constant, irrespective of the lag between different observations. In
    most applications, we limit stationarity to first and second moments so that the
    time series is covariance stationary with constant mean, variance, and autocorrelation.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Note that we specifically allow for dependence between observations at different
    lags, just like we want the input data for linear regression to be correlated
    with the outcome. Stationarity implies that these relationships are stable, which
    facilitates prediction as the model can focus on learning systematic patterns that
    take place within stable statistical properties. It is important because classical
    statistical models assume that the time series input data is stationary.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: The following sections introduce diagnostics that help detect when data is not
    stationary, and transformations that help meet these assumptions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Time series transformations
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To satisfy the stationarity assumption of linear time series models, we need
    to transform the original time series, often in several steps. Common transformations
    include the application of the (natural) logarithm to convert an exponential growth
    pattern into a linear trend and stabilize the variance. Deflation implies dividing
    a time series by another series that causes trending behavior, for example dividing
    a nominal series by a price index to convert it into a real measure.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: A series is trend-stationary if it reverts to a stable long-run linear trend.
    It can often be made stationary by fitting a trend line using linear regression
    and using the residuals, or by including the time index as an independent variable
    in a regression or AR(I)MA model (see the following section on univariate time
    series models), possibly combined with logging or deflating.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, de-trending is not sufficient to make the series stationary.
    Instead, we need to transform the original data into a series of period-to-period
    and/or season-to-season differences. In other words, we use the result of subtracting
    neighboring data points or values at seasonal lags from each other. Note that
    when such differencing is applied to a log-transformed series, the results represent
    instantaneous growth rates or returns in a financial context.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: If a univariate series becomes stationary after differencing d times, it is
    said to be integrated of the order of d, or simply integrated if d=1\. This behavior
    is due to so-called unit roots.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: How to diagnose and address unit roots
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Unit roots pose a particular problem for determining the transformation that
    will render a time series stationary. Time series are often modeled as stochastic
    processes of the following autoregressive form that we will explore in more detail
    as a building block for ARIMA models:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0f3427e1-6785-42b4-bd13-5bb27580a047.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
- en: 'Where the current value is a weighted sum of past values plus a random disturbance.
    Such a process has a characteristic equation of the following form:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/374eda4c-1907-4c05-895e-61937733ba69.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
- en: If one of the roots of this equation equals 1, then the process is said to have
    a unit root. It will be non-stationary but does not necessarily need to have a
    trend. If the remaining roots of the characteristic equation are less than 1 in
    absolute terms, the first difference of the process will be stationary, and the
    process is integrated (of order 1) or I(1). With additional roots larger than
    1 in absolute terms, the order of integration is higher and additional differencing
    will be required.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这个方程的一个根等于1，那么该过程被称为具有单位根。它将是非平稳的，但不一定需要趋势。如果特征方程的其余根绝对值小于1，该过程的一阶差分将是平稳的，该过程是积分的（一阶）或I(1)。如果附加根的绝对值大于1，积分的阶数更高，需要额外的差分。
- en: 'In practice, time series of interest rates or asset prices are often not stationary,
    for example, because there does not exist a price level to which the series reverts.
    The most prominent example of a non-stationary series is the random walk for a
    time series of price, p[t], for a given starting price, p[0] (for example, a stock''s
    IPO price) and a white-noise disturbance, ε, that satisfies the following:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，利率或资产价格的时间序列通常不是平稳的，例如，因为不存在一个价格水平使得序列回归。非平稳序列的最典型例子是价格的随机漫步时间序列，对于给定的起始价格p[0]（例如，股票的首次公开发行价格）和满足以下条件的白噪声扰动ε：
- en: '![](img/5816ce83-e27e-4cff-92fd-1e39ff3715ac.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5816ce83-e27e-4cff-92fd-1e39ff3715ac.png)'
- en: 'Repeated substitution shows that the current value, p[t], is the sum of all
    prior disturbances or innovations, ε, and the initial price, p[0]. If the equation
    includes a constant term, then the random walk is said to have drift. Hence, the
    random walk is an autoregressive stochastic process of the following form:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 重复替换表明，当前值p[t]是所有先前扰动或创新ε和初始价格p[0]的总和。如果方程包括一个常数项，那么随机漫步被称为具有漂移。因此，随机漫步是以下形式的自回归随机过程：
- en: '![](img/54d1d25c-1e8d-4488-a0bc-9f79338dda70.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/54d1d25c-1e8d-4488-a0bc-9f79338dda70.png)'
- en: With the characteristic equation, ![](img/2681505a-2a2e-4c17-90fb-865d2d7c55e7.png),
    that has a unit root and is both non-stationary and integrated of order 1. On
    the one hand, given the i.i.d. nature of ε, the variance of the time series equals σ²,
    which is not second-order stationary and implies that, in principle, the series
    could, over time, assume any variable. On the other hand, taking the first difference, Δp[t=]p[t]-p[t-1],
    leaves Δp[t]=ε [t], which is stationary, given the statistical assumption about ε.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 具有单位根的特征方程，![](img/2681505a-2a2e-4c17-90fb-865d2d7c55e7.png)，既具有单位根，又是非平稳的，积分阶数为1。一方面，鉴于ε的i.i.d.性质，时间序列的方差等于σ²，这不是二阶平稳的，这意味着原则上，该序列随时间可以假定任何变量。另一方面，进行一阶差分，Δp[t=]p[t]-p[t-1]，得到Δp[t]=ε [t]，这是平稳的，根据对ε的统计假设。
- en: 'The defining characteristic of a unit-root non-stationary series is long memory:
    since current values are the sum of past disturbances, large innovations persist
    for much longer than for a mean-reverting, stationary series.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 单位根非平稳序列的定义特征是长期记忆：由于当前值是过去扰动的总和，大的创新比均值回归的平稳序列持续时间更长。
- en: In addition to using the difference between neighboring data points to remove
    a constant pattern of change, it can be used to apply seasonal differencing to
    remove patterns of seasonal change. This involves taking the difference of values
    at a lag distance that represents the length of a seasonal pattern, which is four
    quarters, or 12 months, apart to remove both seasonality and linear trend.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用相邻数据点之间的差异来消除恒定的变化模式外，还可以使用季节性差分来消除季节性变化的模式。这涉及到在代表季节模式长度的滞后距离上取值的差异，这些值相隔四个季度或12个月，以消除季节性和线性趋势。
- en: 'Identifying the correct transformation, and in particular, the appropriate
    number and lags for differencing is not always clear-cut. Some rules have been
    suggested, summarized as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 确定正确的转换，特别是适当的差分数量和滞后并不总是清晰明了。一些规则已经被提出，总结如下：
- en: '**Positive autocorrelations up to 10+ lags**: Probably needs higher-order differencing.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正自相关延迟至10个以上**：可能需要更高阶的差分。'
- en: '**Lag-1 autocorrelation close to zero or negative, or generally small and patternless**:
    No need for higher-order differencing.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**滞后1阶自相关接近零或为负，或者一般较小且无规律**：不需要更高阶的差分。'
- en: '**Lag-1 autocorrelation < -0.5**: Series may be over-differenced.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**滞后1阶自相关<-0.5**：序列可能过度差分。'
- en: Slightly over- or under-differencing can be corrected with AR or MA terms.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轻微过度或不足的差分可以通过AR或MA项进行校正。
- en: Optimal differencing often produces the lowest standard deviation, but not always.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最佳差分通常会产生最低的标准差，但并非总是如此。
- en: A model without differencing assumes that the original series is stationary,
    including mean-reverting. It normally includes a constant term to allow for a
    non-zero mean.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无差分模型假设原始序列是平稳的，包括均值回归。通常包括一个常数项以允许非零均值。
- en: A model with one order of differencing assumes that the original series has
    a constant average trend and should include a constant term.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一阶差分模型假设原始序列具有恒定的平均趋势，并应包括一个常数项。
- en: A model with two orders of differencing assumes that the original series has
    a time-varying trend and should not include a constant.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二阶差分模型假设原始序列具有时变趋势，并且不应包括一个常数项。
- en: Some authors recommend fractional differencing as a more flexible approach to
    rendering an integrated series stationary and may be able to keep more information
    or signal than simple or seasonal differences at discrete intervals (see references
    on GitHub).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一些作者建议使用分数差分作为使积分序列平稳的更灵活的方法，可能能够在离散间隔上保留更多信息或信号（请参阅GitHub上的参考资料）。
- en: Unit root tests
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单位根检验
- en: Statistical unit root tests are a common way to determine objectively whether
    (additional) differencing is necessary. These are statistical hypothesis tests
    of stationarity that are designed to determine whether differencing is required.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: The augmented Dickey-Fuller (ADF) test evaluates the null hypothesis that a
    time series sample has unit root against the alternative of stationarity. It regresses
    the differenced time series on a time trend, the first lag, and all lagged differences,
    and computes a test statistic from the value of the coefficient on the lagged
    time series value. `statsmodels` makes it easy to implement (see companion notebook).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: 'Formally, the ADF test for a time series, y[t], runs the linear regression:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8315a158-09a5-4724-bf8e-54157d7c6344.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
- en: Where α is a constant, β is a coefficient on a time trend, and p refers to the
    number of lags used in the model. The α=β =0 constraint implies a random walk,
    whereas only β=0 implies a random walk with drift. The lag order is usually decided
    using the AIC and BIC information criteria introduced in [Chapter 7](0cf85bb4-8b3f-4f83-b004-f980f348028b.xhtml),
    *Linear Models*.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: The ADF test statistics uses the sample coefficient, γ, that, under the null
    hypothesis of unit-root non-stationarity equals zero, and is negative otherwise.
    It intends to demonstrate that, for an integrated series, the lagged series value
    should not provide useful information in predicting the first difference above
    and beyond lagged differences.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: How to apply time series transformations
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following chart shows time series for the NASDAQ stock index and industrial
    production for the 30 years through 2017 in original form, as well as the transformed
    versions after applying the logarithm and subsequently applying first and seasonal
    differences (at lag 12), respectively. The charts also display the ADF p-value,
    which allows us to reject the hypothesis of unit-root non-stationarity after all
    transformations in both cases:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2dd91936-2438-49d2-90f2-b7c80bc85a9a.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
- en: We can further analyze the relevant time series characteristics for the transformed
    series using a Q-Q plot that compares the quantiles of the distribution of the
    time series observation to the quantiles of the normal distribution and the correlograms
    based on the ACF and PACF.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: 'For the NASDAQ plot, we notice that while there is no trend, the variance is
    not constant but rather shows clustered spikes around periods of market turmoil
    in the late 1980s, 2001, and 2008\. The Q-Q plot highlights the fat tails of the
    distribution with extreme values more frequent than the normal distribution would
    suggest. The ACF and the PACF show similar patterns with autocorrelation at several
    lags appearing significant:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1238bca1-4c4f-490c-b75b-fd6fc84a22f1.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
- en: 'For the monthly time series on industrial manufacturing production, we notice
    a large negative outlier following the 2008 crisis as well as the corresponding
    skew in the Q-Q plot. The autocorrelation is much higher than for the NASDAQ returns
    and declines smoothly. The PACF shows distinct positive autocorrelation patterns
    at lag 1 and 13, and significant negative coefficients at lags 3 and 4:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b5f655fd-0f48-43ad-949a-5f4205ae9053.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
- en: Univariate time series models
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multiple linear-regression models expressed the variable of interest as a linear
    combination of predictors or input variables. Univariate time series models relate the
    value of the time series at the point in time of interest to a linear combination
    of lagged values of the series and possibly past disturbance terms.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: 'While exponential smoothing models are based on a description of the trend
    and seasonality in the data, ARIMA models aim to describe the autocorrelations
    in the data. ARIMA(p, d, q) models require stationarity and leverage two building
    blocks:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '**Autoregressive** (**AR**) terms consisting of p-lagged values of the time
    series'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Moving average** (**MA**) terms that contain q-lagged disturbances'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The I stands for integrated because the model can account for unit-root non-stationarity
    by differentiating the series d times. The term autoregression underlines that
    ARIMA models imply a regression of the time series on its own values.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: We will introduce the ARIMA building blocks, simple autoregressive (AR) and
    moving average (MA) models, and explain how to combine them in autoregressive
    moving-average (ARMA) models that may account for series integration as ARIMA
    models or include exogenous variables as AR(I)MAX models. Furthermore, we will
    illustrate how to include seasonal AR and MA terms to extend the toolbox to also
    include SARMAX models.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: How to build autoregressive models
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An AR model of order p aims to capture the linear dependence between time series
    values at different lags and can be written as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8d109ce0-3b57-4272-8300-100fd7a34f4f.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
- en: 'This closely resembles a multiple linear regression on lagged values of y[t].
    This model has the following characteristic equation:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b808a63c-e313-459c-a1d4-499779ce1ad3.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
- en: The inverses of the solution to this equation in x are the characteristic roots,
    and the AR(p) process is stationary if these roots are all less than 1 in absolute
    terms, and unstable otherwise. For a stationary series, multi-step forecasts will
    converge to the mean of the series.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: We can estimate the model parameters with the familiar least squares method
    using the p+1, ..., T observations to ensure there is data for each lagged term
    and the outcome.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: How to identify the number of lags
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In practice, the challenge consists in deciding on the appropriate order p of
    lagged terms. The time series analysis tools for serial correlation play a key
    role. The ACF estimates the autocorrelation between observations at different
    lags, which in turn results from both direct and indirect linear dependence.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Hence, for an AR model of order k, the ACF will show a significant serial correlation
    up to lag k and, due to the inertia caused by the indirect effects of the linear
    relationship, will extend to subsequent lags and eventually trail off as the effect
    was weakened. On the other hand, the PACF only measures the direct linear relationship
    between observations a given lag apart so that it will not reflect correlation
    for lags beyond *k*.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: How to diagnose model fit
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If the model captures the linear dependence across lags, then the residuals
    should resemble white noise.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to inspecting the ACF to verify the absence of significant autocorrelation
    coefficients, the Ljung-Box Q statistic allows us to test the hypothesis that
    the residual series follows white noise. The null hypothesis is that all m serial
    correlation coefficients are zero against the alternative that some coefficients
    are not. The test statistic is computed from the sample autocorrelation coefficients,
    ρ[k], for different lags, k, and follows an Χ² distribution:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/add319bd-5419-4a0d-9c52-8625bb2ca4d2.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
- en: As we will see, `statsmodels` provides information about the significance of
    coefficients for different lags, and insignificant coefficients should be removed.
    If the Q statistic rejects the null hypothesis of no autocorrelation, you should
    consider additional AR terms.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: How to build moving average models
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An MA model of order q uses q past disturbances rather than lagged values of
    the time series in a regression-like model, as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/013b3331-8be4-462f-89a6-54674e6c988b.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
- en: Since we do not observe the white-noise disturbance values, ε[t], MA(q) is not
    a regression model like the ones we have seen so far. Rather than using least
    squares, MA(q) models are estimated using **maximum likelihood** (**MLE**), alternatively
    initializing or estimating the disturbances at the beginning of the series and
    then recursively and iteratively computing the remainder.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: The MA(q) model gets its name from representing each value of y[t] as a weighted
    moving average of the past q innovations. In other words, current estimates represent
    a correction relative to past errors made by the model. The use of moving averages
    in MA(q) models differs from that of exponential smoothing or the estimation of
    seasonal time series components because an MA(q) model aims to forecast future
    values as opposed to de-noising or estimating the trend cycle of past values.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: MA(q)模型得名于将每个y[t]的值表示为过去q个创新的加权移动平均。换句话说，当前估计代表相对于模型过去误差的修正。MA(q)模型中移动平均的使用与指数平滑或估计季节性时间序列分量的方法不同，因为MA(q)模型旨在预测未来值，而不是去噪或估计过去值的趋势周期。
- en: MA(q) processes are always stationary because they are the weighted sum of white
    noise variables that are themselves stationary.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: MA(q)过程总是平稳的，因为它们是白噪声变量的加权和，而白噪声变量本身是平稳的。
- en: How to identify the number of lags
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何确定滞后数
- en: A time series generated by an MA(q) process is driven by the residuals from
    the q prior-model predictions. Hence, the ACF for the MA(q) process will show
    significant coefficients for values up to the lag, q, and then decline sharply
    because this is how the series values are assumed to have been generated.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 由MA(q)过程生成的时间序列由前q个模型预测的残差驱动。因此，MA(q)过程的ACF将显示出在滞后q之前的值上的显著系数，然后急剧下降，因为这是假定系列值生成的方式。
- en: The relationship between AR and MA models
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AR和MA模型之间的关系
- en: An AR(p) model can be expressed as an MA(∞) process using repeated substitution.
    When imposing constraints on the size of its coefficients, an MA(q) process, it
    becomes invertible and can be expressed as an AR(∞) process.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: AR(p)模型可以使用重复替换表示为MA(∞)过程。当对其系数的大小施加约束时，MA(q)过程变得可逆，并且可以表示为AR(∞)过程。
- en: How to build ARIMA models and extensions
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何构建ARIMA模型和扩展
- en: Autoregressive integrated moving-average ARIMA(p, d, q) models combine AR(p)
    and MA(q) processes to leverage the complementarity of these building blocks and
    simplify model development by using a more compact form and reducing the number
    of parameters, in turn reducing the risk of overfitting.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 自回归积分移动平均ARIMA(p, d, q)模型结合了AR(p)和MA(q)过程，利用这些基本模块的互补性，通过使用更紧凑的形式和减少参数数量来简化模型开发，从而降低过度拟合的风险。
- en: 'The models also take care of eliminating unit-root nonstationarity by using
    the d^(th) difference of the time series values. An ARIMA(p, 1, q) model is the
    same as using an ARMA(p, q) model with the first differences of the series. Using
    y'' to denote the original series after non-seasonal differencing d times, the
    ARIMA(p, d, q) model is simply:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型还通过使用时间序列值的d^(th)差分来消除单位根非平稳性。ARIMA(p, 1, q)模型与使用系列的一阶差分的ARMA(p, q)模型相同。使用y'表示非季节性差分d次后的原始系列，ARIMA(p,
    d, q)模型简单地是：
- en: '![](img/9b7f8efe-736b-496b-9ab8-c57bd417e00a.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9b7f8efe-736b-496b-9ab8-c57bd417e00a.png)'
- en: ARIMA models are also estimated using Maximum Likelihood. Depending on the implementation,
    higher-order models may generally subsume lower-order models. For example, `statsmodels` includes
    all lower-order p and q terms and does not permit removing coefficients for lags
    below the highest value. In this case, higher-order models will always fit better.
    Be careful not to overfit your model to the data by using too many terms.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: ARIMA模型也是使用最大似然估计。根据实现方式，高阶模型通常包含低阶模型。例如，`statsmodels`包括所有低阶p和q项，并且不允许删除最高值以下滞后的系数。在这种情况下，高阶模型将始终拟合得更好。不要使用太多项来过度拟合模型。
- en: How to identify the number of AR and MA terms
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何确定AR和MA项的数量
- en: Since AR(p) and MA(q) terms interact, the information provided by the ACF and
    PACF is no longer reliable and can only be used as a starting point.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 由于AR(p)和MA(q)项相互作用，ACF和PACF提供的信息不再可靠，只能作为一个起点。
- en: Traditionally, the AIC and BIC information criteria have been used to rely on
    in-sample fit when selecting the model design. Alternatively, we can rely on out-of-sample
    tests to cross-validate multiple parameter choices.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，AIC和BIC信息准则一直被用来在选择模型设计时依赖样本内拟合。或者，我们可以依赖样本外测试来交叉验证多个参数选择。
- en: 'The following summary provides some generic guidance to choose the model order
    in the case of considering AR and MA models in isolation:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 以下摘要提供了一些通用指导，以在考虑AR和MA模型时选择模型顺序：
- en: The lag beyond which the PACF cuts off is the indicated number of AR terms.
    If the PACF of the differenced series cuts off sharply and/or the lag-1 autocorrelation
    is positive, add one or more AR terms.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PACF截断的滞后数是指示的AR项数。如果差分系列的PACF截断明显和/或滞后1的自相关是正的，则添加一个或多个AR项。
- en: The lag beyond which the ACF cuts off is the indicated number of MA terms. If
    the ACF of the differenced series displays a sharp cutoff and/or the lag-1 autocorrelation
    is negative, consider adding an MA term to the model.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ACF截断的滞后数是指示的MA项数。如果差分系列的ACF显示出明显的截断和/或滞后1的自相关是负的，则考虑向模型中添加一个MA项。
- en: AR and MA terms may cancel out each other's effects, so always try to reduce
    the number of AR and MA terms by 1 if your model contains both to avoid overfitting,
    especially if the more complex model requires more than 10 iterations to converge.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AR和MA项可能会相互抵消，因此如果您的模型同时包含两者，尝试减少1个AR和MA项的数量，以避免过度拟合，特别是如果更复杂的模型需要超过10次迭代才能收敛。
- en: If the AR coefficients sum to nearly 1 and suggest a unit root in the AR part
    of the model, eliminate 1 AR term and difference the model once (more).
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果AR系数总和接近1，并且在模型的AR部分中表明存在单位根，则消除1个AR项，并将模型差分一次（更多）。
- en: If the MA coefficients sum to nearly 1 and suggest a unit root in the MA part
    of the model, eliminate 1 MA term and reduce the order of differencing by 1.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果MA系数总和接近1，并且在模型的MA部分中表明存在单位根，则消除1个MA项，并将差分阶数减少1。
- en: Unstable long-term forecasts suggest there may be a unit root in the AR or MA
    part of the model.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding features – ARMAX
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An ARMAX model adds input variables or covariate on the right-hand side of
    the ARMA time series model (assuming the series is stationary so we can skip differencing):'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9f28ac09-95ce-439a-b322-a6804b18a1ad.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
- en: This resembles a linear regression model but is quite difficult to interpret
    because the effect of β on y[t] is not the effect of an increase in x[t] by one
    unit as in linear regression. Instead, the presence of lagged values of y[t ]on
    the right-hand side of the equation implies that the coefficient can only be interpreted
    given the lagged values of the response variable, which is hardly intuitive.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Adding seasonal differencing – SARIMAX
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For time series with seasonal effects, we can include AR and MA terms that capture
    the seasonality's periodicity. For instance, when using monthly data and the seasonal
    effect length is one year, the seasonal AR and MA terms would reflect this particular
    lag length.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: The ARIMAX(p, d, q) model then becomes a SARIMAX(p, d, q) x (P, D, Q)[s ]model,
    which is a bit more complicated to write out, but the references on GitHub, including
    the statsmodels documentation, provide this information in detail.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: We will now build a seasonal ARMA model using macro-data to illustrate the implementation.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: How to forecast macro fundamentals
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will build a SARIMAX model for monthly data on an industrial production
    time series for the 1988-2017 period. As illustrated in the first section on analytical
    tools, the data has been log-transformed, and we are using seasonal (lag-12) differences.
    We estimate the model for a range of both ordinary and conventional AR and MA
    parameters using a rolling window of 10 years of training data, and evaluate the
    RMSE of the 1-step-ahead forecast, as shown in the following simplified code (see
    GitHub for details):'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We also collect the AIC and BIC criteria that show a very high rank correlation
    coefficient of 0.94, with BIC favoring models with slightly fewer parameters than
    AIC. The best five models by RMSE are:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We re-estimate a SARIMA(2, 0 ,3) x (1, 0, 0) model, as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We obtain the following summary:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/46e2567f-c100-48b5-b520-724e0a9b629c.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
- en: 'The coefficients are significant, and the Q statistic rejects the hypothesis
    of further autocorrelation. The correlogram similarly indicates that we have successfully
    eliminated the series'' autocorrelation:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cb389378-184c-4c24-a4fb-49b6ae0d3d6c.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
- en: How to use time series models to forecast volatility
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A particularly important area of application for univariate time series models
    is the prediction of volatility. The volatility of financial time series is usually
    not constant over time but changes, with bouts of volatility clustering together.
    Changes in variance create challenges for time series forecasting using the classical
    ARIMA models. To address this challenge, we will now model volatility so that
    we can predict changes in variance.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: Heteroskedasticity is the technical term for changes in a variable's variance.
    The **autoregressive conditional heteroskedasticity** (**ARCH**) model expresses
    the variance of the error term as a function of the errors in previous periods.
    More specifically, it assumes that the error variance follows an AR(p) model.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: The **generalized autoregressive conditional heteroskedasticity **(**GARCH**)
    model broadens the scope to ARMA models. Time series forecasting often combines
    ARIMA models for the expected mean and ARCH/GARCH models for the expected variance
    of a time series. The 2003 Nobel Prize in Economics was awarded to Robert Engle
    and Clive Granger for developing this class of models. The former also runs the
    Volatility Lab at New York University's Stern School (see GitHub references) with
    numerous online examples and tools concerning the models we will discuss and their
    numerous extensions.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: The autoregressive conditional heteroskedasticity (ARCH) model
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The ARCH(p) model is simply an AR(p) model applied to the variance of the residuals
    of a time series model that makes this variance at time t conditional on lagged
    observations of the variance. More specifically, the error terms, ε[t], are residuals
    of a linear model, such as ARIMA, on the original time series and are split into
    a time-dependent standard deviation, σ[t], and a disturbance, *z[t]*, as follows:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/09c5df89-b9d8-46e7-b2b2-81c276a9ba01.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
- en: An ARCH(p) model can be estimated using OLS. Engle proposed a method to identify
    the appropriate ARCH order using the Lagrange multiplier test that corresponds
    to the F-test of the hypothesis that all coefficients in linear regression are
    zero (see [Chapter 7](0cf85bb4-8b3f-4f83-b004-f980f348028b.xhtml), *Linear Models*).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: One strength of the model is that it produces volatility, estimates positive
    excess kurtosis—that is, fat tails relative to the normal distribution—which in
    turn is in line with empirical observations about returns. Weaknesses include
    that the model assumes the same effect for positive and negative volatility shocks because
    it depends on the square of the previous shocks, whereas asset prices are known
    to respond differently to positive and negative shocks. The ARCH model also does
    not offer new insight into the source of variations of a financial time series
    because it just mechanically describes the conditional variance. Finally, ARCH
    models are likely to overpredict the volatility because they respond slowly to
    large, isolated shocks to the return series.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: For a properly-specified ARCH model, the standardized residuals (divided by
    the model estimate for the period of standard deviation) should resemble white
    noise and can be subjected to a Ljung-Box Q test.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: Generalizing ARCH – the GARCH model
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The ARCH model is relatively simple but often requires many parameters to capture
    the volatility patterns of an asset-return series. The **generalized ARCH** (**GARCH**)
    model applies to a log-return series, r[t], with disturbances, ε[t] = r[t ]- μ,
    that follow a GARCH(p, q) model if:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2db414cb-f0fc-4ff1-bb1e-a326cc6df19e.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
- en: The GARCH(p, q) model assumes an ARMA(p, q) model for the variance of the error
    term, ε[t].
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Similar to ARCH models, the tail distribution of a GARCH(1,1) process is heavier
    than that of a normal distribution. The model encounters the same weaknesses as
    the ARCH model. For instance, it responds equally to positive and negative shocks.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Selecting the lag order
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To configure the lag order for ARCH and GARCH models, use the squared residuals
    of the time series trained to predict the mean of the original series. The residuals
    are zero-centered so that their squares are also the variance. Then inspect the
    ACF and PACF plots of the squared residuals to identify autocorrelation patterns
    in the variance of the time series.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: How to build a volatility-forecasting model
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The development of a volatility model for an asset-return series consists of
    four steps:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Build an ARMA time series model for the financial time series based on the serial
    dependence revealed by the ACF and PACF.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test the residuals of the model for ARCH/GARCH effects, again relying on the
    ACF and PACF for the series of the squared residual.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Specify a volatility model if serial correlation effects are significant, and
    jointly estimate the mean and volatility equations.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check the fitted model carefully and refine it if necessary.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When applying volatility forecasting to return series, the serial dependence
    may be limited so that a constant mean may be used instead of an ARMA model.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: The `arch` library provides several options to estimate volatility-forecasting
    models. It offers several options to model the expected mean, including a constant
    mean, the AR(p) model discussed in the section on univariate time series models
    above as well as more recent heterogeneous autoregressive processes (HAR) that
    use daily (1 day), weekly (5 days), and monthly (22 days) lags to capture the
    trading frequencies of short-, medium-, and long-term investors.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: The mean models can be jointly defined and estimated with several conditional
    heteroskedasticity models that include, in addition to ARCH and GARCH, the **exponential
    GARCH** (**EGARCH**) model, which allows for asymmetric effects between positive
    and negative returns and the **heterogeneous ARCH** (**HARCH**) model, which complements
    the HAR mean model.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use daily NASDAQ returns from 1998-2017 to demonstrate the usage of
    a GARCH model (see the notebook `arch_garch_models` for details):'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The rescaled daily return series exhibits only limited autocorrelation, but
    the squared deviations from the mean do have substantial memory reflected in the
    slowly-decaying ACF and the PACF high for the first two and cutting off only after
    the first six lags:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The function `plot_correlogram` produces the following output:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4b0ef301-4d8f-4c6f-a179-19b00ac536cb.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
- en: 'Hence, we can estimate a GARCH model to capture the linear relationship of
    past volatilities. We will use rolling 10-year windows to estimate a GARCH(p,
    q) model with p and q ranging from 1-4 to generate 1-step out-of-sample forecasts.
    We then compare the RMSE of the predicted volatility relative to the actual squared deviation
    of the return from its mean to identify the most predictive model. We are using
    winsorized data to limit the impact of extreme return values reflected in the
    very high positive skew of the volatility:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The GARCH(2, 2) model achieves the lowest RMSE (same value as GARCH(4, 2) but
    with fewer parameters), so we go ahead and estimate this model to inspect the
    summary:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output shows the maximized log-likelihood as well as the AIC and BIC criteria
    that are commonly minimized when selecting models based on in-sample performance
    (see [Chapter 7](0cf85bb4-8b3f-4f83-b004-f980f348028b.xhtml), *Linear Models*).
    It also displays the result for the mean model, which in this case is just a constant
    estimate, as well as the GARCH parameters for the constant omega, the AR parameters,
    α, and the MA parameters, β, all of which are statistically significant:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/95155d6b-b1c4-453c-ba62-25af43f0421c.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
- en: Let's now explore models for multiple time series and the concept of cointegration,
    which will enable a new trading strategy.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: Multivariate time series models
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multivariate time series models are designed to capture the dynamic of multiple
    time series simultaneously and leverage dependencies across these series for more
    reliable predictions.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Systems of equations
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Univariate time series models like the ARMA approach, we just discussed are
    limited to statistical relationships between a target variable and its lagged
    values or lagged disturbances and exogenous series in the ARMAX case. In contrast,
    multivariate time series models also allow for lagged values of other time series
    to affect the target. This effect applies to all series, resulting in complex
    interactions, as illustrated in the following diagram:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/005cd921-cfd5-4fe0-bffa-3f6e674927f8.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
- en: In addition to potentially better forecasting, multivariate time series are
    also used to gain insights into cross-series dependencies. For example, in economics,
    multivariate time series are used to understand how policy changes to one variable,
    for example, an interest rate, may affect other variables over different horizons.
    The impulse-response function produced by the multivariate model we will look
    at serves this purpose and allows us to simulate how one variable responds to
    a sudden change in other variables. The concept of Granger causality analyzes
    whether one variable is useful in forecasting another (in the least squares sense).
    Furthermore, multivariate time series models allow for a decomposition of the
    prediction error variance to analyze how other series contribute.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: The vector autoregressive (VAR) model
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will see how the vector autoregressive VAR(p) model extends the AR(p) model
    to k series by creating a system of k equations where each contains p lagged values
    of all k series. In the simplest case, a VAR(1) model for *k=2* takes the following
    form:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/38b71b86-ca76-451d-b80d-0979d26f6050.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
- en: 'This model can be expressed somewhat more concisely in matrix form:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c9167a29-e14b-41e3-9a12-750d39ea3e40.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
- en: 'The coefficients on the own lags provide information about the dynamics of
    the series itself, whereas the cross-variable coefficients offer some insight
    into the interactions across the series. This notation extends to the k series
    and order p, as follows:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f68272ad-74f3-46a5-810e-206582d3cecd.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
- en: VAR(p) models also require stationarity, so that the initial steps from univariate
    time series modeling carry over. First, explore the series and determine the necessary
    transformations, then apply the Augmented Dickey-Fuller test to verify that the
    stationarity criterion is met for each series and apply further transformations
    otherwise. It can be estimated with OLS conditional on initial information or
    with maximum likelihood, which is equivalent for normally-distributed errors but
    not otherwise.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: If some or all of the k series are unit-root non-stationary, they may be co-integrated.
    This extension of the unit root concept to multiple time series means that a linear
    combination of two or more series is stationary and, hence, mean-reverting. The
    VAR model is not equipped to handle this case without differencing, instead use
    the Vector Error Correction model (VECM, see references on GitHub). We will further
    explore cointegration because, if present and assumed to persist, it can be leveraged
    for a pairs-trading strategy.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: The determination of the lag order also takes its cues from the ACF and PACF
    for each series but is constrained by the fact that the same lag order applies
    to all series. After model estimation, residual diagnostics also call for a result
    resembling white noise, and model selection can use in-sample information criteria
    or, preferably, out-of-sample predictive performance to cross-validate alternative
    model designs if the ultimate goal is to use the model for prediction.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned in the univariate case, predictions of the original time series
    require us to reverse the transformations applied to make a series stationary
    before training the model.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: How to use the VAR model for macro fundamentals forecasts
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will extend the univariate example of a single time series of monthly data
    on industrial production and add a monthly time series on consumer sentiment,
    both provided by the Federal Reserve''s data service. We will use the familiar `pandas-datareader` library
    to retrieve data from 1970 through 2017:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Log-transforming the industrial production series and seasonal differencing
    using lag 12 of both series yields stationary results:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This leaves us with the following series:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5f0588ac-69f2-441b-be7d-20ef8cb7cbdc.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
- en: 'To limit the size of the output, we will just estimate a VAR(1) model using
    the `statsmodels` `VARMAX` implementation (which allows for optional exogenous
    variables) with a constant trend using the first 480 observations:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This results in the following summary:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2513f5d7-cc0d-4629-afbb-ee527bb8c1ac.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
- en: 'The output contains the coefficients for both time series equations, as outlined
    in the preceding VAR(1) illustration. statsmodels provides diagnostic plots to
    check whether the residuals meet the white noise assumptions, which are not exactly
    met in this simple case:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a39b5eca-c0a2-4dc7-9ca1-badc44655fdf.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
- en: 'Out-of-sample predictions can be generated as follows:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'A visualization of actual and predicted values shows how the prediction lags
    the actual values and does not capture non-linear out-of-sample patterns well:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/67bf14a1-9fb1-49ba-ae8c-9f9b755c6300.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
- en: Cointegration – time series with a common trend
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The concept of an integrated multivariate series is complicated by the fact
    that all the component series of the process may be individually integrated but
    the process is not jointly integrated in the sense that one or more linear combinations
    of the series exist that produce a new stationary series.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: In other words, a combination of two co-integrated series has a stable mean
    to which this linear combination reverts. A multivariate series with this characteristic
    is said to be co-integrated. This also applies when the individual series are
    integrated of a higher order and the linear combination reduces the overall order
    of integration.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'cointegration is different from correlation: two series can be highly correlated but
    need not be co-integrated. For example, if two growing series are constant multiples
    of each other, their correlation will be high but any linear combination will
    also grow rather than revert to the mean.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: The VAR analysis can still be applied to integrated processes using the error-correction
    form of a VAR model that uses the first differences of the individual series plus
    an error correction term in levels.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: Testing for cointegration
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two major approaches to testing for cointegration:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: The Engle–Granger two-step method
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Johansen procedure
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Engle–Granger method involves regressing one series on another, and then
    applying an ADF unit-root test to the regression residual. If the null hypothesis
    can be rejected so that we assume the residuals are stationary, then the series
    are co-integrated. A key benefit of this approach is that the regression coefficient
    represents the multiplier that renders the combination stationary, that is, mean-reverting. We
    will return to this aspect when leveraging cointegration for a pairs-trading strategy. On
    the other hand, this approach is limited to identifying cointegration for pairs
    of series as opposed to larger groups of series.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: 'The Johansen procedure, in contrast, tests the restrictions imposed by cointegration
    on a **vector autoregression** (**VAR**) model as discussed in the previous section.
    More specifically, after subtracting the target vector from both sides of the
    generic VAR(p) preceding equation, we obtain the **error correction model** (**ECM**)
    formulation:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ba15f49f-69df-4173-a288-fb3e8fbc8fe1.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
- en: The resulting modified VAR(p) equation has only one vector term in levels, that
    is, not expressed as difference using the operator, Δ. The nature of cointegration
    depends on the properties of the coefficient matrix, Π, of this term, in particular
    on its rank. While this equation appears structurally similar to the ADF test
    setup, there are now several potential constellations of common trends and orders
    of integration because there are multiple series involved. For details, see the
    references listed on GitHub, including with respect to practical challenges regarding
    the scaling of individual series.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: How to use cointegration for a pairs-trading strategy
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pairs-trading relies on a stationary, mean-reverting relationship between two
    asset prices. In other words, the ratio or difference between the two prices,
    also called the spread, may over time diverge but should ultimately return to
    the same level. Given such a pair, the strategy consists of going long (that is,
    purchasing) the under-performing asset because it would require a period of outperformance
    to close the gap. At the same time, one would short the asset that has moved away
    from the price anchor in the positive direction to fund the purchase.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: cointegration represents precisely this type of stable relationship between
    two price series anchored by a common mean. Assuming cointegration persists, convergence
    must ultimately ensue, either by the underperforming stock rising or the outperforming
    stock coming down. The strategy would be profitable regardless, which has the
    added advantage of being hedged against general market movements either way.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: However, the spread will constantly change, sometimes widening and sometimes
    narrowing, or remain unchanged as both assets move in unison. The challenge of
    pairs-trading consists of maintaining a hedged position by adjusting the relative
    holdings as the spread changes.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: In practice, given a universe of assets, a pairs-trading strategy will search
    for co-integrated pairs by running a statistical test on each pair. The key challenge
    here is to account for multiple testing biases, as outlined in [Chapter 6](3efbd9df-a459-406a-a86e-1cb5512a9122.xhtml),
    *Machine Learning Workflow*. The `statsmodels` library implements both the Engle-Granger
    cointegration test and the Johansen test.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: In order to estimate the spread, run a linear regression to get the coefficient
    for the linear combination of two integrated asset price series that produce a
    stationary combined series. As mentioned, using linear regression to estimate
    the coefficient is known as the Engle-Granger test of cointegration.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored linear time series models for the univariate case
    of individual series as well as multivariate models for several interacting series.
    We encountered applications that predict macro fundamentals, models that forecast
    asset or portfolio volatility with widespread use in risk management, as well
    as multivariate VAR models that capture the dynamics of multiple macro series,
    as well as the concept of cointegration, which underpins the popular pair-trading
    strategy.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: Similar to the previous chapter, we saw how linear models add a lot of structure
    to the model, that is, they make strong assumptions that potentially require transformations
    and extensive testing to verify that these assumptions are met. If they are, model-training
    and -interpretation is straightforward, and the models provide a good baseline
    case that more complex models may be able to improve on, as we will see in the
    following chapters.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL

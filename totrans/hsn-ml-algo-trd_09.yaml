- en: Bayesian Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 贝叶斯机器学习
- en: In this chapter, we will introduce Bayesian approaches to machine learning,
    and how their different perspectives on uncertainty add value when developing
    and evaluating algorithmic trading strategies.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍机器学习的贝叶斯方法，以及它们在开发和评估算法交易策略时对不确定性的不同观点如何增加价值。
- en: Bayesian statistics allow us to quantify the uncertainty about future events
    and refine our estimates in a principled way as new information arrives. This
    dynamic approach adapts well to the evolving nature of financial markets. It is
    particularly useful when there is less relevant data and we require methods that
    systematically integrate prior knowledge or assumptions.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯统计学允许我们量化对未来事件的不确定性，并以一种原则性的方式在新信息到来时改进我们的估计。这种动态方法很好地适应了金融市场的不断发展的特性。当存在较少相关数据并且我们需要系统地整合先验知识或假设时，这种方法尤其有用。
- en: We will see that Bayesian approaches to machine learning allow for richer insights
    into the uncertainty around statistical metrics, parameter estimates, and predictions.
    The applications range from more granular risk management to dynamic updates of
    predictive models that incorporate changes in the market environment. The Black-Litterman
    approach to asset allocation (see [Chapter 5](1de6a332-69f8-4530-8d18-1007d0a3eb7e.xhtml), *Strategy
    Evaluation*, can be interpreted as a Bayesian model. It computes the expected
    return as an average of the market equilibrium and the investor's views, weighted
    by each asset's volatility, cross-asset correlations, and the confidence in each
    forecast.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到，贝叶斯机器学习方法允许对统计指标、参数估计和预测的不确定性进行更丰富的洞察。应用范围从更精细的风险管理到预测模型的动态更新，这些模型结合了市场环境的变化。资产配置的Black-Litterman方法（参见[第5章](1de6a332-69f8-4530-8d18-1007d0a3eb7e.xhtml)，*策略评估*）可以被解释为一种贝叶斯模型。它计算预期收益，作为市场均衡和投资者观点的加权平均值，每个资产的波动性、跨资产相关性以及对每个预测的信心。
- en: 'More specifically, in this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地，在本章中，我们将涵盖以下主题：
- en: How Bayesian statistics apply to machine learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贝叶斯统计如何应用于机器学习
- en: How to use probabilistic programming with PyMC3
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用PyMC3进行概率编程
- en: How to define and train machine learning models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何定义和训练机器学习模型
- en: How to run state-of-the-art sampling methods to conduct approximate inference
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何运行最先进的抽样方法进行近似推断
- en: How to apply Bayesian machine learning to compute dynamic Sharpe ratios, build
    Bayesian classifiers, and estimate stochastic volatility
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何应用贝叶斯机器学习来计算动态夏普比率，构建贝叶斯分类器和估计随机波动性
- en: References, links to additional material, and the code examples for this chapter
    are in the corresponding directory of the GitHub repository. Please follow the
    installation instructions provided in [Chapter 1](d68f12f8-66fd-4857-b60e-399e5bbd9ea2.xhtml), *Machine
    Learning for Trading*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的参考资料、额外材料的链接以及代码示例位于GitHub存储库的相应目录中。请按照[第1章](d68f12f8-66fd-4857-b60e-399e5bbd9ea2.xhtml)中提供的安装说明进行操作，*交易的机器学习*。
- en: How Bayesian machine learning works
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 贝叶斯机器学习的工作原理
- en: Classical statistics is also called frequentist because it interprets probability
    as the relative frequency of an event over the long run, that is, after observing
    a large number of trials. In the context of probabilities, an event is a combination
    of one or more elementary outcomes of an experiment, such as any of six equal
    results in rolls of two dice or an asset price dropping by 10% or more on a given
    day.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 古典统计学也被称为频率主义，因为它将概率解释为长期内事件的相对频率，即在观察了大量试验之后。在概率的背景下，事件是实验的一个或多个基本结果的组合，例如两个骰子的六个相同结果中的任何一个，或者给定日的资产价格下跌10%或更多。
- en: Bayesian statistics, in contrast, views probability as a measure of the confidence
    or belief in the occurrence of an event. The Bayesian perspective of probability
    leaves more room for subjective views and, consequently, differences in opinions
    than the frequentist interpretation. This difference is most striking for events
    that do not happen often enough to arrive at an objective measure of long-term
    frequency.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，贝叶斯统计将概率视为对事件发生的信心或信念的度量。贝叶斯概率的观点为主观观点留下了更多的空间，因此，与频率主义解释相比，对于主观看法和因此意见的差异，这种差异最为显著。对于不经常发生以至于无法得出长期频率客观度量的事件来说，这种差异最为显著。
- en: Put differently, frequentist statistics assume that data is a random sample
    from a population and aims to identify the fixed parameters that generated the
    data. Bayesian statistics, in turn, take the data as given and considers the parameters
    to be random variables with a distribution that can be inferred from data. As
    a result, frequentist approaches require at least as many data points as there
    are parameters to be estimated. Bayesian approaches, on the other hand, are compatible
    with smaller datasets and are well-suited for online learning, one sample at a
    time.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，频率统计学假设数据是从总体中随机抽取的样本，并旨在识别生成数据的固定参数。贝叶斯统计学则将数据视为给定的，并认为参数是随机变量，其分布可以从数据中推断出来。因此，频率主义方法至少需要与要估计的参数数量相同的数据点。另一方面，贝叶斯方法与较小的数据集兼容，并且非常适合在线学习，一次一个样本。
- en: The Bayesian view is very useful for many real-world events that are rare or
    unique, at least in important respects. Examples include the outcome of the next
    election or the question of whether the markets will crash within three months.
    In each case, there is both relevant historical data as well as unique circumstances
    that unfold as the event approaches.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '贝叶斯观点对于许多在某些重要方面是罕见或独特的真实世界事件非常有用。例如，下次选举的结果或市场是否会在三个月内崩溃的问题。在每种情况下，都有相关的历史数据以及随着事件的临近而展开的独特情况。 '
- en: 'First, we will introduce Bayes'' theorem, which crystallizes the concept of
    updating beliefs by combining prior assumptions with new empirical evidence and
    comparing the resulting parameter estimates with their frequentist counterparts.
    We will then demonstrate two approaches to Bayesian statistical inference that
    produce insights into the posterior distribution of the latent, that is, unobserved
    parameters, such as their expected values, under different circumstances:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将介绍贝叶斯定理，它通过将先验假设与新的经验证据相结合，并将得到的参数估计与频率主义对应物进行比较，从而凝结了更新信念的概念。然后，我们将演示两种贝叶斯统计推断方法，以揭示潜在参数的后验分布，即未观察到的参数在不同情况下的期望值等：
- en: Conjugate priors facilitate the updating process by providing a closed-form
    solution, but exact, analytical methods are not always available.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 共轭先验通过提供封闭形式的解决方案来促进更新过程，但并非总是可以使用确切的分析方法。
- en: Approximate inference simulates the distribution that results from combining
    assumptions and data and uses samples from this distribution to compute statistical
    insights.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 近似推断模拟了由结合假设和数据得出的分布，并使用该分布的样本来计算统计见解。
- en: How to update assumptions from empirical evidence
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何从经验证据中更新假设
- en: 'The theorem that Reverend Thomas Bayes came up with over 250 years ago uses
    fundamental probability theory to prescribe how probabilities or beliefs should
    change as relevant new information arrives. The following quote by – John Maynard
    Keynes captures the Bayesian mindset:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 250多年前，牧师托马斯·贝叶斯提出了一个定理，使用基本的概率理论来规定随着相关新信息的到来，概率或信念应该如何改变。以下约翰·梅纳德·凯恩斯的引语捕捉了贝叶斯思维方式：
- en: '"When the facts change, I change my mind. What do you do, sir?"'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: “当事实改变时，我改变我的看法。你呢，先生？”
- en: It relies on the conditional and total probability and the chain rule; see the
    references on GitHub for reviews of these concepts.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 它依赖于条件和总概率以及链式法则；有关这些概念的评论，请参阅GitHub上的参考资料。
- en: The belief concerns a single or vector of parameters θ (also called hypotheses).
    Each parameter can be discrete or continuous. θ could be a one-dimensional statistic
    like the (discrete) mode of a categorical variable or a (continuous) mean, or
    a higher dimensional set of values like a covariance matrix or the weights of
    a deep neural network.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 信念涉及单个或参数θ的向量（也称为假设）。每个参数可以是离散的或连续的。θ可以是一维统计量，如分类变量的（离散）模式或（连续）均值，也可以是更高维的值集，如协方差矩阵或深度神经网络的权重。
- en: A key difference of frequentist statistics is that Bayesian assumptions are
    expressed as probability distributions rather than parameter values. Consequently,
    while frequentist inference focuses on point estimates, Bayesian inference yields
    probability distributions.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 频率主义统计的一个关键区别是，贝叶斯假设是以概率分布而不是参数值的形式表达的。因此，虽然频率主义推断侧重于点估计，贝叶斯推断产生概率分布。
- en: 'Bayes'' Theorem updates the beliefs about the parameters of interest by computing
    the posterior probability distribution from the following inputs, as shown in
    the following diagram:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理通过计算以下输入来更新对感兴趣参数的信念，从而计算后验概率分布，如下图所示：
- en: The **prior** distribution indicates how likely we consider each possible hypothesis.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**先验**分布表示我们认为每个可能假设的可能性有多大。'
- en: The **likelihood ****function** outputs the probability of observing a dataset
    given certain values for the θ parameters.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**似然函数**输出了在给定θ参数值的情况下观察到数据集的概率。'
- en: 'The **evidence** measures how likely the observed data is given all possible
    hypotheses. Hence, it is the same for all parameter values and serves to normalize
    the numerator:'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**证据**衡量了在所有可能的假设下观察到的数据的可能性。因此，对于所有参数值来说都是相同的，并用于对分子进行归一化：'
- en: '![](img/cf94d4c2-95fd-4979-8996-50b006b89cba.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cf94d4c2-95fd-4979-8996-50b006b89cba.png)'
- en: Bayes Theorem
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理
- en: The posterior is the product of prior and likelihood, divided by the evidence,
    and reflects the updated probability distribution of the hypotheses, taking into
    account both prior assumptions and the data. Viewed differently, the product of
    the prior and the likelihood results from applying the chain rule to factorize
    the joint distribution of data and parameters.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 后验是先验和似然的乘积，除以证据，并反映了假设的更新概率分布，同时考虑了先验假设和数据。从不同角度看，先验和似然的乘积是通过应用链式法则对数据和参数的联合分布进行因式分解得到的。
- en: With higher-dimensional, continuous variables, the formulation becomes more
    complex and involves (multiple) integrals. An alternative formulation uses odds
    to express the posterior odds as the product of the prior odds times the likelihood
    ratio (see the references for more details).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更高维度、连续变量，公式变得更加复杂，涉及（多个）积分。另一种公式使用赔率来表示后验赔率，作为先验赔率乘以似然比的乘积（有关更多细节，请参阅参考资料）。
- en: Exact inference: Maximum a Posteriori estimation
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 精确推断：最大后验估计
- en: Practical applications of Bayes' rule to exactly compute posterior probabilities
    are quite limited because the computation of the evidence term in the denominator
    is quite challenging. The evidence reflects the probability of the observed data
    over all possible parameter values. It is also called the marginal likelihood
    because it requires *marginalizing out* the parameters' distribution by adding
    or integrating over their distribution. This is generally only possible in simple
    cases with a small number of discrete parameters that assume very few values.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯规则的实际应用，以精确计算后验概率，是相当有限的，因为分母中的证据项的计算非常具有挑战性。证据反映了在所有可能的参数值上观察到的数据的概率。它也被称为边际似然，因为它需要通过对参数的分布进行*边际化*来进行求和或积分。这通常只在具有很少离散参数值的简单情况下才可能。
- en: '**Maximum a posteriori probability (MAP)** estimation leverages that the evidence
    is a constant factor that scales the posterior to meet the requirements for a
    probability distribution. Since the evidence does not depend on θ, the posterior
    distribution is proportional to the product of the likelihood and the prior. Hence,
    MAP estimation chooses the value of θ that maximizes the posterior given the observed
    data and the prior belief, that is, the mode of the posterior.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: The MAP approach contrasts with the **maximum likelihood estimation** (**MLE**)
    of parameters, which define a probability distribution. MLE picks the parameter
    value θ that maximizes the likelihood function for the observed training data.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 'A look at the definitions highlights that MAP differs from MLE by including
    the prior distribution. In other words, unless the prior is a constant, the MAP
    estimate θ will differ from its MLE counterpart:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/33df27eb-e965-467f-a807-0403f6c49c92.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
- en: '![](img/27ec9baf-4009-4439-a702-2681bfc8b8e9.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: The MLE solution tends to reflect the frequentist notion that probability estimates
    should reflect observed ratios. On the other hand, the impact of the prior on
    the MAP estimate often corresponds to adding data that reflects the prior assumptions
    to the MLE. For example, a strong prior that a coin is biased can be incorporated
    in the MLE context by adding skewed trial data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Prior distributions are a critical ingredient for Bayesian models. We will now
    introduce some convenient choices that facilitate analytical inference.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: How to select priors
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The prior should reflect knowledge of the distribution of the parameters because
    it influences the MAP estimate. If a prior is not known with certainty, we need
    to make a choice, often from several reasonable options. In general, it is good
    practice to justify the prior and check for robustness by testing whether alternatives
    lead to the same conclusion.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several types of priors:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '**Objective** priors maximize the impact of the data on the posterior. If the
    parameter distribution is unknown, we can select an uninformative prior like a
    uniform distribution, also called a flat prior, over a relevant range of parameter
    values.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In contrast, **subjective** priors aim to incorporate information that's external
    to the model into the estimate.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An **empirical** prior combines Bayesian and frequentist methods and uses historical
    data to eliminate subjectivity, such as by estimating various moments to fit a
    standard distribution.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the context of a machine learning model, the prior can be viewed as a regularizer
    because it limits the values that the posterior can assume. Parameters that have
    zero prior probability, for example, are not part of the posterior distribution.
    Generally, more good data allows for stronger conclusions and reduces the influence
    of the prior.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: How to keep inference simple – conjugate priors
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A prior distribution is conjugate with respect to the likelihood when the resulting
    posterior is of the same type of distribution as the prior, except for different
    parameters. When both the prior and the likelihood are normally distributed, then
    the posterior is also normally distributed.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: The conjugacy of the prior and likelihood implies a closed-form solution for
    the posterior that facilitates the update process and avoids the need to use numerical
    methods to approximate the posterior. Moreover, the resulting posterior can be
    used as prior for the next update step.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Let's illustrate this process using a binary classification example for stock
    price movements.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: How to dynamically estimate the probabilities of asset price moves
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When the data consists of binary Bernoulli random variables with a certain success
    probability for a positive outcome, the number of successes in repeated trials
    follows a Binomial distribution. The conjugate prior is the Beta distribution
    with support over the interval [0, 1] and two shape parameters to model arbitrary
    prior distributions over the success probability. Hence, the posterior distribution
    is also a Beta distribution that we can derive by directly updating the parameters.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据由具有一定成功概率的二元伯努利随机变量组成时，重复试验中的成功次数遵循二项分布。共轭先验是支持区间[0, 1]上的Beta分布，具有两个形状参数，用于对成功概率进行任意先验分布的建模。因此，后验分布也是一个Beta分布，我们可以通过直接更新参数来得到。
- en: We will collect samples of different sizes of binarized daily S&P 500 returns,
    where the positive outcome is a price increase. Starting from an uninformative
    prior that allocates equal probability to each possible success probability in
    the interval [0, 1], we compute the posterior for different evidence samples.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将收集不同大小的二值化日S&P 500收益样本，其中正面结果是价格上涨。从一个分配相等概率给区间[0, 1]中每个可能成功概率的不确定先验开始，我们计算不同证据样本的后验。
- en: 'The following code sample shows that the update consists of simply adding the
    observed numbers of success and failure to the parameters of the prior distribution
    to obtain the posterior:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例显示了更新的过程只是简单地将观察到的成功和失败次数添加到先验分布的参数中以获得后验：
- en: '[PRE0]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The resulting posterior distributions are plotted in the following graphs. They
    illustrate the evolution from a uniform prior that views all success probabilities
    as equally likely to an increasingly peaked distribution.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的后验分布在下面的图表中绘制出来。它们说明了从一个将所有成功概率视为同等可能的均匀先验到一个越来越尖峰的分布的演变。
- en: 'After 500 samples, the probability is concentrated near the actual probability
    of a positive move at 54.7% from 2010 to 2017\. It also shows the small differences
    between MLE and MAP estimates, where the latter tends to be pulled slightly toward
    the expected value of the uniform prior, as shown in the following diagram:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在500个样本之后，概率集中在2010年至2017年正面变动的实际概率54.7%附近。它还显示了MLE和MAP估计之间的微小差异，后者倾向于稍微向均匀先验的期望值拉动，如下图所示：
- en: '![](img/9875382b-377d-49ee-813a-beaab956a2d4.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9875382b-377d-49ee-813a-beaab956a2d4.png)'
- en: Posterior probabilities
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 后验概率
- en: In practice, the use of conjugate priors is limited to low-dimensional cases.
    In addition, the simplified MAP approach avoids computing the evidence term, but
    has several shortcomings even when it is available; it does not return a distribution
    so that we can derive a measure of uncertainty, or use it as a prior. Hence, we
    need to resort to approximates rather than exact inference using numerical methods
    and stochastic simulation, which we will introduce next.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，使用共轭先验的情况受到了限制，只适用于低维情况。此外，简化的MAP方法避免了计算证据项，但即使在可用时也存在一些缺点；它不返回一个分布，因此我们无法得出不确定性的度量，或者将其用作先验。因此，我们需要使用数值方法和随机模拟来进行近似推断，而不是精确推断，接下来我们将介绍这些方法。
- en: Approximate inference: stochastic versus deterministic approaches
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 近似推断：随机与确定性方法
- en: For most models of practical relevance, it will not be possible to derive the
    exact posterior distribution analytically and compute the expected values for
    the latent parameters. The model may have too many parameters, or the posterior
    distribution may be too complex for an analytical solution. For continuous variables,
    the integrals may not have closed-form solutions, while the dimensionality of
    the space and the complexity of the integrand may prohibit numerical integration.
    For discrete variables, the marginalizations involve summing over all possible
    configurations of the hidden variables, and though this is always possible in
    principle, we often find in practice that there may be exponentially many hidden
    states so that exact calculation is prohibitively expensive.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数实际相关的模型，无法通过解析方法推导出精确的后验分布并计算潜在参数的期望值。模型可能具有太多的参数，或者后验分布可能对于解析解来说太复杂。对于连续变量，积分可能没有封闭形式的解，而空间的维度和被积函数的复杂性可能会阻止数值积分。对于离散变量，边缘化涉及对隐藏变量的所有可能配置进行求和，尽管原则上这是可能的，但在实践中我们经常发现可能存在指数多的隐藏状态，因此精确计算是代价高昂的。
- en: 'Although for some applications the posterior distribution over unobserved parameters
    will be of interest, more often than not it is primarily required to evaluate
    expectations, for example, to make predictions. In such situations, we can rely
    on approximate inference:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管对于一些应用来说，对未观察参数的后验分布可能是感兴趣的，但更多时候主要是需要评估期望，例如进行预测。在这种情况下，我们可以依赖近似推断：
- en: '**Stochastic** techniques based on **Markov Chain Monte Carlo (MCMC)** sampling
    have popularized the use of Bayesian methods across many domains. They generally
    have the ability to converge to the exact result. In practice, sampling methods
    can be computationally demanding and are often limited to small-scale problems.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于马尔可夫链蒙特卡洛（MCMC）采样的**随机**技术已经在许多领域推广了贝叶斯方法的使用。它们通常具有收敛到精确结果的能力。在实践中，采样方法可能需要大量计算，并且通常局限于小规模问题。
- en: '**Deterministic** methods, known as variational inference or variational Bayes,
    are based on analytical approximations to the posterior distribution and can scale
    well to large applications. They make simplified assumptions, for example, that
    the posterior factorizes in a particular way or it has a specific parametric form
    such as a Gaussian. Hence, they do not generate exact results and can be used
    as complements to sampling methods.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**确定性**方法，即变分推断或变分贝叶斯，基于对后验分布的解析近似，并且可以很好地适用于大型应用。它们做出了简化的假设，例如后验分解为特定方式，或者具有特定的参数形式，如高斯分布。因此，它们不会产生精确结果，并且可以用作采样方法的补充。'
- en: Sampling-based stochastic inference
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于采样的随机推断
- en: Sampling is about drawing samples, *X=(x[1], ..., x[n])*, from a given distribution,
    *p(x)*. Assuming the samples are independent, the law of large numbers ensures
    that for a growing number of samples, the fraction of a given instance, *x[i]*,
    in the sample (for the discrete case) corresponds to its probability, *p(x=x[i])*.
    In the continuous case, the analogous reasoning applies to a given region of the
    sample space. Hence, averages over samples can be used as unbiased estimators
    of the expected values of parameters of the distribution.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 抽样是关于从给定分布*p(x)*中抽取样本*X=(x[1], ..., x[n])*。假设样本是独立的，大数定律确保对于越来越多的样本，给定实例*x[i]*在样本中的比例（对于离散情况）对应于其概率*p(x=x[i])*。在连续情况下，类似的推理适用于样本空间的给定区域。因此，样本的平均值可以用作分布参数的期望值的无偏估计。
- en: A practical challenge consists in ensuring independent sampling because the
    distribution is unknown. Dependent samples may still be unbiased, but tend to
    increase the variance of the estimate so that more samples will be needed for
    an equally precise estimate as for independent samples.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一个实际的挑战在于确保独立的抽样，因为分布是未知的。依赖样本可能仍然是无偏的，但倾向于增加估计的方差，因此需要更多的样本来获得与独立样本同样精确的估计。
- en: Sampling from a multivariate distribution is computationally demanding as the
    number of states increases exponentially with the number of dimensions. Numerous
    algorithms facilitate the process (see references for an overview). Now, we will
    introduce a few popular variations of MCMC-based methods.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '从多元分布中抽样在计算上是具有挑战性的，因为状态的数量随着维度的增加呈指数增长。许多算法简化了这个过程（参考概述）。现在，我们将介绍几种基于MCMC的流行变体。 '
- en: Markov chain Monte Carlo sampling
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 马尔可夫链蒙特卡洛采样
- en: A Markov chain is a dynamic stochastic model that describes a random walk over
    a set of states, connected by transition probabilities. The Markov property stipulates
    that the process has no memory, and the next step only depends on the current
    state. In other words, it's conditional on the present, past, and future being
    independent, that is, information about past states does not help to predict the
    future beyond what we know from the present.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫链是描述一组状态之间的随机游走的动态随机模型，这些状态之间通过转移概率相连。马尔可夫性质规定了该过程没有记忆，下一步只取决于当前状态。换句话说，它是有条件的，过去和未来是独立的，也就是说，过去状态的信息不能帮助预测未来，除了我们从现在知道的信息。
- en: Monte Carlo methods rely on repeated random sampling to approximate results
    that may be deterministic, but that does not permit an analytic, exact solution.
    It was developed during the Manhattan Project to estimate energy at the atomic
    level and received its enduring code name to ensure secrecy.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 蒙特卡洛方法依赖于重复的随机抽样来近似可能是确定性的结果，但不允许解析的精确解。它是在曼哈顿计划期间开发的，用于估计原子能量，并获得了其持久的代号以确保保密性。
- en: 'Many algorithms apply the Monte Carlo method to a Markov Chain, and generally
    proceed as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 许多算法将蒙特卡洛方法应用于马尔可夫链，并且通常按照以下步骤进行。
- en: Start at the current position.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从当前位置开始。
- en: Draw a new position from a proposal distribution.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从提议分布中抽取一个新位置。
- en: 'Evaluate the probability of the new position in light of data and prior distributions:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在考虑数据和先验分布的情况下评估新位置的概率：
- en: If sufficiently likely, move to the new position
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果足够可能，移动到新位置
- en: Otherwise, remain at the current position
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 否则，保持在当前位置
- en: Repeat from step 1.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从步骤1重复。
- en: After a given number of iterations, return all accepted positions.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在给定数量的迭代之后，返回所有接受的位置。
- en: MCMC aims to identify and explore interesting regions of the posterior that
    concentrate on significant probability density. The memoryless process is said
    to converge when it consistently moves through nearby high probability states
    of the posterior where the acceptance rate increases. A key challenge is to balance
    the need for random exploration of the sample space with the risk of reducing
    the acceptance rate.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: MCMC旨在识别和探索后验的有趣区域，这些区域集中在显著的概率密度上。无记忆过程在一致地移动到后验的附近高概率状态时被认为是收敛的，接受率增加。一个关键挑战是在随机探索样本空间的需求与降低接受率的风险之间取得平衡。
- en: The initial steps of this process are likely to be more reflective of the starting
    position than the posterior and are typically discarded as **burn-in** samples.
    A key MCMC property is that the process should forget about its initial position
    after a certain (but unknown) number of iterations.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程的初始步骤很可能更反映起始位置而不是后验，通常被丢弃作为**burn-in**样本。 MCMC的一个关键特性是，该过程在一定（但未知）数量的迭代后应该忘记其初始位置。
- en: The remaining samples are called the trace of the process. Assuming convergence,
    the relative frequency of samples approximates the posterior and can be used to
    compute expected values based on the law of large numbers.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的样本被称为过程的迹。假设收敛，样本的相对频率近似于后验，并且可以用来根据大数定律计算期望值。
- en: As indicated previously, the precision of the estimate depends on the serial
    correlation of the samples collected by the random walk, each of which, by design,
    depends only on the previous state. Higher correlation limits the effective exploration
    of the posterior and needs to be subjected to diagnostic tests.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，估计的精度取决于随机游走收集的样本的串行相关性，每个样本都是根据前一个状态设计的。更高的相关性限制了对后验的有效探索，并且需要经过诊断测试。
- en: General techniques to design such a Markov chain include Gibbs sampling, the
    Metropolis-Hastings algorithm, and more recent Hamiltonian MCMC methods that tend
    to perform better.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 设计这样一个马尔可夫链的一般技术包括Gibbs采样、Metropolis-Hastings算法以及更近期的哈密顿MCMC方法，这些方法往往表现更好。
- en: Gibbs sampling
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Gibbs采样
- en: Gibbs sampling simplifies multivariate sampling to a sequence of one-dimensional
    draws. From a starting point, it iteratively holds *n*-1 variables constant while
    sampling the *n^(th)* variable. It incorporates this sample and repeats.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Gibbs采样将多元采样简化为一系列一维抽样。从一个起始点开始，它迭代地将*n*-1个变量保持不变，同时对第*n*个变量进行抽样。它将这个样本合并并重复。
- en: The algorithm is very simple and easy to implement but produces highly correlated
    samples that slow down convergence. Its sequential nature also prevents parallelization.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法非常简单易行，但产生高度相关的样本，导致收敛速度变慢。它的顺序性也阻止了并行化。
- en: Metropolis-Hastings sampling
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Metropolis-Hastings采样
- en: The Metropolis-Hastings algorithm randomly proposes new locations based on its
    current state to effectively explore the sample space and reduce the correlation
    of samples relative to Gibbs sampling. To ensure that it samples from the posterior,
    it evaluates the proposal using the product of prior and likelihood, which is
    proportional to the posterior. It accepts with a probability that depends on the
    result, which is relative to the corresponding value for the current sample.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Metropolis-Hastings算法基于当前状态随机提出新的位置，以有效地探索样本空间，并减少相对于Gibbs采样的样本相关性。为了确保从后验中抽样，它使用先验和似然的乘积来评估提案，这与后验成比例。它接受的概率取决于结果，相对于当前样本的相应值。
- en: A key benefit of the proposal evaluation method is that it works with a proportional
    evaluation rather than an exact evaluation of the posterior. However, it can take
    a long time to converge because the random movements that are not related to the
    posterior can reduce the acceptance rate so that a large number of steps produces
    only a small number of (potentially correlated) samples. The acceptance rate can
    be tuned by reducing the variance of the proposal distribution, but the resulting
    smaller steps imply less exploration.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 提案评估方法的一个关键优势是它使用比后验的精确评估更为比例的评估。然而，它可能需要很长时间才能收敛，因为与后验无关的随机移动可能会降低接受率，导致大量步骤只产生少量（可能相关的）样本。接受率可以通过减小提案分布的方差来调整，但结果是更小的步长意味着更少的探索。
- en: Hamiltonian Monte Carlo – going NUTS
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 哈密顿蒙特卡洛 - 走NUTS
- en: '**Hamiltonian Monte Carlo (HMC)** is a hybrid method that leverages the first-order
    derivative information of the gradient of the likelihood to propose new states
    for exploration and overcome some of the challenges of MCMC. In addition, it incorporates
    momentum to efficiently jump around the posterior. As a result, it converges faster
    to a high-dimensional target distribution than simpler random-walk Metropolis
    or Gibbs sampling.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**哈密顿蒙特卡洛（HMC）**是一种混合方法，利用似然梯度的一阶导数信息来提出新的状态以进行探索，并克服MCMC的一些挑战。此外，它结合了动量，以有效地在后验周围跳跃。因此，它比简单的随机游走Metropolis或Gibbs采样更快地收敛到高维目标分布。'
- en: The No-U-Turn sampler is a self-tuning HMC extension that adaptively regulates
    the size and number of moves around the posterior before selecting a proposal.
    It works well on high-dimensional and complex posterior distributions and allows
    many complex models to be fit without specialized knowledge about the fitting
    algorithm itself. As we will see in the next section, it is the default sampler
    in PyMC3.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: No-U-Turn采样器是一个自调节的HMC扩展，它在选择提案之前自适应地调节后验周围的移动大小和数量。它在高维和复杂的后验分布上表现良好，并允许拟合许多复杂模型，而无需对拟合算法本身有专门的知识。正如我们将在下一节中看到的，它是PyMC3中的默认采样器。
- en: Variational Inference
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变分推断
- en: '**Variational Inference (VI)** is a machine learning method that approximates
    probability densities through optimization. In the Bayesian context, it approximates
    the posterior distribution as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**变分推断（VI）**是一种通过优化来近似概率密度的机器学习方法。在贝叶斯背景下，它近似后验分布如下：'
- en: Select a parametrized family of probability distributions
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个参数化的概率分布族
- en: Find the member of this family closest to the target, as measured by Kullback-Leibler
    divergence
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到这个族中距离目标最近的成员，以Kullback-Leibler散度来衡量
- en: Compared to MCMC, Variational Bayes tends to converge faster and scales to large
    data better. While MCMC approximates the posterior with samples from the chain
    that will eventually converge arbitrarily close to the target, variational algorithms
    approximate the posterior with the result of the optimization, which is not guaranteed
    to coincide with the target.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 与MCMC相比，变分贝叶斯往往收敛更快，并且更适用于大数据。虽然MCMC用链中的样本来逼近后验，最终会收敛到目标，但变分算法用优化结果来逼近后验，这并不保证与目标一致。
- en: Variational Inference is better suited for large datasets and to quickly explore
    many models. In contrast, MCMC will deliver more accurate results on smaller datasets
    or when time and computational resources pose fewer constraints.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 变分推断更适用于大型数据集和快速探索许多模型。相比之下，MCMC在较小的数据集或时间和计算资源约束较少时会提供更准确的结果。
- en: Automatic Differentiation Variational Inference (ADVI)
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动微分变分推断（ADVI）
- en: The downside of Variational Inference is the need for model-specific derivations
    and the implementation of a tailored optimization routine that has slowed down
    widespread adoption.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 变分推断的缺点是需要模型特定的导数和实施一个定制的优化例程，这减缓了广泛的采用速度。
- en: The recent **Automatic Differentiation Variational Inference (ADVI)** algorithm
    automates this process so that the user only specifies the model, expressed as
    a program, and ADVI automatically generates a corresponding variational algorithm
    (see references on GitHub for implementation details).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的**自动微分变分推断（ADVI）**算法自动化了这个过程，用户只需指定模型，表达为一个程序，ADVI会自动生成相应的变分算法（有关实现细节，请参阅GitHub上的参考资料）。
- en: We will see that PyMC3 supports various Variational Inference techniques, including
    ADVI.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到PyMC3支持各种变分推断技术，包括ADVI。
- en: Probabilistic programming with PyMC3
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PyMC3进行概率编程
- en: Probabilistic programming provides a language to describe and fit probability
    distributions so that we can design, encode, and automatically estimate and evaluate
    complex models. It aims to abstract away some of the computational and analytical
    complexity to allow us to focus on the conceptually more straightforward and intuitive
    aspects of Bayesian reasoning and inference.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 概率编程提供了一种描述和拟合概率分布的语言，以便我们可以设计、编码和自动估计和评估复杂模型。它旨在抽象出一些计算和分析复杂性，以便我们可以专注于贝叶斯推理和推断的概念上更为简单和直观的方面。
- en: The field has become quite dynamic since new languages emerged. Uber open sourced
    Pyro (based on PyTorch) and Google recently added a probability module to TensorFlow
    (see the resources linked on GitHub).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 自从新语言出现以来，该领域变得非常活跃。Uber开源了Pyro（基于PyTorch），而Google最近在TensorFlow中添加了一个概率模块（请参见GitHub上链接的资源）。
- en: As a result, the practical relevance and use of Bayesian methods in machine
    learning will likely increase to generate insights into uncertainty and for use
    cases that require transparent rather than black-box models in particular.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，贝叶斯方法在机器学习中的实际相关性和使用可能会增加，以生成对不确定性的洞察，并且特别适用于需要透明模型而不是黑匣模型的用例。
- en: In this section, we will introduce the popular PyMC3 library, which implements
    advanced MCMC sampling and Variational Inference for machine learning models using
    Python. Together with Stan, named after Stanislaw Ulam, who invented the Monte
    Carlo method, and developed by Andrew Gelman at Columbia University since 2012,
    it is the most popular probabilistic programming language.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍流行的PyMC3库，该库使用Python实现了高级MCMC采样和变分推断，用于机器学习模型。与Stan一起，Stan是以Monte
    Carlo方法的发明者Stanislaw Ulam命名的，并由哥伦比亚大学的Andrew Gelman自2012年以来开发，它是最流行的概率编程语言。
- en: Bayesian machine learning with Theano
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Theano进行贝叶斯机器学习
- en: PyMC3 was released in January 2017 to add Hamiltonian MC methods to the Metropolis-Hastings
    sampler that's used in PyMC2 (released in 2012). PyMC3 uses Theano as its computational
    backend for dynamic C compilation and automatic differentiation. Theano is a matrix-focused
    and GPU-enabled optimization library that was developed at Yoshua Bengio's Montreal
    Institute for Learning Algorithms (MILA) and inspired TensorFlow. MILA recently
    ceased to further develop Theano due to the success of newer deep learning libraries
    (see Chapter 16 *Deep Learning* for details). PyMC4, which is planned for 2019,
    will use TensorFlow instead, with presumably limited impact on the API.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: PyMC3于2017年1月发布，以将Hamiltonian MC方法添加到PyMC2中使用的Metropolis-Hastings采样器中（2012年发布）。PyMC3使用Theano作为其计算后端，用于动态C编译和自动微分。Theano是一个以矩阵为重点并且支持GPU的优化库，由Yoshua
    Bengio的蒙特利尔学习算法研究所（MILA）开发，并受到TensorFlow的启发。由于新的深度学习库的成功，MILA最近停止进一步开发Theano（有关详细信息，请参见第16章*深度学习*）。计划于2019年发布的PyMC4将改用TensorFlow，对API的影响可能有限。
- en: The PyMC3 workflow
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyMC3工作流程
- en: 'PyMC3 aims for intuitive and readable, yet powerful syntax that reflects how
    statisticians describe models. The modeling process generally follows these five
    steps:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: PyMC3旨在具有直观且可读的强大语法，反映统计学家描述模型的方式。建模过程通常遵循以下五个步骤：
- en: 'Encode a probability model by defining the following:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过定义以下内容来编码概率模型：
- en: The prior distributions that quantify knowledge and uncertainty about latent
    variables
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 量化关于潜在变量的知识和不确定性的先验分布
- en: The likelihood function that conditions the parameters on observed data
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将似然函数条件化为观察到的数据的参数
- en: 'Analyze the posterior using one of the options described in the previous section:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用前一节描述的选项之一分析后验：
- en: Obtain a point estimate using MAP inference
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用MAP推断获得一个点估计
- en: Sample from the posterior using MCMC methods
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用MCMC方法从后验中抽样
- en: Approximate the posterior using variational Bayes.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用变分贝叶斯近似后验。
- en: Check your model using various diagnostic tools.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用各种诊断工具检查您的模型。
- en: Generate predictions.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成预测。
- en: The resulting model can be used for inference to gain detailed insights into
    parameter values as well as to predict outcomes for new data points.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 由此产生的模型可以用于推断，以获得对参数值的详细洞察，以及对新数据点的预测结果。
- en: We will illustrate this workflow using simple logistic regression (see the notebook
    bayesian_logistic_regression). Subsequently, we will use PyMC3 to compute and
    compare Bayesian Sharpe ratios, estimate dynamic pairs trading ratios, and implement
    Bayesian linear time series models.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用简单的逻辑回归来说明这个工作流程（请参阅笔记本贝叶斯逻辑回归）。随后，我们将使用PyMC3来计算和比较贝叶斯夏普比率，估计动态配对交易比率，并实现贝叶斯线性时间序列模型。
- en: Model definition – Bayesian logistic regression
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型定义 - 贝叶斯逻辑回归
- en: As discussed in [Chapter 6](3efbd9df-a459-406a-a86e-1cb5512a9122.xhtml), *Machine
    Learning Workflow*, logistic regression estimates a linear relationship between
    a set of features and a binary outcome, which is mediated by a sigmoid function
    to ensure that the model produces probabilities. The frequentist approach resulted
    in point estimates for the parameters that measure the influence of each feature
    on the probability that a data point belongs to the positive class, with confidence
    intervals based on assumptions about the parameter distribution.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第6章](3efbd9df-a459-406a-a86e-1cb5512a9122.xhtml)中所讨论的，*机器学习工作流*，逻辑回归估计了一组特征与二元结果之间的线性关系，这是通过S形函数中介的，以确保模型产生概率。频率学派方法导致了参数的点估计，这些参数衡量了每个特征对数据点属于正类的概率的影响，置信区间基于对参数分布的假设。
- en: In contrast, Bayesian logistic regression estimates the posterior distribution
    over the parameters itself. The posterior allows for more robust estimates of
    what is called a Bayesian credible interval for each parameter, with the benefit
    of more transparency about the model's uncertainty.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，贝叶斯逻辑回归估计参数本身的后验分布。后验允许更健壮的估计，称为贝叶斯可信区间，对于每个参数，更透明地了解模型的不确定性。
- en: A probabilistic program consists of observed and unobserved random variables
    (RVs). As we have discussed, we define the observed RVs via likelihood distributions
    and unobserved RVs via prior distributions. PyMC3 includes numerous probability
    distributions for this purpose.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 概率程序由观察到的和未观察到的随机变量（RVs）组成。正如我们所讨论的，我们通过似然分布定义观察到的RVs，通过先验分布定义未观察到的RVs。PyMC3包括许多概率分布用于此目的。
- en: We will use a simple dataset that classifies 30,000 individuals by income using
    a threshold of $50K per year. This dataset will contain information on age, sex,
    hours worked, and years of education. Hence, we are modeling the probability that
    an individual earns more than $50K using these features.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个简单的数据集，根据年收入超过5万美元的标准对3万名个体进行分类。该数据集将包含有关年龄、性别、工作小时数和教育年限的信息。因此，我们正在使用这些特征对个体收入超过5万美元的概率进行建模。
- en: 'The PyMC3 library makes it very straightforward to perform approximate Bayesian
    inference for logistic regression. Logistic regression models the probability
    that individual *i* earns a high income based on *k* features, as outlined on
    the left-hand side of the following diagram:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: PyMC3库使得对逻辑回归进行近似贝叶斯推断非常简单。逻辑回归模型了解个体*i*基于*k*特征获得高收入的概率，如下图左侧所示：
- en: '![](img/0cfa2c56-e0a9-4395-9dec-4939160703ac.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0cfa2c56-e0a9-4395-9dec-4939160703ac.png)'
- en: 'We will use the context manager `with` to define a `manual_logistic_model`
    that we can refer to later as a probabilistic model:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用上下文管理器`with`来定义一个`manual_logistic_model`，以便以后可以将其作为概率模型引用：
- en: The random variables for the unobserved parameters for intercept and two features
    are expressed using uninformative priors that assume normal distributions with
    a mean of 0 and a standard deviation of 100.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 未观察到的截距和两个特征的参数的随机变量使用假设均值为0，标准差为100的不知情先验进行表达。
- en: The likelihood combines the parameters with the data according to the specification
    of the logistic regression.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 似然将参数与数据结合起来，根据逻辑回归的规范。
- en: 'The outcome is modeled as a Bernoulli RV with success probability given by
    the likelihood:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果被建模为伯努利RV，其成功概率由似然给出：
- en: '[PRE1]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Visualization and plate notation
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化和板符号
- en: The `pm.model_to_graphviz(manual_logistic_model)` command produces the plate
    notation displayed in the preceding diagram on the right. It shows the unobserved
    parameters as light and the observed elements as dark circles. The rectangle indicates
    the number of repetitions of the observed model element implied by the data included
    in the model definition.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`pm.model_to_graphviz(manual_logistic_model)`命令生成了右侧图表中显示的板符号。它显示了未观察到的参数为浅色，观察到的元素为深色圆圈。矩形表示模型定义中包含的数据隐含的观察模型元素的重复次数。'
- en: The Generalized Linear Models module
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 广义线性模型模块
- en: 'PyMC3 includes numerous common models so that we can usually leave the manual
    specification for custom applications. The following code defines the same logistic
    regression as a member of the **Generalized Linear Models** (**GLM**) family using
    the formula format inspired by the statistical language R that''s ported to Python
    by the `patsy` library:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: PyMC3包括许多常见的模型，因此通常可以将手动规范留给自定义应用程序。以下代码使用受统计语言R启发的公式格式，通过`patsy`库将相同的逻辑回归定义为**广义线性模型**（**GLM**）家族的成员：
- en: '[PRE2]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: MAP inference
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MAP推断
- en: 'We obtain point MAP estimates for the three parameters using the just defined
    model''s `.find_MAP()` method:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用刚刚定义的模型的`.find_MAP()`方法获得了三个参数的点MAP估计：
- en: '[PRE3]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: PyMC3 solves the optimization problem of finding the posterior point with the
    highest density using the quasi-Newton **Broyden-Fletcher-Goldfarb-Shanno (BFGS)**
    algorithm, but offers several alternatives, which are provided by the sciPy library.
    The result is virtually identical to the corresponding statsmodels estimate (see
    the notebook for more information).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: PyMC3使用拟牛顿**Broyden-Fletcher-Goldfarb-Shanno (BFGS)**算法解决了寻找具有最高密度的后验点的优化问题，但提供了几种替代方案，这些替代方案由sciPy库提供。结果几乎与相应的statsmodels估计相同（有关更多信息，请参阅笔记本）。
- en: Approximate inference – MCMC
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 近似推断 - MCMC
- en: 'We will use a slightly more complicated model to illustrate Markov chain Monte
    Carlo inference:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个稍微复杂一点的模型来说明马尔可夫链蒙特卡洛推断：
- en: '[PRE4]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Patsy's function, `I()`, allows us to use regular Python expressions to create
    new variables on the fly. Here, we square `age` to capture the non-linear relationship
    that more experience adds less income later in life.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: Patsy的函数`I()`允许我们使用常规的Python表达式即时创建新变量。在这里，我们对`age`进行平方处理，以捕捉更多经验在后期增加收入的非线性关系。
- en: Note that variables measured on very different scales can slow down the sampling
    process. Hence, we first apply sklearn's `scale()` function to standardize the
    `age`, `hours`, and `educ` variables.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，测量单位差异很大的变量可能会减慢采样过程。因此，我们首先应用sklearn的`scale()`函数来标准化`age`、`hours`和`educ`变量。
- en: Once we have defined our model with the new formula, we are ready to perform
    inference to approximate the posterior distribution. MCMC sampling algorithms
    are available through the `pm.sample()` function.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们用新公式定义了我们的模型，我们就可以进行推断以近似后验分布。MCMC采样算法可通过`pm.sample()`函数获得。
- en: By default, PyMC3 automatically selects the most efficient sampler and initializes
    the sampling process for efficient convergence. For a continuous model, PyMC3
    chooses the NUTS sampler that we discussed in the previous section. It also runs
    variational inference via ADVI to find good starting parameters for the sampler.
    One among several alternatives is to use the MAP estimate.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，PyMC3会自动选择最有效的采样器，并初始化采样过程以实现有效的收敛。对于连续模型，PyMC3选择了我们在前一节中讨论的NUTS采样器。它还通过ADVI运行变分推断来找到采样器的良好起始参数。其中一种替代方案是使用MAP估计。
- en: 'To see what convergence looks like, we first draw only `100` samples after
    tuning the sampler for `1000` iterations. This will be discarded afterwards. The
    sampling process can be parallelized for multiple chains using the `cores` argument
    (except when using GPU):'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 为了看看收敛是什么样子，我们首先在调整采样器1000次迭代后只抽取100个样本。之后这些样本将被丢弃。使用`cores`参数可以为多个链并行进行采样过程（除非使用GPU）：
- en: '[PRE5]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The resulting trace contains the sampled values for each random variable. We
    can continue sampling by providing the trace of a prior run as input (see the
    notebook for more information).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的跟踪包含了每个随机变量的抽样值。我们可以通过提供先前运行的跟踪作为输入来继续抽样（有关更多信息，请参阅笔记本）。
- en: Credible intervals
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可信区间
- en: We can compute the credible intervals—the Bayesian counterpart of confidence
    intervals—as percentiles of the trace. The resulting boundaries reflect confidence
    about the range of the parameter value for a given probability threshold, as opposed
    to the number of times the parameter will be within this range for a large number
    of trials. The notebook illustrates computation and visualization.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以计算可信区间 - 贝叶斯置信区间的百分位数。结果的边界反映了对于给定概率阈值的参数值范围的置信度，而不是参数在大量试验中在此范围内的次数。笔记本中说明了计算和可视化。
- en: Approximate inference – variational Bayes
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 近似推断 - 变分贝叶斯
- en: 'The interface for variational inference is very similar to the MCMC implementation.
    We just use the `fit()` function instead of the `sample()` function, with the
    option to include an early stopping `CheckParametersConvergence` callback if the
    distribution-fitting process converged up to a given tolerance:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 变分推断的接口与MCMC实现非常相似。我们只需使用`fit()`函数而不是`sample()`函数，还可以选择包括一个早停止的`CheckParametersConvergence`回调，如果分布拟合过程收敛到给定的容差：
- en: '[PRE6]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can draw samples from the approximated distribution to obtain a trace object
    like we did previously for the MCMC sampler:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从近似分布中抽取样本，以获得类似我们之前对MCMC采样器所做的跟踪对象：
- en: '[PRE7]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Inspection of the trace summary shows that the results are slightly less accurate.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 检查跟踪摘要显示结果略微不够准确。
- en: Model diagnostics
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型诊断
- en: Bayesian model diagnostics includes validating that the sampling process has
    converged and consistently samples from high probability areas of the posterior,
    and confirming that the model represents the data well.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯模型诊断包括验证采样过程是否收敛并且从后验的高概率区域中一致地采样，并确认模型是否很好地代表了数据。
- en: Convergence
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收敛
- en: 'We can visualize the samples over time and their distributions to check the
    quality of the results. The following charts show the posterior distributions
    after an initial 100 and an additional 100,000 samples, respectively, and illustrate
    how convergence implies that multiple chains identify the same distribution. The
    `pm.trace_plot()` function shows the evolution of the samples as well (see the
    notebook for more information):'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以随时间可视化样本及其分布，以检查结果的质量。下图显示了初始100个样本和额外的100,000个样本后的后验分布，说明了收敛意味着多个链识别相同的分布。`pm.trace_plot()`函数也显示了样本的演变（有关更多信息，请参阅笔记本）：
- en: '![](img/a0a30aea-9601-4882-b21c-b5463825d26d.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a0a30aea-9601-4882-b21c-b5463825d26d.png)'
- en: Posterior distributions
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 后验分布
- en: 'PyMC3 produces various summary statistics for a sampler. These are available
    as individual functions in the stats module, or by providing a trace to the `pm.summary()`
    function:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: PyMC3为采样器生成各种摘要统计信息。这些信息可以作为stats模块中的单独函数使用，也可以通过将跟踪提供给`pm.summary()`函数来使用：
- en: '|  | **statsmodels** | **mean** | **sd** | **hpd_2.5** | **hpd_97.5** | **n_eff**
    | **Rhat** |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '|  | **statsmodels** | **均值** | **标准差** | **hpd_2.5** | **hpd_97.5** | **n_eff**
    | **Rhat** |'
- en: '| Intercept | -1.97 | -1.97 | 0.04 | -2.04 | -1.89 | 69,492.17 | 1.00 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 截距 | -1.97 | -1.97 | 0.04 | -2.04 | -1.89 | 69,492.17 | 1.00 |'
- en: '| sex[T. Male] | 1.20 | 1.20 | 0.04 | 1.12 | 1.28 | 72,374.10 | 1.00 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 性别[T. 男性] | 1.20 | 1.20 | 0.04 | 1.12 | 1.28 | 72,374.10 | 1.00 |'
- en: '| age | 1.10 | 1.10 | 0.03 | 1.05 | 1.15 | 68,446.73 | 1.00 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 年龄 | 1.10 | 1.10 | 0.03 | 1.05 | 1.15 | 68,446.73 | 1.00 |'
- en: '| I(age ** 2) | -0.54 | -0.54 | 0.02 | -0.58 | -0.50 | 66,539.66 | 1.00 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| I(age ** 2) | -0.54 | -0.54 | 0.02 | -0.58 | -0.50 | 66,539.66 | 1.00 |'
- en: '| hours | 0.32 | 0.32 | 0.02 | 0.28 | 0.35 | 93,008.86 | 1.00 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 小时 | 0.32 | 0.32 | 0.02 | 0.28 | 0.35 | 93,008.86 | 1.00 |'
- en: '| educ | 0.84 | 0.84 | 0.02 | 0.80 | 0.87 | 98,125.26 | 1.00 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 教育 | 0.84 | 0.84 | 0.02 | 0.80 | 0.87 | 98,125.26 | 1.00 |'
- en: The preceding tables includes the (separately computed) statsmodels `logit`
    coefficients in the first column to show that, in this simple case, both models
    agree because the sample mean is very close to the coefficients.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的表格包括了（分别计算的）statsmodels `logit`系数，以显示在这种简单情况下，两个模型是一致的，因为样本均值非常接近系数。
- en: The remaining columns contain the **highest posterior density** (**HPD**) estimate
    for the minimum width credible interval, the Bayesian version of a confidence
    interval, which here is computed at the 95% level. The `n_eff` statistic summarizes
    the number of effective (not rejected) samples resulting from the ~100K draws.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 其余列包含了最高后验密度（HPD）估计的最小宽度可信区间，这是置信区间的贝叶斯版本，在这里计算的置信水平为95%。`n_eff`统计量总结了从约100K次抽样中得到的有效（未被拒绝）样本的数量。
- en: R-hat, also known as the Gelman-Rubin statistic, checks convergence by comparing
    the variance between chains to the variance within each chain. If the sampler
    converged, these variances should be identical, that is, the chains should look
    similar. Hence, the statistic should be near 1\. The `pm.forest_plot()` function
    also summarizes this statistic for the multiple chains (see the notebook for more
    information).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: R-hat，也称为Gelman-Rubin统计量，通过比较链之间的方差与每个链内的方差来检查收敛性。如果采样器收敛，这些方差应该是相同的，即链应该看起来相似。因此，统计量应该接近1。`pm.forest_plot()`函数还总结了多个链的这个统计量（有关更多信息，请参阅笔记本）。
- en: 'For high-dimensional models with many variables, it becomes cumbersome to inspect
    numerous traces. When using NUTS, the energy plot helps to assess problems of
    convergence. It summarizes how efficiently the random process explores the posterior.
    The plot shows the energy and the energy transition matrix, which should be well-matched,
    as in the following example (see references for conceptual detail):'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有许多变量的高维模型，检查大量的轨迹变得很麻烦。在使用NUTS时，能量图有助于评估收敛问题。它总结了随机过程探索后验的效率。该图显示了能量和能量转移矩阵，它们应该匹配良好，如下例所示（有关概念细节，请参阅参考资料）：
- en: '![](img/942e20a0-7f47-4a68-bec8-b9c441eb2998.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/942e20a0-7f47-4a68-bec8-b9c441eb2998.png)'
- en: Posterior Predictive Checks
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 后验预测检查
- en: '**Posterior Predictive Checks** (**PPCs**) are very useful for examining how
    well a model fits the data. They do so by generating data from the model using
    parameters from draws from the posterior. We use the `pm.sample_ppc` function
    for this purpose and obtain *n* samples for each observation (the GLM module automatically
    names the outcome `''y''`):'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '**后验预测检查**（**PPCs**）非常有用，可以检查模型与数据的拟合程度。它通过使用从后验中抽取的参数生成模型的数据来实现。我们使用`pm.sample_ppc`函数来实现这一目的，并为每个观察结果获得*n*个样本（GLM模块会自动将结果命名为`''y''`）：'
- en: '[PRE8]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can evaluate the in-sample fit using the auc score, for example, to compare
    different models:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用auc分数来评估样本内拟合，例如，比较不同模型：
- en: '[PRE9]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Prediction
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测
- en: 'Predictions use Theano''s shared variables to replace the training data with
    test data before running posterior predictive checks. To facilitate visualization,
    we create a variable with a single predictor hours, create the train and test
    datasets, and convert the former to a shared variable. Note that we need to use
    numPy arrays and provide a list of column labels (see the notebook for details):'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行后验预测检查之前，预测使用Theano的共享变量来替换训练数据为测试数据。为了便于可视化，我们创建一个具有单个预测变量小时的变量，创建训练和测试数据集，并将前者转换为共享变量。请注意，我们需要使用numPy数组并提供列标签的列表（有关详细信息，请参阅笔记本）：
- en: '[PRE10]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We then run the sampler as before, and apply the `pm.sample_ppc` function to
    the resulting trace after replacing the train with test data:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们像以前一样运行采样器，并在用测试数据替换训练数据后，将`pm.sample_ppc`函数应用于生成的轨迹：
- en: '[PRE11]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The AUC score for this model with a single feature is 0.65\. The following
    plot shows the actual outcomes and uncertainty surrounding the predictions for
    each sampled predictor value:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型具有单个特征的AUC分数为0.65。下图显示了每个抽样预测值的实际结果和预测周围的不确定性：
- en: '![](img/fdbd2eb0-564b-4cfa-a6db-79e5f0ff5838.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fdbd2eb0-564b-4cfa-a6db-79e5f0ff5838.png)'
- en: We will now illustrate how to apply Bayesian analysis to trading-related use
    cases.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将说明如何将贝叶斯分析应用于与交易相关的用例。
- en: Practical applications
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实际应用
- en: There are numerous applications to Bayesian machine learning methods to investment.
    The transparency that probabilistic estimates create are naturally useful for
    risk management and performance evaluation. We will illustrate the computation
    and comparison of a metric like the Sharpe ratio. The GitHub repository also includes
    two notebooks referenced below that present the use of Bayesian ML for modeling
    linear time series and stochastic volatility.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯机器学习方法在投资中有许多应用。概率估计所产生的透明度对风险管理和绩效评估非常有用。我们将说明如何计算和比较夏普比率等指标。GitHub存储库还包括下面引用的两个笔记本，介绍了使用贝叶斯ML对线性时间序列和随机波动性进行建模。
- en: These notebooks have been adapted from tutorials created at Quantopian where
    Thomas Wiecki leads data science and has significantly contributed to popularizing
    the use of Bayesian methods. The references also include a tutorial on using Bayesian
    ML to estimate pairs trading hedging ratios.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这些笔记本是从Quantopian创建的教程中改编而来，Thomas Wiecki在数据科学方面发挥了领导作用，并对推广贝叶斯方法做出了重大贡献。参考资料还包括使用贝叶斯ML估计配对交易套期保值比率的教程。
- en: Bayesian Sharpe ratio and performance comparison
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 贝叶斯夏普比率和绩效比较
- en: In this section, we will illustrate how to define the Sharpe ratio as a probability
    model and compare the resulting posterior distributions for different return series.
    The Bayesian estimation for two groups provides complete distributions of credible
    values for the effect size, group means and their difference, standard deviations
    and their difference, and the normality of the data.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将说明如何将夏普比率定义为概率模型，并比较不同回报序列的后验分布。两组的贝叶斯估计提供了效应大小、组均值及其差异、标准差及其差异以及数据的正态性的完整可信值分布。
- en: Key use cases include the analysis of differences between alternative strategies,
    or between a strategy's in-sample return in relation to its out-of-sample return
    (see the `bayesian_sharpe_ratio` notebook for details). The Bayesian Sharpe ratio
    is also part of pyfolio's Bayesian tearsheet.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 关键用例包括分析替代策略之间的差异，或者分析策略的样本内回报与样本外回报之间的差异（有关详细信息，请参阅`bayesian_sharpe_ratio`笔记本）。贝叶斯夏普比率也是pyfolio的贝叶斯tearsheet的一部分。
- en: Model definition
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型定义
- en: To model the Sharpe ratio as a probabilistic model, we need the priors about
    the distribution of returns and the parameters that govern this distribution.
    The student t distribution exhibits fat tails that are relative to the normal
    distribution for low **degrees of freedom** (**df**), and is a reasonable choice
    to capture this aspect of returns.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将夏普比率建模为概率模型，我们需要关于回报分布和控制该分布的参数的先验。学生t分布相对于低**自由度**（**df**）的正态分布具有厚尾，是捕捉回报这一方面的合理选择。
- en: 'Hence, we need to model the three parameters of this distribution, namely the
    mean and standard deviation of returns, and the degrees of freedom. We''ll assume
    normal and uniform distributions for the mean and the standard deviation, respectively,
    and an exponential distribution for the df with a sufficiently low expected value
    to ensure fat tails. Returns are based on these probabilistic inputs, and the
    annualized Sharpe ratio results from the standard computation, ignoring a risk-free
    rate (using daily returns):'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要对这个分布的三个参数进行建模，即收益的均值和标准差，以及自由度。我们将假设均值和标准差分别服从正态和均匀分布，自由度服从指数分布，期望值足够低以确保尾部厚重。收益基于这些概率输入，并且年化夏普比率的结果来自标准计算，忽略无风险利率（使用每日收益）：
- en: '[PRE12]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The notebook contains details on sampling and evaluating the Sharpe ratio for
    a single stock.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本包含有关对单只股票进行采样和评估夏普比率的细节。
- en: Performance comparison
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能比较
- en: 'To compare the performance of two return series, we model each group''s Sharpe
    ratio separately and compute the effect size as the difference between the volatility-adjusted
    returns. Visualizing the traces reveals granular performance insights into the
    distributions of each metric, as illustrated by the following chart:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较两个收益系列的性能，我们分别对每组的夏普比率进行建模，并计算效应大小作为波动率调整收益之间的差异。可视化跟踪揭示了对每个指标分布的细粒度性能见解，如下图所示：
- en: '![](img/913b974b-938b-49b9-a005-f2b140943d2a.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![](img/913b974b-938b-49b9-a005-f2b140943d2a.png)'
- en: Bayesian Linear Regression for Pairs Trading
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 用于配对交易的贝叶斯线性回归
- en: In the last chapter, we introduced pairs trading as a popular algorithmic trading
    strategy that relies on the cointegration of two or more assets. Given such assets,
    we need to estimate the hedging ratio to decide on the relative magnitude of long
    and short positions. A basic approach uses linear regression.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一章中，我们介绍了配对交易作为一种依赖于两个或更多资产的协整的流行算法交易策略。鉴于这样的资产，我们需要估计对冲比率，以决定多头和空头头寸的相对大小。一个基本的方法使用线性回归。
- en: The `linear_regression` notebook illustrates how Bayesian linear regression
    tracks changes in the relationship between two assets over time.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '`linear_regression`笔记本演示了贝叶斯线性回归如何跟踪两个资产之间的关系随时间的变化。'
- en: Bayesian time series models
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 贝叶斯时间序列模型
- en: PyMC3 includes AR(p) models that allow us to gain similar insights into the
    parameter uncertainty, as for the previous models. The `bayesian_time_series`
    notebook illustrates a time series model for one or more lags.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: PyMC3包括AR(p)模型，允许我们对参数不确定性获得类似的见解，就像对于之前的模型一样。`bayesian_time_series`笔记本演示了一个或多个滞后的时间序列模型。
- en: Stochastic volatility models
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机波动模型
- en: As discussed in the last chapter, asset prices have time-varying volatility.
    In some periods, returns are highly variable, while in others, they are very stable.
    Stochastic volatility models model this with a latent volatility variable, which
    is modeled as a stochastic process. The No-U-Turn sampler was introduced using
    such a model, and the `stochastic_volatility` notebook illustrates this use case.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 正如上一章所讨论的，资产价格具有时变波动性。在某些时期，收益高度变化，而在其他时期，它们非常稳定。随机波动模型使用潜在波动率变量来模拟这一点，这个变量被建模为一个随机过程。No-U-Turn采样器是使用这样一个模型引入的，`stochastic_volatility`笔记本演示了这种用例。
- en: Summary
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we explored Bayesian approaches to machine learning. We saw
    that they have several advantages, including the ability to encode prior knowledge
    or opinions, deeper insights into the uncertainty surrounding model estimates
    and predictions, and the suitability for online learning, where each training
    sample incrementally impacts the model's prediction.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了机器学习的贝叶斯方法。我们发现它们有几个优点，包括能够编码先验知识或观点，更深入地了解模型估计和预测周围的不确定性，以及适用于在线学习，其中每个训练样本逐渐影响模型的预测。
- en: We learned to apply the Bayesian workflow from model specification to estimation,
    diagnostics, and prediction using PyMC3 and explored several relevant applications.
    We will encounter more Bayesian models in [Chapter 14](beb6fa08-c790-47d5-82ef-f48a81dcf3d1.xhtml), *Topic
    Modeling* and in Chapter 19 on unsupervised deep learning where we will introduce
    variational autoencoders.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学会了应用贝叶斯工作流程，从模型规范到估计、诊断和预测，使用PyMC3并探索了几个相关的应用。我们将在[第14章](beb6fa08-c790-47d5-82ef-f48a81dcf3d1.xhtml)中遇到更多的贝叶斯模型，*主题建模*，以及第19章中的无监督深度学习，我们将介绍变分自动编码器。
- en: The next two chapter introduce tree-based, non-linear ensemble models, namely
    random forests and gradient boosting machines.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的两章介绍了基于树的非线性集成模型，即随机森林和梯度提升机。

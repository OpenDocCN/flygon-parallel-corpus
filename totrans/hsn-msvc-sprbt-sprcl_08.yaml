- en: Developing Reactive Microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to develop reactive microservices, that is,
    how to develop non-blocking synchronous REST APIs and asynchronous event-driven
    services using Spring. We will also learn about how to choose between these two
    alternatives. Finally, we will see how to create and run manual and automated
    tests of a reactive microservice landscape.
  prefs: []
  type: TYPE_NORMAL
- en: As already described in the *Reactive microservices* section in [Chapter 1](282e7b49-42b8-4649-af81-b4b6830d391d.xhtml),
    *Introduction to Microservices*, the foundations for reactive systems is that
    they are message-driven—they use asynchronous communication. This enables them
    to be elastic, that is, scalable and resilient, meaning that they will be tolerant
    to failures. Elasticity and resilience together will enable a reactive system
    to be responsive; they will be able to respond in a timely fashion.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Choosing between non-blocking synchronous APIs and event-driven asynchronous
    services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing non-blocking synchronous REST APIs using Spring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing event-driven asynchronous services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running manual tests of the reactive microservice landscape
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running automated tests of the reactive microservice landscape
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the commands described in this book are run on a MacBook Pro using macOS
    Mojave but should be straightforward to modify so that they can run on another
    platform such as Linux or Windows.
  prefs: []
  type: TYPE_NORMAL
- en: No new tools need to be installed in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The source code for this chapter can be found on GitHub: [https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter07](https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter07).
  prefs: []
  type: TYPE_NORMAL
- en: 'To be able to run the commands as described in the book, download the source
    code to a folder and set up an environment variable, `$BOOK_HOME`, that points
    to that folder. Some sample commands are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The Java source code is written for Java 8 and tested on Java 12\. This chapter
    uses Spring Cloud 2.1.0 (also known as the **Greenwich** release), Spring Boot
    2.1.2, and Spring 5.1.4, which are the latest available versions of the Spring
    components at the time of writing this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The source code contains the following Gradle projects:'
  prefs: []
  type: TYPE_NORMAL
- en: '`api`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`util`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`microservices/product-service`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`microservices/review-service`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`microservices/recommendation-service`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`microservices/product-composite-service`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code examples in this chapter all come from the source code in `$BOOK_HOME/Chapter07`,
    but are edited in many cases in order to remove irrelevant parts of the source
    code, such as comments and import and log statements.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter*,* you can take a look at the changes that ware applied to the
    source code and what it took to make the microservices reactive. This code can
    be compared to the source code for [Chapter 6](6c495e97-f473-4cb1-a404-11fd938f5478.xhtml),
    *Adding Persistence*. You can use your favorite `diff`-tool and compare the two
    folders – `$BOOK_HOME/Chapter06` and `$BOOK_HOME/Chapter07`.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing between non-blocking synchronous APIs and event-driven asynchronous
    services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When developing reactive microservices, it is not always obvious when to use
    non-blocking synchronous APIs and when to use event-driven asynchronous services.
    In general, to make a microservice robust and scalable, it is important to make
    it as autonomous as possible, for example, minimizing its runtime dependencies.
    This is also known as **loose** **coupling**. Therefore, asynchronous message
    passing of events, is preferable over synchronous APIs. This is because the microservice
    will only depend on access to the messaging system at runtime instead of being
    dependent on synchronous access to a number of other microservices.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are, however, a number of cases where non-blocking synchronous APIs could
    be favorable to use, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: For read operations where an end user is waiting for a response
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where the client platforms are more suitable for consuming synchronous APIs,
    for example, mobile apps or SPA web applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where the clients will connect to the service from other organizations—where
    it might be hard to agree over a common messaging system to use across organizations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For the system landscape used in this book, we will use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The create, read, and delete services exposed by the product composite microservice
    will be based on synchronous APIs. The composite microservice is assumed to have
    clients on both web and mobile platforms, as well as clients coming from other
    organizations rather than the ones that operate the system landscape. Therefore,
    synchronous APIs seem like a natural match.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The read services provided by the core microservices will also be developed
    as non-blocking synchronous APIs since there is an end user waiting for their
    responses.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The create and delete services provided by the core microservices will be developed
    as event-driven asynchronous services. The synchronous APIs provided by the composite
    microservices to create and delete aggregated product information will simply
    publish, create, and delete events on the topics that the core services listen
    on and then return with a 200 (OK) response.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This is illustrated by the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a8f1c5bd-e29b-4f4d-a527-a0f86fd863b1.png)'
  prefs: []
  type: TYPE_IMG
- en: First, let's learn how we can develop non-blocking synchronous REST APIs, and
    thereafter, we will look at how to develop event-driven asynchronous services.
  prefs: []
  type: TYPE_NORMAL
- en: Developing non-blocking synchronous REST APIs using Spring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will learn how to develop non-blocking versions of the
    read APIs. The composite service will make reactive, that is, non-blocking, calls
    in parallel to the three core services. When the composite service has received
    responses from the core services, it will create a composite response and send
    it back to the caller. This is illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/676c4d79-653b-438c-b8ff-7ffe0477644d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We will cover the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to Spring Reactor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-blocking persistence using Spring Data for MongoDB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-blocking REST APIs in the core services, including how to handle blocking
    code for the JPA-based persistence layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-blocking REST APIs in the composite service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An introduction to Spring Reactor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we mentioned in the *Beginning with Spring WebFlux* section in [Chapter 2](9878a36a-5760-41a4-a132-1a2387b61037.xhtml),
    *Introduction to Spring Boot*, the reactive support in Spring 5 is based on **Project
    Reactor** ([https://projectreactor.io](https://projectreactor.io)).  Project Reactor
    is based on the *Reactive Streams specification* ([http://www.reactive-streams.org](http://www.reactive-streams.org)),
    a standard for building reactive applications. Spring Reactor is fundamental and
    it is what Spring WebFlux, Spring WebClient, and Spring Data rely on to provide
    their reactive and non-blocking features.
  prefs: []
  type: TYPE_NORMAL
- en: 'The programming model is based on processing streams of data, and the core
    data types in Project Reactor are `Flux` and `Mono`. A `Flux` object is used to
    process a stream of *0*...*n* elements and a `Mono` object is used to process
    *0*...*1* elements. We will see numerous examples of its usage in this chapter.
    As a short introduction, let''s look at the following test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an explanation of the preceding source code:'
  prefs: []
  type: TYPE_NORMAL
- en: We initiate the stream with the integers `1`, `2`, `3`, and `4`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we `filter` out the odd numbers—we only allow even numbers to proceed
    through the stream—in this test, these are `2` and `4`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we transform (or `map`) the values in the stream by multiplying them by
    `2`, that is, to `4` and `8`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, we `log` the data that flows through the stream after the `map` operation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: So far, we have only declared the processing of a stream. To actually get the
    stream processed, we need someone to subscribe to it. The final call to the `subscribe`
    method will register a subscriber and the subscriber will apply the lambda function
    specified in the call to the `subscribe` method on each element it gets from the
    stream. Thereafter, it will add them to the `list` element.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we can assert that `list` after the processing of the stream contains
    the expected result—the integers `4` and `8`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The log output will look like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an explanation of the preceding source code:'
  prefs: []
  type: TYPE_NORMAL
- en: The processing of the stream is started by a subscriber that subscribes to the
    stream and requests its content.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, the integers `4` and `8` pass through the `log` operation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The processing concludes with a call to the `onComplete` method on the subscriber,
    notifying it that the stream has come to an end.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For the full source code, see the `se.magnus.util.reactor.ReactorTests` test
    class in the `util` project.
  prefs: []
  type: TYPE_NORMAL
- en: Normally, we don't initiate the processing of the stream. Instead, we will only
    define how it shall be processed, and it will be the responsibility of an infrastructure
    component, such as Spring WebFlux, to initiate the processing, for example, as
    a response to an incoming HTTP request. An exception to this rule of thumb is
    the case where blocking code needs a response from the reactive stream. In these
    cases, the blocking code can call the `block()` method on the `Flux` or `Mono`
    object to get the response from the `Flux` or `Mono` object in a blocking way.
  prefs: []
  type: TYPE_NORMAL
- en: Non-blocking persistence using Spring Data for MongoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Making the MongoDB-based repositories for the `product` and `recommendation`
    services reactive is very simple:'
  prefs: []
  type: TYPE_NORMAL
- en: Change to the `ReactiveCrudRepository` base class for the repositories
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change the custom finder methods to return a `Mono` or `Flux` object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `ProductRepository` and `RecommendationRepository` look like the following
    after the change:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: No changes are applied to the persistence code for the `review` service, it
    will remain blocking using the JPA repository!
  prefs: []
  type: TYPE_NORMAL
- en: 'For the full source code, take a look at the following classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`se.magnus.microservices.core.product.persistence.ProductRepository` in the `product` project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`se.magnus.microservices.core.recommendation.persistence.RecommendationRepository`
    in the `recommendation` project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changes in the test code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When it comes to testing the persistence layer, we have to make some changes.
    Since our persistence methods now return a `Mono` or `Flux` object, the test methods
    have to wait for the response to be available in the returned reactive objects.
    The test methods can either use an explicit call to the `block()` method on the
    `Mono`/`Flux` object to wait until a response is available or use the `StepVerifier` helper
    class from Project Reactor to declare a verifiable sequence of asynchronous events.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows how to change the test code to work for the reactive
    version of the repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use the `block()` method on the `Mono` object returned by the `repository.findById()`
    method and keep the imperative programming style, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we can use the `StepVerifier` class to set up a sequence of
    processing steps that both execute the repository find operation and also verifies
    the result. The sequence is initialized by the final call to the `verifyComplete()`
    method like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: For examples of using the `StepVerifier` class to write tests, see the `se.magnus.microservices.core.product.PersistenceTests` test
    class in the `product` project.
  prefs: []
  type: TYPE_NORMAL
- en: For corresponding examples of using the `block()` method to write tests, see
    the `se.magnus.microservice.core.recommendation.PersistenceTests` test class in
    the `recommendation` project.
  prefs: []
  type: TYPE_NORMAL
- en: Non-blocking REST APIs in the core services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With a non-blocking persistence layer in place, it''s time to make the APIs
    in the core services non-blocking as well. We need to make the following changes:'
  prefs: []
  type: TYPE_NORMAL
- en: Change the APIs so that they only return reactive data types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change the service implementations so they don't contain any blocking code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change our tests so that they can test the reactive services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deal with blocking code—isolate the code that still needs to be blocking from
    the non-blocking code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changes in the APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To make the APIs of the core services reactive, we need to update their methods
    so that they return either a `Mono` or `Flux` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, `getProduct()` in the `product` service now returns `Mono<Product>`
    instead of a `Product` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'For the full source code, take a look at the following classes in the `api`
    project:'
  prefs: []
  type: TYPE_NORMAL
- en: '`se.magnus.api.core.product.ProductService`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`se.magnus.api.core.recommendation.RecommendationService`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`se.magnus.api.core.review.ReviewService`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changes in the service implementations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the implementations of the services in the `product` and `recommendation`
    services that use a reactive persistence layer, we can use the fluent API in Project
    Reactor. For example, the implementation of the `getProduct()` method looks like
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an explanation of the preceding source code:'
  prefs: []
  type: TYPE_NORMAL
- en: The method will return a `Mono` object; the processing here is declared, not
    triggered. It is triggered by the web framework, `WebFlux`, once it receives a
    request to this service!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A product will be retrieved using its `productId` from the underlying database
    using the `findByProductId()` method in the persistence repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If no product is found for the given `productId`, `NotFoundException` will be
    thrown.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `log` method will produce log output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `mapper.entityToApi()` method will be called to transform the returned entity
    from the persistence layer to an API model object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The final `map` method will set the DNS name and IP address of the microservices
    that processed the request in the `serviceAddress` field of the model object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Some sample log output for successful processing is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is a sample of failed processing (throwing a not found exception):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'For the full source code, see the following classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`se.magnus.microservices.core.product.services.ProductServiceImpl` in the `product`
    project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`se.magnus.microservices.core.recommendation.services.RecommendationServiceImpl` in
    the `recommendation` project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changes in the test code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The test code for service implementations has been changed in the same way as
    the tests for the persistence layer we described previously. To handle the asynchronous
    behavior of the reactive return types, `Mono` and `Flux`, the tests use a mix
    of calling the `block()` method and using the `StepVerifier` helper class.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the full source code, see the following test classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`se.magnus.microservices.core.product.ProductServiceApplicationTests` in the `product` project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`se.magnus.microservices.core.recommendation.RecommendationServiceApplicationTests` in
    the `recommendation` project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dealing with blocking code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the case of the `review` service, which uses JPA to access its data in a
    relational database, we don't have support for a non-blocking programming model.
    Instead, we can run the blocking code using `Scheduler`, which is capable of running
    the blocking code on a thread from a dedicated thread pool with a limited number
    of threads. Using a thread pool for the blocking code avoids draining the available
    threads in the microservice (avoids affecting the non-blocking processing in the
    microservice).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how this process works, as laid out in the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Firstly, we configure the thread pool in the `main` `ReviewServiceApplication` class,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We can configure the size of the thread pool using the `spring.datasource.maximum-pool-size` parameter.
    If it is not set, it will default to 10 threads. For the full source code, see
    the `se.magnus.microservices.core.review.ReviewServiceApplication` class in the `review`
    project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we inject the scheduler into the `review` service implementation class,
    as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we use the thread pool in the reactive implementation of the `getReviews()`
    method, like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an explanation of the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: The blocking code is placed in the `getByProductId()` method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `getReviews()` method uses the `asyncFlux()` method to run the blocking
    code in a thread from the thread pool
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the full source code, see the `se.magnus.microservices.core.review.services.ReviewServiceImpl` class in
    the `review` project.
  prefs: []
  type: TYPE_NORMAL
- en: Non-blocking REST APIs in the composite services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To make our REST API in the composite service non-blocking, we need to do the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Change the APIs so that they only return reactive datatypes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change the integration layer so it uses a non-blocking HTTP client
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change the service implementation so it calls the core services APIs in parallel
    and non-blocking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change our tests so that they can test the reactive service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changes in the API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To make the API of the composite service reactive, we need to apply the same
    type of change that we applied for the APIs of the core services we described
    previously. This means that the return type of the `getCompositeProduct` method,
    `ProductAggregate`, needs to be replaced with `Mono<ProductAggregate>`.
  prefs: []
  type: TYPE_NORMAL
- en: For the full source code, see the `se.magnus.api.composite.product.ProductCompositeService` class
    in the `api` project.
  prefs: []
  type: TYPE_NORMAL
- en: Changes in the integration layer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the `ProductCompositeIntegration` integration class, we have replaced the
    `RestTemplate` blocking HTTP client with the `WebClient` non-blocking HTTP client that
    comes with Spring 5.
  prefs: []
  type: TYPE_NORMAL
- en: 'A builder for the `WebClient` is auto-injected in to the constructor. If customization
    is required, for example, in setting up common headers or filters, it can be done
    in the constructor. For the available configuration options, see [https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux-client-builder](https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux-client-builder).
    Please have a look at the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we simply build the `WebClient` instance that we will use in our integration
    class, without any configuration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we use the `webClient` instance to make our non-blocking requests for
    calling the `product` service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: If the API call to the `product` service fails, the whole request will fail.
    The `WebClient onErrorMap()` method will call our `handleException(ex)` method,
    which maps the exceptions thrown previously by the HTTP layer to our own exceptions,
    for example, `NotFoundException` and `InvalidInputException`.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, if calls to the `product` service succeed but the call to either the recommendation
    or review API fails, we don''t want to let the whole request fail. Instead, we
    want to return as much information that is available, back to the caller. Therefore,
    instead of propagating an exception in these cases, we will instead return an
    empty list of recommendations or reviews using the `WebClient onErrorResume(error
    -> empty())` method. For this, consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: For the full source code, see the `se.magnus.microservices.composite.product.services.ProductCompositeIntegration` class in
    the `product-composite` project.
  prefs: []
  type: TYPE_NORMAL
- en: Changes in the service implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To be able to call the three APIs in parallel, the service implementation uses
    the static `zip()`  method on the `Mono` class. The `zip` method is capable of
    handling a number of parallel requests and zipping them together once they all
    are complete. The code looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an explanation of the preceding source code:'
  prefs: []
  type: TYPE_NORMAL
- en: The first parameter of the `zip` method is a lambda function that will receive
    the responses in an array. The actual aggregation of the responses from the three
    API calls is handled by the same helper method as before, `createProductAggregate`,
    without any changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The parameters after the lambda function are a list of the requests that the
    `zip` method will call in parallel, one `Mono` object per request. In our case,
    we send in three `Mono` objects that were created by the methods in the integration
    class, one for each request that's sent to each core microservice.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For the full source code, see the `se.magnus.microservices.composite.product.services.ProductCompositeServiceImpl` class
    in the `product-composite` project.
  prefs: []
  type: TYPE_NORMAL
- en: Changes in the test code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The only change that''s required in the test classes is to update the setup
    of the mock of the integration class so that the `Mono` and `Flux` objects are
    returned using the  `Mono.just()` helper methods and `Flux.fromIterable()`, as
    shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: For the full source code, see the `se.magnus.microservices.composite.product.ProductCompositeServiceApplicationTests` test
    class in the `product-composite` project.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have developed non-blocking REST APIs with Spring, it is time to
    develop an event-driven synchronous service.
  prefs: []
  type: TYPE_NORMAL
- en: Developing event-driven asynchronous services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will learn how to develop event-driven and asynchronous
    versions of the create and delete services. The composite service will publish create
    and delete events on each core service topic and then return a OK response back
    to the caller without waiting for processing to take place in the core services.
    This is illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6a55381b-4a64-4aa4-84fb-02f258aca361.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Spring Cloud Stream to handle challenges with messaging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining topics and events
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changes in Gradle build files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Publishing events in the composite service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consuming events in the core services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring Spring Cloud Stream to handle challenges with messaging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To implement the event-driven create and delete services, we will use Spring
    Cloud Stream. In [Chapter 2](9878a36a-5760-41a4-a132-1a2387b61037.xhtml), *Introduction
    to Spring Boot*, in the *Spring Cloud Stream* section, we have already seen how
    easy it is to publish and consume messages on a topic using Spring Cloud Stream.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, to publish a message on a topic defined by `mysource`, we only
    have to write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'For consuming a message, we write the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This programming model can be used independently of the messaging system used,
    for example, RabbitMQ or Apache Kafka!
  prefs: []
  type: TYPE_NORMAL
- en: 'Even though sending asynchronous messages is preferred over synchronous API
    calls, it comes with challenges. We will see how we can use Spring Cloud Stream
    to handle some of them. The following features in Spring Cloud Stream will be
    covered:'
  prefs: []
  type: TYPE_NORMAL
- en: Consumer groups
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retries and dead-letter queues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guaranteed orders and partitions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We'll study each of these in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Consumer groups
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The problem here is, if we scale up the number of instances of a message consumer,
    for example, start two instances of the product microservice, both instances of
    the product microservice will consume the same messages, as illustrated by the
    following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/37c34a80-a777-4301-b2dd-c36e1ac8b50d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The solution to this is that we only want one instance per consumer to process
    each message. This can be solved by introducing a *consumer group*, as illustrated
    by the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e4713a81-9342-4fa1-a32d-ea3f544a7596.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In Spring Cloud Stream, a consumer group can be configured on the consumer
    side, for example, for the product microservice, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding configuration, Spring Cloud Stream will use the value of the `group`
    field to add instances of the `product` microservice to the consumer group called `productsGroup`.
    This means that messages sent to the `products` topic will only be delivered by
    Spring Cloud Stream to one of the instances of the product microservice.
  prefs: []
  type: TYPE_NORMAL
- en: Retries and dead-letter queues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will learn how retries and dead-letter queues are used by
    message consumers.
  prefs: []
  type: TYPE_NORMAL
- en: If a consumer fails to process a message, it may lost or be requeued for the
    failing consumer until it is successfully processed. If the content of the message
    is invalid, also known as a **poisoned message**, it will block the consumer from
    processing other messages until it is manually removed. If the failure is due
    to a temporary problem, for example, the database can't be reached due to a temporary
    network error, the processing will probably succeed after a number of retries.
  prefs: []
  type: TYPE_NORMAL
- en: It must be possible to specify the number of retries until a message is moved
    to another storage for fault analysis and correction. A failing message is typically
    moved to a dedicated queue called a dead-letter queue. To avoid overloading the
    infrastructure during temporary failure, for example, a network error, it must
    be possible to configure how often retries are performed and preferably with increasing
    time between each retry.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Spring Cloud Stream, this can be configured on the consumer side, for example,
    for the product microservice, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we specify that Spring Cloud Stream shall perform
    `3` retries before placing a message on the dead-letter queue. The first retry
    shall be attempted after `500` ms and the two other attempts after `1000` ms.
  prefs: []
  type: TYPE_NORMAL
- en: Enabling the use of dead-letter queues is binding-specific; therefore, we have
    one configuration for RabbitMQ and one for Kafka.
  prefs: []
  type: TYPE_NORMAL
- en: Guaranteed order and partitions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can use partitions to ensure that messages are delivered in the same order
    as they were sent but without losing performance and scalability.
  prefs: []
  type: TYPE_NORMAL
- en: If the business logic requires that messages are consumed and processed in the
    same order as they were sent, we cannot use multiple instances per consumer to
    increase processing performance; for example, we cannot use consumer groups. This
    might, in some cases, lead to an unacceptable latency in the processing of incoming
    messages.
  prefs: []
  type: TYPE_NORMAL
- en: In most cases, strict order in the processing of messages is only required for
    messages that affect the same business entities, for example, products.
  prefs: []
  type: TYPE_NORMAL
- en: For example, messages affecting the product with product ID `1` can, in many
    cases, be processed independently of messages that affect the product with product
    ID `2`. This means that the order only needs to be guaranteed for messages that
    have the same product ID.
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution to this is to make it possible to specify a key for each message
    that the messaging system can use in order to guarantee that the order is kept
    between messages with the same key. This can be solved by introducing sub-topics,
    also known as **partitions**, in a topic. The messaging system places messages
    in a specific partition based on its key. Messages with the same key are always
    placed in the same partition. The messaging system only needs to guarantee the
    delivery order for messages in one and the same partition. To ensure the order
    of the messages, we configure one consumer instance per partition within a consumer
    group. By increasing the number of partitions, we can allow a consumer to increase
    its number of instances. This increases its processing message performance without
    losing the delivery order. This is illustrated in the following  diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2962fb3e-d606-4550-8328-c846114f8965.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In Spring Cloud Stream, this needs to be configured on both the publisher and
    consumer side. On the publisher side, the key and number of partitions must be
    specified. For example, for the `product-composite` service, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The preceding configuration means that the key will be taken from the payload
    in the message using a field named `key` and that two partitions will be used.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each consumer can specify which partition it wants to consume messages from. For
    example, for the `product` microservice, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The preceding configuration tells Spring Cloud Stream that this consumer will
    only consume messages from partition number `0`, that is, the first partition.
  prefs: []
  type: TYPE_NORMAL
- en: Defining topics and events
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we already mentioned in the *Spring Cloud Stream* section in [Chapter 2](7d969006-ea94-4bbb-858d-30dce8177a2c.xhtml),
    *Introduction to Spring Boot*, Spring Cloud Stream is based on the publishing
    and subscribe pattern, where a publisher publishes messages to topics and subscribers
    subscribe to topics they are interested in to receive messages.
  prefs: []
  type: TYPE_NORMAL
- en: We will use one **topic** per type of entity: `products`, `recommendations`, and `reviews`.
  prefs: []
  type: TYPE_NORMAL
- en: Messaging systems handle **messages** that typically consist of headers and
    a body. An **event** is a message that describes something that has happened.
    For events, the message body can be used to describe the type of event, the event
    data, and a timestamp for when the event occurred.
  prefs: []
  type: TYPE_NORMAL
- en: 'An event is, for the scope of this book, defined by the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The **type** of event, for example, create or delete an event
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **key**, that identifies the data, for example, a product ID
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **data** element, that is, the actual data in the event
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **timestamp**, which describes when the event occurred
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The event class we will use looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s explain the preceding source code in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: The `Event` class is a generic class parameterized over the types of its `key`
    and `data` field, `K` and `T`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The event type is declared as an enumerator with the allowed values, that is, `CREATE`
    and `DELETE`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The class defines two constructors, one empty and one that can be used to initialize
    the type, key, and value members.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, the class defines getter methods for its member variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the full source code, see the `se.magnus.api.event.Event` class in the `api`
    project.
  prefs: []
  type: TYPE_NORMAL
- en: Changes in the Gradle build files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To bring in Spring Cloud Stream and its binders for RabbitMQ and Kafka, we
    need to add the two starter dependencies known as `spring-cloud-starter-stream-rabbit`
    and `spring-cloud-starter-stream-kafka`. We also need a test dependency, `spring-cloud-stream-test-support`,
    to bring in the test support. The following code shows this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'To specify what version of Spring Cloud that we want to use, we first declare
    a variable for the version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'To wrap up setting up dependency management for that version, we use the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: For the full source code, see the `build.gradle` build file in the `product-composite`
    project.
  prefs: []
  type: TYPE_NORMAL
- en: Publishing events in the composite service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When the composite service receives requests for the creation or deletion of
    products, it shall publish the corresponding events to the core services on their
    topics. To be able to publish events in the composite service, we need to perform
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Declare message sources and publish events in the integration layer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add configuration for publishing events.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change our tests so that they can test the publishing of events.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: No changes are required in the composite service implementation class!
  prefs: []
  type: TYPE_NORMAL
- en: Declaring message sources and publishing events in the integration layer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To be able to publish events to different topics, we need to declare one `MessageChannel` per
    topic in a Java interface and also declare that we want to use it with an `EnableBinding` annotation.
    Let''s us see how to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We declare our message channels in the `MessageSources` interface in the `ProductCompositeIntegration` class
    and ask Spring to inject an instance of it in the constructor, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: When we want to publish an event on a topic, we use the injected `messageSources` object.
    For example, to send a delete event for a product, we can use the `outputProducts()` method
    to get a message channel for the product's topic and then use its `send()` method
    to publish an event.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create the message that contains the event, we can use the built-in `MessageBuilder` class,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: For the full source code, see the `se.magnus.microservices.composite.product.services.ProductCompositeIntegration` class
    in the `product-composite` project.
  prefs: []
  type: TYPE_NORMAL
- en: Adding configuration for publishing events
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We also need to set up a configuration for the messaging system to be able
    to publish events. To do this, we need to complete the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We declare that RabbitMQ is the default messaging system and that the default
    content type is JSON:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we bind our output channels to specific topic names, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we declare connectivity information for both Kafka and RabbitMQ:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: In the default Spring profile, we specify hostnames to be used when we run our
    system landscape without Docker on `localhost` with the IP address `127.0.0.1`.
    In the `docker` Spring profile, we specify the hostnames we will use when running
    in Docker and using Docker Compose, that is, `rabbitmq` and `kafka`.
  prefs: []
  type: TYPE_NORMAL
- en: For the full source code, see the `src/main/resources/application.yml` configuration
    file in the `product-composite` project.
  prefs: []
  type: TYPE_NORMAL
- en: Changes in the test code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing asynchronous event-driven microservices is, by their nature, difficult.
    Tests typically need to synchronize on the asynchronous background processing
    in some way to be able to verify its result. Spring Cloud Stream comes with support,
    in terms of `TestSupportBinder`, for verifying what messages have been sent without
    using any messaging system during the tests!
  prefs: []
  type: TYPE_NORMAL
- en: 'The test support includes a  `MessageCollector` helper class that can be used
    to get all the messages that were sent during a test. To see how it is done, check
    out these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `MessagingTests` test class, we set up a queue that can be used to inspect
    the messages that are sent to each topic, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'An actual test can verify the content in the queue like the following test
    can for the creation of a product:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The `receivesPayloadThat()` method is a static method in another test support
    class in Spring Cloud Stream, `MessageQueueMatcher`. This class contains a set
    of methods that simplify the verification of messages in a queue.
  prefs: []
  type: TYPE_NORMAL
- en: The `sameEventExceptCreatedAt()` method is a static method in the `IsSameEvent`
    class that compares `Event` objects and treats them as equal if all the fields
    are equal, except for the `eventCreatedAt` field.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the full source code, see the following test classes in the `product-composite`
    project:'
  prefs: []
  type: TYPE_NORMAL
- en: '`se.magnus.microservices.composite.product.MessagingTests`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`se.magnus.microservices.composite.product.IsSameEvent`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consuming events in the core services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To be able to consume events in the core services, we need to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Declare message processors that listen for events on its topic.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change our service implementations so it uses the reactive persistence layer
    correctly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add configuration for consuming events.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change our tests so that they can test the asynchronous processing of the events.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Declaring message processors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The REST APIs for creating and deleting entities have been replaced with a
    message processor in each core microservice that listens for creating and deleting
    events on each entity''s topic. To be able to consume messages that have been
    published to a topic, we need to bind to `SubscribableChannel`, similar to how
    we bind to `MessageChannel` when we want to publish messages. Since each message
    processor only listens to one topic, we can use the built-in `Sink` interface
    to bind to that topic. We use the `EnableBinding` annotation to declare the use
    of the `Sink` interface, as shown in the following source code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'To actually consume and process messages, we can annotate a method with the
    `StreamListener` annotation, where we specify what channel we shall listen to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The implementation of the `process()` method uses a `switch` statement to call
    the create method in the service component for creating events and the delete
    method for deleting events. The source code looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s explain the preceding source code in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: The `switch` statement expects an event type that is either a `CREATE` or a
    `DELETE` event.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `productService.createProduct()` method is called for create events.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `productService.deleteProduct()` method is called for delete events.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the event type is neither a  `CREATE` or a `DELETE` event; an exception of
    the `EventProcessingException` type is thrown.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The service component is injected as usual using constructor injection, as
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'For the full source code, see the following classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`se.magnus.microservices.core.product.services.MessageProcessor` in the `product`
    project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`se.magnus.microservices.core.recommendation.services.MessageProcessor` in
    the `recommendation` project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`se.magnus.microservices.core.review.services.MessageProcessor` in the `review`
    project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changes in the service implementations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The service implementations of the create and delete methods for the `product`
    and `recommendation` service have been rewritten to use the non-blocking reactive
    persistence layer for MongoDB. For example, creating product entities is done
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The `onErrorMap()` method is used to map the `DuplicateKeyException` persistence
    exception to our own `InvalidInputException` exception.
  prefs: []
  type: TYPE_NORMAL
- en: Since our message processor is based on a blocking programming model, we need
    to call the `block()` method on the returned `Mono` object from the persistence
    layer before we return it to the message processor. If we don't call the `block()` method,
    we won't be able to trigger the error handling in the messaging system if the
    processing in the service implementation fails; the event will not be requeued,
    and eventually, it will be moved to the dead-letter queue, as expected.
  prefs: []
  type: TYPE_NORMAL
- en: The `review` service that uses the blocking persistence layer for JPA, as before,
    does not need to be updated.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the full source code, see the following classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`se.magnus.microservices.core.product.services.ProductServiceImpl` in the `product`
    project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`se.magnus.microservices.core.recommendation.services.RecommendationServiceImpl` in
    the `recommendation` project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding configuration for consuming events
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We also need to set up the configuration for the messaging system, to be able
    to consume events; this is similar to what we did for the publisher. Declaring
    RabbitMQ as the default messaging system, JSON as the default content type, and
    Kafka and RabbitMQ for connectivity information is the same as for the publisher.
    Added to the common parts, the consumer configuration specifies consumer groups;
    retry handling and dead-letter queues are as they were described earlier in the
    *Configuring Spring Cloud Stream to handle challenges with messaging* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the full source code, see the following configuration files:'
  prefs: []
  type: TYPE_NORMAL
- en: '`src/main/resources/application.yml` in the `product` project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src/main/resources/application.yml` in the `recommendation` project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src/main/resources/application.yml` in the `review` project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changes in the test code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since the core services now receive events for creating and deleting their
    entities, the tests need to be updated so that they send events instead of calling
    REST APIs, like they did previously. In the following source code, we can see
    how the `send()` method on the `input` method channel is used to send an event:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The `input` channel is set up by the test class before any tests are run. It
    is based on the same built-in `Sink` interface that the message processor uses.
    In the following source code, we can see how the `input` channel is created in
    the `setupDb()` method. Since the `setupDb()` method is annotated with `@Before`,
    it will run before any tests are executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: This construction shortcuts the messaging system and the call to the `send()`
    method in the `input` channel will be processed synchronously by the message processor,
    that is, like a normal method call its `process()` method. This means that the
    test code doesn't need to implement any synchronization or *wait logic* for the
    asynchronous processing of an event. Instead, the test code can apply validation
    logic directly after calls to the `sendCreateProductEvent` and `sendDeleteProductEvent` send
    helper methods return.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the full source code, see the following test classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`se.magnus.microservices.core.product.ProductServiceApplicationTests` in the `product`
    project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`se.magnus.microservices.core.recommendation.RecommendationServiceApplicationTests` in
    the `recommendation` project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`se.magnus.microservices.core.review.ReviewServiceApplicationTests` in the `review`
    project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running manual tests of the reactive microservice landscape
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we have fully reactive microservices, both in terms of non-blocking synchronous
    REST APIs and event-driven asynchronous services. Let's try them out!
  prefs: []
  type: TYPE_NORMAL
- en: 'Three different configurations are prepared as follows, each in a separate
    Docker Compose file:'
  prefs: []
  type: TYPE_NORMAL
- en: Using RabbitMQ without the use of partitions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using RabbitMQ with two partitions per topic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Kafka with two partitions per topic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, before testing these three configurations, we first need to simplify
    testing of the reactive microservice landscape. Once simplified, we can proceed
    with testing the microservices.
  prefs: []
  type: TYPE_NORMAL
- en: 'So accordingly, the following two features need to be checked:'
  prefs: []
  type: TYPE_NORMAL
- en: Saving events for later inspection when using RabbitMQ
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A health API that can be used to monitor the state of the landscape
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saving events
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After running some tests on event-driven asynchronous services, it might be
    of interest to see what event was actually sent. When using Spring Cloud Stream
    with Kafka, events are retained in the topics, even after consumers have processed
    them. However, when using Spring Cloud Stream with RabbitMQ, the events are removed
    after they have been processed successfully.
  prefs: []
  type: TYPE_NORMAL
- en: 'To be able to see what events have been published on each topic, Spring Cloud
    Stream is configured to save published events in a separate `auditGroup` consumer
    group per topic. For the `products` topic, the configuration looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: When using RabbitMQ, this will result in extra queues being created where the
    events are stored for later inspection.
  prefs: []
  type: TYPE_NORMAL
- en: For the full source code, see the `src/main/resources/application.yml` configuration
    file in the `product-composite` project.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a health API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing a system landscape of microservices that use a combination of synchronous
    APIs and asynchronous messaging is challenging. For example, how do we know when
    a newly started landscape of microservices, together with their databases and
    messaging system, are ready to process requests and messages?
  prefs: []
  type: TYPE_NORMAL
- en: To make it easier to know when all the microservices are ready to process requests
    and messages, we have added a health API in all the microservices. They are based
    on the support for health endpoints that comes with the Spring Boot module known
    as the Actuator. By default, a `health` endpoint based on the Actuator answers
    `UP` (and gives 200 as the HTTP return status) if the microservice itself and
    all the dependencies Spring Boot knows about are available, for example, dependencies
    to databases and messaging systems; otherwise, the health endpoint answers `DOWN` (and
    returns 500 as the HTTP return status).
  prefs: []
  type: TYPE_NORMAL
- en: We can also extend the `health` endpoint to cover dependencies that Spring Boot
    is not aware of. We will use this feature to extend to the product composite's
    `health` endpoint, which will also include the health of the three core services.
    This means that the product composite `health` endpoint will only respond with
    `UP` if itself and the three core microservices are healthy. This can be used
    either manually or automatically by the `test-em-all.bash` script to find out
    when all the microservices and their dependencies are up and running.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `ProductCompositeIntegration` integration class, we have added helper
    methods for checking the health of the three core microservices, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: This code is similar to the code we used previously to call the core services
    to read APIs.
  prefs: []
  type: TYPE_NORMAL
- en: For the full source code, see the `se.magnus.microservices.composite.product.services.ProductCompositeIntegration` class
    in the `product-composite` project.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the main `ProductCompositeServiceApplication` application class, we use
    these helper methods to register three health checks, one for each core microservice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: For the full source code, see the `se.magnus.microservices.composite.product.ProductCompositeServiceApplication` class
    in the `product-composite` project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, in the `application.yml` file of all four microservices, we configure
    the Spring Boot Actuator so that it does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Show details about the state of health, which not only includes `UP` or `DOWN`,
    but also information about its dependencies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Expose all its endpoints over HTTP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The configuration for these two settings looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: For an example of the full source code, see the `src/main/resources/application.yml` configuration
    file in the `product-composite` project.
  prefs: []
  type: TYPE_NORMAL
- en: '**WARNING**: These configuration settings are good during development, but
    it can be a security issue to reveal too much information in actuator endpoints
    in production systems. Therefore, plan for minimizing the information exposed
    by the actuator endpoints in production!'
  prefs: []
  type: TYPE_NORMAL
- en: 'For details regarding the endpoints that are exposed by Spring Boot Actuator,
    see [https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-endpoints.html](https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-endpoints.html):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Try it out (when you have all the microservices up and running using Docker
    Compose, as described in the next section):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following response:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/2ae85fa6-c021-4370-9850-fb6daec78d0c.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding output, we can see that the composite service reports that
    it is healthy, that is, its status is `UP`. At the end of the response, we can
    see that all three core microservices are also reported as healthy.
  prefs: []
  type: TYPE_NORMAL
- en: With a health API in place, we are ready to test our reactive microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Using RabbitMQ without using partitions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will test the reactive microservices together with RabbitMQ
    but without using partitions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The default `docker-compose.yml` Docker Compose file is used in this configuration.
    The following changes have been applied to the file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'RabbitMQ has been added, as shown here:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The microservices now have a dependency declared to the RabbitMQ service. This
    means that Docker will not start the microservice containers until the RabbitMQ
    service is reported to be healthy:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'To run our tests, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Build and start the system landscape with the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Now, we have to wait for the microservice landscape to be up and running.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Try running the following command a few times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: When it returns `UP`, we are ready to run our tests!
  prefs: []
  type: TYPE_NORMAL
- en: 'First, create a composite product with the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: When using Spring Cloud Stream together with RabbitMQ, it will create one RabbitMQ
    exchange per topic and a set of queues, depending on our configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see what queues that Spring Cloud Stream has created for us!
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the following URL in a web browser: `http://localhost:15672/#/queues`.
    You should see the following queues:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00372e65-3efd-4733-8c3a-773b383cde7e.png)'
  prefs: []
  type: TYPE_IMG
- en: For each topic, we can see one queue for auditGroup, one for the consumer group
    that's used by the corresponding core microservice, and one dead-letter queue.
    We can also see that the auditGroup queues contain messages, as expected!
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the products.auditGroup queue and scroll down to Get Message(s), expand
    it, and click on the button named Get Message(s) to see the message in the queue:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1ce813e3-39eb-4b9a-a69e-b2d4f0a6be85.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, try to get the product composite using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, delete it, like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Trying to get the deleted product again should result in a `404 - "NotFound"`
    response!
  prefs: []
  type: TYPE_NORMAL
- en: If you look in the RabbitMQ audit queues again, you should be able to find new
    messages containing delete events.
  prefs: []
  type: TYPE_NORMAL
- en: 'Wrap up the test by bringing down the microservice landscape with the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: This completes the tests where we use RabbitMQ without partitions. Now, let's
    move on and test RabbitMQ with partitions.
  prefs: []
  type: TYPE_NORMAL
- en: Using RabbitMQ with two partitions per topic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let's try out the partitioning support in Spring Cloud Stream!
  prefs: []
  type: TYPE_NORMAL
- en: 'We have a separate Docker Compose file prepared for using RabbitMQ with two
    partitions per topic: `docker-compose-partitions.yml`. It will also start two
    instances per core microservice, one for each partition. For example, a second
    `product` instance is configured as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an explanation of the preceding source code:'
  prefs: []
  type: TYPE_NORMAL
- en: We use the same source code and Dockerfile that we did for the first `product`
    instance but configure them differently.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specifically, we assign the two `product` instances to different partitions
    using the `instance-index` property we described earlier in this chapter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When using system environment variables to specify Spring properties, we must
    use an uppercase format where dots are replaced with underscores.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This `product` instance will only process asynchronous events; it will not respond
    to API calls. Since it has a different name, `product-p1` (also used as its DNS
    name), it will not respond to calls to a URL starting with `http://product:8080`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Start up the microservice landscape with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Repeat the tests from the previous section but also create a product with the
    product ID set to `2`. If you take a look into the queues set up by Spring Cloud
    Stream, you will see one queue per partition and that the product audit queues
    now contain one message each, that is, the event for product ID `1` was placed
    in one partition and the event for product ID `2` was placed in the other partition.
    If you go back to `http://localhost:15672/#/queues` in your web browser, you should
    see something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4d333160-75e8-4a56-87f6-aeee8765402e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To end the test with RabbitMQ using partitions, bring down the microservice
    landscape with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: We are now done with tests using RabbitMQ, both with and without partitions.
    The final test configuration we shall try out is testing the microservices together
    with Kafka.
  prefs: []
  type: TYPE_NORMAL
- en: Using Netflix Eureka as a discovery service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A discovery service is probably the most important support function required
    to make a landscape of cooperating microservices production-ready. As we already
    described in [Chapter 1](282e7b49-42b8-4649-af81-b4b6830d391d.xhtml), *Introduction
    to Microservices*, in the *Service discovery* section, a discovery service can
    be used to keep track of existing microservices and their instances. The first discovery
    service that Spring Cloud supported was *Netflix Eureka***.**
  prefs: []
  type: TYPE_NORMAL
- en: We will use this in [Chapter 9](9a514887-19f2-4962-9736-2c0d457bfd9e.xhtml),
    *Adding Service Discovery Using Netflix Eureka and Ribbon**,* along with aload
    balancer and the new Spring Cloud load balancer.
  prefs: []
  type: TYPE_NORMAL
- en: We will see how easy it is to register microservices with Netflix Eureka when
    using Spring Cloud, and as a client sends HTTP requests such as a call to a RESTful
    API to one of the instances registered in Netflix Eureka. We will also see how
    to scale up the number of instances of a microservice, and how requests to a microservice
    will be load-balanced over its available instances (based on, by default, round-robin
    scheduling).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot demonstrates the web UI from Eureka, where we can
    see what microservices we have registered:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9d6bf02d-f466-40cf-9bf1-140cbf7d1766.png)'
  prefs: []
  type: TYPE_IMG
- en: The review service has three instances available, while the other two services
    only have one instance each.
  prefs: []
  type: TYPE_NORMAL
- en: With Netflix Eureka introduced, let's introduce how to use Spring Cloud Gateway
    as an edge server.
  prefs: []
  type: TYPE_NORMAL
- en: Using Kafka with two partitions per topic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, we shall try out a very cool feature of Spring Cloud Stream: changing
    the messaging system from RabbitMQ to Apache Kafka!'
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be done simply by changing the value of the `spring.cloud.stream.defaultBinder` property
    from `rabbit` to `kafka`. This is handled by the `docker-compose-kafka.yml` Docker
    Compose file that has also replaced RabbitMQ with Kafka and Zookeeper. The configuration
    of Kafka and Zookeeper looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Kafka is also configured to use two partitions per topic, and like before, we
    start up two instances per core microservice, one for each partition. See the
    Docker Compose file, `docker-compose-kafka.yml`, for details!
  prefs: []
  type: TYPE_NORMAL
- en: 'Start up the microservice landscape with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Repeat the tests from the previous section, for example, create two products,
    one with the product ID set to `1`, and one with the product ID set to `2`.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, Kafka doesn't come with any graphical tools that can be used
    to inspect topics, partitions, and the messages that are placed within them. Instead,
    we can run CLI commands in the Kafka Docker container.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see a list of topics, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Expect an output like the one shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/824bee38-2547-4e15-9c1f-d4a7550eb6a0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here is an explanation of the preceding source code:'
  prefs: []
  type: TYPE_NORMAL
- en: The topics prefixed with `error` are the topics corresponding to dead-letter
    queues.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will not find any `auditGroup` in the case of RabbitMQ; instead, all messages
    the are available in the topics for any consumer to process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To see the partitions in a specific topic, for example, the `products` topic,
    run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Expect an output like the one shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0ba3ea90-0eb6-49b9-94f2-71b377357e60.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To see all the messages in a specific topic, for example, the `products` topic, run
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Expect an output like the one shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7570391d-189e-4c89-b544-547f054cfc71.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To see all the messages in a specific partition, for example, partition `1`
    in the `products` topic, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Expect an output like the one shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9dd71100-be1f-4d1c-b3aa-06094d47fe58.png)'
  prefs: []
  type: TYPE_IMG
- en: The output will end with a timeout exception since we stop the command by specifying
    a timeout for the command of `1000` ms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Bring down the microservice landscape with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: Now, we have learned how Spring Cloud Stream can be used to switch a message
    broker from RabbitMQ to Kafka without requiring any changes in the source code.
    It just requires a few changes in the Docker Compose file.
  prefs: []
  type: TYPE_NORMAL
- en: Running automated tests of the reactive microservice landscape
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To be able to run tests of the reactive microservice landscape automatically
    instead of manually, the automated `test-em-all.bash` test script has been enhanced.
    The most important changes are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The script uses the new `health` endpoint to know when the microservice landscape
    is operational, as shown here:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: The script has a new `waitForMessageProcessing()` function, which is called
    after the test data is set up. Its purpose is simply to wait for the creation
    of the test data to be completed by the asynchronous create services.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To use the test script to automatically run the tests with RabbitMQ and Kafka,
    perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the tests using the default Docker Compose file, that is, with RabbitMQ
    without partitions, with the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the tests for RabbitMQ with two partitions per topic using the Docker Compose `docker-compose-partitions.yml` file
    with the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, run the tests with Kafka and two partitions per topic using the Docker
    Compose `docker-compose-kafka.yml` file with the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: In this section, we have learned how to use the `test-em-all.bash` test script
    to automatically run tests of the reactive microservice landscape that have been
    either configured to use RabbitMQ or Kafka as its message broker.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have seen how we can develop reactive microservices!
  prefs: []
  type: TYPE_NORMAL
- en: Using Spring WebFlux and Spring WebClient, we can develop non-blocking synchronous
    APIs that can handle incoming HTTP requests and send outgoing HTTP requests without
    blocking any threads. Using Spring Data's reactive support for MongoDB, we can
    also access MongoDB databases in a non-blocking way, that is, without blocking
    any threads while waiting for responses from the database. Spring WebFlux, Spring
    WebClient, and Spring Data rely on Spring Reactor to provide their reactive and
    non-blocking features. When we must use blocking code, for example, when using
    Spring Data for JPA, we can encapsulate the processing of the blocking code by
    scheduling the processing of it in a dedicated thread pool.
  prefs: []
  type: TYPE_NORMAL
- en: We have also seen how Spring Data Stream can be used to develop event-driven
    asynchronous services that work on both RabbitMQ and Kafka as messing systems
    without requiring any changes in the code. By doing some configuration, we can
    use features in Spring Cloud Stream such as consumer groups, retries, dead-letter
    queues, and partitions to handle the various challenges of asynchronous messaging.
  prefs: []
  type: TYPE_NORMAL
- en: We have also learned how to manually and automatically test a system landscape
    consisting of reactive microservices.
  prefs: []
  type: TYPE_NORMAL
- en: This was the final chapter on how to use fundamental features in Spring Boot
    and Spring Framework.
  prefs: []
  type: TYPE_NORMAL
- en: Next up is an introduction to Spring Cloud and how it can be used to make our
    services production-ready, scalable, robust, configurable, secure, and resilient!
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why is it important to know how to develop reactive microservices?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do you choose between non-blocking synchronous APIs and event/message-driven
    asynchronous services?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What makes a message different from an event?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name some challenges with message-driven asynchronous services. How do we handle
    them?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is the following test failing?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: What are the challenges of writing tests with reactive code using JUnit, and
    how can we handle them?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL

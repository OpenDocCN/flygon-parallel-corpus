- en: Understanding Distributed Tracing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解分布式跟踪
- en: In this chapter, we will learn how to use distributed tracing to better understand
    how our microservices cooperate; for example, fulfilling a request sent to the
    external API. Being able to utilize distributed tracing is essential for being
    able to manage a system landscape of cooperating microservices. As already described
    in [Chapter 8](9878a36a-5760-41a4-a132-1a2387b61037.xhtml), *Introduction to Spring
    Cloud*, in reference to the *Spring Cloud Sleuth and Zipkin for distributed tracing* section,
    Spring Cloud Sleuth will be used to collect trace information, and Zipkin will
    be used for the storage and visualization of said trace information.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们将学习如何使用分布式跟踪来更好地理解我们的微服务是如何合作的；例如，如何满足发送到外部API的请求。能够利用分布式跟踪对于管理合作微服务的系统架构至关重要。正如在[第8章](9878a36a-5760-41a4-a132-1a2387b61037.xhtml)中已经描述的那样，*Spring
    Cloud*的介绍，关于*Spring Cloud Sleuth和Zipkin用于分布式跟踪*部分，Spring Cloud Sleuth将用于收集跟踪信息，而Zipkin将用于存储和可视化该跟踪信息。
- en: 'In this chapter, we will learn about the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习以下主题：
- en: Introducing distributed tracing with Spring Cloud Sleuth and Zipkin
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spring Cloud Sleuth和Zipkin介绍分布式跟踪
- en: How to add distributed tracing to the source code
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将分布式跟踪添加到源代码中
- en: 'How to perform distributed tracing:'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何执行分布式跟踪：
- en: 'We will learn how to visualize trace information using Zipkin in relation to
    the following:'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将学习如何使用Zipkin可视化跟踪信息，包括以下内容：
- en: Successful and unsuccessful API requests
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成功和不成功的API请求
- en: Synchronous and asynchronous processing of API requests
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API请求的同步和异步处理
- en: We will use both RabbitMQ and Kafka to send trace events from our microservices
    to the Zipkin server
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将使用RabbitMQ和Kafka从我们的微服务发送跟踪事件到Zipkin服务器
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All commands described in this book are run on a MacBook Pro using macOS Mojave
    but should be straightforward to modify so that they can be run on another platform
    such as Linux or Windows.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中描述的所有命令都是在使用macOS Mojave的MacBook Pro上运行的，但应该很容易修改，以便在其他平台（如Linux或Windows）上运行。
- en: No new tools need to be installed in this chapter.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中不需要安装新工具。
- en: The source code for this chapter can be found on GitHub at [https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter14](https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter14).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的源代码可以在GitHub上找到，网址为[https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter14](https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter14)。
- en: 'To be able to run the commands as described in the book, download the source
    code to a folder and set up an environment variable, `$BOOK_HOME`, that points
    to that folder. Some sample commands are as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '要能够按照书中描述的方式运行命令，请将源代码下载到一个文件夹，并设置一个环境变量`$BOOK_HOME`，指向该文件夹。以下是一些示例命令： '
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The Java source code is written for Java 8 and tested on Java 12\. This chapter
    uses Spring Cloud 2.1.0, SR1 (also known as the **Greenwich** release), Spring
    Boot 2.1.4, and Spring 5.1.6, that is, the latest available version of the Spring
    components at the time of writing this chapter.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Java源代码是针对Java 8编写的，并在Java 12上进行了测试。本章使用的是Spring Cloud 2.1.0，SR1（也称为**Greenwich**发布），Spring
    Boot 2.1.4和Spring 5.1.6，即编写本章时可用的Spring组件的最新版本。
- en: The base Docker image, `openjdk:12.0.2`, is used in all Dockerfiles.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 所有Docker文件中都使用基本Docker镜像`openjdk:12.0.2`。
- en: All source code examples in this chapter come from the source code in `$BOOK_HOME/Chapter14` but
    are, in several cases, edited to remove non-relevant parts of the source code,
    such as comments and import and log statements.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的所有源代码示例都来自`$BOOK_HOME/Chapter14`中的源代码，但在几种情况下进行了编辑，以删除源代码的非相关部分，如注释和导入和日志语句。
- en: If you want to see the changes applied to the source code in this chapter, that
    is, see what it took to add distributed tracing using Spring Cloud Sleuth and
    Zipkin, you can compare it with the source code for [Chapter 13](23795d34-4068-4961-842d-989cde26b642.xhtml),
    *Improving Resilience Using Resilience4j*. You can use your favorite `diff` tool
    and compare the two folders – `$BOOK_HOME/Chapter13` and `$BOOK_HOME/Chapter14`.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想查看本章中应用于源代码的更改，也就是说，查看使用Spring Cloud Sleuth和Zipkin添加分布式跟踪所需的内容，您可以将其与[第13章](23795d34-4068-4961-842d-989cde26b642.xhtml)中的源代码进行比较，*使用Resilience4j改善弹性*。您可以使用您喜欢的`diff`工具并比较这两个文件夹
    - `$BOOK_HOME/Chapter13`和`$BOOK_HOME/Chapter14`。
- en: Introducing distributed tracing with Spring Cloud Sleuth and Zipkin
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spring Cloud Sleuth和Zipkin介绍分布式跟踪
- en: 'To recapitulate from [Chapter 8](9878a36a-5760-41a4-a132-1a2387b61037.xhtml), *Introduction
    to Spring Cloud*, in reference to the *Spring Cloud Sleuth and Zipkin for distributed
    tracing* section, the tracing information from a complete workflow is called a
    **trace** or a **trace** **tree**, and sub-parts of the tree, for example, the
    basic units of work, are called a **span**. Spans can consist of sub spans forming
    the trace tree. The Zipkin UI can visualize a trace tree and its spans as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 从[第8章](9878a36a-5760-41a4-a132-1a2387b61037.xhtml)中再次强调，*Spring Cloud*的介绍，关于*Spring
    Cloud Sleuth和Zipkin用于分布式跟踪*部分，完整工作流程的跟踪信息称为**trace**或**trace** **tree**，树的子部分，例如基本工作单元，称为**span**。跨度可以由形成跟踪树的子跨度组成。Zipkin
    UI可以将跟踪树及其跨度可视化如下：
- en: '![](img/c486eb1c-6ecf-4f66-9783-fdecfe33f7dc.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c486eb1c-6ecf-4f66-9783-fdecfe33f7dc.png)'
- en: 'Spring Cloud Sleuth can send trace information to Zipkin either synchronously
    over HTTP, or asynchronously using a message broker such as RabbitMQ or Kafka.
    To avoid creating runtime dependencies on the Zipkin server from the microservices,
    it is preferable to send trace information to Zipkin asynchronously using either
    RabbitMQ or Kafka. This is illustrated in the following diagram:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Sleuth可以通过HTTP同步或使用消息代理（如RabbitMQ或Kafka）异步地将跟踪信息发送到Zipkin。为了避免微服务对Zipkin服务器的运行时依赖，最好使用RabbitMQ或Kafka异步地将跟踪信息发送到Zipkin。下图说明了这一点：
- en: '![](img/0006d41f-9f89-4f39-a1ca-8d3971451602.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0006d41f-9f89-4f39-a1ca-8d3971451602.png)'
- en: Zipkin comes with native support for storing trace information either in memory,
    or in Apache Cassandra, Elasticsearch, or MySQL. Added to this, a number of extensions
    are available. For details, refer to [https://zipkin.apache.org/pages/extensions_choices.html](https://zipkin.apache.org/pages/extensions_choices.html)[.](https://zipkin.apache.org/pages/extensions_choices.html) In
    this chapter, we will store the trace information in memory.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Zipkin本身原生支持将跟踪信息存储在内存中，或者在Apache Cassandra、Elasticsearch或MySQL中。此外，还提供了许多扩展。有关详细信息，请参阅[https://zipkin.apache.org/pages/extensions_choices.html](https://zipkin.apache.org/pages/extensions_choices.html)。在本章中，我们将把跟踪信息存储在内存中。
- en: Adding distributed tracing to the source code
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向源代码添加分布式跟踪
- en: 'In this section, we will learn how to update the source code to enable distributed
    tracing using Spring Cloud Sleuth and Zipkin. This can be done through the following
    steps:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何更新源代码以使用Spring Cloud Sleuth和Zipkin进行分布式跟踪。可以通过以下步骤完成：
- en: Add dependencies to the build files to bring in Spring Cloud Sleuth and the
    capability of sending trace information to Zipkin.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向构建文件添加依赖项，以引入Spring Cloud Sleuth和发送跟踪信息到Zipkin的能力。
- en: Add dependencies to RabbitMQ and Kafka for the projects that haven't used them
    before, that is, the Spring Cloud projects `authorization-server`, `eureka-server`, and
    `gateway`.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为之前未使用RabbitMQ和Kafka的项目（即Spring Cloud项目`authorization-server`，`eureka-server`和`gateway`）添加依赖项。
- en: Configure the microservices to send trace information to Zipkin using either
    RabbitMQ or Kafka.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置微服务使用RabbitMQ或Kafka发送跟踪信息到Zipkin。
- en: Add a Zipkin server to the Docker compose files.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向Docker compose文件添加Zipkin服务器。
- en: Add the `kafka` Spring profile in `docker-compose-kafka.yml` to the Spring Cloud
    projects `authorization-server`, `eureka-server`, and `gateway`.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`docker-compose-kafka.yml`中为Spring Cloud项目`authorization-server`，`eureka-server`和`gateway`添加`kafka`
    Spring配置文件。
- en: Adding the Zipkin server will be effected using a Docker image from Docker Hub
    that has been published by the Zipkin project. Refer to [https://hub.docker.com/r/openzipkin/zipkin](https://hub.docker.com/r/openzipkin/zipkin)
    for details.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 将使用Zipkin项目在Docker Hub上发布的Docker镜像来添加Zipkin服务器。有关详细信息，请参阅[https://hub.docker.com/r/openzipkin/zipkin](https://hub.docker.com/r/openzipkin/zipkin)。
- en: Zipkin is itself a Spring Boot application and is, at the time of writing, undergoing
    incubation at the **Apache Software Foundation** (**ASF**). Refer to [https://zipkin.apache.org/](https://zipkin.apache.org/)
    for more information.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Zipkin本身是一个Spring Boot应用程序，目前正在**Apache软件基金会**（**ASF**）进行孵化。有关更多信息，请参阅[https://zipkin.apache.org/](https://zipkin.apache.org/)。
- en: Adding dependencies to build files
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向构建文件添加依赖项
- en: To be able to utilize Spring Cloud Sleuth and the ability to send trace information
    to Zipkin, we need to add a couple of dependencies to the Gradle project build
    files, `build.gradle`.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够利用Spring Cloud Sleuth和发送跟踪信息到Zipkin的能力，我们需要向Gradle项目构建文件`build.gradle`中添加一些依赖项。
- en: 'This is accomplished by adding the following two lines:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过添加以下两行来实现：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'For the Gradle projects that haven''t used RabbitMQ and Kafka before, that
    is, the Spring Cloud projects `authorization-server`, `eureka-server`, and `gateway`,
    the following dependencies have to be added:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对于之前未使用RabbitMQ和Kafka的Gradle项目（即Spring Cloud项目`authorization-server`，`eureka-server`和`gateway`），需要添加以下依赖项：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Adding configuration for Spring Cloud Sleuth and Zipkin
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为Spring Cloud Sleuth和Zipkin添加配置
- en: 'Configuration for using Spring Cloud Sleuth and Zipkin is added to the common
    configuration file, `config-repo/application.yml`. In the default profile, it
    is specified that trace information shall be sent to Zipkin using RabbitMQ:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 添加使用Spring Cloud Sleuth和Zipkin的配置到通用配置文件`config-repo/application.yml`中。在默认配置文件中，指定了使用RabbitMQ发送跟踪信息到Zipkin：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'By default, Spring Cloud Sleuth only sends 10% of the traces to Zipkin. To
    ensure that all traces are sent to Zipkin, the following property is added in
    the default profile:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Spring Cloud Sleuth只发送10%的跟踪信息到Zipkin。为了确保所有的跟踪信息都发送到Zipkin，需要在默认配置文件中添加以下属性：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'When sending traces to Zipkin using Kafka, the Spring profile `kafka` will
    be used. In earlier chapters, the `kafka` Spring profile was defined in the configuration
    files specific to the composite and core microservices. In this chapter, where
    the Spring Cloud services will also use Kafka to send trace information to Zipkin,
    the `kafka` Spring profile is moved to the common configuration file, `config-repo/application.yml`.
    The following two properties have also been added to the `kafka` Spring profile:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用Kafka发送跟踪信息到Zipkin时，将使用Spring配置文件`kafka`。在早期的章节中，`kafka` Spring配置文件是在特定于复合和核心微服务的配置文件中定义的。在本章中，Spring
    Cloud服务也将使用Kafka发送跟踪信息到Zipkin，因此`kafka` Spring配置文件被移动到通用配置文件`config-repo/application.yml`中。还添加了以下两个属性到`kafka`
    Spring配置文件中：
- en: '`spring.zipkin.sender.type: kafka` tells Spring Cloud Sleuth to send trace
    information to Zipkin using Kafka.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spring.zipkin.sender.type: kafka`告诉Spring Cloud Sleuth使用Kafka发送跟踪信息到Zipkin。'
- en: '`spring.kafka.bootstrap-servers: kafka:9092` specifies where to find the Kafka
    server.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spring.kafka.bootstrap-servers: kafka:9092`指定了Kafka服务器的位置。'
- en: 'All in all, the `kafka` Spring profile appears as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，`kafka` Spring配置文件如下所示：
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Adding Zipkin to the Docker Compose files
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向Docker Compose文件添加Zipkin
- en: 'As we mentioned previously, the Zipkin server is added to the Docker Compose
    files using an already existing Docker image, `openzipkin/zipkin`, published by
    the Zipkin project. In `docker-compose.yml` and `docker-compose-partitions.yml`,
    where RabbitMQ is used, the definition of the Zipkin server appears as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，Zipkin服务器是通过Zipkin项目发布的现有Docker镜像`openzipkin/zipkin`添加到Docker Compose文件中的。在使用RabbitMQ的`docker-compose.yml`和`docker-compose-partitions.yml`中，Zipkin服务器的定义如下：
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let''s explain the preceding source code:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解释前面的源代码：
- en: The version of the Docker image, `openzipkin/zipkin`, is specified to be version
    `2.12.19`.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker镜像`openzipkin/zipkin`的版本指定为`2.12.19`。
- en: The `RABBIT_ADDRESSES=rabbitmq` environment variable is used to specify that
    Zipkin shall receive trace information using RabbitMQ and that Zipkin shall connect
    to RabbitMQ using the hostname `rabbitmq`.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`RABBIT_ADDRESSES=rabbitmq`环境变量来指定Zipkin应使用RabbitMQ接收跟踪信息，并且Zipkin应使用主机名`rabbitmq`连接到RabbitMQ。
- en: The `STORAGE_TYPE=mem` environment variable is used to specify that Zipkin shall keep
    all trace information in memory.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`STORAGE_TYPE=mem`环境变量来指定Zipkin应将所有跟踪信息保存在内存中。
- en: The memory limit for Zipkin is increased to 512 MB, compared to 350 MB for all
    other containers. The reason for this is that since Zipkin is configured to keep
    all trace information in memory, it will consume more memory than the other containers
    after a while.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zipkin的内存限制增加到512MB，而其他所有容器的内存限制为350MB。这是因为Zipkin被配置为将所有跟踪信息保存在内存中，所以它会比其他容器在一段时间后消耗更多的内存。
- en: Zipkin exposes the HTTP port `9411` for web browsers to access its web user
    interface.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zipkin为Web浏览器公开了HTTP端口9411，以便访问其Web用户界面。
- en: Docker will wait to start up the Zipkin server until the RabbitMQ service reports
    being healthy to Docker.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker将等待启动Zipkin服务器，直到RabbitMQ服务向Docker报告健康状态。
- en: While this is OK to store the trace information in Zipkin in memory for development
    and test activities, Zipkin should be configured to store trace information in
    a database such as Apache Cassandra, Elasticsearch, or MySQL in a production environment.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在开发和测试活动中将跟踪信息存储在Zipkin中的内存中是可以的，但在生产环境中，Zipkin应该配置为将跟踪信息存储在数据库中，例如Apache
    Cassandra、Elasticsearch或MySQL。
- en: 'In `docker-compose-kafka.yml`, where Kafka is used, the definition of the Zipkin
    server appears as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Kafka的`docker-compose-kafka.yml`中，Zipkin服务器的定义如下：
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let''s explain for the preceding source code in detail:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细解释前面的源代码：
- en: The configuration for using Zipkin together with Kafka is similar to the configuration
    when using Zipkin with RabbitMQ previously.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与以前使用RabbitMQ时使用Zipkin的配置类似，使用Kafka与Zipkin一起使用的配置。
- en: The main difference it the use of the `KAFKA_BOOTSTRAP_SERVERS=kafka:9092` environment
    variable, which is used to specify that Zipkin shall use Kafka to receive trace
    information and that Zipkin shall connect to Kafka using the hostname `kafka` and
    the port `9092`.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主要区别在于使用`KAFKA_BOOTSTRAP_SERVERS=kafka:9092`环境变量，该变量用于指定Zipkin应使用Kafka接收跟踪信息，并且Zipkin应使用主机名`kafka`和端口`9092`连接到Kafka。
- en: 'In `docker-compose-kafka.yml`, the `kafka` Spring profile is added to the Spring
    Cloud services `eureka`, `gateway`, and `auth-server`:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在`docker-compose-kafka.yml`中，将`kafka` Spring配置文件添加到Spring Cloud服务`eureka`，`gateway`和`auth-server`中：
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: That's what it takes to add distributed tracing using Spring Cloud Sleuth and
    Zipkin, so let's try it out in the next section!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是使用Spring Cloud Sleuth和Zipkin添加分布式跟踪所需的步骤，让我们在下一节中尝试一下！
- en: Trying out distributed tracing
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 尝试分布式跟踪
- en: 'With the necessary changes to the source code in place, we can try out distributed
    tracing! We will do this by performing the following steps:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在源代码中进行必要的更改后，我们可以尝试分布式跟踪！我们将通过执行以下步骤来实现这一点：
- en: Build, start, and verify the system landscape with RabbitMQ as the queue manager.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用RabbitMQ作为队列管理器构建、启动和验证系统架构。
- en: Send a successful API request and see what trace information we can find in
    Zipkin related to this API request.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送一个成功的API请求，并查看我们可以在Zipkin中找到与此API请求相关的跟踪信息。
- en: Send an unsuccessful API request and see what the trace information in Zipkin
    looks like.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送一个不成功的API请求，并查看Zipkin中的跟踪信息是什么样的。
- en: Send a successful API request that triggers asynchronous processing and see
    how its trace information is represented in Zipkin.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送一个触发异步处理的成功API请求，并查看其在Zipkin中的跟踪信息是如何表示的。
- en: Investigate how we can monitor trace information that's passed to Zipkin in
    RabbitMQ.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调查如何监视传递给Zipkin的RabbitMQ中的跟踪信息。
- en: Switch the queue manager to Kafka and repeat the preceding steps.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将队列管理器切换到Kafka，并重复之前的步骤。
- en: We will discuss these steps in detail in the upcoming sections.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的章节中详细讨论这些步骤。
- en: Starting up the system landscape with RabbitMQ as the queue manager
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用RabbitMQ作为队列管理器启动系统架构
- en: 'Let''s start up the system landscape. Build the Docker images with the following
    commands:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们启动系统架构。使用以下命令构建Docker镜像：
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Start the system landscape in Docker and run the usual tests with the following
    command:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在Docker中启动系统架构，并使用以下命令运行通常的测试：
- en: '[PRE10]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Before we can call the API, we need an access token. Run the following commands
    to acquire an access token:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们调用API之前，我们需要一个访问令牌。运行以下命令获取访问令牌：
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Sending a successful API request
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发送成功的API请求
- en: 'Now, we are ready to send a normal request to the API. Run the following command:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备向API发送正常请求。运行以下命令：
- en: '[PRE12]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Expect the command to returns the HTTP status code for success, 200.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 预期该命令返回成功的HTTP状态码200。
- en: 'We can now launch the Zipkin UI to look into what trace information has been
    sent to Zipkin:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以启动Zipkin UI来查看已发送到Zipkin的跟踪信息：
- en: Open the following URL in your web browser: `http://localhost:9411/zipkin/.`
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Web浏览器中打开以下URL：`http://localhost:9411/zipkin/.`
- en: 'To find the trace information for our request, implement the following steps:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要找到我们请求的跟踪信息，实施以下步骤：
- en: Select Service Name: gateway.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择服务名称：`gateway`。
- en: 'Set Sort order: to Newest First.'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置排序顺序：最新的在前。
- en: Click on the Find Traces button.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击“查找跟踪”按钮。
- en: 'The response from finding traces should look like the following screenshot:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 找到跟踪的响应应该如下截图所示：
- en: '![](img/ee509be8-dcc5-41bb-b758-361379f8fe94.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee509be8-dcc5-41bb-b758-361379f8fe94.png)'
- en: 'The trace information from our preceding API request is the first one in the
    list. Click on it to see details pertaining to the trace:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前的API请求的跟踪信息是列表中的第一个。单击它以查看有关跟踪的详细信息：
- en: '![](img/8fa726b9-d1b5-424a-ade5-c5324f925c2c.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8fa726b9-d1b5-424a-ade5-c5324f925c2c.png)'
- en: 'In the detailed trace information view, we can observe the following:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在详细的跟踪信息视图中，我们可以观察到以下内容：
- en: The request was received by the gateway service.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该请求被`gateway`服务接收。
- en: It delegated the processing of the request to the product-composite service.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The product-composite service, in turn, sent three parallel requests to the
    core services: product, recommendation, and review.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the product-composite service received the response from all three core
    services, it created a composite response.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The composite response was sent back to the caller through the gateway service.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When using Safari, I have noticed that the trace tree isn't always rendered
    correctly. Switching to either Chrome or Firefox resolved the issue.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: 'If we click on the first span, gateway, we can see even more details:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f6f693ce-7cea-43ea-ba6c-8faa8db74269.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
- en: Here, we can see the actual request we sent: product-composite/2\. This is very
    valuable when analyzing traces that, for example, take a long time to complete!
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Sending an unsuccessful API request
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see what the trace information looks like if we make an unsuccessful
    API request; for example, searching for a product that does not exist:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'Send an API request for product ID `12345` and verify that it returns the HTTP
    status code for Not Found, 404:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In the Zipkin UI, go back to the search page (use the back button in the web
    browser) and click on the Find Traces button. You should see the failed request
    at the top of the returned list, in red:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3b7bf196-16fe-4277-8e51-3f393696278f.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
- en: 'Click on the top trace marked in red:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4ca53dfa-35ad-4c3c-b50f-8e3a3c357f61.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
- en: 'In the detailed trace view, we can see by the color-coding that the request
    went wrong when product-composite called the product service. Click on the product
    span to see details of what went wrong:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b33855c9-3b3e-4aaf-81ed-8a080c05dec7.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
- en: 'Here, we can see what request caused the error, product/12345, as well as the
    error code and the reason returned: 404 Not Found. This is very useful when analyzing
    the root cause of a failure!'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: Sending an API request that triggers asynchronous processing
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The third type of request that is interesting to see how it is represented in
    the Zipkin UI is a request where parts of its processing are done asynchronously.
    Let's try a delete request, where the delete process in the core services is done
    asynchronously. The `product-composite` service sends a delete event to each of
    the three core services over the message broker and each core service picks up
    the delete event and processes it asynchronously. Thanks to Spring Cloud Sleuth,
    trace information is added to the events that are sent to the message broker,
    resulting in a coherent view of the total processing of the delete request.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to delete the product with a product ID of `12345` and verify
    that it returns the HTTP status code for success, 200:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Remember that the delete operation is idempotent, that is, it will succeed even
    if the product doesn't exist!
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: 'In the Zipkin UI, go back to the search page (use the back button in the web
    browser) and click on the Find Traces button. You should see the trace from the
    delete request at the top of the returned list:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c8304d85-6234-4bf4-9470-e18b2f92a68a.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
- en: 'Click on the first trace to see its trace information:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b06714c3-aec0-4166-a066-2001d3c14c3d.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
- en: 'Here, we can see the trace information for processing the delete request:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: The request was received by the gateway service.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It delegated the processing of the request to the product-composite service.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The product-composite service, in turn, published three events on the message
    broker (RabbitMQ, in this case).
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The product-composite service is now done and returns a success HTTP status
    code, 200, through the gateway service back to the caller.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The core services, product, recommendation, and review, receive the delete events
    and start to process them asynchronously, that is, independent of one another.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To see more detailed information, click on the product span:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7fd269c2-3bc7-4c83-91cd-6a16c6010757.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
- en: Here, we can see that the product service was triggered by an event coming in
    to its input channel, which was sent from the message broker.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: The Zipkin UI contains much more functionality for finding traces of interest!
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: To get more accustomed to the Zipkin UI, try out the `Annotation Query` parameter;
    for example, search for a specific request using `http.path=/product-composite/214`
    or `error=401` to find requests that failed due to authorization failures. Watch
    out for the `Limit` parameter, which is set to `10` by default; this can hide
    results of interest if not raised. Also, ensure that the `Lookback` parameter
    doesn't remove traces of interest!
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring trace information passed to Zipkin in RabbitMQ
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To monitor trace information that''s sent to Zipkin over RabbitMQ, we can use
    the RabbitMQ management web UI. Open the following URL in your web browser: `http://localhost:15672/#/queues/%2F/zipkin`.
    If required, log in using the username `guest` and the password `guest`. Expect
    a web page that looks like the following:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0ebbf762-280a-457c-b52e-7344c666c249.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
- en: In the graph named `Message Rates`, we can see that trace messages are sent
    to Zipkin, currently at an average rate of 1.2 messages per second.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: 'Wrap up the tests of distributed tracing using RabbitMQ by bringing down the
    system landscape. Run the following command:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Using Kafka as a message broker
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's also verify that we can send trace information to Zipkin using Kafka instead
    of RabbitMQ!
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: 'Start up the system landscape using the following commands:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Repeat the commands we performed in the previous sections, where we used RabbitMQ,
    and verify that you can see the same trace information in the Zipkin UI when using
    Kafka!
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: 'Kafka doesn''t come with a management web UI like RabbitMQ. Therefore, we need
    to run a few Kafka commands to be able to verify that the trace events actually
    were passed to the Zipkin server using Kafka:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: For a recap on how to run Kafka commands when running Kafka as a Docker container,
    refer to the *Using Kafka with two partitions per topic* section in [Chapter 7](436fb8c1-0c4d-410c-a3ec-da251aba4ca1.xhtml),
    *Developing Reactive Microservices.*
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: 'First, list the available topics in Kafka:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Expect to find a topic named `zipkin`:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8ce689f9-3d7a-49de-b487-817b43554f35.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
- en: 'Next, ask for trace events that were sent to the `zipkin` topic:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Expect a lot of events similar to the following:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8fcdde07-be13-497a-8b95-1b56e4fe3a95.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
- en: The details of a trace event are not important. The Zipkin server sorts that
    out for us and makes the information presentable in the Zipkin UI. The important
    point here is that we can see that the trace events actually were sent to the
    Zipkin server using Kafka.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, bring down the system landscape and unset the `COMPOSE_FILE` environment
    variable:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: That concludes this chapter on distributed tracing!
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned how to use distributed tracing to understand
    how our microservices cooperate. We have learned how to use Spring Cloud Sleuth
    to collect trace information, and how to use Zipkin to store and visualize the
    trace information.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: To promote the decoupling of runtime components, we have learned how to configure
    microservices to send trace information to the Zipkin server asynchronously while
    using RabbitMQ and Kafka as message brokers. We have seen how adding Spring Cloud
    Sleuth to microservices is effected by adding a couple of dependencies to the
    build files and setting up a few configuration parameters. We have also seen how
    the Zipkin UI makes it very easy to identify what part of a complex workflow caused
    either an unexpectedly long response time or an error. Both synchronous and asynchronous
    workflows can be visualized by Zipkin UI.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about container orchestrators, specifically
    Kubernetes. We will learn how to use Kubernetes to deploy and manage microservices,
    while also improving important runtime characteristics such as scalability, high
    availability, and resilience.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习有关容器编排器，特别是Kubernetes。我们将学习如何使用Kubernetes来部署和管理微服务，同时改善重要的运行时特性，如可伸缩性、高可用性和韧性。
- en: Questions
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What configuration parameter is used to control how trace information is sent
    to Zipkin?
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用于控制如何将跟踪信息发送到Zipkin的配置参数是什么？
- en: What is the purpose of the `spring.sleuth.sampler.probability` configuration
    parameter?
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`spring.sleuth.sampler.probability`配置参数的目的是什么？'
- en: How can you identify the longest-running request after executing the `test-em-all.bash` test
    script?
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在执行`test-em-all.bash`测试脚本后，如何识别运行时间最长的请求？
- en: How can we find requests that have been interrupted by the timeout introduced
    in [Chapter 13](23795d34-4068-4961-842d-989cde26b642.xhtml), *Improving Resilience
    Using Resilience4j*?
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何找到已被[第13章](23795d34-4068-4961-842d-989cde26b642.xhtml)中引入的超时中断的请求，*使用Resilience4j改善韧性*？
- en: What does the trace look like for an API request when the circuit breaker introduced
    in [Chapter 13](23795d34-4068-4961-842d-989cde26b642.xhtml), *Improving Resilience
    Using Resilience4j*, is open?
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当在[第13章](23795d34-4068-4961-842d-989cde26b642.xhtml)中引入的断路器打开时，API请求的跟踪是什么样的，*使用Resilience4j改善韧性*？
- en: How can we locate APIs that failed on the caller not being authorized to perform
    the request?
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何找到因调用者未被授权执行请求而失败的API？

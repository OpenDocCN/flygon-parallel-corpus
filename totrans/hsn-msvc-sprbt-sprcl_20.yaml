- en: Implementing Kubernetes Features as an Alternative
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The current microservice landscape contains a number of supportive services
    that implement important design patterns required in a large-scale microservice
    landscape; for example an edge, config, and authorization server, and a service
    for distributed tracing. For details, see [Chapter 1](282e7b49-42b8-4649-af81-b4b6830d391d.xhtml),
    *Introduction to Microservices*, and refer to the *Design patterns for microservices*
    section. In the previous chapter, we replaced the implementation of the design
    pattern for service discovery, based on Netflix Eureka, with the built-in discovery
    service in Kubernetes. In this chapter, we will further simplify the microservice
    landscape by reducing the number of supportive services required to be deployed.
    Instead, the corresponding design patterns will be handled by built-in capabilities
    in Kubernetes. The Spring Cloud Config Server will be replaced with Kubernetes
    config maps and secrets. The Spring Cloud Gateway will be replaced by a Kubernetes
    ingress resource, which can act as an edge server in the same way as Spring Cloud
    Gateway.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 11](bcb9bba0-d2fe-4ee8-954b-07a7e38e1115.xhtml), S*ecuring Access
    to APIs*, refer to the *Protecting the external communication with HTTPS* section,
    where we use certificates to protect the external API. Manual handling of certificates
    is both time-consuming and error-prone. As an alternative, we will be introduced
    to the Cert Manager, which can automatically provide new certificates and replace
    expired ones for the external HTTPS endpoint exposed by the ingress. We will configure `cert-manager`
    to use **Let's Encrypt** to issue the certificates. Let's Encrypt is a free Certificate
    Authority that can be used to automatically issue certificates. Let's Encrypt
    must be able to verify that we own the DNS name that the certificate will be issued
    for. Since our Kubernetes cluster runs locally in Minikube, we have to make it
    possible for Let's Encrypt to access our cluster during the provisioning. We will
    use `ngrok` to create a temporary HTTP tunnel from the internet to our local Kubernetes
    cluster to be used by Let's Encrypt.
  prefs: []
  type: TYPE_NORMAL
- en: When using more and more features in a platform such as Kubernetes, it is important
    to ensure that the source code of the microservices isn't dependent on the platform;
    that is, should ensure that the microservices can still be used without Kubernetes.
    To ensure that we can still use the microservices outside Kubernetes, the chapter
    will conclude by deploying the microservice landscape using Docker Compose and
    executing the `test-em-all.bash` test script to verify that the microservices
    still work without using Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Replacing Spring Cloud Config Server with Kubernetes config maps and secrets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replacing Spring Cloud Gateway with a Kubernetes ingress resource
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding the Cert Manager to automatically provide certificates issued by Let's
    Encrypt
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using `ngrok` to establish an HTTP tunnel from the internet to our local Kubernetes
    cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying and testing the microservice landscape using Docker Compose to ensure
    that the source code in the microservices isn't locked into Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All commands described in this book are run on a MacBook Pro using macOS Mojave
    but modifying this so that it can run on other platforms, such as Linux or Windows,
    should be straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: 'The only new tool required for this chapter is the command-line `ngrok` tool
    used for establishing an HTTP tunnel from the internet to our local environment.
    It can be installed using Homebrew with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To use `ngrok`, a free account has to be created and an authorization token
    also has to be registered by taking the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sign up here: [https://dashboard.ngrok.com/signup](https://dashboard.ngrok.com/signup).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After the account is created, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here, `<YOUR_AUTH_TOKEN>` is replaced with the authorization token found on
    the following page—[https://dashboard.ngrok.com/auth](https://dashboard.ngrok.com/auth).
  prefs: []
  type: TYPE_NORMAL
- en: The source code for this chapter can be found on GitHub: [https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter17](https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter17).
  prefs: []
  type: TYPE_NORMAL
- en: 'To be able to run the commands as described in the book, you need to download
    the source code to a folder and set up an environment variable, `$BOOK_HOME`,
    that points to that folder. Sample commands are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The Java source code is written for Java 8 and tested on Java 12\. This chapter
    uses Spring Cloud 2.1, SR2 (also known as the **Greenwich** release), Spring Boot
    2.1.6, and Spring 5.1.8—the latest available versions of the Spring components
    at the time of writing this chapter. The source code has been tested using Kubernetes
    v1.15.
  prefs: []
  type: TYPE_NORMAL
- en: All source code examples in this chapter come from the source code in `$BOOK_HOME/Chapter17` but
    have been edited in several cases to remove non-relevant parts of the source code,
    such as comments, imports, and log statements.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to see the changes applied to the source code in [Chapter 17](a9327ecc-49e7-4f72-9221-3321b7158d83.xhtml), *Implementing
    Kubernetes Features as an Alternative*, that is, the changes required to replace
    the Spring Cloud Config Server and Spring Cloud Gateway with corresponding features
    in Kubernetes, you can compare it with the source code for [Chapter 16](ebeb41b4-eea4-4d73-89ba-6788e2e68bac.xhtml),
    *Deploying Our Microservices to Kubernetes*.  You can use your favorite `diff`
    tool and compare the `$BOOK_HOME/Chapter16` and `$BOOK_HOME/Chapter17` folders.
  prefs: []
  type: TYPE_NORMAL
- en: Replacing the Spring Cloud Config Server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have seen in the previous chapter, [Chapter 16](ebeb41b4-eea4-4d73-89ba-6788e2e68bac.xhtml),
    *Deploying Our Microservices to Kubernetes*, in the *Deploying to Kubernetes*
    section, config maps and secrets can be used to hold configuration information
    for our microservices. The Spring Cloud Config Server adds values such as keeping
    all configuration in one place, optional version control using Git, and the ability
    to encrypt sensitive information on the disk. But it also consumes a non-negligible
    amount of memory (as with any Java and Spring-based application) and adds significant
    overhead during startup. For example, when running automated integration tests
    such as the test script we are using in this book, `test-em-all.bash`, all microservices
    are started up at the same time, including the configuration server. Since the
    other microservices must get their configuration from the configuration server
    before they can start up, they all have to wait for the configuration server to
    be up and running before they can start up. This leads to a significant delay
    when running integration tests. If we use Kubernetes config maps and secrets instead,
    this delay is eliminated, making automated integration tests run faster. To me,
    it makes sense to use the Spring Cloud Config Server where the underlying platform
    doesn't provide a similar capability, but when deploying to Kubernetes, it is
    better to use config maps and secrets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using Kubernetes config maps and secrets instead of the Spring Cloud Config
    Server will make the microservice landscape start up faster and it will require
    less memory. It will also simplify the microservice landscape by eliminating one
    supportive service, the configuration server. This is illustrated by the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7ab391b2-00bd-4930-8d8f-371cd083215a.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's see what is required to replace the Spring Cloud Config Server with Kubernetes
    config maps and secrets!
  prefs: []
  type: TYPE_NORMAL
- en: Note especially that we only change the configuration; that is, no changes are
    required in the Java source code!
  prefs: []
  type: TYPE_NORMAL
- en: Changes in the source code to replace the Spring Cloud Config Server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following changes have been applied in the configuration of the source
    code to replace the Spring Cloud Config Server with Kubernetes config maps and
    secrets:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Removed the project `spring-cloud/config-server`, also including:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removed the project in the `settings.gradle` build file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removed the configuration server YAML files and its declaration in the `kustomization.yml`
    files in the `kubernetes/services/base` and `kubernetes/services/overlays/prod` folders.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Removed configuration from all microservices:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removed the `spring-cloud-starter-config` dependency in the `build.gradle` build
    files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removed the `bootstrap.yml` files in the `src/main/resource` folders in each
    project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removed the  `spring.clod.config.enabled=false` property setting in integration
    tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Changes in the configuration files in the `config-repo` folder:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removed properties with sensitive information, that is, credentials for MongoDB,
    MySQL, RabbiMQ, and the password for the TLS certificate used by the edge server.
    They will be replaced by Kubernetes secrets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The route to the configuration server API is removed in the configuration of
    the edge server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Changes in the Kubernetes definition files for deployment resources in the `kubernetes/services/base` folder:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Config maps are mounted as volumes, that is, as folders in the filesystem of
    the container.  Each microservice gets its own config maps, which contain the
    configuration files applicable for the specific microservice.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define the `SPRING_CONFIG_LOCATION` environment variable to point out the configuration
    files in the volume.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define credentials for access to resource managers using secrets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Most changes are in the Kubernetes definitions files for the deployment resources.
    Let''s look at the definition of the deployment resource for the `product` microservice
    as an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note that parts of the definition that have not been affected by the changes
    are left out for improved readability. See `kubernetes/services/base/product.yml`
    for the full source code.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following explains the preceding source code:'
  prefs: []
  type: TYPE_NORMAL
- en: The `config-repo-product` config map is mapped in a volume named `config-repo-volume`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `config-repo-volume` volume is mounted in the filesystem at `/config-repo`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `SPRING_CONFIG_LOCATION` environment variable tells Spring where to find
    the property files, in this case, the `/config-repo/application.yml` and `/config-repo/product.yml` files.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Credentials for accessing RabbitMQ and MongoDB are set up as environment variables
    based on the content in the `rabbitmq-credentials` and `mongodb-credentials` secrets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Kubernetes config maps and secrets will be created in the *Testing with
    ConfigMaps, secrets, and ingress* section.
  prefs: []
  type: TYPE_NORMAL
- en: That is what is required to replace the configuration server with Kubernetes
    config maps and secrets. In the next section, we will learn about how we can replace
    the Spring Cloud Gateway with a Kubernetes ingress resource.
  prefs: []
  type: TYPE_NORMAL
- en: Replacing the Spring Cloud Gateway
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will further simplify the microservice landscape by replacing
    the Spring Cloud Gateway with the built-in ingress resource in Kubernetes, reducing
    the number of supportive services required to be deployed.
  prefs: []
  type: TYPE_NORMAL
- en: As introduced in [Chapter 15](87949e5b-2761-4dc1-a70c-d9d21f03d530.xhtml), *Introduction
    to Kubernetes*, an ingress resource can be used in Kubernetes to act as an edge
    server in the same way as a Spring Cloud Gateway. The Spring Cloud Gateway comes
    with a richer routing functionality compared to an ingress resource. But the ingress
    feature is part of the Kubernetes platform and can also be extended using the
    Cert Manager to automatically provide certificates, as we will see later on in
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We have also used the Spring Cloud Gateway to protect our microservices from
    unauthenticated requests; that is, the microservices require a valid OAuth 2.0/OIDC
    access token from a trusted OAuth Authorization Server or OIDC Provider. See [Chapter
    11](bcb9bba0-d2fe-4ee8-954b-07a7e38e1115.xhtml), *Securing Access to APIs*, if
    a recap is required. Generally, Kubernetes ingress resources do not have support
    for that. Specific implementations of the ingress controller might, however, support
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the composite health check we added to the gateway in [Chapter 10](a3383211-405d-4319-b142-ddb8cf3674fd.xhtml),
    *Using Spring Cloud Gateway to Hide Microservices Behind an Edge Server* can be
    replaced by the Kubernetes liveness and readiness probes defined in each microservices
    deployment resource. To me, it makes sense to use the Spring Cloud Gateway where
    the underlying platform doesn't provide a similar capability, but when deploying
    to Kubernetes, it is better to use ingress resources.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will delegate the responsibility for validating that the
    request contains a valid access token to the `product-composite` microservice.
    The next chapter will introduce the concept of a Service Mesh, where we will see
    an alternate implementation of an ingress that fully supports validating JWT-encoded
    access tokens, that is, the type of access tokens that we are using in this book.
  prefs: []
  type: TYPE_NORMAL
- en: In the *Verifying that the microservices work without Kubernetes* section, we
    will still use the Spring Cloud Gateway together with Docker Compose, so we will
    not remove the project.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows how to remove the Spring Cloud Gateway from the
    microservice landscape when deploying to Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d19dde2e-6974-428d-a6e3-ba564833e00a.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's see what is required to replace the Spring Cloud Gateway with a Kubernetes
    ingress resource!
  prefs: []
  type: TYPE_NORMAL
- en: Note especially that we only change the configuration; that is, no changes are
    required in the Java source code!
  prefs: []
  type: TYPE_NORMAL
- en: Changes in the source code for Spring Cloud Gateway
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following changes have been applied in the configuration of the source
    code to replace the Spring Cloud Gateway with a Kubernetes ingress resource:'
  prefs: []
  type: TYPE_NORMAL
- en: Changes in the Kubernetes definition files for deployment resources in the `kubernetes/services` folder.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removed the gateway YAML files and its declaration in the `kustomization.yml` files
    in the `base` and `overlays/prod` folders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Added the ingress resource in `base/ingress-edge-server.yml` and added a reference
    to it in `base/kustomization.yml`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The definition of the ingress resource looks like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The following are the explanations for the preceding source code:'
  prefs: []
  type: TYPE_NORMAL
- en: The ingress resource is named `edge`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `tls` section specifies that the ingress will require the use of HTTPS and
    that it will use a certificate issued for the `minikube.me` hostname.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The certificate is stored in a secret named `tls-certificate`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `tls-certificate` secret will be created in *step 4* in the *Testing with
    Kubernetes ConfigMaps, secrets, and ingress resource* section.
  prefs: []
  type: TYPE_NORMAL
- en: Routing rules are defined for requests to the `minikube.me` hostname.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The DNS name `minikube.me` will be mapped to the IP address of the Minikube
    instance in the next topic.
  prefs: []
  type: TYPE_NORMAL
- en: 'Routes are defined for the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `auth-server` on the `/oauth` path
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `product-composite` microservice on the `/product-composite` path
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `health` endpoint in the `product-composite` microservice on the `/actuator/health` path
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Kubernetes ingress resource will be created in the next section where we
    will test the microservice landscape together with Kubernetes config maps, secrets,
    and an ingress resource.
  prefs: []
  type: TYPE_NORMAL
- en: Testing with Kubernetes ConfigMaps, secrets, and ingress resource
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the preceding changes described, we are ready to test the system landscape
    with the Spring Cloud Config Server and the Spring Cloud Gateway replaced by Kubernetes
    config maps, secrets, and an ingress resource.  As before, when we used the Spring
    Cloud Gateway as the edge server, the external API will be protected by HTTPS.
    With this deployment, we will configure the ingress resource to reuse the self-signed
    certificate we used with the Spring Cloud Gateway for HTTPS. This is illustrated
    by the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5eb38462-0a35-4944-a8e6-0e6ff5e338b1.png)'
  prefs: []
  type: TYPE_IMG
- en: In the next section, we will enhance the certificate usage and replace the self-signed
    certificate with certificates issued by Let's Encrypt.
  prefs: []
  type: TYPE_NORMAL
- en: 'The ingress will be exposed on the default HTTPS port, `443`, on the Minikube
    instance. This is handled by the ingress controller that was installed when we
    performed the `minikube addons enable ingress` command; see [Chapter 15](87949e5b-2761-4dc1-a70c-d9d21f03d530.xhtml),
    *Introduction to Kubernetes *and refer to the *Creating a Kubernetes cluster*
    section for a recap. The ingress controller consists of a deployment, `nginx-ingress-controller`,
    in the `kube-system` namespace. The deployment configures its pod using a `hostPort`
    to map port `443` in the host, that is, the Minikube instance, to port `443` in
    the container that runs in the pod. The central parts in the definition of the
    deployment look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This setup works for a single-node Kubernetes cluster used for development and
    testing. In a multi-node Kubernetes cluster, external load balancers are used
    to expose an ingress controller for high availability and scalability.
  prefs: []
  type: TYPE_NORMAL
- en: The deployment uses the same type of commands as we used in [Chapter 16](ebeb41b4-eea4-4d73-89ba-6788e2e68bac.xhtml),
    *Deploying Our Microservices to Kubernetes*; refer to the *Deploying to Kubernetes
    for development and test* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The major differences are that this deployment will:'
  prefs: []
  type: TYPE_NORMAL
- en: Create one config map for each microservice instead of one config map for the configuration
    server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create secrets for credentials to the resource managers and a secret for the
    TLS certificate used by the ingress instead of creating secrets for the credentials
    to the configuration server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create one ingress instead of using Spring Cloud Gateway
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To simplify the deployment, deploy scripts for the development and production environments
    have been added to the source code. Let's go through the deploy script for the development environment
    that we will use in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Walking through the deploy script
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `kubernetes/scripts/deploy-dev-env.bash` script, contains the necessary
    commands for performing the deployment. The script will perform the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'It will create config maps, one per microservice. For example, for the `product`
    microservice, we have the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, it will create the required secrets. For example, credentials for accessing
    RabbitMQ are created with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Secrets are also created for the resource managers; their names are suffixed
    with `server-credentials`. They are used in the Kubernetes definitions files in
    the `kubernetes/services/overlays/dev` folder. For example, credentials used by
    RabbitMQ are created with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The secret that contains the TLS certificate for the ingress, `tls-certificate`,
    is based on the already existing self-signed certificate in the `kubernetes/cert` folder.
    It is created with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The self-signed certificate has been created with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '`openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout kubernetes/cert/tls.key
    -out kubernetes/cert/tls.crt -subj "/CN=minikube.me/O=minikube.me"`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Deploy the microservices for the development environment, based on the `dev` overlay,
    using the `-k` switch to activate Kustomize:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Wait for the deployment and its pods to be up and running:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: After this walkthrough, we are ready to run the commands required for deploying
    and testing!
  prefs: []
  type: TYPE_NORMAL
- en: Running commands for deploying and testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we can perform the deployment, we need to make the following preparations:'
  prefs: []
  type: TYPE_NORMAL
- en: Map the DNS name used by the ingress, `minikube.me`, to the IP address of the
    Minikube instance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build Docker images from source
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a namespace in Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Run the following commands to prepare, deploy, and test:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Map `minikube.me` to the IP address of the Minikube instance by adding a line
    to the file `/etc/hosts` with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Verify the result with the `cat /etc/hosts` command. Expect a line that contains
    the IP address of your Minikube instance followed by `minikube.me` as shown in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e620ccae-5f94-4d2f-a0cc-9c5b94ffb268.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Build Docker images from source with the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Recreate the namespace, `hands-on`, and set it as the default namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Execute the deployment by running the script with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the deployment is complete, start the tests with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Expect the normal output that we have seen from the previous chapters as shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2029adbf-aead-45bf-b8a5-78f258baa0f6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can try out the APIs manually by performing the same steps as in the earlier
    chapters: just replace the host and port with `minikube.me`. Get an OAuth/OIDC
    access token and use it to call an API with the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Expect the requested product ID, `2`, in the response.
  prefs: []
  type: TYPE_NORMAL
- en: The deployment we have set up in this section is based on an environment aimed
    at developing and testing. If you want to set up an environment aimed at staging
    and production, such as the one described in [Chapter 16](ebeb41b4-eea4-4d73-89ba-6788e2e68bac.xhtml),
    *Deploying Our Microservices to Kubernetes*, refer to the *Deploying to Kubernetes
    for staging and production* section. For this, you can use the `./kubernetes/scripts/deploy-prod-env.bash` script.
    Use it in *step 4* as previously outlined instead of the `deploy-dev-env.bash` script.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the `deploy-prod-env.bash` script will launch the three resource managers
    for MySQL, MongoDB, and RabbitMQ using Docker Compose; that is, they will run as
    Docker containers outside Kubernetes (in the same way as in [Chapter 16](ebeb41b4-eea4-4d73-89ba-6788e2e68bac.xhtml),
    *Deploying Our Microservices to Kubernetes*).
  prefs: []
  type: TYPE_NORMAL
- en: This deployment uses a self-signed certificate that was exposed by the Kubernetes
    ingress and that requires manual provisioning. Manual handling of certificates
    is both time-consuming and error-prone. It is, for example, very easy to forget
    to renew a certificate in time. In the next section, we will learn how to use
    the Cert Manager and Let's Encrypt to automate this provisioning process!
  prefs: []
  type: TYPE_NORMAL
- en: Automating the provision of certificates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned in the introduction to this chapter, we will use the Cert Manager
    to automate the provision of certificates used by the external HTTPS endpoint
    exposed by the ingress. The Cert Manager will run as an add-on in Kubernetes and
    will be configured to request the issuing of certificates from Let's Encrypt with
    a free Certificate Authority that can be used to automate the issuing of certificates.
    To be able to verify that we own the DNS name that the certificate shall be issued
    for, Let's Encrypt requires access to the endpoint we want to issue the certificate
    for. Since our Kubernetes cluster runs locally in Minikube, we must make it possible
    for Let's Encrypt to access our cluster during the provisioning. We will use the ngrok
    tool to create a temporary HTTP tunnel from the internet to our local Kubernetes
    cluster to be used by Let's Encrypt.
  prefs: []
  type: TYPE_NORMAL
- en: 'For more information on each product, see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Cert Manager: [http://docs.cert-manager.io/en/latest/index.html](http://docs.cert-manager.io/en/latest/index.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's Encrypt: [https://letsencrypt.org/docs/](https://letsencrypt.org/docs/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ngrok: [https://ngrok.com/docs](https://ngrok.com/docs)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'All this together might seem a bit overwhelming, so let''s take it step by
    step:'
  prefs: []
  type: TYPE_NORMAL
- en: Deploy the Cert Manager and define issuers in Kubernetes based on Let's Encrypt.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an HTTP tunnel using ngrok.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Provision certificates with the Cert Manager and Let's Encrypt.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Verify that we got certificates from Let's Encrypt.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Clean up.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The HTTP tunnel is only required if your Kubernetes cluster isn't reachable
    on the internet. If its ingress resource can be accessed directly from the internet,
    the use of ngrok can be skipped.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the Cert Manager and defining Let's Encrypt issuers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To deploy the Cert Manager, we can execute a single Kubernetes definition file
    that will create a namespace, `cert-manager`, and then deploy the Cert Manager
    into the namespace. We will install version 0.8.1, the latest available version
    when writing this chapter. Run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'If you get an error message such as `unable to recognize "https://github.com/jetstack/cert-manager/releases/download/v0.8.1/cert-manager.yaml":
    no matches for kind "Issuer" in version "certmanager.k8s.io/v1alpha1"`, then simply
    rerun the command again.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Wait for the deployment and its pods to be available:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Expect output similar to the following from the command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/196e1fc3-83ec-4d71-84dc-18e5f84a59ed.png)'
  prefs: []
  type: TYPE_IMG
- en: With the Cert Manager in place, we can define issuers in Kubernetes that are
    based on Let's Encrypt.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s Encrypt exposes the following issuers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Staging environment**, to be used during development and test phases where
    it can be expected that a lot of short-lived certificates are requested. The staging
    environment allows for the creation of many certificates but the root **CA** *(*short
    for **Certificate Authority**) in the certificate is not trusted. This means that
    certificates from the staging environment can''t be used to protect web pages
    or APIs used by a web browser. A web browser won''t trust its root CA and will
    complain when a user opens a web page protected by certificates from the staging
    environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Production environment**, it uses a trusted root CA to issue certificates.
    It can, therefore, be used to issue certificates that are trusted by web browsers.
    The production environment limits the number of certificates that can be issued.
    For example, only 50 new certificates per week can be issued per registered domain,
    for instance, in case `ngrok.io`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will register two issuers in Kubernetes, one for the staging environment
    and one for the production environment. Issuers can be registered either globally
    in the cluster or locally in a namespace. To keep things together, we will use
    namespace local issuers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Communication between the Cert Manager and Let''s Encrypt during the provision
    of certificates is based on a standard protocol, **Automated Certificate Management
    Environment v2**, or **ACME v2** for short. Let''s Encrypt will act as a CA and
    the Cert Manager will act as an ACME client. To validate the ownership of a DNS
    name, the ACME protocol specifies two types of challenge that a CA can use:'
  prefs: []
  type: TYPE_NORMAL
- en: '`http-01`: The CA asks the ACME client for a randomly named file to be made
    available under the following URL: `http://<domainname>/.well-known/acme-challenge/<randomfilename>`.
    If the CA succeeds in accessing the file using this URL, the ownership of the
    domain is validated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dns-01`: The CA asks the ACME client for a specified value to be placed in
    a TXT record, `_acme-challenge.<YOUR_DOMAIN>`, under the domain in the DNS server.
    This is typically achieved by using an API of the DNS provider. If the CA succeeds
    in accessing the specified content in the TXT record in the DNS server, the ownership
    of the domain is validated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automating a `dns-01` based challenge is harder to achieve than automating an
    `http-01` challenge in most cases; however, it is preferred, for example, if the
    HTTP endpoint isn't available on the internet. A `dns-01` challenge also supports
    issuing wildcard certificates, which an `http-01` challenge can't be used for.
    In this chapter, we will configure the Cert Manager to use an `http-01`—based
    challenge.
  prefs: []
  type: TYPE_NORMAL
- en: 'The definition of the issuer for the Let''s Encrypt staging environment looks
    like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The following explains the preceding source code:'
  prefs: []
  type: TYPE_NORMAL
- en: The `name` of the issuer, `letsencrypt-issuer-staging`, will be used in the
    ingress when referring to the issuer to be used when provisioning certificates
    for the ingress.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `email` must be filled in with your email address. Let's Encrypt will use
    the email address to contact you about expiring certificates and issues, if any,
    related to your account.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `server` field points out the URL for the Let's Encrypt staging environment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `privateKeySecretRef` field contains the name of a secret. This secret will
    be created by the Cert Manager and will contain an ACME/Let's Encrypt `account
    private key`. This key identifies you (or your company) as a user of the ACME
    service, that is, Let's Encrypt. It is used to sign requests sent to Let's Encrypt
    to validate your identity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `solver` definition declares that an `http-01` challenge shall be used to
    verify the ownership of the domain name.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The definition of the issuer for the Let's Encrypt production environment looks
    the same, the major difference is the ACME server URL used: [https://acme-v02.api.letsencrypt.org/directory](https://acme-v02.api.letsencrypt.org/directory).
  prefs: []
  type: TYPE_NORMAL
- en: 'Edit the following files and replace `<your email address>` with your email
    address:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kubernetes/services/base/letsencrypt-issuer-staging.yaml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kubernetes/services/base/letsencrypt-issuer-prod.yaml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Apply the definitions with the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: We now have the Cert Manager in place and have registered issuers for the Let's
    Encrypt staging and production environment. The next step is to create an HTTP
    tunnel using `ngrok`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an HTTP tunnel using ngrok
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The free subscription to `ngrok` can be used to create an HTTP tunnel where
    `ngrok` terminates the HTTPS traffic using its own wildcard certificate for `***.ngrok.io`,
    that is, before the HTTP requests reach the ingress resource in Kubernetes. The
    client that sends the HTTPS request will only see the `ngrok` certificate and
    not the certificate exposed by the ingress resource in Kubernetes. This means
    that we can''t use the HTTP tunnel to test a certificate that has been issued
    by Let''s Encrypt and is used by the ingress resource in Kubernetes. This is illustrated
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a5583460-7ef4-4f1a-a566-507395d3be49.png)'
  prefs: []
  type: TYPE_IMG
- en: 'But the HTTP tunnel can be used during the provisioning phase where Let''s
    Encrypt needs to verify that the ACME client owns the DNS name it is requested
    to issue a certificate for. The DNS name will be the hostname that `ngrok` assigns
    to the HTTP tunnel, for example, `6cc09528.ngrok.io`. Once the provisioning is
    performed, we can shut down the HTTP tunnel and redirect the hostname to the IP
    address of the Minikube instance (using the local `/etc/hosts` file). This is
    illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d42306ac-0d80-43ca-bbc8-f783f35353ed.png)'
  prefs: []
  type: TYPE_IMG
- en: For paying customers, `ngrok` provides a TLS tunnel that passes through HTTPS
    traffic instead of terminating it; that is, a client that sends an HTTPS request
    will be able to see and verify the certificate exposed by the ingress resource
    in Kubernetes. Using a TLS tunnel instead of the HTTP tunnel should make this
    extra step unnecessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to create the HTTP tunnel:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the HTTP tunnel with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Expect output similar to the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/cc23906d-f9c7-44e8-aa0d-da848bd6e750.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Pick up the hostname for the HTTP tunnel, `6cc09528.ngrok.io` in the preceding
    example, and save it in an environment variable such as the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: With the HTTP tunnel in place, we can prepare the definition of the ingress
    resource for automatic provisioning of its certificate using the Cert Manager
    and Let's Encrypt!
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning certificates with the Cert Manager and Let's Encrypt
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before configuring the ingress resource, it might be good to have a high level
    understanding of how the provisioning is performed. The automated provisioning of
    a certificate using the Cert Manager and Let''s Encrypt looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ed4a016d-32e6-4381-af09-0f5d93641c42.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following steps will be taken during the provisioning:'
  prefs: []
  type: TYPE_NORMAL
- en: 'An ingress is created annotated with `certmanager.k8s.io/issuer: "name of a
    Let''s Encrypt issuer"`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This annotation will trigger the Cert Manager to start to provide a certificate
    for the ingress using Let's Encrypt.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: During the provisioning process, Let's Encrypt will perform an `http-01` challenge
    and use the HTTP tunnel to verify that the Cert Manager owns the DNS name.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the provisioning is complete, the Cert Manager will store the certificate
    in Kubernetes and create a secret with the name specified by the ingress.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We will add a new ingress, `edge-ngrok`, defined in the `ingress-edge-server-ngrok.yml` file, which will
    route requests to the hostname of the HTTP tunnel. This ingress will have the
    same routing rules as the existing ingress. The part that differs looks like the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an explanation for the preceding source code:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `certmanager.k8s.io/issuer: "letsencrypt-issuer-staging"` annotation, 
    we ask the Cert Manager to provision a certificate for this ingress using the
    issuer named `letsencrypt-issuer-staging`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `xxxxxxxx.ngrok.io` hostname in the `tls` and `rules` declarations must
    be replaced with the actual hostname of your HTTP tunnel.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The secret with the name `tls-ngrok-letsencrypt-certificate` is where the certificate
    will be stored once the provisioning is complete.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this high level of understanding of the provisioning process and an ingress
    resource prepared for using it in place, we can start to provision certificates
    using the two environments that Let's Encrypt supports. Let's start with the staging
    environment, suitable for development and test activities.
  prefs: []
  type: TYPE_NORMAL
- en: Using Let's Encrypt's staging environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Perform the following steps to provision a certificate from Let''s Encrypt
    staging environment and verify that it works:'
  prefs: []
  type: TYPE_NORMAL
- en: Edit the `kubernetes/services/base/ingress-edge-server-ngrok.yml` file and replace `xxxxxxxx.ngrok.io` with
    the hostname of your HTTP tunnel in two places!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (`6cc09528.ngrok.io` in the preceding example.)
  prefs: []
  type: TYPE_NORMAL
- en: 'Before starting up the provisioning, run a watch command in a separate Terminal
    window to monitor the provisioning of the certificate. Run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Initiate the provisioning by applying the new ingress definition with the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The Cert Manager will now detect the new ingress and start to provide a certificate
    with Let's Encrypt staging environment as the issuer using the ACME v2 protocol
    via the HTTP tunnel set up by `ngrok`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After a while, you should notice the `http-01` challenge in the Terminal window
    where the HTTP tunnel runs. Expect a request like the following in the output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/48532285-e42c-41b8-87c5-953c433986d2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A `tls-ngrok-letsencrypt-certificate` certificate will be created and it will
    be stored in the `tls-ngrok-letsencrypt-certificate` secret, as specified in the
    ingress. Expect output from the `kubectl get cert --watch` command similar to
    the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/75548aa6-b6b1-4b86-b7f3-24a40a679869.png)'
  prefs: []
  type: TYPE_IMG
- en: After a while the `READY` state of the certificate will be changed to `True`,
    meaning that the certificate is provisioned and we are ready to try it out!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To try out the certificate provisioned by Let''s Encrypt, we need to redirect
    the `ngrok` hostname to point directly to the Minikube IP address. We will add
    the hostname of the HTTP tunnel to the `/etc/hosts` file resolved to the IP address
    of the Minikube instance. This will result in local requests sent to the hostname
    of the HTTP tunnel being directed to the Minikube instance as illustrated by the
    following diagram:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e82140ea-df2b-41c7-9abd-a64f465ec373.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Edit the `/etc/hosts` file and add the hostname of your HTTP tunnel after `minikube.me`
    in the line we added earlier in the chapter. After the edit, the line should look
    similar to the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/bc8718bb-49a9-4a2d-835a-7a07a6b48936.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the `keytool` command to see what certificate the hostname of the HTTP
    tunnel exposes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Expect a response such as the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/02d1d310-1b40-4966-ab53-2a8b2a6dd43a.png)'
  prefs: []
  type: TYPE_IMG
- en: If your `keytool` is localized, that is, it prints its output in another language
    rather than English, you will need to change the `Owner:|Issuer:` string used
    by the preceding `grep` command, to the localized version.
  prefs: []
  type: TYPE_NORMAL
- en: The certificate is issued for the hostname of the HTTP tunnel (`6cc09528.ngrok.io` in
    the preceding example) and it is issued by `Fake LE Intermediate X1` using `Fake
    LE Root X1` as its Root CA. This verifies that the ingress uses the Let's Encrypt
    staging certificate!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Wrap up by running the `test-em-all.bash` test script using the same command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Expect the usual output from the test script; check that it concludes with
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b922e10e-eac0-41a4-8ca6-c714f34b08e5.png)'
  prefs: []
  type: TYPE_IMG
- en: Certificates provisioned by Let's Encrypt staging environment are, as mentioned
    previously, good for development and test activities. But since its root CA is
    not trusted by web browsers, they can't be used in production scenarios. Let's
    also try out Let's Encrypt's production environment, which is capable of provisioning
    trusted certificates, albeit in limited numbers.
  prefs: []
  type: TYPE_NORMAL
- en: Using Let's Encrypt's production environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To provision a certificate from Let''s Encrypt production environment, instead
    of the staging environment, we have to change the issuer in the ingress definition
    and then apply the updated definition. Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Edit the `kubernetes/services/base/ingress-edge-server-ngrok.yml`  file and
    change the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code should now be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the change by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Monitor the output from the `kubectl get cert --watch` command and wait for
    the new certificate to be provisioned. Its ready state will change to `False`
    immediately after the apply command, and after a short while it will go back to
    `True`. This means that the Cert Manager has provisioned a certificate issued
    by Let's Encrypt production environment!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Check the certificate with the following `keytool` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Expect output such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5d0e1392-a7d9-469e-9b9e-6c49555ebdcb.png)'
  prefs: []
  type: TYPE_IMG
- en: The new certificate is like the one previously issued for the hostname of the
    HTTP tunnel (`6cc09528.ngrok.io` in the preceding example), but this time the
    issuer and Root CA are from the production environment. This means that the certificate
    should be trusted by a web browser.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open the `https://6cc09528.ngrok.io/actuator/health` URL (replace `6cc09528.ngrok.io`
    with the hostname of your HTTP tunnel) in a local web browser. If you use Google
    Chrome and click on the certificate icon (the padlock in front of the URL) you
    should see something like the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/152c06f8-df1e-4c52-b633-84ac22f7717e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As seen in the preceding screenshot Chrome reports: This certificate is valid!'
  prefs: []
  type: TYPE_NORMAL
- en: 'Wrap up by verifying that the `test-em-all.bash` test script also works with
    this certificate as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Expect the usual output from the test script; check that it concludes with
    the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6d63d35e-1728-4d39-a779-d1f4424d0918.png)'
  prefs: []
  type: TYPE_IMG
- en: You can switch back to the staging issuer by following the same procedure but
    also change back to the staging issuer in the ingress definition.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When you are done, clean up the resources created in Kubernetes (and optionally
    in Docker) using Docker Compose by running the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: Stop the `kubectl get cert --watch` command with *Ctrl + C.*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Stop the HTTP tunnel with *Ctrl* *+* *C.*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Delete the namespace in Kubernetes with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'If you tried out the production environment deployment using the `./kubernetes/scripts/deploy-prod-env.bash`
    script, you also need to stop the resource managers that were launched as Docker
    containers using Docker Compose. Run the following command to stop them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Now that we are done automating the certificates to provision them, let's see
    how to verify that microservices work without Kubernetes. Let's see how this is
    done.
  prefs: []
  type: TYPE_NORMAL
- en: Verifying that microservices work without Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter and the previous one, we have seen how features in the Kubernetes
    platform, such as config maps, secrets, services, and ingress resources, can simplify
    the effort of developing a landscape of cooperating microservices. But it is important
    to ensure that the source code of the microservices doesn't get dependent on the
    platform from a functional perspective. Avoiding such a lock-in makes it possible
    to change to another platform in the future, if required, with minimal effort.
    Changing the platform should not require changes in the source code but only in
    the configuration of the microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the microservices using Docker Compose and the `test-em-all.bash` test
    script will ensure that they work from a functional perspective, meaning that
    they will verify that the functionality in the microservice source code still
    works without Kubernetes. When running microservices without Kubernetes, we will
    lack the non-functional features that Kubernetes provides us with, for example,
    monitoring, scaling, and restarting containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'When using Docker Compose, we will map the following Kubernetes features:'
  prefs: []
  type: TYPE_NORMAL
- en: Instead of config maps, we use volumes that map the configuration files directly
    from the host filesystem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instead of using secrets, we keep sensitive information such as credentials
    in the `.env` file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instead of an ingress, we will use the Spring Cloud Gateway.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instead of services, we will map hostnames used by the clients directly to the
    hostnames of the containers, meaning that we will not have any service discovery
    in place and will not be able to scale containers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Docker Compose this way will result in significant disadvantages from
    a non-functional perspective compared to using Kubernetes. But it is acceptable,
    given that Docker Compose will only be used to run functional tests.
  prefs: []
  type: TYPE_NORMAL
- en: Let's go through the code changes in the `docker-compose*.yml` files before
    we run the tests using Docker Compose.
  prefs: []
  type: TYPE_NORMAL
- en: Changes in the source code for Docker Compose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To run microservices outside Kubernetes, using Docker Compose, the following
    changes have been applied to the `docker-compose*.yml` files:'
  prefs: []
  type: TYPE_NORMAL
- en: Removed the configuration server definition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removed the use of the following configuration server environment variables: `CONFIG_SERVER_USR` and `CONFIG_SERVER_PWD`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mapped the `config-repo` folder as a volume in each container that needs to
    read configuration files from the configuration repository
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defined the `SPRING_CONFIG_LOCATION` environment variable to point to the configuration
    files in the configuration repository
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stored sensitive information such as credentials and passwords in TLS certificates
    in the Docker Compose `.env` file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defined environment variables with credentials for access to resource managers
    using the variables defined in the `.env` file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, the configuration of the `product` microservice looks like the
    following in `docker-compose.yml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an explanation for the preceding source code:'
  prefs: []
  type: TYPE_NORMAL
- en: The `config-repo` folder is mapped as a volume into the container at `/config-repo`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `SPRING_CONFIG_LOCATION` environment variable tells Spring where to find
    the property files, in this case, the `/config-repo/application.yml` and `/config-repo/product.yml` files.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Credentials for accessing RabbitMQ and MongoDB are set up as environment variables
    based on the content in the `.env` file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The credentials referred to in the preceding source code are defined in the `.env` file
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Testing with Docker Compose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To test with Docker Compose, we will use Docker Desktop (earlier named Docker
    for macOS) instead of Minikube. Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To direct the Docker client to use Docker Desktop instead of Minikube run the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'To save memory, you might want to stop the Minikube instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Start Docker Desktop (if not already running).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Build the Docker images in Docker Desktop with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the tests using RabbitMQ (with one partition per topic):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The tests should begin by starting all the containers, run the tests, and finally
    stop all the containers. Expect output like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/949cd3b9-d551-4336-a25d-a256cae5ad6e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Optionally, run the tests using RabbitMQ with multiple partitions per topic:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Expect output that's similar to the preceding test.
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, run the test using Kafka with multiple partitions per topic:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Expect output that's similar to the preceding test.
  prefs: []
  type: TYPE_NORMAL
- en: Stop Docker Desktop to save memory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Start the Minikube instance, if it was stopped previously, and set the default
    namespace to `hands-on`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Point the Docker client back to the Kubernetes cluster in the Minikube instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: With the successful execution of these tests, we have verified that the microservices
    work without Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have seen how capabilities in Kubernetes can be used to
    simplify a microservice landscape, meaning that we reduce the number of support
    services to be developed and deployed together with the microservices. We have
    seen how Kubernetes config maps and secrets can be used to replace the Spring
    Cloud Config Server and how a Kubernetes ingress can replace an edge service based
    on Spring Cloud Gateway.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Cert Manager together with Let's Encrypt allowed us to automatically
    provision certificates for HTTPS endpoints exposed by the ingress, eliminating
    the need for manual and cumbersome work. Since our Kubernetes cluster running
    in a local Minikube instance isn't available from the internet, we used `ngrok`
    to establish an HTTP tunnel from the internet to the Minikube instance. The HTTP
    tunnel was used by Let's Encrypt to verify that we are the owner of the DNS name
    we requested a certificate for.
  prefs: []
  type: TYPE_NORMAL
- en: To verify that the source code of the microservices can run on other platforms,
    that is, isn't locked into Kubernetes, we deployed the microservices using Docker
    Compose and ran the `test-em-all.bash` test script.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will be introduced to the concept of a service mesh
    and learn how a service mesh product, **Istio**, can be used to improve observability,
    security, resilience, and routing in a landscape of cooperating microservices
    that are deployed on Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Head over to the next chapter!
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How was the Spring Cloud Config Server replaced by Kubernetes resources?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How was the Spring Cloud Gateway replaced by Kubernetes resources?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does ACME stand for and what is it used for?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What role does the Cert Manager and Let's Encrypt play in automating the provision
    of certificates?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What Kubernetes resources are involved in automating the provision of certificates?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why did we use `ngrok` and what is required to be added to remove the use of
    ngrok?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why did we run the tests using Docker Compose?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL

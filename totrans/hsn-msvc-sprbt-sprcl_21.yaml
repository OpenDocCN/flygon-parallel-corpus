- en: Using a Service Mesh to Improve Observability and Management
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用服务网格改善可观察性和管理
- en: In this chapter, you will be introduced to the concept of a service mesh and
    see how its capabilities can be used to handle challenges in a system landscape
    of microservices in areas including security, policy enforcement, resilience,
    and traffic management. A service mesh can also be used to provide observability,
    that is, the capability to visualize how traffic flows between microservices in
    a service mesh.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将介绍服务网格的概念，并了解其能力如何用于处理微服务系统景观中的挑战，包括安全性、策略执行、弹性和流量管理等领域。服务网格还可以用于提供可观察性，即可视化服务网格中微服务之间的流量流动能力。
- en: A service mesh overlaps partly with the capabilities of Spring Cloud and Kubernetes
    we learned about earlier in this book. But most of the functionality in a service
    mesh complements Spring Cloud and Kubernetes, as we will see in this chapter.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 服务网格在某种程度上与我们在本书中早期学习的Spring Cloud和Kubernetes的功能重叠。但是，服务网格中的大多数功能都是为了补充Spring
    Cloud和Kubernetes，这一点我们将在本章中看到。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: An introduction to the service mesh concept and Istio, a popular open source
    implementation
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务网格概念和Istio的介绍，这是一个流行的开源实现
- en: 'You will also learn how to do the following:'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您还将学习如何执行以下操作：
- en: Deploy Istio in Kubernetes
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Kubernetes中部署Istio
- en: Create a service mesh
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建服务网格
- en: Observe a service mesh
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察服务网格
- en: Secure a service mesh
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保护服务网格
- en: Ensure that a service mesh is resilient
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保服务网格具有弹性
- en: Perform zero downtime deployments using a service mesh
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用服务网格执行零停机部署
- en: Test the microservice landscape using Docker Compose to ensure that the source
    code in the microservices is not locked into either Kubernetes or Istio
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Docker Compose测试微服务景观，以确保微服务中的源代码不会被锁定在Kubernetes或Istio中
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All commands described in this book are run on a MacBook Pro using macOS Mojave,
    but modifying these commands should be sufficiently straightforward to run them
    on another platform such as Linux or Windows.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中描述的所有命令都是在使用macOS Mojave的MacBook Pro上运行的，但修改这些命令以在其他平台（如Linux或Windows）上运行应该是相当简单的。
- en: 'The only new tool required for this chapter is Istio''s command-line tool, `istioctl`.
    This can be installed using Homebrew with the following command:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章唯一需要的新工具是Istio的命令行工具`istioctl`。可以使用Homebrew安装，命令如下：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The source code for this chapter can be found on GitHub at [https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter18](https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter18).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的源代码可以在GitHub上找到，网址为[https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter18](https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter18)。
- en: 'To be able to run the commands as described in the book, you need to download
    the source code to a folder and set up an environment variable, `$BOOK_HOME`,
    that points to that folder. Examples of sample commands include the following:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要能够按照书中描述的命令运行命令，您需要将源代码下载到一个文件夹，并设置一个指向该文件夹的环境变量`$BOOK_HOME`。示例命令包括以下内容：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The Java source code is written for Java 8 and tested on Java 12\. This chapter
    uses Spring Cloud 2.1, SR2 (also known as the **Greenwich** release), Spring Boot
    2.1.6, and Spring 5.1.8, that is, the latest available version of the Spring components
    at the time of writing this chapter. The source code has been tested using Kubernetes
    V1.15.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Java源代码是为Java 8编写的，并在Java 12上进行了测试。本章使用Spring Cloud 2.1，SR2（也称为**Greenwich**发布），Spring
    Boot 2.1.6和Spring 5.1.8，即编写本章时可用的Spring组件的最新版本。源代码已经在Kubernetes V1.15上进行了测试。
- en: All source code examples in this chapter come from the source code in `$BOOK_HOME/Chapter18`,
    but are, in several cases, edited to remove non-relevant parts of the source code,
    such as comments, and import and log statements.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的所有源代码示例均来自`$BOOK_HOME/Chapter18`中的源代码，但在几种情况下进行了编辑，以删除源代码的非相关部分，如注释、导入和日志语句。
- en: If you want to see the changes applied to the source code in [Chapter 18](422649a4-94bc-48ae-b92b-e3894c014962.xhtml), *Using
    a Service Mesh to Improve Observability and Management*, that is, the changes
    required to create a service mesh using Istio, you can compare it with the source
    code for [Chapter 17](a9327ecc-49e7-4f72-9221-3321b7158d83.xhtml), *Implementing
    Kubernetes Features as an Alternative*. You can use your favorite diff tool and
    compare the two folders, `$BOOK_HOME/Chapter17` and `$BOOK_HOME/Chapter18`.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想要查看应用于源代码的更改[第18章](422649a4-94bc-48ae-b92b-e3894c014962.xhtml)，即使用Istio创建服务网格所需的更改，您可以将其与[第17章](a9327ecc-49e7-4f72-9221-3321b7158d83.xhtml)的源代码进行比较，即使用Kubernetes功能作为替代。您可以使用您喜欢的差异工具比较两个文件夹，`$BOOK_HOME/Chapter17`和`$BOOK_HOME/Chapter18`。
- en: Introduction to service mesh using Istio
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍使用Istio的服务网格
- en: A service mesh is an infrastructure layer that controls and observes the communication
    between services, for example, microservices. The capabilities in a service mesh,
    for example, observability, security, policy enforcement, resilience, and traffic
    management,are implemented by controlling and monitoring all internal communication
    inside the service mesh, that is, between the microservices in the service mesh.
    One of the core components in a service mesh is a lightweight **proxy **component
    that is injected into all microservices that will be part of the service mesh.
    All traffic in and out of a microservice is configured to go through its proxy
    component. The proxy components are configured in runtime by a **control plane** in
    the service mesh using API's exposed by the proxy. The control plane also collects
    telemetry data through these APIs from the proxies to visualize how the traffic
    flows in the service mesh.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 服务网格是一种基础架构层，用于控制和观察服务之间的通信，例如微服务。服务网格中的功能，例如可观察性、安全性、策略执行、弹性和流量管理，是通过控制和监控服务网格内部通信来实现的，也就是在服务网格中的微服务之间。服务网格中的核心组件之一是轻量级的代理组件，它被注入到服务网格中的所有微服务中。微服务的所有流量都被配置为通过其代理组件进行。代理组件通过服务网格中的控制平面在运行时进行配置，使用代理公开的API。控制平面还通过这些API从代理中收集遥测数据，以可视化服务网格中的流量情况。
- en: 'A service mesh also contains a** data plane**, consisting of the proxy components
    in all microservices in the service mesh together with separate components for
    handling external incoming and outgoing traffic to and from the service mesh.
    This is illustrated by the following diagram:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 服务网格还包含一个数据平面，由服务网格中所有微服务的代理组件以及用于处理服务网格中外部进出流量的单独组件组成。如下图所示：
- en: '![](img/6f4234c5-40c7-405d-856e-9e11009c242d.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f4234c5-40c7-405d-856e-9e11009c242d.png)'
- en: The first publicly available implementation of a service mesh was the open source
    project Linkerd, managed by Buoyant ([https://linkerd.io](https://linkerd.io)),
    having its origins in Twitter's Finagle project ([http://twitter.github.io/finagle](http://twitter.github.io/finagle)).
    It was launched during 2016 and, one year later, in 2017, IBM, Google, and Lyft
    launched the open source project, Istio ([https://istio.io](https://istio.io)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 服务网格的第一个公开可用的实现是由Buoyant管理的开源项目Linkerd（[https://linkerd.io](https://linkerd.io)），其起源于Twitter的Finagle项目（[http://twitter.github.io/finagle](http://twitter.github.io/finagle)）。它于2016年推出，一年后，即2017年，IBM、Google和Lyft推出了开源项目Istio（[https://istio.io](https://istio.io)）。
- en: One of the core components in Istio, the proxy component, is based on Lyft's Envoy
    proxy ([https://www.envoyproxy.io](https://www.envoyproxy.io)). Linkerd and Istio
    are, at the time of writing this chapter, the two most popular and widely used
    service mesh implementations. In this chapter, we will use Istio.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Istio的核心组件之一，代理组件，基于Lyft的Envoy代理（[https://www.envoyproxy.io](https://www.envoyproxy.io)）。在撰写本章时，Linkerd和Istio是两种最受欢迎和广泛使用的服务网格实现。在本章中，我们将使用Istio。
- en: Istio can be deployed in various environments, including Kubernetes (see [https://istio.io/docs/setup](https://istio.io/docs/setup)). When
    deploying Istio on Kubernetes, its runtime components are deployed into a separate
    Kubernetes namespace, `istio-system`. Istio also comes with a set of Kubernetes
    **Custom Resources Definitions** (**CRDs**). CRDs are used in Kubernetes to extend
    its API, that is, to add new objects to its API. The Istio objects added are used
    to configure how Istio will be used. Finally, Istio comes with a CLI tool, `istioctl`,
    which will be used to inject Istio proxies into the microservices that participate
    in the service mesh.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Istio可以部署在各种环境中，包括Kubernetes（参见[https://istio.io/docs/setup](https://istio.io/docs/setup)）。在Kubernetes上部署Istio时，其运行时组件将部署到一个单独的Kubernetes命名空间`istio-system`中。Istio还配备了一组Kubernetes自定义资源定义（CRD）。CRD在Kubernetes中用于扩展其API，即向其API添加新对象。添加的Istio对象用于配置Istio的使用方式。最后，Istio配备了一个名为`istioctl`的CLI工具，用于将Istio代理注入参与服务网格的微服务中。
- en: Istio is, as explained previously, divided into a control plane and a data plane. As
    an operator, we will define a desired state by creating Istio objects in the Kubernetes
    API server, for example, declaring routing rules. The control plane will read
    these objects and send commands to the proxies in the data plane to take actions
    according to the desired state, for example, configuring routing rules. The proxies
    handle the actual communication between the microservices and report back telemetry
    data to the control plane. The telemetry data is used by various components in
    a control plane to visualize what's going on in the service mesh.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前所解释的，Istio分为控制平面和数据平面。作为操作员，我们将通过在Kubernetes API服务器中创建Istio对象来定义所需的状态，例如声明路由规则。控制平面将读取这些对象，并向数据平面中的代理发送命令，根据所需的状态采取行动，例如配置路由规则。代理处理微服务之间的实际通信，并向控制平面报告遥测数据。遥测数据被控制平面中的各种组件使用，以可视化服务网格中的情况。
- en: 'In the following subsections, we will cover the following topics:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的小节中，我们将涵盖以下主题：
- en: How Istio proxies are injected into microservices
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Istio代理是如何注入到微服务中的
- en: The Istio API objects that we will use in this chapter
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中将使用的Istio API对象
- en: The runtime components in Istio that constitute the control plane and the data
    plane
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构成控制平面和数据平面的Istio运行时组件
- en: Changes in the microservice landscape as a result of the introduction of Istio
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于引入Istio而导致的微服务景观变化
- en: Injecting Istio proxies into existing microservices
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Istio代理注入现有微服务
- en: The microservices we have deployed in Kubernetes in the previous chapters run
    as a single container in a Kubernetes pod (refer to the *Introducing Kubernetes
    API objects* section in [Chapter 15](87949e5b-2761-4dc1-a70c-d9d21f03d530.xhtml), *Introduction
    to Kubernetes*, for a recap). To make a microservice join an Istio-based service
    mesh, an Istio proxy is injected into each microservice. This is done by adding
    an extra container to the pod that runs the Istio proxy.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中在Kubernetes中部署的微服务作为Kubernetes Pod中的单个容器运行（请参阅[第15章](87949e5b-2761-4dc1-a70c-d9d21f03d530.xhtml)中的*介绍Kubernetes
    API对象*部分，*Kubernetes简介*，进行回顾）。为了使微服务加入基于Istio的服务网格，需要向每个微服务注入Istio代理。这是通过向运行Istio代理的Pod添加额外的容器来完成的。
- en: Containers added to a pod with the aim of supporting the main container, such
    as an Istio proxy, are referred to as a *sideca**r*.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 添加到Pod中以支持主容器的容器，例如Istio代理，被称为*sidecar*。
- en: 'The following diagram shows how an Istio proxy has been injected into a sample
    pod, **Pod A**, as a sidecar:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了如何将Istio代理作为sidecar注入到示例Pod**Pod A**中：
- en: '![](img/a824d18b-8f01-4c08-97ef-d697d7154fc8.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a824d18b-8f01-4c08-97ef-d697d7154fc8.png)'
- en: The main container in the pod, **Container A**, is configured to route all its
    traffic through the Istio proxy.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Pod中的主容器**Container A**被配置为通过Istio代理路由其所有流量。
- en: Istio proxies can be injected either automatically when a deployment object
    is created or manually using the `istioctl` tool.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当创建部署对象时，Istio代理可以自动注入，也可以使用`istioctl`工具手动注入。
- en: 'In this chapter, we will inject the Istio proxies manually. The reason for
    this is that Istio proxies do not support the protocols used by MySQL, MongoDB,
    and RabbitMQ, so we will only inject Istio proxies into pods where the HTTP protocol
    is used. An Istio proxy can be injected into the pods of an existing deployment
    object by means of the following command:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将手动注入Istio代理。原因是Istio代理不支持MySQL、MongoDB和RabbitMQ使用的协议，因此我们只会将Istio代理注入使用HTTP协议的Pod中。可以通过以下命令将Istio代理注入到现有部署对象的Pod中：
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This command may, at first glance, appear somewhat daunting, but it is actually
    just three separate commands. The previous command sends its output to the next
    command using pipes, that is, the `|` character. Let''s go through each command:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，这个命令可能看起来有些令人生畏，但实际上只是三个单独的命令。前一个命令使用管道将其输出发送到下一个命令，即`|`字符。让我们逐个命令来看：
- en: The `kubectl get deployment` command gets the current definition of a deployment
    named `sample-deployment` from the Kubernetes API server and returns its definition
    in the YAML format.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kubectl get deployment`命令从Kubernetes API服务器获取名为`sample-deployment`的部署的当前定义，并以YAML格式返回其定义。'
- en: The `istioctl kube-inject` command reads the definition from the `kubectl get
    deployment` command and adds an extra container for an Istio proxy in pods that
    the deployment handles. The configuration for the existing container in the deployment
    object is updated so that incoming and outgoing traffic goes through the Istio
    proxy.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`istioctl kube-inject`命令从`kubectl get deployment`命令中读取定义，并在部署处理的Pod中添加一个额外的Istio代理容器。更新部署对象中现有容器的配置，以便入站和出站流量通过Istio代理。'
- en: The `istioctl` command returns the new definition of the deployment object,
    including a container for the Istio proxy.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`istioctl`命令返回部署对象的新定义，包括用于Istio代理的容器。'
- en: The `kubectl apply` command reads the updated configuration from the `istioctl
    kube-inject` command and applies the updated configuration. A rolling upgrade
    of the pods belonging to the deployment will start up in the same way as we have
    seen before (refer to the *Performing a rolling upgrade* section in [Chapter 16](ebeb41b4-eea4-4d73-89ba-6788e2e68bac.xhtml), *Deploying
    Our Microservices to Kubernetes)*.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kubectl apply`命令从`istioctl kube-inject`命令读取更新的配置，并应用更新的配置。与之前一样，部署的Pod将以相同的方式进行滚动升级（请参阅[第16章](ebeb41b4-eea4-4d73-89ba-6788e2e68bac.xhtml)中的*执行滚动升级*部分，*将我们的微服务部署到Kubernetes)*。'
- en: The deployment scripts in the `kubernetes/scripts` folder have been extended
    to use `istioctl` to inject the Istio proxies. Refer to the upcoming *Creating
    the service mesh* section for details.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubernetes/scripts`文件夹中的部署脚本已经扩展为使用`istioctl`注入Istio代理。有关详细信息，请参阅即将到来的*创建服务网格*部分。'
- en: Introducing Istio API objects
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Istio API对象
- en: 'Istio extends the Kubernetes API with a number of objects using its CRDs. Refer
    to the *Introducing Kubernetes API objects* section in [Chapter 15](87949e5b-2761-4dc1-a70c-d9d21f03d530.xhtml), *Introduction
    to Kubernetes*, for a recap of the Kubernetes API. In this chapter we will use
    the following Istio objects:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Istio使用其CRD向Kubernetes API扩展了一些对象。有关Kubernetes API的回顾，请参阅[第15章](87949e5b-2761-4dc1-a70c-d9d21f03d530.xhtml)中的*介绍Kubernetes
    API对象*部分，*Kubernetes简介*。在本章中，我们将使用以下Istio对象：
- en: '`Gateway` is used to configure how to handle incoming traffic to, and outgoing
    traffic from, the service mesh. A gateway depends on a virtual service routing
    the incoming traffic to Kubernetes services. We will use a gateway object to accept
    incoming traffic to the DNS name, `minikube.me`, using HTTPS. Refer to the *Kubernetes
    Ingress resource replaced with Istio Ingress Gateway as an edge server* section
    for details.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`网关`用于配置如何处理服务网格的入站和出站流量。网关依赖于将入站流量路由到Kubernetes服务的虚拟服务。我们将使用网关对象来接受对DNS名称`minikube.me`的入站流量，使用HTTPS。有关详细信息，请参阅*将Kubernetes
    Ingress资源替换为Istio Ingress Gateway作为边缘服务器*部分。'
- en: '`VirtualService` is used to define routing rules in the service mesh. We will
    use virtual services to describe how to route incoming traffic from an Istio gateway
    to the Kubernetes services and between services. We will also use virtual services to
    inject faults and delays in order to test the reliability and resilience capabilities
    of the service mesh.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`VirtualService`用于在服务网格中定义路由规则。我们将使用虚拟服务来描述如何将来自Istio网关的入站流量路由到Kubernetes服务和服务之间。我们还将使用虚拟服务来注入故障和延迟，以测试服务网格的可靠性和弹性能力。'
- en: '`DestinationRule` is used to define policies and rules for traffic that is
    routed (using a virtual service) to a specific service (that is, a destination).
    We will use destination rules to set up encryption policies to encrypt internal
    HTTP traffic and define service subsets that describe available versions of the
    services. We will use service subsets when performing zero downtime (blue/green)
    deployments from an existing version of a microservice to a new version.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DestinationRule`用于定义路由到特定服务（即目标）的流量的策略和规则（使用虚拟服务）。我们将使用目标规则设置加密策略以加密内部HTTP流量，并定义描述服务可用版本的服务子集。在从现有版本的微服务执行零停机（蓝/绿）部署到新版本时，我们将使用服务子集。'
- en: '`Policy` is used to define how requests will be authenticated. We will use
    policies to require incoming requests to the service mesh to be authenticated
    using a JWT-based OAuth 2.0/OIDC access token. Refer to the *Authenticating external
    requests using OAuth 2.0/OIDC access tokens* section of this chapter. A policy
    can also be used to define how to secure parts of the internal communication in
    the service mesh. For example, a policy can require that internal requests are
    encrypted using HTTPS or allow plain text requests. Finally, a `MeshPolicy` object
    can be used to define global policies that apply to the whole service mesh.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Policy`用于定义请求的身份验证方式。我们将使用策略要求对服务网格的传入请求使用基于JWT的OAuth 2.0/OIDC访问令牌进行身份验证。请参阅本章的*使用OAuth
    2.0/OIDC访问令牌对外部请求进行身份验证*部分。策略还可以用于定义如何保护服务网格内部通信的部分。例如，策略可以要求使用HTTPS加密内部请求，或允许明文请求。最后，`MeshPolicy`对象可用于定义适用于整个服务网格的全局策略。'
- en: Introducing runtime components in Istio
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Istio中的运行时组件
- en: Istio contains a number of runtime components, is highly configurable in terms
    of what components to use, and provides fine-grained control over the configuration
    of each component. Refer to the *Deploying Istio in a Kubernetes cluster* section
    of this chapter for information on the configuration we will use in this chapter.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Istio包含许多运行时组件，可以在使用哪些组件方面进行高度配置，并且可以对每个组件的配置进行细粒度控制。有关我们将在本章中使用的配置信息，请参阅*在Kubernetes集群中部署Istio*部分。
- en: 'In the configuration used in this chapter, the Istio control plane consists
    of the following runtime components:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中使用的配置中，Istio控制平面由以下运行时组件组成：
- en: '**Pilot**:responsible for supplying all sidecars with updates of the service mesh
    configuration.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pilot**：负责向所有旁车提供服务网格配置的更新。'
- en: '**Mixer**: consists of two different runtime components:'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Mixer**：由两个不同的运行时组件组成：'
- en: '**Policy** – enforces network policies such as authentication, authorization,
    rate limits, and quotas.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Policy**–执行网络策略，如身份验证、授权、速率限制和配额。'
- en: '**Telemetry***–*collects telemetry information and sends it to Prometheus, for
    example.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Telemetry**–收集遥测信息并将其发送到Prometheus，例如。'
- en: '**Galley**:responsible for collecting and validating configuration information
    and distribution to the other Istio components in the control plane.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Galley**：负责收集和验证配置信息，并将其分发给控制平面中的其他Istio组件。'
- en: '**Citadel**: responsible for issuing and rotating internally used certificates.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Citadel：负责签发和轮换内部使用的证书。
- en: '**Kiali**: provides observability to the service mesh, visualizing what is
    going on in the mesh. Kiali is a separate open source project (see [https://www.kiali.io](https://www.kiali.io))'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kiali**：为服务网格提供可观察性，可视化网格中正在发生的事情。Kiali是一个独立的开源项目（请参阅[https://www.kiali.io](https://www.kiali.io)）'
- en: '**Prometheus**: performs data ingestion and storage for time series-based data,
    for example, performance metrics.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus**：执行时间序列数据的数据摄入和存储，例如性能指标。'
- en: Prometheus is a separate open source project (refer to [https://prometheus.io](https://prometheus.io)).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus是一个独立的开源项目（参见[https://prometheus.io](https://prometheus.io)）。
- en: '**Grafana**: visualizes performance metrics and other time series-related data
    collected in Prometheus. Grafana is a separate open source project (see [https://grafana.com](https://grafana.com)).'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Grafana**：可视化在Prometheus中收集的性能指标和其他时间序列相关数据。Grafana是一个独立的开源项目（请参见[https://grafana.com](https://grafana.com)）。'
- en: '**Tracing**: handles and visualizes distributed tracing information. Based
    on Jaeger, it is an open source project for distributed tracing (refer to [https://www.jaegertracing.io](https://www.jaegertracing.io)).
    Jaeger provides the same type of functionality as Zipkin, which we used in [Chapter 14](42f456c5-d911-494a-a1ba-4631863068b6.xhtml),
    *Understanding Distributed Tracing*.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tracing**：处理和可视化分布式跟踪信息。基于Jaeger，它是一个用于分布式跟踪的开源项目（参见[https://www.jaegertracing.io](https://www.jaegertracing.io)）。Jaeger提供与我们在[第14章](42f456c5-d911-494a-a1ba-4631863068b6.xhtml)中使用的Zipkin相同类型的功能，即*理解分布式跟踪*。'
- en: Kiali is accessed using a web browser and integrates Grafana for viewing performance
    metrics and Jaeger for visualizing distributed tracing information.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Kiali可以通过Web浏览器访问，并集成了Grafana用于查看性能指标和Jaeger用于可视化分布式跟踪信息。
- en: 'The Istio data plane consists of the following runtime components:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Istio数据平面包括以下运行时组件：
- en: '**Ingress** **Gateway**: handles incoming traffic to the service mesh'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ingress Gateway**：处理服务网格的传入流量'
- en: '**E****gress** **Gateway**: handles outgoing traffic from the service mesh'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Egress Gateway**：处理服务网格的出站流量'
- en: All pods with an Istio proxy are injected as a sidecar
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有具有Istio代理的Pod都被注入为旁车
- en: 'The runtime components in Istio''s control plane and data plane are summarized
    in the following diagram:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Istio控制平面和数据平面中的运行时组件总结如下图所示：
- en: '![](img/bc1d5d4f-c2d3-4504-8d01-506c8fec94c4.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bc1d5d4f-c2d3-4504-8d01-506c8fec94c4.png)'
- en: In the next section, we will go through changes applied to the microservice
    landscape arising from the introduction of Istio.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将介绍由引入Istio引起的微服务景观的变化。
- en: Changes in the microservice landscape
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微服务景观中的变化
- en: 'As we have seen in the preceding section, Istio comes with components that
    overlap with components currently used in the microservice landscape in terms
    of functionality:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前一节中所看到的，Istio具有与微服务架构中当前使用的组件在功能上重叠的组件：
- en: The Istio Ingress Gateway can act as an edge server, an alternative to the Kubernetes
    Ingress resources.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Istio入口网关可以充当边缘服务器，是Kubernetes入口资源的替代品。
- en: The Jaeger component that comes bundled with Istio can be used for distributed
    tracing instead of Zipkin.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Istio捆绑的Jaeger组件可以用于分布式跟踪，而不是Zipkin。
- en: In the following two subsections, we will learn why and how Kubernetes Ingress
    resources are replaced with Istio Ingress Gateway, and how and why Zipkin is replaced
    with Jaeger.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的两个小节中，我们将学习为什么以及如何用Istio入口网关替换Kubernetes入口资源，以及为什么以及如何用Jaeger替换Zipkin。
- en: Kubernetes Ingress resources are replaced with Istio Ingress Gateway as an edge
    server
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Kubernetes入口资源替换为Istio入口网关作为边缘服务器
- en: In the previous chapter, we introduced Kubernetes Ingress resources as edge
    servers (refer to the *Replacing the Spring Cloud Gateway* section in [Chapter
    17](a9327ecc-49e7-4f72-9221-3321b7158d83.xhtml), *Implementing Kubernetes Features
    as an Alternative)*. Unfortunately, ingress resources cannot be configured to
    handle the fine-grained routing rules that come with Istio. Instead, Istio has
    its own edge server, the Istio ingress Gateway, introduced previously in the *Introducing
    runtime components in Istio* section. The Istio Ingress Gateway is used by creating
    `Gateway` and `VisualService` resources described previously in the *Introducing
    Istio API objects* section.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们将Kubernetes入口资源介绍为边缘服务器（参见[第17章](a9327ecc-49e7-4f72-9221-3321b7158d83.xhtml)中的*替换Spring
    Cloud Gateway*部分，*将Kubernetes功能实现为替代方案)*。不幸的是，入口资源无法配置为处理Istio提供的细粒度路由规则。相反，Istio有自己的边缘服务器，即Istio入口网关，如*在Istio中引入运行时组件*部分中介绍的。Istio入口网关是通过在*介绍Istio
    API对象*部分中描述的`Gateway`和`VisualService`资源创建的。
- en: The definition files for the following Kubernetes Ingress resources, `kubernetes/services/base/ingress-edge-server.yml`
    and `kubernetes/services/base/ingress-edge-server-ngrok.yml`, have therefore been
    removed. Definition files for Istio `Gateway` and `VirtualService` resources will
    be added in the *Creating the service mesh* section.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，以下Kubernetes入口资源的定义文件`kubernetes/services/base/ingress-edge-server.yml`和`kubernetes/services/base/ingress-edge-server-ngrok.yml`已被删除。Istio
    `Gateway`和`VirtualService`资源的定义文件将在*创建服务网格*部分中添加。
- en: The Istio Ingress Gateway is reached using a different IP address than the IP
    address used to access Kubernetes Ingress resources, so we also need to update
    the IP address mapped to the hostname, `minikube.me`, which we use when running
    tests. This is handled in the *Setting up access to Istio services* section in
    this chapter.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问Istio入口网关，需要使用不同的IP地址，而不是用于访问Kubernetes入口资源的IP地址，因此我们还需要更新映射到主机名`minikube.me`的IP地址，这是在运行测试时使用的。这将在本章的*设置访问Istio服务*部分中处理。
- en: Simplifying the system landscape and replacing Zipkin with Jaeger
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简化系统架构并用Jaeger替换Zipkin
- en: As mentioned in the *Introducing runtime components in Istio* section, Istio
    comes with built-in support for distributed tracing using Jaeger*.* Using Jaeger,
    we can offload and simplify the microservice landscape by removing the Zipkin
    server we introduced in [Chapter 14](42f456c5-d911-494a-a1ba-4631863068b6.xhtml),
    *Understanding Distributed Tracing*.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如*在Istio中引入运行时组件*部分所述，Istio内置支持使用Jaeger进行分布式跟踪。使用Jaeger，我们可以通过删除我们在[第14章](42f456c5-d911-494a-a1ba-4631863068b6.xhtml)中介绍的Zipkin服务器来卸载和简化微服务架构中的景观。
- en: 'The following changes have been applied to the source code to remove the Zipkin
    server:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 已对源代码进行了以下更改以删除Zipkin服务器：
- en: The dependency to `org.springframework.cloud:spring-cloud-starter-zipkin` in
    all microservice build files, `build.gradle`, has been removed.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在所有微服务构建文件`build.gradle`中，已删除对`org.springframework.cloud:spring-cloud-starter-zipkin`的依赖。
- en: The definition of the Zipkin server in the three Docker Compose files, `docker-compose.yml`, `docker-compose-partitions.yml`,
    and `docker-compose-kafka.yml`, has been removed.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已删除三个Docker Compose文件`docker-compose.yml`、`docker-compose-partitions.yml`和`docker-compose-kafka.yml`中的Zipkin服务器定义。
- en: 'The following Kubernetes definition files for Zipkin have been removed:'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已删除以下用于Zipkin的Kubernetes定义文件：
- en: '`kubernetes/services/base/zipkin-server.yml`'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubernetes/services/base/zipkin-server.yml`'
- en: '`kubernetes/services/overlays/prod/zipkin-server-prod.yml`'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubernetes/services/overlays/prod/zipkin-server-prod.yml`'
- en: Jaeger will be installed in the *Creating the service mesh* section.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Jaeger将在*创建服务网格*部分中安装。
- en: The changes were made to the microservice landscape due to the introduction
    of Istio. We are now ready to deploy Istio in the Kubernetes cluster.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 由于引入Istio，微服务架构发生了变化。我们现在准备在Kubernetes集群中部署Istio。
- en: Deploying Istio in a Kubernetes cluster
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Kubernetes集群中部署Istio
- en: In this section, we will learn how to deploy Istio in a Kubernetes cluster and
    how to access Istio services in it.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何在Kubernetes集群中部署Istio以及如何访问其中的Istio服务。
- en: We will use v1.2.4 of Istio, the latest release available when this chapter
    was written.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Istio的v1.2.4版本，这是本章撰写时可用的最新版本。
- en: We will be using a demo configuration of Istio that is suitable for testing
    Istio in a development environment, that is, with most features enabled but configured
    for minimalistic resource usage.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用适用于在开发环境中测试Istio的演示配置，即启用大多数功能但配置为最小资源使用。
- en: This configuration is unsuitable for production usage and for performance testing.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 此配置不适用于生产环境和性能测试。
- en: For other installation options, see [https://istio.io/docs/setup/kubernetes/install](https://istio.io/docs/setup/kubernetes/install).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 有关其他安装选项，请参阅[https://istio.io/docs/setup/kubernetes/install](https://istio.io/docs/setup/kubernetes/install)。
- en: 'To deploy Istio, perform the following steps:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署Istio，请执行以下步骤：
- en: 'Download Istio as follows:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下方式下载Istio：
- en: '[PRE3]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Ensure that your Minikube instance is up-and-running with the following command:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保您的Minikube实例正在运行，使用以下命令：
- en: '[PRE4]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Expect a response along the lines of the following, provided it is up and running:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 期望得到以下类似的响应，前提是它正在运行：
- en: '![](img/b73dc4d8-a721-40eb-87be-a3395fc8c84f.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b73dc4d8-a721-40eb-87be-a3395fc8c84f.png)'
- en: 'Install Istio-specific custom resource definitions (CRDs) in Kubernetes:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Kubernetes中安装Istio特定的自定义资源定义（CRD）：
- en: '[PRE5]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Install Istio demo configurations in Kubernetes as follows:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Kubernetes中安装Istio演示配置如下：
- en: '[PRE6]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Wait for the Istio deployments to become available:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待Istio部署变得可用：
- en: '[PRE7]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The command will report deployment resources in Istio as available, one after
    another. Expect 12 messages such as `deployment.extensions/NNN condition met` before
    the command ends. It can take a couple of minutes (or more) depending on your
    hardware and internet connectivity.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '该命令将报告Istio中的部署资源是否可用，一一列出。在命令结束之前，期望得到12条类似`deployment.extensions/NNN condition
    met`的消息。这可能需要几分钟（或更长时间），具体取决于您的硬件和互联网连接。 '
- en: 'Update Kiali''s config map with URLs to Jaeger and Grafana with the following
    commands:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令更新Kiali的配置映射到Jaeger和Grafana的URL：
- en: '[PRE8]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The config map, `kubernetes/istio/setup/kiali-configmap.yml`, contains URLs
    to Jaeger and Grafana that utilize the DNS names set up by the `minikube tunnel`
    command used in the next section.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 配置映射`kubernetes/istio/setup/kiali-configmap.yml`包含了使用下一节中`minikube tunnel`命令设置的Jaeger和Grafana的URL。
- en: Istio is now deployed in Kubernetes, but before we move on and create the service
    mesh, we need to learn a bit about how to access Istio services in a Minikube
    environment.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Istio现在部署在Kubernetes中，但在我们继续并创建服务网格之前，我们需要了解一些关于如何在Minikube环境中访问Istio服务的知识。
- en: Setting up access to Istio services
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置访问Istio服务
- en: The demo configuration used in the previous section to install Istio comes with
    a few connectivity-related issues that we need to resolve. The Istio Ingress Gateway
    is configured as a load-balanced Kubernetes service; that is, its type is `LoadBalancer`.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中使用的演示配置安装Istio存在一些需要解决的连接相关问题。Istio Ingress Gateway配置为负载均衡的Kubernetes服务；也就是说，它的类型是`LoadBalancer`。
- en: It can also be reached using its node port, in the port range `30000`-`32767`,
    on the IP address of the Minikube instance. Unfortunately, HTTPS-based routing
    in Istio can't include port numbers; that is, Istio's Ingress Gateway must be
    reached over the default port for HTTPS (`443`). Therefore, a node port can't
    be used. Instead, a load balancer must be used to be able to use Istio's routing
    rules with HTTPS.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 它也可以通过Minikube实例的IP地址的节点端口在端口范围`30000`-`32767`上访问。不幸的是，Istio中基于HTTPS的路由不能包括端口号；也就是说，Istio的Ingress
    Gateway必须通过HTTPS的默认端口（`443`）访问。因此，不能使用节点端口。相反，必须使用负载均衡器才能使用Istio的HTTPS路由规则。
- en: Minikube contains a command that can be used to simulate a local load balancer,
    `minikube tunnel`. This command assigns an external IP address to each load-balanced
    Kubernetes service, including the Istio Ingress Gateway. This gives you what we
    need to update the translation of the hostname `minikube.me`, which we use in
    our tests. The hostname, `minikube.me`, now needs to be translated to the external
    IP address of the Istio Ingress Gateway, instead of to the IP address of the Minikube
    instance that we used in the previous chapters.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Minikube包含一个命令，可以用来模拟本地负载均衡器，`minikube tunnel`。这个命令为每个负载均衡的Kubernetes服务分配一个外部IP地址，包括Istio
    Ingress Gateway。这为我们更新主机名`minikube.me`的翻译提供了所需的内容，我们在测试中使用。主机名`minikube.me`现在需要被翻译成Istio
    Ingress Gateway的外部IP地址，而不是我们在之前章节中使用的Minikube实例的IP地址。
- en: 'The `minikube tunnel` command also makes cluster-local Kubernetes services
    accessible using their DNS name. The DNS name is based on the naming convention:
    `{service-name}.{namespace}.svc.cluster.local`. For example, Istio''s Kiali service
    can be reached from a local web browser using the DNS name, `kiali.istio-system.svc.cluster.local`,
    when the tunnel is up and running.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '`minikube tunnel`命令还使得集群本地的Kubernetes服务可以使用它们的DNS名称进行访问。DNS名称基于命名约定：`{service-name}.{namespace}.svc.cluster.local`。例如，当隧道运行时，可以使用DNS名称`kiali.istio-system.svc.cluster.local`从本地Web浏览器访问Istio的Kiali服务。'
- en: 'The following diagram summarizes how Istio services are accessed:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表总结了如何访问Istio服务：
- en: '![](img/6df8153e-3139-4cc7-9cb2-0f832f9e5129.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6df8153e-3139-4cc7-9cb2-0f832f9e5129.png)'
- en: 'Perform the following steps to set up the Minikube tunnel:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤设置Minikube隧道：
- en: 'Make Kubernetes services available locally. Run the following command in a
    separate terminal window (the command locks the terminal window when the tunnel
    is up and running):'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使Kubernetes服务在本地可用。在单独的终端窗口中运行以下命令（当隧道运行时，该命令会锁定终端窗口）：
- en: '[PRE9]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note that this command requires that your user has `sudo` privileges and that
    you enter your password during startup and shutdown. It takes a couple of seconds
    before the command asks for the password, so it is easy to miss!
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，此命令要求您的用户具有`sudo`权限，并且在启动和关闭过程中输入密码。在命令要求输入密码之前，可能需要几秒钟的时间，因此很容易错过！
- en: 'Config `minikube.me` to be resolved to the IP address of the Istio Ingress
    Gateway as follows:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`minikube.me`配置为解析为Istio Ingress Gateway的IP地址如下：
- en: 'Get the IP address exposed by the `minikube tunnel` command for the Istio Ingress
    Gateway and save it in an environment variable named `INGRESS_HOST`:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取`minikube tunnel`命令暴露的Istio Ingress Gateway的IP地址，并将其保存在名为`INGRESS_HOST`的环境变量中：
- en: '[PRE10]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Update `/etc/hosts` so that `minikube.me` points to the Istio Ingress Gateway:'
  id: totrans-136
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新`/etc/hosts`，使`minikube.me`指向Istio Ingress Gateway。
- en: '[PRE11]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Remove the line in `/etc/hosts` where `minikube.me` that points to the IP address
    of the Minikube instance (`minikube ip`). Verify that `/etc/hosts` only contains
    one line that translates `minikube.me` and that it points to the IP address of
    the Istio Ingress Gateway; for example, the value of `$INGRESS_HOST`:'
  id: totrans-138
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除`/etc/hosts`中指向Minikube实例IP地址（`minikube ip`）的`minikube.me`行。验证`/etc/hosts`只包含一个将`minikube.me`翻译为Istio
    Ingress Gateway的IP地址的行；例如，`$INGRESS_HOST`的值：
- en: '![](img/466a71aa-3959-4801-8017-ce9c50266daf.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](img/466a71aa-3959-4801-8017-ce9c50266daf.png)'
- en: 'Verify that Kiali, Jaeger, and Grafana can be reached through the tunnel with
    the following commands:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过以下命令验证可以通过隧道访问Kiali、Jaeger和Grafana：
- en: '[PRE12]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Each command should return `200` (OK).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 每个命令应返回`200`（OK）。
- en: The `minikube tunnel` command can stop running if, for example, your computer
    or the Minikube instance in the virtual machine is paused or restarted. The command needs
    to be restarted manually in these cases. So, if you fail to call API's on the
    `https://minikube.me` URL or if Kiali's web UI can't reach Jaeger to visualize
    distributed tracing, or Grafana to visualize performance metrics, always check
    whether the Minikube tunnel is running and restart it if required.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果例如您的计算机或虚拟机中的Minikube实例暂停或重新启动，则`minikube tunnel`命令可能会停止运行。在这些情况下，需要手动重新启动命令。因此，如果无法在`https://minikube.me`
    URL上调用API，或者Kiali的Web UI无法到达Jaeger以可视化分布式跟踪，或者Grafana以可视化性能指标，请始终检查Minikube隧道是否正在运行，并在需要时重新启动它。
- en: An added bonus from using the minikube tunnel command
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用minikube隧道命令的额外奖励
- en: 'Running the `minikube tunnel` command also makes it possible to access some
    other cluster-internal Kubernetes services that may be of interest. Once the environment
    is up and running as described in the *Running commands to create the service
    mesh* section, the following can be achieved:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 运行`minikube tunnel`命令还可以访问一些其他可能感兴趣的集群内部Kubernetes服务。一旦环境按照*运行命令创建服务网格*部分中描述的方式启动并运行，就可以实现以下目标：
- en: 'The `health` endpoint of the `product-composite` microservice can be checked
    with the following command:'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`product-composite`微服务的`health`端点可以使用以下命令进行检查：'
- en: '[PRE13]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Refer to the *Observing the service mesh* section for an explanation of the
    use of port `4004`.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 参考*观察服务网格*部分，了解端口`4004`的用法。
- en: 'MySQL tables in the review database can be accessed with the following command:'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用以下命令访问评论数据库中的MySQL表：
- en: '[PRE14]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'MongoDB collections in the `product` and `recommendations` databases can be
    accessed with the following commands:'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用以下命令访问`product`和`recommendations`数据库中的MongoDB集合：
- en: '[PRE15]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: RabbitMQ's web UI can be accessed using the following URL: `http://rabbitmq.hands-on.svc.cluster.local:15672`.
    Log in using the credentials `rabbit-user-dev` and `rabbit-pwd-dev`.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用以下URL访问RabbitMQ的Web UI：`http://rabbitmq.hands-on.svc.cluster.local:15672`。使用凭据`rabbit-user-dev`和`rabbit-pwd-dev`登录。
- en: With the Minikube tunnel in place, we are now ready to create the service mesh.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 有了Minikube隧道，我们现在准备创建服务网格。
- en: Creating the service mesh
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建服务网格
- en: With Istio deployed, we are ready to create the service mesh. We will use the
    `kubernetes/scripts/deploy-dev-env.bash` script to set up an environment for development
    and testing.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Istio部署后，我们准备创建服务网格。我们将使用`kubernetes/scripts/deploy-dev-env.bash`脚本来设置一个用于开发和测试的环境。
- en: The steps required to create the service mesh are basically the same as those
    we used in [Chapter 17](a9327ecc-49e7-4f72-9221-3321b7158d83.xhtml), *Implementing
    Kubernetes Features as an Alternative* (refer to the *Testing with Kubernetes
    ConfigMaps, secrets, and ingress* section). Let's first see what additions have
    been made to the Kubernetes definition files to set up the service mesh before
    we run the commands to create the service mesh.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 创建服务网格所需的步骤基本上与我们在[第17章](a9327ecc-49e7-4f72-9221-3321b7158d83.xhtml)中使用的步骤相同，即*将Kubernetes功能实现为替代方案*（参考*使用Kubernetes
    ConfigMaps、secrets和ingress进行测试*部分）。在运行命令创建服务网格之前，让我们首先看看Kubernetes定义文件中为设置服务网格所做的添加。
- en: Source code changes
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 源代码更改
- en: 'To be able to run the microservices in a service mesh managed by Istio, the
    following changes have been applied to the Kubernetes definition files:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够在由Istio管理的服务网格中运行微服务，对Kubernetes定义文件进行了以下更改：
- en: The deployment scripts have been updated to inject Istio proxies
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署脚本已更新以注入Istio代理
- en: The file structure of the Kubernetes definition files has been changed
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes定义文件的文件结构已经更改
- en: Kubernetes definition files for Istio have been added
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已添加Istio的Kubernetes定义文件
- en: Let's go through them one by one.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐个进行。
- en: Updating the deployment scripts to inject Istio proxies
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新部署脚本以注入Istio代理
- en: The scripts used to deploy microservices in Kubernetes, `deploy-dev-env.bash` and `deploy-prod-env.bash`,
    both in the `kubernetes/scripts` folder, have been updated to inject Istio proxies
    into the five microservices, that is, the `auth-server`, `product-composite`,
    `product`, `recommendation`, and `review` services.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 用于在Kubernetes中部署微服务的脚本，即`kubernetes/scripts`文件夹中的`deploy-dev-env.bash`和`deploy-prod-env.bash`已更新，以将Istio代理注入到`auth-server`、`product-composite`、`product`、`recommendation`和`review`服务中。
- en: The `deploy-prod-env.bash` script will be used in the *Performing zero downtime
    deploys *section*. *
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`deploy-prod-env.bash`脚本将在*执行零停机部署*部分中使用。'
- en: 'The `istioctl kube-inject` command previously described in the *Injecting Istio
    proxies in existing microservices* section has been added to both deployment scripts
    as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在*向现有微服务注入Istio代理*部分中先前描述的`istioctl kube-inject`命令已添加到两个部署脚本中，如下所示：
- en: '[PRE16]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Since the `kubectl apply` command will start a rolling upgrade, the following
    command has been added to wait for the upgrade to be completed:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`kubectl apply`命令将启动滚动升级，因此已添加以下命令以等待升级完成：
- en: '[PRE17]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'During the rolling upgrade, we will have two pods running for each microservice:
    an old one without an Istio proxy and a new one with the Istio proxy injected.
    The `waitForPods` function will wait until the old pods are terminated; that is,
    the rolling upgrade is complete, and only the five new pods are running. To identify
    what pods to wait for, a label named `version` is used. In a development environment,
    all microservice pods are labeled with `version=latest`.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在滚动升级期间，每个微服务将有两个运行的pod：一个没有Istio代理的旧pod和一个注入了Istio代理的新pod。`waitForPods`函数将等待旧pod终止；也就是说，滚动升级完成后，只有五个新pod在运行。用于等待的标签名为`version`。在开发环境中，所有微服务pod都带有`version=latest`标签。
- en: 'For example, the deployment file for the product microservice, `kubernetes/services/base/deployments/product-deployment.yml`, has
    the following definition of the `version` label:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，产品微服务的部署文件`kubernetes/services/base/deployments/product-deployment.yml`中定义了`version`标签如下：
- en: '[PRE18]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In the *Performing zero downtime deployments* section, where we will upgrade
    microservices from version `v1` to `v2`, the version label will be set to `v1` and `v2`.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在*执行零停机部署*部分，我们将从版本`v1`升级微服务到`v2`，版本标签将设置为`v1`和`v2`。
- en: 'Finally, the following command has been added to the scripts to make them wait
    until the deployments and their pods are ready:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，以下命令已添加到脚本中，以使它们等待部署及其pod就绪：
- en: '[PRE19]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: After reviewing the updates in the deployment scripts, let's see how the file
    structure of the Kubernetes definition files has been affected as a result of
    the introduction of Istio.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在审查部署脚本的更新后，让我们看看由于引入Istio而导致的Kubernetes定义文件的文件结构如何受到影响。
- en: Changing the file structure of the Kubernetes definition files
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更改Kubernetes定义文件的文件结构
- en: 'The file structure for the Kubernetes definition files in `kubernetes/services` has
    been expanded a bit since [Chapter 16](ebeb41b4-eea4-4d73-89ba-6788e2e68bac.xhtml),
    *Deploying Our Microservices to Kubernetes* (refer to the *Introduction to Kustomize*
    section) and this now appears as follows:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 自[第16章](ebeb41b4-eea4-4d73-89ba-6788e2e68bac.xhtml)以来，`kubernetes/services`中的Kubernetes定义文件的文件结构已经有所扩展，现在如下所示：
- en: '![](img/cc35c1d8-4834-4161-9759-347150bb845d.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cc35c1d8-4834-4161-9759-347150bb845d.png)'
- en: The `base` folder consists of three subfolders. The reason for this is that
    we will run two versions of the microservices concurrently in the *Performing zero
    downtime deploys* section, that is, one pod per microservice version. Since pods
    are managed by the deployment object, we also need two deployment objects per
    microservice. To be able to achieve this, the base version of the deployment objects
    has been placed in a separate folder, `deployments`. The service objects and the
    Istio definitions are placed in their own base folders: `services` and `istio`, respectively.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '`base`文件夹包括三个子文件夹。这是因为我们将在*执行零停机部署*部分同时运行两个版本的微服务，即每个微服务版本一个pod。由于pod由部署对象管理，因此每个微服务还需要两个部署对象。为了能够实现这一点，部署对象的基本版本已放在一个单独的文件夹`deployments`中。服务对象和Istio定义分别放在它们自己的基本文件夹`services`和`istio`中。'
- en: 'In the development environment, we will only run one version per microservice. Its
    kustomization file, `kubernetes/services/overlays/dev/kustomization.yml`, has
    been updated to include all three folders as base folders:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发环境中，我们将只运行每个微服务的一个版本。其kustomization文件`kubernetes/services/overlays/dev/kustomization.yml`已更新，以包括所有三个文件夹作为基本文件夹：
- en: '[PRE20]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Refer to the following *Performing zero downtime deploys* section for details
    on how two concurrent versions of the microservices will be deployed using the
    setup for the production environment.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 有关如何使用生产环境的设置部署两个并发版本的微服务的详细信息，请参考以下*执行零停机部署*部分。
- en: For now, let's also go through the new files in the Istio folder.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们也看一下Istio文件夹中的新文件。
- en: Adding Kubernetes definition files for Istio
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为Istio添加Kubernetes定义文件
- en: Istio definitions have been added to the `istio` folder. The Istio files of
    interest in this section are the gateway definition and its corresponding virtual
    services. The other Istio files will be explained in the *Authenticating external
    requests using OAuth 2.0/OIDC access tokens* and *Protecting internal communication
    using mutual authentication (mTLS)* sections.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: Istio定义已添加到`istio`文件夹中。本节中感兴趣的Istio文件是网关定义及其对应的虚拟服务。其他Istio文件将在*使用OAuth 2.0/OIDC访问令牌对外部请求进行身份验证*和*使用相互认证（mTLS）保护内部通信*部分中进行解释。
- en: 'The Istio gateway is declared in the `kubernetes/services/base/istio/gateway.yml` file and
    appears as follows:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: Istio网关在`kubernetes/services/base/istio/gateway.yml`文件中声明如下：
- en: '[PRE21]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following are some explanations of the preceding source code:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前面源代码的一些解释：
- en: The gateway is named `hands-on-gw`; this name is used by the virtual services
    underneath.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网关命名为`hands-on-gw`；虚拟服务在其下使用此名称。
- en: The `selector` field specifies that the gateway resource will be handled by
    the built-in Istio Ingress Gateway.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`selector`字段指定网关资源将由内置的Istio入口网关处理。'
- en: The `hosts` and `port` fields specify that the gateway will handle incoming
    requests for the `minikube.me` hostname using HTTPS over port `443`.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hosts`和`port`字段指定网关将使用HTTPS在端口`443`上处理`minikube.me`主机名的传入请求。'
- en: The `tls` field specifies where the Istio Ingress Gateway can find the certificate
    and private key used for HTTPS communication. Refer to the *Protecting external
    endpoints with HTTPS and certificates* section for details on how these certificate
    files are created.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tls`字段指定Istio入口网关可以在哪里找到用于HTTPS通信的证书和私钥。有关这些证书文件如何创建的详细信息，请参考*使用HTTPS和证书保护外部端点*部分。'
- en: 'The virtual service object for routing requests from the gateway to the `product-composite`
    service, `kubernetes/services/base/istio/product-composite-virtual-service.yml`,
    appears as follows:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 用于将请求从网关路由到`product-composite`服务的虚拟服务对象`kubernetes/services/base/istio/product-composite-virtual-service.yml`如下所示：
- en: '[PRE22]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Explanations for the preceding source code are as follows:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 前面源代码的解释如下：
- en: The `hosts` field specifies that the virtual service will route requests sent
    to the host, `minikube.me`.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hosts`字段指定虚拟服务将路由发送到主机`minikube.me`的请求。'
- en: The `match` and `route` blocks specify that requests that contain a URI starting
    with `/product-composite` will be forwarded to the Kubernetes service named `product-composite`.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`match`和`route`块指定包含以`/product-composite`开头的URI的请求将转发到名为`product-composite`的Kubernetes服务。'
- en: In the preceding source code, the destination host is specified using its short
    name, in other words, `product-composite`. This works since the example in this
    chapter keeps all Kubernetes definitions in one and the same namespace, `hands-on`.
    If that is not the case, it is recommended in the Istio documentation using the
    host's **fully qualified domain name **(**FQDN**) instead, that is, `product-composite.hands-on.svc.cluster.local`.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的源代码中，目标主机是使用其短名称指定的，换句话说，`product-composite`。这是因为本章的示例将所有Kubernetes定义都保存在同一个命名空间`hands-on`中。如果不是这种情况，建议在Istio文档中使用主机的**完全限定域名**（FQDN），也就是`product-composite.hands-on.svc.cluster.local`。
- en: Finally, the virtual service object for routing requests from the gateway to
    the auth server, `kubernetes/services/base/istio/auth-server-virtual-service.yml`,
    looks very similar, the difference being that it routes requests that start with `/oauth`
    to the Kubernetes service, `auth-server`.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，用于将请求从网关路由到认证服务器的虚拟服务对象`kubernetes/services/base/istio/auth-server-virtual-service.yml`看起来非常相似，不同之处在于它将以`/oauth`开头的请求路由到Kubernetes服务`auth-server`。
- en: With these changes in the source code in place, we are now ready to create the
    service mesh.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在源代码中进行了这些更改后，我们现在准备创建服务网格。
- en: Running commands to create the service mesh
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行命令创建服务网格
- en: 'Create the service mesh by running the following commands:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行以下命令创建服务网格：
- en: 'Build Docker images from source with the following commands:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令从源代码构建Docker镜像：
- en: '[PRE23]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Recreate the `hands-on` namespace, and set it as the default namespace:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新创建`hands-on`命名空间，并将其设置为默认命名空间：
- en: '[PRE24]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Execute the deployment by running the `deploy-dev-env.bash` script with the
    following command:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过以下命令运行`deploy-dev-env.bash`脚本来执行部署：
- en: '[PRE25]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Once the deployment is complete, verify that we have two containers in each
    of the microservice pods:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署完成后，请验证每个微服务pod中是否有两个容器：
- en: '[PRE26]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Expect a response along the lines of the following:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 期望得到以下类似的响应：
- en: '![](img/f0040d84-3544-45f4-9dd2-fd7a30e5ea31.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f0040d84-3544-45f4-9dd2-fd7a30e5ea31.png)'
- en: Note that the pods that run our microservices report two containers per pod;
    that is, they have the Istio proxy injected as a sidecar!
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，运行我们微服务的pod报告每个pod两个容器；也就是说，它们已经注入了Istio代理作为边车！
- en: 'Run the usual tests with the following command:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令运行常规测试：
- en: '[PRE27]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The default values for `script test-em-all.bash` have been updated from previous
    chapters to accommodate Kubernetes running in Minikube.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '`script test-em-all.bash`的默认值已从之前的章节更新，以适应在Minikube中运行的Kubernetes。'
- en: 'Expect the output to be similar to what we have seen in previous chapters:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 期望输出与之前章节中看到的类似：
- en: '![](img/f18d0079-84bb-4a36-96db-00e71ec593df.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f18d0079-84bb-4a36-96db-00e71ec593df.png)'
- en: 'You can try out the APIs manually by running the following commands:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以通过运行以下命令手动尝试API：
- en: '[PRE28]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Expect the requested product ID, `2`, in the response.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 期望在响应中得到请求的产品ID`2`。
- en: With the service mesh up and running, let's see how we can observe what's going
    on in the service mesh using Kiali!
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 服务网格已经运行起来了，让我们看看如何使用Kiali观察服务网格中发生的情况！
- en: Observing the service mesh
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 观察服务网格
- en: In this section, we will use Kiali together with Jaeger to observe what's going
    on in the service mesh. For performance monitoring using Grafana, refer to [Chapter
    20](5e6cce2d-d426-4f55-95c9-52b596769a57.xhtml), *Monitoring Microservices*.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用Kiali与Jaeger一起观察服务网格中发生的情况。有关使用Grafana进行性能监控，请参阅[第20章](5e6cce2d-d426-4f55-95c9-52b596769a57.xhtml)，*监控微服务*。
- en: Before we do that, we need to get rid of some noise created by the health checks
    performed by Kubernetes' liveness and readiness probes. In the previous chapters,
    they have been using the same port as the API requests. This means that Istio
    will collect telematics data for both health checks and requests sent to the API.
    This will cause the graphs shown by Kiali to become unnecessarily cluttered. Kiali
    can filter out traffic that we are not interested in, but a simpler solution is
    to use a different port for the health checks.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行此操作之前，我们需要消除Kubernetes的活跃性和就绪探针执行的健康检查产生的一些噪音。在之前的章节中，它们一直在使用与API请求相同的端口。这意味着Istio将收集健康检查和发送到API的请求的遥测数据。这将导致Kiali显示的图表变得杂乱无章。Kiali可以过滤我们不感兴趣的流量，但更简单的解决方案是为健康检查使用不同的端口。
- en: 'Microservices can be configured to use a separate port for requests sent to
    the actuator endpoints, for example, health checks sent to the `/actuator/health` endpoint. The
    following line has been added to the common configuration file for all microservices,
    `config-repo/application.yml`:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 可以配置微服务使用单独的端口发送到执行器端点的请求，例如，发送到`/actuator/health`端点的健康检查。在所有微服务的通用配置文件`config-repo/application.yml`中添加了以下行：
- en: '[PRE29]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This will make all microservices use port `4004` to expose the health endpoints.
    All deployment files in the `kubernetes/services/base/deployments` folder have
    been updated to use port `4004` in their liveness and readiness probes.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使所有微服务使用端口`4004`来公开健康端点。`kubernetes/services/base/deployments`文件夹中的所有部署文件都已更新为在其活跃性和就绪探针中使用端口`4004`。
- en: 'The Spring Cloud Gateway (this is retained so we can run tests in Docker Compose)
    will continue to use the same port for requests to the API and the `health` endpoint.
    In the `config-repo/gateway.yml` configuration file, the management port is reverted
    to the port used for the API:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Gateway（保留此项以便我们可以在Docker Compose中运行测试）将继续使用相同的端口发送到API和`health`端点。在`config-repo/gateway.yml`配置文件中，管理端口恢复为用于API的端口：
- en: '[PRE30]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: With the requests sent to the health endpoint out of the way, we can start to
    send some requests through the service mesh.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将发送到健康端点的请求解决掉，我们可以开始通过服务网格发送一些请求。
- en: 'We will start a low-volume load test using `siege`, which we got to know in
    [Chapter 16](ebeb41b4-eea4-4d73-89ba-6788e2e68bac.xhtml), *Deploying Our Microservices
    to Kubernetes* (refer to the *Performing a rolling upgrade* section). After that,
    we will go through some of the most important parts of Kiali to see how Kiali
    can be used to observe a service mesh. We will also explore Kiali''s integration
    with Jaeger and how Jaeger is used for distributed tracing:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`siege`进行低负载测试，我们在[第16章](ebeb41b4-eea4-4d73-89ba-6788e2e68bac.xhtml)中了解到它，*将我们的微服务部署到Kubernetes*（参考*执行滚动升级*部分）。之后，我们将浏览Kiali的一些最重要的部分，看看Kiali如何用于观察服务网格。我们还将探索Kiali与Jaeger的集成，以及Jaeger如何用于分布式跟踪：
- en: 'Start the test with the following commands:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令开始测试：
- en: '[PRE31]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The first command will get an OAuth 2.0/OIDC access token that will be used
    in the next command, where `siege` is used to submit one HTTP request per second
    to the product-composite API.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个命令将获取一个OAuth 2.0/OIDC访问令牌，该令牌将在下一个命令中使用，其中`siege`用于向产品组合API提交每秒一个HTTP请求。
- en: 'Expect output from the `siege` command as follows:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 期望从`siege`命令输出如下：
- en: '![](img/124bc0e4-2fda-4b01-be2f-81c0653eaa0a.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![](img/124bc0e4-2fda-4b01-be2f-81c0653eaa0a.png)'
- en: 'Open Kiali''s web UI using the `http://kiali.istio-system.svc.cluster.local:20001/kiali` URL in
    a web browser and log in with the following username and password: `admin` and
    `admin`. Expect a web page similar to the following:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`http://kiali.istio-system.svc.cluster.local:20001/kiali` URL在Web浏览器中打开Kiali的Web
    UI，并使用以下用户名和密码登录：`admin`和`admin`。期望一个类似以下的网页：
- en: '![](img/621bc3a8-d0ad-4254-9de3-fea188d12428.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![](img/621bc3a8-d0ad-4254-9de3-fea188d12428.png)'
- en: Click on the Overview tab, if not already active.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击概述选项卡，如果尚未激活。
- en: 'Click on the graph icon in the hands-on namespace. Expect a graph to be shown,
    representing the current traffic flow through the service mesh, along the lines
    of the following:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击手动命名空间中的图标。期望显示一个代表当前通过服务网格的流量流动的图形，类似于以下内容：
- en: '![](img/8e6dcb80-2f70-4714-acb9-b8abcf8e49cd.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8e6dcb80-2f70-4714-acb9-b8abcf8e49cd.png)'
- en: Click on the Display-button, unselect Service Nodes, and select Traffic Animation.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击显示按钮，取消选择服务节点，并选择流量动画。
- en: Kiali displays a graph representing requests that are currently sent through
    the service mesh, where active requests are represented by small moving circles
    along with arrows.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: Kiali显示了一个代表当前通过服务网格发送的请求的图形，其中活动请求由小移动圆圈和箭头表示。
- en: This gives a pretty good initial overview of what's going on in the service
    mesh!
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 这在很大程度上初步概述了服务网格中正在发生的事情！
- en: 'Let''s now look at some distributed tracing using Jaeger:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们来看一下使用Jaeger进行一些分布式跟踪：
- en: '![](img/36f57f31-b217-474d-8bd6-99ddb55b7370.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/36f57f31-b217-474d-8bd6-99ddb55b7370.png)'
- en: Click on the product node.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击产品节点。
- en: 'Click on the Service: product link. On the web page for the service, click
    on the Traces tab in the menu and Kiali will use Jaeger to show an embedded view
    of traces that the product service is involved in. Expect a web page such as the
    following:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击服务：产品链接。在服务的网页上，点击菜单中的跟踪选项卡，Kiali将使用Jaeger显示产品服务涉及的跟踪的嵌入式视图。期望一个如下的网页：
- en: '![](img/4e530bf8-fba4-4321-9f45-450dfb3fe9dc.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4e530bf8-fba4-4321-9f45-450dfb3fe9dc.png)'
- en: 'Click on one of the traces to examine it. Expect a web page such as the following:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击其中一个跟踪以检查它。期望一个类似以下的网页：
- en: '![](img/402e5bb3-c03c-48dc-a5aa-ed14e971ecb0.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![](img/402e5bb3-c03c-48dc-a5aa-ed14e971ecb0.png)'
- en: This is basically the same tracing information as Zipkin, made available in
    [Chapter 14](42f456c5-d911-494a-a1ba-4631863068b6.xhtml), *Understanding Distributed
    Tracing*.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 这基本上是与Zipkin相同的跟踪信息，可以在[第14章](42f456c5-d911-494a-a1ba-4631863068b6.xhtml)，*理解分布式跟踪*中找到。
- en: There is much more to explore, but this is enough by way of an introduction.
    Feel free to explore the web UI in Kiali, Jaeger, and Grafana on your own.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 还有很多可以探索的，但这已经足够作为介绍。请随意自行探索Kiali、Jaeger和Grafana的Web UI。
- en: In [Chapter 20](5e6cce2d-d426-4f55-95c9-52b596769a57.xhtml), *Monitoring Microservices*,
    we will explore performance monitoring capabilities further.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第20章](5e6cce2d-d426-4f55-95c9-52b596769a57.xhtml)，*监控微服务*中，我们将进一步探索性能监控能力。
- en: Let's move on and learn how Istio can be used to improve security in the service
    mesh!
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续学习如何使用Istio来改善服务网格中的安全性！
- en: Securing a service mesh
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护服务网格
- en: 'In this section, we will learn how to use Istio to improve the security of
    a service mesh. We will cover the following topics:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何使用Istio来改善服务网格的安全性。我们将涵盖以下主题：
- en: How to protect external endpoints with HTTPS and certificates
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用HTTPS和证书保护外部端点
- en: How to require that external requests are authenticated using OAuth 2.0/OIDC
    access tokens
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何要求使用OAuth 2.0/OIDC访问令牌对外部请求进行身份验证
- en: How to protect internal communication using mutual authentication (mTLS)
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用相互认证（mTLS）保护内部通信
- en: Let's now understand each of these in the following sections.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们在以下部分了解每个部分。
- en: Protecting external endpoints with HTTPS and certificates
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用HTTPS和证书保护外部端点
- en: 'In the *Creating the service mesh* section, we saw how the Istio Ingress Gateway
    is configured to use the following certificate files to protect external requests
    sent to `minikube.me` using HTTPS. The Istio Ingress Gateway is configured as
    follows:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在*创建服务网格*部分，我们看到Istio Ingress Gateway配置为使用以下证书文件来保护通过HTTPS发送到`minikube.me`的外部请求。Istio
    Ingress Gateway的配置如下：
- en: '[PRE32]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: But where did these files come from, you may ask?
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 但是你可能会问，这些文件是从哪里来的？
- en: 'We can see how the Istio Ingress Gateway is configured by running the following
    command:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过运行以下命令来查看Istio Ingress Gateway的配置：
- en: '[PRE33]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We will find that it is prepared to mount an optional secret named `istio-ingressgateway-certs`
    and that it will be mapped to the folder, `/etc/istio/ingressgateway-certs/`:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将发现它准备好挂载一个名为`istio-ingressgateway-certs`的可选秘密，并且它将映射到文件夹`/etc/istio/ingressgateway-certs/`：
- en: '![](img/206f48a3-7bfa-42df-97ad-e1be388adda9.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![](img/206f48a3-7bfa-42df-97ad-e1be388adda9.png)'
- en: This results in certificate files, `tls.crt` and `tls.key`, from a secret named `istio-ingressgateway-certs`
    being made available to the Istio Ingress Gateway on the `/etc/istio/ingressgateway-certs/tls.crt`
    and `/etc/istio/ingressgateway-certs/tls.key` file paths.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致名为`istio-ingressgateway-certs`的秘密中的证书文件`tls.crt`和`tls.key`在`/etc/istio/ingressgateway-certs/tls.crt`和`/etc/istio/ingressgateway-certs/tls.key`文件路径上可用于Istio入口网关。
- en: 'Creating of this secret is handled by means of the `deploy-dev-env.bash` and `deploy-prod-env.bash` deployment
    scripts, found in the `kubernetes/scripts` folder, by means of the following command:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 创建此密钥是通过`kubernetes/scripts`文件夹中的`deploy-dev-env.bash`和`deploy-prod-env.bash`部署脚本处理的，通过以下命令进行处理：
- en: '[PRE34]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The certificate files were created in [Chapter 17](a9327ecc-49e7-4f72-9221-3321b7158d83.xhtml),
    *Implementing Kubernetes Features as an Alternative* (refer to the *Testing with
    Kubernetes ConfigMaps, secrets, and ingress* section).
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 证书文件是在[第17章](a9327ecc-49e7-4f72-9221-3321b7158d83.xhtml)中创建的，*实现Kubernetes功能作为替代*（参见*使用Kubernetes
    ConfigMaps、secrets和ingress进行测试*部分）。
- en: 'To verify that it is these certificates that are used by the Istio Ingress
    Gateway, we can run the following command:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证这些证书是否被Istio入口网关使用，我们可以运行以下命令：
- en: '[PRE35]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Expect the following output:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 期望以下输出：
- en: '![](img/a5d99e95-d5ab-49fc-b2c3-62afb06295d1.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a5d99e95-d5ab-49fc-b2c3-62afb06295d1.png)'
- en: The output shows that the certificate is issued for `minikube.se` and that it
    is self-signed; that is, the issuer is also `minikube.me`.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示该证书是为`minikube.se`颁发的，并且是自签名的；也就是说，发行者也是`minikube.me`。
- en: This self-signed certificate can be replaced with a certificate bought by a
    trusted certificate authority (CA) for production use cases. Istio has recently
    added support for the automated provisioning of trusted certificates using, for
    example, the cert manager and Let's Encrypt, as we did in [Chapter 17](a9327ecc-49e7-4f72-9221-3321b7158d83.xhtml),
    *Implementing Kubernetes Features as an Alternative* (refer to the *Provisioning
    certificates with the cert manager and Let's Encrypt* section). This support is
    currently a bit too complex to fit into this chapter.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这个自签名证书可以在生产用例中由受信任的证书颁发机构（CA）购买的证书替换。例如，Istio最近增加了对自动使用证书管理器和Let's Encrypt等工具提供受信任证书的支持，就像我们在[第17章](a9327ecc-49e7-4f72-9221-3321b7158d83.xhtml)中所做的那样，*实现Kubernetes功能作为替代*（参见*使用证书管理器和Let's
    Encrypt提供证书*部分）。这种支持目前有点太复杂，不适合本章。
- en: With the certificate configuration verified, let's now move on to see how the
    Istio Ingress Gateway can protect microservices from unauthenticated requests**.**
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 经过证书配置验证，现在让我们继续看看Istio入口网关如何保护微服务免受未经身份验证的请求**。**
- en: Authenticating external requests using OAuth 2.0/OIDC access tokens
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用OAuth 2.0/OIDC访问令牌对外部请求进行身份验证
- en: Istio Ingress Gateway is capable of requiring and validating JWT-based OAuth
    2.0/OIDC access tokens, in other words, protecting the microservices in the service
    mesh from external unauthenticated requests. For a recap on JWT, OAuth 2.0, and
    OIDC, refer to [Chapter 11](a9327ecc-49e7-4f72-9221-3321b7158d83.xhtml), *Secure
    Access to APIs* (see the *Authenticating and authorizing API access using OAuth
    2.0 and OpenID Connect* section).
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: Istio入口网关能够要求并验证基于JWT的OAuth 2.0/OIDC访问令牌，换句话说，保护服务网格中的微服务免受外部未经身份验证的请求。有关JWT、OAuth
    2.0和OIDC的回顾，请参阅[第11章](a9327ecc-49e7-4f72-9221-3321b7158d83.xhtml)，*安全访问API*（参见*使用OAuth
    2.0和OpenID Connect进行API访问的身份验证和授权*部分）。
- en: 'To enable authentication, we need to create an Istio `Policy` object that specifies
    which targets should be protected and which access token issuers, that is, OAuth
    2.0/OIDC providers, should be trusted. This is done in the `kubernetes/services/base/istio/jwt-authentication-policy.yml`
    file and appears as follows:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 要启用身份验证，我们需要创建一个指定应该受到保护的目标和应该受信任的访问令牌发行者（即OAuth 2.0/OIDC提供者）的Istio `Policy`对象。这是在`kubernetes/services/base/istio/jwt-authentication-policy.yml`文件中完成的，如下所示：
- en: '[PRE36]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Explanations for the preceding source code are as follows:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 上述源代码的解释如下：
- en: The `targets` list specifies that the authentication check will be performed
    for requests sent to the `product-composite` microservice.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`targets`列表指定对`product-composite`微服务发送的请求将执行身份验证检查。'
- en: The `origins` list specifies the OAuth 2.0/OIDC providers we rely on. For each
    issuer, the name of the issuer and the URL for its JSON web key set are specified.
    For a recap, see [Chapter 11](bcb9bba0-d2fe-4ee8-954b-07a7e38e1115.xhtml), *Securing
    Access to APIs* (refer to the *Introducing OpenId Connect* section). We have specified
    the local auth server, `http://auth-server.local`.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`origins`列表指定了我们依赖的OAuth 2.0/OIDC提供者。对于每个发行者，都指定了发行者的名称和其JSON web密钥集的URL。有关回顾，请参阅[第11章](bcb9bba0-d2fe-4ee8-954b-07a7e38e1115.xhtml)，*保护API访问*（参考*介绍OpenId
    Connect*部分）。我们已经指定了本地认证服务器，`http://auth-server.local`。'
- en: The policy file was applied by the `kubernetes/scripts/deploy-dev-env.bash` deployment
    script, when it was used in the *Running commands to create the service mesh* section.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 策略文件是在*运行命令创建服务网格*部分中使用`kubernetes/scripts/deploy-dev-env.bash`部署脚本应用的。
- en: The easiest way to verify that an invalid request is rejected by the Istio Ingress
    Gateway and not the `product-composite` microservice is to make a request without
    an access token and observe the error message that is returned. The Istio Ingress
    Gateway returns the following error message, `Origin authentication failed.`,
    in the event of a failed authentication, while the `product-composite` microservice
    returns an empty string. Both return the HTTP code `401` (Unauthorized).
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 验证无效请求是否被Istio入口网关拒绝而不是`product-composite`微服务的最简单方法是发送一个没有访问令牌的请求，并观察返回的错误消息。在身份验证失败的情况下，Istio入口网关返回以下错误消息`Origin
    authentication failed.`，而`product-composite`微服务返回一个空字符串。两者都返回HTTP代码`401`（未经授权）。
- en: 'Try it out with the following commands:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令进行尝试：
- en: 'Make a request without an access token along the lines of the following:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送一个类似以下的没有访问令牌的请求：
- en: '[PRE37]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Expect a response saying `Origin authentication failed. HTTP Code: 401`.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '期望收到`Origin authentication failed. HTTP Code: 401`的响应。'
- en: 'Temporarily delete the policy with the following command:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令暂时删除策略：
- en: '[PRE38]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Wait a minute to allow that policy change to be propagated to the Istio Ingress
    Gateway and then retry the request without an access token. The response should
    now only contain the HTTP code: `HTTP Code: 401`.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '等待一分钟，以便策略更改传播到Istio入口网关，然后重新尝试不使用访问令牌的请求。响应现在应该只包含HTTP代码：`HTTP Code: 401`。'
- en: 'Enable the policy again with the following command:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令再次启用策略：
- en: '[PRE39]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '**Suggested additional exercise:** Try out the Auth0 OIDC provider, as described
    in [Chapter 11](bcb9bba0-d2fe-4ee8-954b-07a7e38e1115.xhtml), *Securing Access
    to APIs* (refer to the T*esting with an OpenID Connect provider, Auth0,* section.
    Add your Auth0 provider to `jwt-authentication-policy.yml`. In my case, it appears
    as follows:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '**建议的额外练习：**尝试使用Auth0 OIDC提供程序，如[第11章](bcb9bba0-d2fe-4ee8-954b-07a7e38e1115.xhtml)中所述，*保护API的访问*（参考*使用OpenID
    Connect提供程序Auth0进行测试*部分。将您的Auth0提供程序添加到`jwt-authentication-policy.yml`。在我的情况下，它如下所示：'
- en: '[PRE40]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Now, let's move on to the last security mechanism that we will cover in Istio
    – the automatic protection of internal communication in the service mesh using
    mutual authentication, mTLS.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续讨论我们将在Istio中涵盖的最后一个安全机制——使用相互认证（mTLS）自动保护服务网格内部通信。
- en: Protecting internal communication using mutual authentication (mTLS)
  id: totrans-305
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用相互认证（mTLS）保护内部通信
- en: In this section, we will learn how Istio can be configured to automatically
    protect internal communication within the service mesh using *mutual* *authentication*,
    mTLS. When using mutual authentication, not only does the service side prove its
    identity by exposing a certificate, but also the clients prove their identity
    to the servers by exposing a client-side certificate. This provides a higher level
    of security compared to normal TLS/HTTPS usage, where only the identity of the
    server is proven. Setting up and maintaining mutual authentication; that is, the
    provision of new, and the rotating of outdated, certificates, is known to be complex
    and is therefore seldom used. Istio fully automates the provisioning and rotation
    of certificates for mutual authentication used for internal communication inside
    the service mesh. This makes it much easier to use mutual authentication compared
    to setting it up manually.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何配置Istio以自动使用相互认证（mTLS）保护服务网格内部通信。使用相互认证时，服务端不仅通过暴露证书来证明其身份，客户端也通过暴露客户端证书向服务器证明其身份。这与普通的TLS/HTTPS使用相比提供了更高级别的安全性，普通的TLS/HTTPS只能证明服务器的身份。设置和维护相互认证，即提供新证书和轮换过时证书，被认为是复杂的，因此很少被使用。Istio完全自动化了用于服务网格内部通信的相互认证证书的提供和轮换。这使得相互认证的使用比手动设置要容易得多。
- en: So, why should we use mutual authentication? Isn't it sufficient to protect
    external APIs with HTTPS and OAuth 2.0/OIDC access tokens?
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么我们要使用相互认证？仅仅使用HTTPS和OAuth 2.0/OIDC访问令牌保护外部API不就足够了吗？
- en: As long as the attacks come through the external API, it might be sufficient.
    But what if a pod inside the Kubernetes cluster becomes compromised? For example,
    if an attacker gains control over a pod, then the attacker can start listening
    to traffic between other pods in the Kubernetes cluster. If the internal communication
    is sent as plain text, it will be very easy for the attacker to gain access to
    sensitive information sent between pods in the cluster. To minimize the damage
    caused by such an intrusion, mutual authentication can be used to prevent an attacker
    from eavesdropping on internal network traffic.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 只要攻击来自外部API，这可能就足够了。但是，如果Kubernetes集群中的一个Pod受到损害怎么办？例如，如果攻击者控制了一个Pod，那么攻击者可以开始监听Kubernetes集群中其他Pod之间的流量。如果内部通信以明文形式发送，那么攻击者很容易就能够获取集群中Pod之间发送的敏感信息。为了最大程度地减少此类入侵造成的损害，可以使用相互认证来防止攻击者窃听内部网络流量。
- en: To enable the use of mutual authentication managed by Istio, Istio needs to
    be configured both on the server side, using a policy, and on the client side,
    using a destination rule.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 要启用由Istio管理的相互认证，需要在服务器端使用策略以及在客户端端使用目标规则进行配置。
- en: 'When using the demo configuration of Istio, as we did in the *Deploying Istio
    in a Kubernetes cluster* section, we got a global mesh policy created that configures
    the server side to use a permissive mode, meaning the Istio proxies will allow
    both plain text and encrypted requests. This can be verified with the following
    command:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Istio的演示配置时，就像我们在“在Kubernetes集群中部署Istio”部分中所做的那样，我们得到了一个全局网格策略，配置服务器端使用宽松模式，这意味着Istio代理将允许明文和加密请求。可以使用以下命令进行验证：
- en: '[PRE41]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Expect a response similar to the following:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 期望得到类似以下的响应：
- en: '![](img/adef0bf8-61fd-484e-854c-a07e50609603.png)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
  zh: '![](img/adef0bf8-61fd-484e-854c-a07e50609603.png)'
- en: 'To configure microservices to use mutual authentication when sending requests
    internally to other microservices, a destination rule is created for each microservice.
    This is done in the `kubernetes/services/base/istio/internal_mtls_destination_rules.yml` file. The destination
    rules all look the same; for example, for the `product-composite` service, they
    appear as follows:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 要配置微服务在向其他微服务内部发送请求时使用相互认证，需要为每个微服务创建一个目标规则。这是在`kubernetes/services/base/istio/internal_mtls_destination_rules.yml`文件中完成的。所有目标规则看起来都一样；例如，对于`product-composite`服务，它们如下所示：
- en: '[PRE42]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '`trafficPolicy` is set to use `tls` with `ISTIO_MUTUAL`, meaning mutual authentication
    is managed by Istio.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '`trafficPolicy`设置为使用`tls`和`ISTIO_MUTUAL`，这意味着Istio管理相互认证。'
- en: The destination rules were applied by the `kubernetes/scripts/deploy-dev-env.bash` deployment
    script, when it was used in the preceding *Running commands to create the service
    mesh* section.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 目标规则是在`kubernetes/scripts/deploy-dev-env.bash`部署脚本中应用的，当它在前面的“运行命令创建服务网格”部分中使用时。
- en: 'To verify that the internal communication is protected, perform the following
    steps:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 要验证内部通信是否受到保护，请执行以下步骤：
- en: Ensure that the load tests started in the preceding *Observing the service mesh* section are
    still running.
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保在前面的*观察服务网格*部分中启动的负载测试仍在运行。
- en: Go to the Kiali graph in a web browser ([http://kiali.istio-system.svc.cluster.local:20001/kiali](http://kiali.istio-system.svc.cluster.local:20001/kiali)).
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Web浏览器中转到Kiali图表（[http://kiali.istio-system.svc.cluster.local:20001/kiali](http://kiali.istio-system.svc.cluster.local:20001/kiali)）。
- en: 'Click on the Display button to enable the Security label. The graph will show
    a padlock on all communication links that are protected by Istio''s automated
    mutual authentication, as follows:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击“显示”按钮以启用安全标签。图表将显示所有由Istio的自动双向身份验证保护的通信链接上的挂锁，如下所示：
- en: '![](img/cc3e1088-449c-4140-8da3-9d90d416f1ab.png)'
  id: totrans-322
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cc3e1088-449c-4140-8da3-9d90d416f1ab.png)'
- en: Expect a padlock on all links except for those to resource managers – RabbitMQ,
    MySQL, and MongoDB.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 除了与资源管理器（RabbitMQ、MySQL和MongoDB）的链接外，预期在所有链接上都有一个挂锁。
- en: Calls to RabbitMQ, MySQL, and MongoDB are not handled by Istio proxies, and
    therefore require manual configuration to be protected using TLS.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 对RabbitMQ、MySQL和MongoDB的调用不受Istio代理的处理，因此需要手动配置以使用TLS进行保护。
- en: With this, we have seen all three security mechanisms in Istio in action, and
    it's now time to see how Istio can help us to verify that a service mesh is resilient.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个功能，我们已经看到了Istio中的所有三种安全机制的运作情况，现在是时候看看Istio如何帮助我们验证服务网格的弹性了。
- en: Ensuring that a service mesh is resilient
  id: totrans-326
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确保服务网格具有弹性
- en: In this section, we will learn how to use Istio to ensure that a service mesh
    is resilient; that is, it can handle temporary faults in a service mesh. Istio
    comes with mechanisms similar to what the Spring Framework offers in terms of
    timeouts, retries, and a type of circuit breaker called **outlier detection** to
    handle temporary faults. When it comes to deciding whether language-native mechanisms
    should be used to handle temporary faults, or whether this should be delegated
    to a service mesh such as Istio, I tend to favor using language-native mechanisms,
    as in the examples in [Chapter 13](23795d34-4068-4961-842d-989cde26b642.xhtml),
    *Improving Resilience Using Resilience4J*. In many cases, it is important to keep
    the logic for handling errors, for example, handling fallback alternatives for
    a circuit breaker, together with other business logic for a microservice.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何使用Istio来确保服务网格具有弹性；也就是说，它可以处理服务网格中的临时故障。Istio提供了类似于Spring Framework的机制，用于处理超时、重试和一种名为**异常检测**的断路器，以处理临时故障。在决定是否应该使用语言本机机制来处理临时故障，还是应该将其委托给Istio等服务网格时，我倾向于使用语言本机机制，就像[第13章](23795d34-4068-4961-842d-989cde26b642.xhtml)中的示例中所示的那样，*使用Resilience4J改善弹性*。在许多情况下，将处理错误的逻辑（例如，为断路器处理备用方案）与微服务的其他业务逻辑放在一起非常重要。
- en: There are cases when the corresponding mechanisms in Istio could be of great
    help. For example, if a microservice is deployed and it is determined that it
    can't handle temporary faults that occur in production from time to time, then
    it can be very convenient to add a timeout or a retry mechanism using Istio instead
    of waiting for a new release of the microservice with corresponding error handling
    features put in place.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，Istio中的相应机制可能非常有帮助。例如，如果部署了一个微服务，并且确定它无法处理在生产环境中不时发生的临时故障，那么使用Istio添加超时或重试机制会非常方便，而不是等待微服务的新版本放置相应的错误处理功能。
- en: Another capability in the area of resilience that comes with Istio is the capability
    to inject faults and delays into an existing service mesh. Why would anyone want
    to do that?
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: Istio在弹性领域的另一个功能是能够向现有服务网格中注入故障和延迟。为什么有人会想要这样做呢？
- en: Injecting faults and delays in a controlled way is very useful for verifying
    that the resilient capabilities in the microservices work as expected! We will
    try them out in this section, verifying that the retry, timeout, and circuit breaker
    in the `product-composite` microservice work as expected.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 以受控方式注入故障和延迟非常有用，可以验证微服务中的弹性功能是否按预期工作！我们将在本节中尝试它们，并验证`product-composite`微服务中的重试、超时和断路器是否按预期工作。
- en: In [Chapter 13](23795d34-4068-4961-842d-989cde26b642.xhtml), *Improving Resilience
    Using Resilience4j* (refer to the *Adding programmable delays and random errors*
    section), we added support for injecting faults and delays in the microservices source
    code. That source code can preferably be replaced by using Istio's capabilities
    for injecting faults and delays at runtime, as demonstrated in the following.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第13章](23795d34-4068-4961-842d-989cde26b642.xhtml)中，*使用Resilience4j改善弹性*（参见*添加可编程延迟和随机错误*部分），我们添加了对在微服务源代码中注入故障和延迟的支持。该源代码可以被Istio在运行时注入故障和延迟的能力所取代，如下所示。
- en: We will begin by injecting faults to see whether the retry mechanisms in the
    `product-composite` microservice work as expected. After that, we will delay the
    responses from the product service and verify that the circuit breaker handles
    the delay as expected.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先注入故障，以查看`product-composite`微服务中的重试机制是否按预期工作。之后，我们将延迟产品服务的响应，并验证断路器是否按预期处理延迟。
- en: Testing resilience by injecting faults
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过注入故障来测试弹性
- en: Let's make the product service throw random errors and verify that the microservice
    landscape handles this correctly. We expect the retry mechanism in the `product-composite`
    microservice to kick in and retry the request until it succeeds or its limit of
    max numbers of retries is reached. This will ensure that a shortlived fault does
    not affect the end user more than the delay introduced by the retry attempts.
    Refer to the *Adding a retry mechanism* section in [Chapter 13](23795d34-4068-4961-842d-989cde26b642.xhtml),
    *Improving Resilience Using Resilience4j*, for a recap on the retry mechanism in
    the `product-composite` microservice.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 让产品服务抛出随机错误，并验证微服务架构是否正确处理。我们期望`product-composite`微服务中的重试机制启动并重试请求，直到成功或达到最大重试次数的限制。这将确保短暂的故障不会比重试尝试引入的延迟更多地影响最终用户。参考[第13章](23795d34-4068-4961-842d-989cde26b642.xhtml)中的*添加重试机制*部分，了解`product-composite`微服务中的重试机制。
- en: 'Faults can be injected using `kubernetes/resilience-tests/product-virtual-service-with-faults.yml`.
    This appears as follows:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`kubernetes/resilience-tests/product-virtual-service-with-faults.yml`来注入故障。如下所示：
- en: '[PRE43]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The definition says that 20% of the requests sent to the product service shall
    be aborted with the HTTP status code 500 (Internal Server Error).
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 定义指出，20%发送到产品服务的请求将被中止，HTTP 状态码为500（内部服务器错误）。
- en: 'Perform the following steps to test this:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤进行测试：
- en: Ensure that the load tests using `siege`, as started in the *Observing the service
    mesh*section, are running.
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保使用“siege”进行的负载测试，如*观察服务网格*部分中所启动的那样，正在运行。
- en: 'Apply fault injection with the following command:'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令进行故障注入：
- en: '[PRE44]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Monitor the output from the `siege` load tests tool. Expect output similar
    to the following:'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 监视`siege`负载测试工具的输出。期望类似以下的输出：
- en: '![](img/0bc01f04-88dd-4507-8e09-21be25135194.png)'
  id: totrans-343
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0bc01f04-88dd-4507-8e09-21be25135194.png)'
- en: From the sample output, we can see that all requests are still successful, in
    other words, status 200 (OK) is returned; however, some of them (20%) take an
    extra second to complete. This indicates that the retry mechanism in the `product-composite`
    microservice has kicked in and has retried a failed request to the product service.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 从示例输出中，我们可以看到所有请求仍然成功，换句话说，返回状态码200（OK）；但是其中一些（20%）需要额外的一秒才能完成。这表明`product-composite`微服务中的重试机制已启动，并重试了对产品服务的失败请求。
- en: 'Kiali will also indicate that something is wrong with requests sent to the
    product service, as follows:'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kiali 还将指示发送到产品服务的请求存在问题，如下所示：
- en: Go to the call graph in Kiali's web UI that we used earlier to observe the traffic
    in our namespace, `hands-on`.
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到 Kiali 的 web UI 中的调用图，我们之前用来观察我们的命名空间“hands-on”中的流量。
- en: Click on the Display menu button and select Service Nodes.
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击显示菜单按钮，选择服务节点。
- en: Click on the menu button to the left of the Display button, named No edge labels,
    and select the Response time option.
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击显示按钮左侧的菜单按钮，名为无边标签，选择响应时间选项。
- en: 'The graph will show something like the following:'
  id: totrans-349
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图表将显示类似以下的内容：
- en: '![](img/ee4ac35f-e8a5-437f-b1de-261228e0ed60.png)'
  id: totrans-350
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee4ac35f-e8a5-437f-b1de-261228e0ed60.png)'
- en: The arrow to the Service Node product will be shown in red to indicate that
    failed requests are detected. If we click on the arrow, we can see fault statistics
    to the right.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 指向服务节点产品的箭头将显示为红色，表示检测到失败的请求。如果我们点击箭头，就可以在右侧看到故障统计信息。
- en: In the preceding sample screenshot, an error rate of 19.4% is reported, which
    corresponds well with the 20% we asked for. Note that the arrow from the Istio
    Gateway to the `product-composite` service is still green. This means that the
    retry mechanism in the `product-composite` service protects the end user; in other
    words, the faults do not propagate to the end user.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述示例截图中，报告了19.4%的错误率，这与我们要求的20%相当吻合。请注意，从 Istio 网关到`product-composite`服务的箭头仍然是绿色的。这意味着`product-composite`服务中的重试机制保护了最终用户；换句话说，故障不会传播到最终用户。
- en: 'Conclude the removal of the fault injection with the following command:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令结束故障注入：
- en: '[PRE45]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Let's now move on to the next section, where we will inject delays to trigger
    the circuit breaker.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们转到下一部分，在那里我们将注入延迟以触发断路器。
- en: Testing resilience by injecting delays
  id: totrans-356
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过注入延迟测试韧性
- en: From [Chapter 13](23795d34-4068-4961-842d-989cde26b642.xhtml), *Improving Resilience
    Using Resilience4j* (refer to the *Introducing the circuit breaker* section),
    we know that a circuit breaker can be used to prevent problems due to the slow
    response of services, or the fact that the services do not respond at all.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 从[第13章](23795d34-4068-4961-842d-989cde26b642.xhtml)中的*使用 Resilience4j 改善韧性*（参考*引入断路器*部分），我们知道断路器可用于防止由于服务响应缓慢或服务根本不响应而导致的问题。
- en: Let's verify that the circuit breaker in the `product-composite` service works
    as expected by injecting a delay into the product service using Istio. A delay
    can be injected using a virtual service.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用 Istio 在产品服务中注入延迟，验证`product-composite`服务中的断路器是否按预期工作。可以使用虚拟服务来注入延迟。
- en: 'Refer to `kubernetes/resilience-tests/product-virtual-service-with-delay.yml`.
    Its code appears as follows:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 参考`kubernetes/resilience-tests/product-virtual-service-with-delay.yml`。其代码如下：
- en: '[PRE46]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The preceding definition says that all requests sent to the product service
    shall be delayed by 3 seconds.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 上述定义指出，发送到产品服务的所有请求将延迟3秒。
- en: Requests sent to the product service from the `product-composite` service are
    configured to timeout after 2 seconds. The circuit breaker is configured to open
    its circuit if 3 consecutive requests fail. When the circuit is open, it will
    fast-fail; in other words, it will immediately throw an exception, not attempting
    to call the underlying service. The business logic in the `product-composite`
    microservice will catch this exception and apply fallback logic. For a recap,
    see  [Chapter 13](23795d34-4068-4961-842d-989cde26b642.xhtml), *Improving Resilience
    Using Resilience4j* (refer to the *Adding a circuit breaker* section).
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 产品服务从`product-composite`服务发送的请求被配置为在2秒后超时。如果有3个连续的请求失败，断路器将打开其电路。当电路打开时，它将快速失败；换句话说，它将立即抛出异常，而不尝试调用底层服务。`product-composite`微服务中的业务逻辑将捕获此异常并应用回退逻辑。有关详细信息，请参阅[第13章](23795d34-4068-4961-842d-989cde26b642.xhtml)，*使用Resilience4j改进弹性*（参见*添加断路器*部分）。
- en: 'Perform the following steps to test the circuit breaker by injecting a delay:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤来通过注入延迟来测试断路器：
- en: Stop the load test run by means of the `siege` command by pressing *Ctrl + C* in
    the terminal window where `siege` is running.
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在运行`siege`的终端窗口中按*Ctrl + C*来停止`siege`命令的负载测试运行。
- en: 'Create a temporary delay in the product service with the following command:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令在产品服务中创建临时延迟：
- en: '[PRE47]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Acquire an access token as follows:'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取访问令牌的方法如下：
- en: '[PRE48]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Send six requests in a row. Expect the circuit to open up after the first three
    failed calls, that the circuit breaker applies fast-fail logic for the three last
    calls, and that a fallback response is returned, as follows:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连续发送六个请求。预期在前三个失败的调用后，电路将打开，断路器将对最后三个调用应用快速失败逻辑，并返回回退响应，如下所示：
- en: '[PRE49]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The responses from the first 3 calls are expected to be a timeout-related error
    message, and a response time of 2 seconds, in other words, the timeout time. Expect
    responses for the first 3 calls along the lines of the following:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 前3个调用的响应预期是与超时相关的错误消息，并且响应时间为2秒，换句话说，是超时时间。预期前3个调用的响应如下：
- en: '**![](img/c61d561d-e023-488b-9e75-1dbb32bd2f5c.png)**'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '**![](img/c61d561d-e023-488b-9e75-1dbb32bd2f5c.png)**'
- en: 'The responses from the last 3 calls are expected to be a response from the
    fallback logic with a short response time. Expect responses for the last 3 calls
    as follows:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 最后3个调用的响应预期是回退逻辑的响应，并且响应时间很短。预期最后3个调用的响应如下：
- en: '![](img/468fa43c-0a38-47fa-8baf-80de72b55711.png)'
  id: totrans-374
  prefs: []
  type: TYPE_IMG
  zh: '![](img/468fa43c-0a38-47fa-8baf-80de72b55711.png)'
- en: 'Simulate the fact that the delay problem is fixed by removing the temporary
    delay with the following command:'
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令模拟延迟问题已通过移除临时延迟：
- en: '[PRE50]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Verify that correct answers are returned again and without any delay by sending
    a new request using the preceding command.
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用上述命令发送新请求来验证再次返回正确的答案并且没有任何延迟。
- en: 'If you want to check the state of the circuit breaker, you can do it with the
    following command:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要检查断路器的状态，可以使用以下命令进行检查：
- en: '**`curl product-composite.hands-on.svc.cluster.local:4004/actuator/health -s
    | jq -r .details.productCircuitBreaker.details.state`**'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '**`curl product-composite.hands-on.svc.cluster.local:4004/actuator/health -s
    | jq -r .details.productCircuitBreaker.details.state`**'
- en: It should report `CLOSED`, `OPEN`, or `HALF_OPEN`, depending on its state.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 它应该报告`CLOSED`，`OPEN`或`HALF_OPEN`，具体取决于其状态。
- en: This proves that the circuit breaker reacts as expected when we inject a delay
    using Istio. This concludes testing features in Istio that can be used to verify
    that the microservice landscape is resilient. The final feature we will explore
    in Istio is its support for traffic management; we will establish how it can be
    used to enable deployments with zero downtime.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 这证明了当我们使用Istio注入延迟时，断路器会如预期地做出反应。这结束了在Istio中测试可用于验证微服务架构具有弹性的功能。我们将在Istio中探索的最后一个功能是其对流量管理的支持；我们将建立它如何用于实现零停机时间的部署。
- en: Performing zero-downtime deployments
  id: totrans-382
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行零停机时间部署
- en: As already mentioned in [Chapter 16](ebeb41b4-eea4-4d73-89ba-6788e2e68bac.xhtml),
    *Deploying Our Microservices to Kubernetes* (refer to the *Performing a rolling
    upgrade* section), being able to deploy an update without downtime becomes crucial
    with a growing number of autonomous microservices that are updated independently
    of one another.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在[第16章](ebeb41b4-eea4-4d73-89ba-6788e2e68bac.xhtml)中已经提到的，*将我们的微服务部署到Kubernetes*（参见*执行滚动升级*部分），能够在一组独立更新的自主微服务中进行更新而无需停机时间变得至关重要。
- en: In this section, we will learn about Istio's traffic management and routing
    capabilities and how they can be used to perform deployments of new versions of
    microservices without requiring any downtime. In [Chapter 16](ebeb41b4-eea4-4d73-89ba-6788e2e68bac.xhtml),
    *Deploying Our Microservices to Kubernetes* (refer to the *Performing a rolling
    upgrade* section), we saw how Kubernetes can be used to perform a rolling upgrade
    without requiring any downtime. Using the Kubernetes rolling upgrade mechanism
    automates the entire process, but unfortunately provides no option to test the
    new version before all users are routed to the new version.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将了解Istio的流量管理和路由功能，以及如何使用它们来执行新版本的微服务部署而无需任何停机时间。在[第16章](ebeb41b4-eea4-4d73-89ba-6788e2e68bac.xhtml)，*将我们的微服务部署到Kubernetes*（参见*执行滚动升级*部分），我们看到了Kubernetes如何在无需任何停机时间的情况下执行滚动升级。使用Kubernetes滚动升级机制自动化了整个过程，但不幸的是，在所有用户被路由到新版本之前，它没有提供测试新版本的选项。
- en: 'Using Istio, we can deploy the new version, but initially route all users to
    the existing version (called the old version in this chapter). After that, we
    can use Istio''s fine-grained routing mechanism to control how users are routed
    to the new and the old versions. We will see how two popular upgrade strategies
    can be implemented using Istio:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Istio，我们可以部署新版本，但最初将所有用户路由到现有版本（在本章中称为旧版本）。之后，我们可以使用Istio的细粒度路由机制来控制用户如何路由到新版本和旧版本。我们将看到如何使用Istio来实现两种流行的升级策略：
- en: '**Canary deploys*: ***When using canary deploys, most users are routed to the
    old version, except for a group of selected test users who are routed to the new
    version. When the test users have approved the new version, regular users can
    be routed to the new version using a blue/green deploy.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Blue/****green** **deploys*****: ***Traditionally, a blue/green deploy means
    that all users are switched to either the blue or the green version, one being
    the new version and the other being the old version. If something goes wrong when
    switching over to the new version, it is very simple to switch back to the old
    version. Using Istio, this strategy can be refined by gradually shifting users
    over to the new version, for example, starting with 20% of the users and then
    slowly increasing the percentage of users who are routed to the new version. At
    all times, it is very easy to route all users back to the old version if a fatal
    error is revealed in the new version.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As already stated in[ ](ebeb41b4-eea4-4d73-89ba-6788e2e68bac.xhtml)[Chapter
    16](ebeb41b4-eea4-4d73-89ba-6788e2e68bac.xhtml), *Deploying Our Microservices
    to Kubernetes* (refer to the *Performing a rolling upgrade* section), it is important
    to remember that a prerequisite for these types of upgrade strategies is that
    the upgrade is backward-compatible. Such an upgrade is compatible both in terms
    of APIs and message formats, which are used to communicate with other services
    and database structures. If the new version of the microservice requires changes
    to external APIs, message formats, or database structures that the old version
    can't handle, these upgrade strategies can't be applied.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: 'We will go through the following deploy scenario in the following subsections:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: We will start by deploying the `v1` and `v2` versions of the microservices,
    with routing configured to send all requests to the `v1` version of the microservices.
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we will allow a test group to run canary tests; that is, we'll verify
    the new `v2` versions of the microservices. To simplify the tests somewhat, we
    will only route test users to the new versions of the core microservices, that
    is, the `product`, `recommendation`, and `review` microservices.
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, we will start to move regular users over to the new versions using
    a blue/green deploy: initially, a small percentage of users and then, over time,
    more and more users until, eventually, they are all routed to the new version.
    We will also see how we can quickly switch back to the `v1` versions if a fatal
    error is detected in the new v2 version.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's first see what changes have been applied to the source code to deploy
    two concurrent versions, `v1` and `v2`, of the microservices.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: Source code changes
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As already mentioned in the *Changing the file structure of the Kubernetes
    definition files *section, the file structure for the Kubernetes definition files
    in `kubernetes/services` has been expanded in this chapter to support the deployment
    of concurrent versions of the microservices in the production environment. The
    expanded file structure appears as follows:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/26f33b74-c0c1-46ea-80f3-259b536c3bf8.png)'
  id: totrans-396
  prefs: []
  type: TYPE_IMG
- en: Details regarding the development environment have been removed from the preceding
    diagram.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: Let's first see how service and deployment objects for the `v1` and `v2` versions
    of the microservices are configured and created. After that, we will go through
    additional definition files for Istio objects used to control the routing.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: Service and deployment objects for concurrent versions of microservices
  id: totrans-399
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To be able to run multiple versions of a microservice concurrently, the deployment
    objects and their corresponding pods must have different names, for example, `product-v1`
    and `product-v2`. There must, however, be only one Kubernetes service object per
    microservice. All traffic to a specific microservice always goes through one and
    the same service object, irrespective of what version of the pod the request will
    be routed to in the end. This is achieved using Kustomize by splitting up deployment
    objects and service objects into different folders.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够同时运行多个版本的微服务，部署对象及其对应的pod必须具有不同的名称，例如`product-v1`和`product-v2`。然而，每个微服务只能有一个Kubernetes服务对象。无论最终请求将被路由到哪个版本的pod，所有流量都始终通过同一个服务对象进行。这是通过使用Kustomize将部署对象和服务对象拆分到不同的文件夹中来实现的。
- en: 'To give deployment objects and their pods version-dependent names, the `kustomization.yml`
    file can use the `nameSuffix` directive to tell Kustomize to add the given suffix
    to all Kubernetes objects it creates. For example, the `kustomization.yml` file
    used for the `v1` version of the microservices in the `kubernetes/services/overlays/prod/v1` folder
    appears as follows:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 为了给部署对象及其pod提供与版本相关的名称，`kustomization.yml`文件可以使用`nameSuffix`指令告诉Kustomize为其创建的所有Kubernetes对象添加给定的后缀。例如，用于`kubernetes/services/overlays/prod/v1`文件夹中微服务的`v1`版本的`kustomization.yml`文件如下所示：
- en: '[PRE51]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The `nameSuffix: -v1` setting will result in all objects created using this `kustomization.yml` file
    being named with the `-v1` suffix.'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: '`nameSuffix: -v1`设置将导致使用此`kustomization.yml`文件创建的所有对象都以`-v1`后缀命名。'
- en: 'To create the objects without a version suffix, and the deployment objects
    and their pods with the `v1` and `v2` version suffixes, the `kubernetes/scripts/deploy-prod-env.bash` deployment
    script executes separate `kubectl apply` commands as follows:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建没有版本后缀的对象，以及具有`v1`和`v2`版本后缀的部署对象和它们的pod，`kubernetes/scripts/deploy-prod-env.bash`部署脚本将分别执行`kubectl
    apply`命令，如下所示：
- en: '[PRE52]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Let's also see what Istio definition files we have added to configure routing
    rules.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也看看我们已经添加的Istio定义文件来配置路由规则。
- en: Added Kubernetes definition files for Istio
  id: totrans-407
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为Istio添加了Kubernetes定义文件
- en: 'To configure routing rules, we will add Istio objects to the `kubernetes/services/overlays/prod/istio` folder.
    Each microservice has a virtual service object that defines the weight distribution
    for the routing between the old and the new versions. Initially, it is set to
    route 100% of the traffic to the old version. For example, the routing rule for
    the product microservice in `product-routing-virtual-service.yml` appears as follows:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 为了配置路由规则，我们将向`kubernetes/services/overlays/prod/istio`文件夹添加Istio对象。每个微服务都有一个虚拟服务对象，定义了旧版本和新版本之间的路由权重分配。最初，它被设置为将100%的流量路由到旧版本。例如，`product-routing-virtual-service.yml`中产品微服务的路由规则如下：
- en: '[PRE53]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The virtual service defines subsets for the old and the new versions. To define
    what actual versions the old and new versions are, each microservice also has
    a destination rule defined. The destination rule details how the old subset and
    the new subset shall be identified, for example, in the case of the product microservice
    in `old_new_subsets_destination_rules.yml`:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟服务为旧版本和新版本定义了子集。为了定义旧版本和新版本的实际版本，每个微服务还定义了一个目标规则。目标规则详细说明了如何识别旧子集和新子集，例如产品微服务中的`old_new_subsets_destination_rules.yml`：
- en: '[PRE54]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: The subset named `old` points to product pods that have the `version` label
    set to `v1`, while the subset named `new` points to pods with the `version` label
    set to `v2`.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 名为`old`的子集指向具有`version`标签设置为`v1`的产品pod，而名为`new`的子集指向具有`version`标签设置为`v2`的pod。
- en: To route traffic to a specific version, Istio documentation recommends that
    pods are labeled with a label named `version` to identify its version. Refer to [https://istio.io/docs/setup/kubernetes/additional-setup/requirements/](https://istio.io/docs/setup/kubernetes/additional-setup/requirements/) for
    details.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将流量路由到特定版本，Istio文档建议为pod添加一个名为`version`的标签来标识其版本。有关详细信息，请参阅[https://istio.io/docs/setup/kubernetes/additional-setup/requirements/](https://istio.io/docs/setup/kubernetes/additional-setup/requirements/)。
- en: 'Finally, to support canary testers, an extra routing rule has been added to
    the virtual services for the three core microservices: product, recommendation,
    and review. This routing rule states that any incoming request that has an HTTP
    header named `X-group` set to the value `test` will always be routed to the new
    version of the service. This appears as follows:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了支持金丝雀测试，虚拟服务的额外路由规则已添加到三个核心微服务：产品、推荐和评论。这个路由规则规定，任何带有名为`X-group`的HTTP头设置为值`test`的传入请求将始终路由到服务的新版本。如下所示：
- en: '[PRE55]'
  id: totrans-415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: The `match` and `route` sections specify that requests with the HTTP header, `X-group`,
    set to the value, `test`, shall be routed to the subset named `new`.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: '`match`和`route`部分指定了将HTTP头`X-group`设置为值`test`的请求路由到名为`new`的子集。'
- en: 'To create these Istio objects, the `kubernetes/scripts/deploy-prod-env.bash` deployment
    script executes the following command:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建这些Istio对象，`kubernetes/scripts/deploy-prod-env.bash`部署脚本执行以下命令：
- en: '[PRE56]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Finally, to be able to route canary testers to the new version based on header-based
    routing, the `product-composite` microservice has been updated to forward the
    HTTP header `X-group`. Refer to the `getCompositeProduct()` method in the `se.magnus.microservices.composite.product.services.ProductCompositeServiceImpl` class  for
    details.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了能够基于基于头的路由将金丝雀测试员路由到新版本，`product-composite`微服务已更新以转发HTTP头`X-group`。有关详细信息，请参阅`se.magnus.microservices.composite.product.services.ProductCompositeServiceImpl`类中的`getCompositeProduct()`方法。
- en: Now, we have seen all the changes to the source code and we are ready to deploy
    v1 and v2 versions of the microservices.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经看到了源代码的所有更改，准备部署微服务的v1和v2版本。
- en: Deploying v1 and v2 versions of the microservices with routing to the v1 version
  id: totrans-421
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署微服务的v1和v2版本，并将流量路由到v1版本
- en: To be able to test the `v1` and `v2` versions of the microservices, we need
    to remove the development environment we have been using earlier in this chapter
    and create a production environment where we can deploy the v1 and v2 versions
    of the microservices.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够测试微服务的`v1`和`v2`版本，我们需要删除本章早期使用的开发环境，并创建一个生产环境，我们可以在其中部署微服务的v1和v2版本。
- en: 'To achieve this, run the following commands:'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，请运行以下命令：
- en: 'Recreate the `hands-on` namespace:'
  id: totrans-424
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新创建`hands-on`命名空间：
- en: '[PRE57]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Execute the deployment by running the script with the following command:'
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令执行部署：
- en: '[PRE58]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The command takes a couple of minutes and should eventually list all the v1
    or v2 versions of the pods as follows:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令需要几分钟时间，最终应列出所有pod的v1或v2版本，如下所示：
- en: '![](img/3ac160f5-b56c-46fd-8d26-d0cad647e4d5.png)'
  id: totrans-429
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3ac160f5-b56c-46fd-8d26-d0cad647e4d5.png)'
- en: 'Run the usual tests to verify that everything works:'
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行通常的测试以验证一切是否正常运行：
- en: '[PRE59]'
  id: totrans-431
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: If this command is executed immediately after the `deploy` command, it sometimes
    fails. Simply rerun the command and it should run fine!
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 如果此命令在`deploy`命令之后立即执行，有时会失败。只需重新运行命令，它应该可以正常运行！
- en: Since we now have two pods (version V1 and V2) running for each microservice,
    the circuit breaker tests no longer work. The reason for this is that the test
    script can't control which pod it talks to, through the Kubernetes service. The
    test script asks about the state of the circuit breaker in the `product-composite`
    microservice using the actuator endpoint on port `4004`. This port is not managed
    by Istio, so its routing rules do no apply. The test script will therefore not
    know whether it is checking the state of the circuit breaker in V1 or V2 of the `product-composite`
    microservice. We can skip circuit breaker tests by using the `SKIP_CB_TESTS=true` flag.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 由于现在每个微服务都有两个pod（版本V1和V2）在运行，断路器测试不再起作用。原因是测试脚本无法通过Kubernetes服务控制它与哪个pod通信。测试脚本通过端口`4004`上的执行器端点询问`product-composite`微服务的断路器状态。这个端口不受Istio管理，因此其路由规则不适用。因此，测试脚本将无法知道它是在检查`product-composite`微服务的V1还是V2的断路器状态。我们可以通过使用`SKIP_CB_TESTS=true`标志来跳过断路器测试。
- en: 'Expect output that is similar to what we have seen from the previous chapters,
    but excluding the circuit breaker tests:'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 期望的输出与前几章类似，但不包括断路器测试：
- en: '![](img/4ebb9d21-ccfc-4210-92a0-8be37b37fd74.png)'
  id: totrans-435
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4ebb9d21-ccfc-4210-92a0-8be37b37fd74.png)'
- en: We are now ready to run some *zero-downtime deploy* tests. Let's begin by verifying
    that all traffic goes to the v1 version of the microservices!
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好运行一些*零停机部署*测试。让我们首先验证所有流量是否都流向微服务的v1版本！
- en: Verifying that all traffic initially goes to the v1 version of the microservices
  id: totrans-437
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 验证所有流量最初都流向微服务的v1版本
- en: To verify that all requests are routed to the v1 version of the microservices,
    we will start up the load test tool, `siege`, and then observe the traffic that
    flows through the service mesh using Kiali.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 验证所有请求是否都路由到微服务的v1版本，我们将启动负载测试工具`siege`，然后使用Kiali观察服务网格中的流量。
- en: 'Perform the following steps:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤：
- en: 'Get a new access token and start the `siege` load test tool, with the following
    commands:'
  id: totrans-440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取新的访问令牌，并使用以下命令启动`siege`负载测试工具：
- en: '[PRE60]'
  id: totrans-441
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Go to the graph view in Kiali''s web UI ([http://kiali.istio-system.svc.cluster.local:20001/kiali](http://kiali.istio-system.svc.cluster.local:20001/kiali)):'
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到Kiali的Web UI中的图形视图（[http://kiali.istio-system.svc.cluster.local:20001/kiali](http://kiali.istio-system.svc.cluster.local:20001/kiali)）：
- en: Click on the Display menu button and deselect Service Nodes.
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击显示菜单按钮，取消选择服务节点。
- en: 'After a minute or two, expect only traffic to the v1 version of the microservices as
    follows:'
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一两分钟后，期望只有流量流向微服务的v1版本，如下所示：
- en: '![](img/e2170279-e949-462e-b545-b0b5c6c69d54.png)'
  id: totrans-445
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e2170279-e949-462e-b545-b0b5c6c69d54.png)'
- en: Good! This means that, even though the v2 versions of the microservices are
    deployed, they do not get any traffic routed to them. Let's now try out canary
    tests where selected test users are allowed to try out the v2 versions of the
    microservices!
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 很好！这意味着，尽管部署了微服务的v2版本，但它们没有得到任何流量路由到它们。现在让我们尝试一下金丝雀测试，其中选择的测试用户被允许尝试微服务的v2版本！
- en: Running canary tests
  id: totrans-447
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行金丝雀测试
- en: To run a canary test, in other words, in order to be routed to the new versions
    while all other users are still routed to the old versions of the deployed microservices,
    we need to add the `X-group` HTTP header set to the value `test` in our requests
    sent to the external API.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行金丝雀测试，换句话说，为了在所有其他用户仍然路由到部署的微服务的旧版本的情况下被路由到新版本，我们需要在发送到外部API的请求中添加设置为值`test`的`X-group`
    HTTP头。
- en: To see which version of a microservice served a request, the `serviceAddresses`
    field in the response can be inspected. The `serviceAddresses` field contains
    the hostname of each service that took part in creating the response. The hostname
    is equal to the name of the pod, so we can find the version in the hostname; for
    example, `product-v1-...` for a product service of version V1, and `product-v2-...` for
    a product service of version V2.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看哪个版本的微服务提供了请求，可以检查响应中的`serviceAddresses`字段。`serviceAddresses`字段包含参与创建响应的每个服务的主机名。主机名等于pod的名称，因此我们可以在主机名中找到版本；例如，`product-v1-...`表示版本V1的产品服务，`product-v2-...`表示版本V2的产品服务。
- en: Let's begin by sending a normal request and verify that it is the v1 versions
    of the microservices that respond to our request. Next, send a request with the `X-group` HTTP
    header set to the value `test`, and verify that the new v2 versions are responding.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先发送一个正常请求，并验证它是微服务的v1版本响应我们的请求。接下来，发送一个设置为值`test`的`X-group` HTTP头的请求，并验证新的v2版本是否响应。
- en: 'To do this, perform the following steps:'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，请执行以下步骤：
- en: 'Perform a normal request to verify that the request is routed to the v1 version
    of the microservices by using `jq` to filter out the `serviceAddresses` field
    in the response:'
  id: totrans-452
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行正常请求以验证请求是否路由到微服务的v1版本，使用`jq`过滤响应中的`serviceAddresses`字段：
- en: '[PRE61]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Expect a response along the lines of the following:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 期望类似以下的响应：
- en: '![](img/661a5a65-6610-40c6-aaf4-5a55f2e57b81.png)'
  id: totrans-455
  prefs: []
  type: TYPE_IMG
  zh: '![](img/661a5a65-6610-40c6-aaf4-5a55f2e57b81.png)'
- en: As expected, all three core services are v1 versions of the microservices.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，所有三个核心服务都是微服务的v1版本。
- en: 'If we add the `X-group=test` header, we expect the request to be served by
    v2 versions of the core microservices. Run the following command:'
  id: totrans-457
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们添加`X-group=test`头，我们期望请求由核心微服务的v2版本提供。运行以下命令：
- en: '[PRE62]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Expect a response similar to the following:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 期望类似以下的响应：
- en: '![](img/1f63113a-ae33-446b-bdde-05fa4cf621c6.png)'
  id: totrans-460
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1f63113a-ae33-446b-bdde-05fa4cf621c6.png)'
- en: As expected, all three core microservices that respond are now v2 versions;
    that is, as a canary tester, we are routed to the new v2 versions!
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，所有三个响应的核心微服务现在都是v2版本；也就是说，作为金丝雀测试者，我们被路由到了新的v2版本！
- en: Given that the canary tests returned the expected results, we are ready to allow
    normal users to be routed to the new v2 versions using blue/green deployment.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于金丝雀测试返回了预期结果，我们准备允许普通用户使用蓝/绿部署路由到新的v2版本。
- en: Running blue/green tests
  id: totrans-463
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行蓝/绿测试
- en: To route parts of the normal users to the new v2 versions of the microservices,
    we have to modify the weight distribution in the virtual services. They are currently
    100/0; in other words, all traffic is routed to the old v1 versions. We can achieve
    this as we did before, that is, by editing the definition files of the virtual
    services in the `kubernetes/services/overlays/prod/istio` folder and then running
    a `kubectl apply` command to make the change take effect. As an alternative, we
    can use the `kubectl patch` command to change the weight distribution directly
    on the virtual service objects in the Kubernetes API server.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将部分普通用户路由到微服务的新v2版本，我们必须修改虚拟服务中的权重分配。它们目前是100/0；换句话说，所有流量都路由到旧的v1版本。我们可以像以前一样实现这一点，即通过编辑`kubernetes/services/overlays/prod/istio`文件夹中虚拟服务的定义文件，然后运行`kubectl
    apply`命令使更改生效。作为替代，我们可以使用`kubectl patch`命令直接在Kubernetes API服务器中的虚拟服务对象上更改权重分配。
- en: I find the patch command useful when making a number of changes to the same
    objects to try something out, for example, to change the weight distribution in
    the routing rules. In this section, we will use the `kubectl patch` command to
    quickly change the weight distribution in the routing rules between the v1 and
    v2 versions of the microservices. To get the state of a virtual service after
    a number of `kubectl patch` commands have been executed, a command such as `kubectl
    get vs NNN -o yaml` can be issued. For example, to get the state of the virtual
    service of the product microservice, issue the following command: `kubectl get
    vs product-vs -o yaml`.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现`patch`命令在对同一对象进行多次更改以尝试某些操作时非常有用，例如更改路由规则中的权重分配。在本节中，我们将使用`kubectl patch`命令快速更改微服务的v1和v2版本之间的路由规则中的权重分配。在执行了多个`kubectl
    patch`命令后，可以发出诸如`kubectl get vs NNN -o yaml`的命令来获取虚拟服务的状态。例如，要获取产品微服务的虚拟服务状态，请发出以下命令：`kubectl
    get vs product-vs -o yaml`。
- en: Since we haven't used the `kubectl patch` command before and it can be a bit
    involved to start with, let's undertake a short introduction to how it works before
    we perform the green/blue deploy.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们以前没有使用过`kubectl patch`命令，而且开始可能有点复杂，让我们在执行蓝/绿部署之前先进行一次简短的介绍。
- en: A short introduction to the kubectl patch command
  id: totrans-467
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: kubectl patch命令的简短介绍
- en: 'The `kubectl patch` command can be used to update specific fields in an existing
    object in the Kubernetes API server. We will try the patch command on the virtual
    service for the review microservice, named `review-vs`. The relevant parts of
    the definition for the virtual service, `review-vs`, appear as follows:'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl patch`命令可用于更新Kubernetes API服务器中现有对象的特定字段。我们将在名为`review-vs`的review微服务的虚拟服务上尝试`patch`命令。虚拟服务`review-vs`的相关部分定义如下：'
- en: '[PRE63]'
  id: totrans-469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: For the full source code, refer to `kubernetes/services/overlays/prod/istio/review-routing-virtual-service.yml`.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 有关完整的源代码，请参考`kubernetes/services/overlays/prod/istio/review-routing-virtual-service.yml`。
- en: 'A sample patch command that changes the weight distribution of the routing
    to the v1 and v2 pods in the `review` microservice appears as follows:'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 更改`review`微服务中路由到v1和v2 pods的权重分配的示例`patch`命令如下：
- en: '[PRE64]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: The command will configure the routing rules of the review microservice to route
    80% of the requests to the old version, and 20% of the requests to the new version.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将配置review微服务的路由规则，将80%的请求路由到旧版本，20%的请求路由到新版本。
- en: To specify that the `weight` value shall be changed in the `review-vs` virtual
    service, the `/spec/http/1/route/0/weight` path is given for the old version and `/spec/http/1/route/1/weight`
    for the new version.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 为了指定在`review-vs`虚拟服务中更改`weight`值，给出了旧版本的`/spec/http/1/route/0/weight`路径和新版本的`/spec/http/1/route/1/weight`。
- en: The `0` and `1` in the path are used to specify the index of array elements
    in the definition of the virtual service. For example, `http/1` means the second
    element in the array under the `http` element. See the definition of the preceding `review-vs`
    virtual service.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 路径中的`0`和`1`用于指定虚拟服务定义中数组元素的索引。例如，`http/1`表示`http`元素下数组中的第二个元素。请参阅前面的`review-vs`虚拟服务的定义。
- en: From the preceding definition we can see that the second element is the `route`
    element. The first element with index `0` being the match element.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的定义中，我们可以看到第二个元素是`route`元素。索引为`0`的第一个元素是匹配元素。
- en: Now that we know a bit more about the `kubectl patch` command, we are ready
    to test a blue/green deployment.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对`kubectl patch`命令有了一些了解，我们准备测试蓝/绿部署。
- en: Performing the blue/green deployment
  id: totrans-478
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行蓝/绿部署
- en: 'Now, it is time to gradually move more and more users to the new versions using
    blue/green deployment. To perform the deployment, run the following steps:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候逐渐将更多用户迁移到新版本，使用蓝/绿部署。执行部署，运行以下步骤：
- en: Ensure that the load test tool, `Siege`, is still running.
  id: totrans-480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保负载测试工具`Siege`仍在运行。
- en: It was started in the preceding *Verifying that all traffic initially goes to
    the v1 version of the microservices* section.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: 'To allow 20% of the users to be routed to the new v2 version of the review
    microservice, we can patch the virtual service and change weights with the following
    command:'
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  id: totrans-483
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: To observe the change in the routing rule, go to the Kiali web UI ([http://kiali.istio-system.svc.cluster.local:20001/kiali](http://kiali.istio-system.svc.cluster.local:20001/kiali))
    and select the graph view.
  id: totrans-484
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the edge label to `Requests percentage`.
  id: totrans-485
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Wait for a minute before the statics are updated in Kiali so that we can observe
    the change. Expect the graph in Kiali to show something like the following:'
  id: totrans-486
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a610a4da-ad35-4bbd-ab61-f30f72241355.png)'
  id: totrans-487
  prefs: []
  type: TYPE_IMG
- en: Depending on how long you have waited, the graph might look a bit different!
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
- en: In the screenshot, we can see that Istio now routes traffic to both the v1 and
    v2 versions of the `review` microservice.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
- en: 'Of the 33% of the traffic that is sent to the `review` microservice from the
    `product-composite` microservice, 7% are routed to the new v2 pod, and 26% to
    the old v1 pod. This means that 7/33 (= 21%) of the requests are routed to the
    v2 pod, and 26/33 (= 79%) to the v1 pod. This is in line with the 20/80 distribution
    we have requested:'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: 'Please feel free to try out the preceding `kubectl patch` command to affect
    the routing rules for the other core microservices: `product` and `recommendation`.'
  id: totrans-491
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you want to route all traffic to the v2 version of all microservices, you
    can run the following script:'
  id: totrans-492
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: You have to give Kiali a minute or two to collect metrics before it can visualize
    the changes in routing between the v1 and v2 versions of the microservices, but
    remember that the change in the actual routing is immediate!
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: 'Expect only v2 versions of the microservices to show up in the graph after
    a while:'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fafbc4a4-4e90-47d5-8a5f-b933a548edf3.png)'
  id: totrans-496
  prefs: []
  type: TYPE_IMG
- en: Depending on how long you have waited, the graph might look a bit different!
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
- en: 'If something goes terribly wrong after the upgrade to v2, the following command
    can be executed to revert all traffic back to the v1 version of all microservices:'
  id: totrans-498
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  id: totrans-499
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: After a short while, the graph in Kiali should look like the screenshot in the
    previous *Verifying that all traffic initially goes to the v1 version of the microservices* section;
    that is, visualize that all requests go to the v1 version of all microservices
    again.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
- en: This concludes the introduction to the service mesh concept and Istio as an
    implementation of the concept.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
- en: Before we wrap up the chapter, let's recap how we can run tests in Docker Compose
    to ensure that the source code of our microservices does not rely on deployment
    in Kubernetes.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
- en: Running tests with Docker Compose
  id: totrans-503
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned in [Chapter 17](a9327ecc-49e7-4f72-9221-3321b7158d83.xhtml), *Implementing
    Kubernetes Features as an Alternative* (refer to the *Verifying that the microservices
    work without Kubernetes* section), it is important to ensure that the source code
    of the microservices doesn't become dependent on a platform such as Kubernetes
    or Istio from a functional perspective.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
- en: 'To verify that the microservices work as expected without the presence of Kubernetes
    and Istio, run the tests as described in [Chapter 1*7*](a9327ecc-49e7-4f72-9221-3321b7158d83.xhtml)*,
    Implementing Kubernetes Features as an Alternative* (refer to the T*esting with
    Docker Compose* section). Since the default values of the test script, `test-em-all.bash`,
    are changed, as described previously in the *Running commands to create the service
    mesh* section, the following parameters must be set when using Docker Compose: `HOST=localhost
    PORT=8443 HEALTH_URL=https://localhost:8443`. For example, to run the tests using
    the default Docker Compose file, `docker-compose.yml`, run the following command:'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  id: totrans-506
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: The tests should, as before, begin by starting all containers; it should then
    run the tests, and finally stop all containers. For details of the expected output,
    see [Chapter 17](a9327ecc-49e7-4f72-9221-3321b7158d83.xhtml), *Implementing Kubernetes
    Features as an Alternative* (refer to the *Verifying that the microservices work
    without Kubernetes* section).
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 测试应该像以前一样，首先启动所有容器；然后运行测试，最后停止所有容器。有关预期输出的详细信息，请参阅[第17章](a9327ecc-49e7-4f72-9221-3321b7158d83.xhtml)，*作为替代方案实现Kubernetes功能*（参考*验证微服务在没有Kubernetes的情况下工作*部分）。
- en: After successfully executing the tests using Docker Compose, we have verified
    that the microservices are dependent neither on Kubernetes nor Istio from a functional
    perspective. These tests conclude the chapter on using Istio as a service mesh.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 成功使用Docker Compose执行测试后，我们已经验证了从功能角度来看，微服务既不依赖于Kubernetes也不依赖于Istio。这些测试结束了使用Istio作为服务网格的章节。
- en: Summary
  id: totrans-509
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about the service mesh concept and Istio, an open
    source project that implements it. A service mesh provides capabilities for handling
    challenges in a system landscape of microservices in areas such as security, policy
    enforcement, resilience, and traffic management. A service mesh can also be used
    to make a system landscape of microservices observable by visualizing the traffic
    that flows through the microservices.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了服务网格概念和Istio，一个实现了该概念的开源项目。服务网格提供了处理微服务系统景观中的挑战的能力，如安全性、策略执行、弹性和流量管理。服务网格还可以用于通过可视化流经微服务的流量来使微服务系统景观可观察。
- en: For observability, Istio uses Kiali, Jaeger, and Grafana (more on Grafana in
    [Chapter 20](5e6cce2d-d426-4f55-95c9-52b596769a57.xhtml), *Monitoring Microservices*). When
    it comes to security, Istio can be configured to use a certificate to protect
    external APIs with HTTPS and require that external requests contain valid JWT-based
    OAuth 2.0/OIDC access tokens. Finally, Istio can be configured to automatically
    protect internal communication using **mutual authentication** (**mTLS**).
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 在可观察性方面，Istio使用Kiali、Jaeger和Grafana（有关Grafana的更多信息，请参阅[第20章](5e6cce2d-d426-4f55-95c9-52b596769a57.xhtml)，*监控微服务*）。在安全方面，可以配置Istio使用证书来保护外部API，并要求外部请求包含有效的基于JWT的OAuth
    2.0/OIDC访问令牌。最后，可以配置Istio自动使用**双向认证**（**mTLS**）来保护内部通信。
- en: For resilience and robustness, Istio comes with mechanisms for handling retries,
    timeouts, and an outlier detection mechanism similar to a circuit breaker. In
    many cases, it is preferable to implement these resilience capabilities in the
    source code of the microservices, if possible. The ability in Istio to inject
    faults and delays is very useful for verifying that the microservices in the service
    mesh work together as a resilient and robust system landscape. Istio can also
    be used to handle zero-downtime deployments. Using its fine-grained routing rules,
    both canary and blue/green deployments can be performed.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现弹性和健壮性，Istio具有处理重试、超时和异常检测机制，类似于断路器。在许多情况下，如果可能的话，最好在微服务的源代码中实现这些弹性能力。Istio中注入故障和延迟的能力非常有用，可以验证服务网格中的微服务是否作为一个具有弹性和健壮系统景观一起工作。Istio还可以用于处理零停机时间部署。使用其细粒度的路由规则，可以执行金丝雀和蓝/绿部署。
- en: One important area that we haven't covered yet is how to collect and analyze
    log files created by all microservice instances. In the next chapter, we will
    see how this can be done using a popular stack of tools, known as the EFK stack,
    based on Elasticsearch, Fluentd, and Kibana.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尚未涵盖的一个重要领域是如何收集和分析所有微服务实例创建的日志文件。在下一章中，我们将看到如何使用一套流行的工具堆栈，即基于Elasticsearch、Fluentd和Kibana的EFK 堆栈来实现这一点。
- en: Questions
  id: totrans-514
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is the purpose of a proxy component in a service mesh?
  id: totrans-515
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务网格中代理组件的目的是什么？
- en: What's the difference between a control plane and a data plane in a service
    mesh?
  id: totrans-516
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务网格中控制平面和数据平面之间有什么区别？
- en: What is the `istioctl kube-inject` command used for?
  id: totrans-517
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`istioctl kube-inject`命令用于什么？'
- en: What is the `minikube tunnel`  command used for?
  id: totrans-518
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`minikube tunnel`命令用于什么？'
- en: What tools are used in Istio for observability?
  id: totrans-519
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Istio在可观察性方面使用了哪些工具？
- en: What configuration is required to make Istio protect communication within the
    service mesh using mutual authentication?
  id: totrans-520
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需要哪些配置来使Istio使用双向认证保护服务网格内的通信？
- en: What can the `abort` and `delay` elements in a virtual service be used for?
  id: totrans-521
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 虚拟服务中的`abort`和`delay`元素可以用于什么？
- en: What configuration is required to set up a blue/green deploy scenario?
  id: totrans-522
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置蓝/绿部署场景需要哪些配置？

- en: Chapter 1\. Meet Kafka
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章。遇见Kafka
- en: Every enterprise is powered by data. We take information in, analyze it, manipulate
    it, and create more as output. Every application creates data, whether it is log
    messages, metrics, user activity, outgoing messages, or something else. Every
    byte of data has a story to tell, something of importance that will inform the
    next thing to be done. In order to know what that is, we need to get the data
    from where it is created to where it can be analyzed. We see this every day on
    websites like Amazon, where our clicks on items of interest to us are turned into
    recommendations that are shown to us a little later.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 每个企业都由数据驱动。我们接收信息，分析它，操纵它，并将其作为输出创建更多信息。每个应用程序都会创建数据，无论是日志消息，度量标准，用户活动，传出消息，还是其他内容。每个字节的数据都有一个故事要讲，一个重要的东西，将告知下一步要做的事情。为了知道那是什么，我们需要将数据从创建它的地方传输到可以分析它的地方。我们每天都在网站上看到这一点，比如亚马逊，我们对我们感兴趣的项目的点击被转化为稍后向我们展示的推荐。
- en: The faster we can do this, the more agile and responsive our organizations can
    be. The less effort we spend on moving data around, the more we can focus on the
    core business at hand. This is why the pipeline is a critical component in the
    data-driven enterprise. How we move the data becomes nearly as important as the
    data itself.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能够越快地做到这一点，我们的组织就能越具敏捷性和响应性。我们在数据传输上花费的精力越少，我们就能更多地专注于手头的核心业务。这就是为什么管道是数据驱动企业的关键组成部分。我们如何移动数据几乎与数据本身一样重要。
- en: Any time scientists disagree, it’s because we have insufficient data. Then we
    can agree on what kind of data to get; we get the data; and the data solves the
    problem. Either I’m right, or you’re right, or we’re both wrong. And we move on.
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 每当科学家们意见不一致时，那是因为我们缺乏数据。然后我们可以就要获取什么类型的数据达成一致；我们获取数据；数据解决了问题。要么我是对的，要么你是对的，要么我们都错了。然后我们继续前进。
- en: '>'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '>'
- en: Neil deGrasse Tyson
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 尼尔·德格拉斯·泰森
- en: Publish/Subscribe Messaging
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发布/订阅消息传递
- en: Before discussing the specifics of Apache Kafka, it is important for us to understand
    the concept of publish/subscribe messaging and why it is a critical component
    of data-driven applications. *Publish/subscribe (pub/sub) messaging* is a pattern
    that is characterized by the sender (publisher) of a piece of data (message) not
    specifically directing it to a receiver. Instead, the publisher classifies the
    message somehow, and that receiver (subscriber) subscribes to receive certain
    classes of messages. Pub/sub systems often have a broker, a central point where
    messages are published, to facilitate this pattern.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论Apache Kafka的具体内容之前，重要的是我们理解发布/订阅消息传递的概念，以及为什么它是数据驱动应用程序的关键组成部分。*发布/订阅（pub/sub）消息传递*是一种模式，其特点是数据（消息）的发送者（发布者）不会将其直接发送给接收者。相反，发布者以某种方式对消息进行分类，而接收者（订阅者）订阅接收某些类别的消息。发布/订阅系统通常有一个代理，即消息发布的中心点，以促进这种模式。
- en: How It Starts
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何开始的
- en: 'Many use cases for publish/subscribe start out the same way: with a simple
    message queue or interprocess communication channel. For example, you create an
    application that needs to send monitoring information somewhere, so you open a
    direct connection from your application to an app that displays your metrics on
    a dashboard, and push metrics over that connection, as seen in [Figure 1-1](#fig-1-singleconn).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 许多发布/订阅的用例都是从同样的方式开始的：使用简单的消息队列或进程间通信通道。例如，您创建一个需要将监控信息发送到某个地方的应用程序，因此您从应用程序直接连接到在仪表板上显示您的度量标准的应用程序，并通过该连接推送度量标准，如[图1-1](#fig-1-singleconn)所示。
- en: '![kdg2 0101](assets/kdg2_0101.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: ！[kdg2 0101]（assets/kdg2_0101.png）
- en: Figure 1-1\. A single, direct metrics publisher
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1。单一，直接的度量发布者
- en: This is a simple solution to a simple problem that works when you are getting
    started with monitoring. Before long, you decide you would like to analyze your
    metrics over a longer term, and that doesn’t work well in the dashboard. You start
    a new service that can receive metrics, store them, and analyze them. In order
    to support this, you modify your application to write metrics to both systems.
    By now you have three more applications that are generating metrics, and they
    all make the same connections to these two services. Your coworker thinks it would
    be a good idea to do active polling of the services for alerting as well, so you
    add a server on each of the applications to provide metrics on request. After
    a while, you have more applications that are using those servers to get individual
    metrics and use them for various purposes. This architecture can look much like
    [Figure 1-2](#fig-2-multiconn), with connections that are even harder to trace.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的解决方案，用于解决刚开始监控时的简单问题。不久之后，您决定希望分析您的度量标准长期运行，而这在仪表板上效果不佳。您启动了一个新的服务，可以接收度量标准，存储它们并分析它们。为了支持这一点，您修改了应用程序，使其将度量标准写入这两个系统。到目前为止，您有三个应用程序正在生成度量标准，并且它们都与这两个服务建立了相同的连接。您的同事认为定期轮询服务以进行警报是个好主意，因此您在每个应用程序上都添加了一个服务器，以便按请求提供度量标准。过了一会儿，您有更多的应用程序正在使用这些服务器获取个别度量标准，并将它们用于各种目的。这种架构看起来可能与[图1-2](#fig-2-multiconn)相似，连接甚至更难追踪。
- en: '![kdg2 0102](assets/kdg2_0102.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: ！[kdg2 0102]（assets/kdg2_0102.png）
- en: Figure 1-2\. Many metrics publishers, using direct connections
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2。许多度量发布者，使用直接连接
- en: The technical debt built up here is obvious, so you decide to pay some of it
    back. You set up a single application that receives metrics from all the applications
    out there, and provide a server to query those metrics for any system that needs
    them. This reduces the complexity of the architecture to something similar to
    [Figure 1-3](#fig-3-single-pubsub). Congratulations, you have built a publish/subscribe
    messaging system!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这里积累的技术债务是显而易见的，因此您决定偿还其中的一部分。您设置了一个单一的应用程序，从所有外部应用程序接收度量标准，并提供一个服务器来查询那些需要它们的任何系统的度量标准。这将架构的复杂性降低到类似于[图1-3](#fig-3-single-pubsub)的东西。恭喜，您已经构建了一个发布/订阅消息传递系统！
- en: '![kdg2 0103](assets/kdg2_0103.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: ！[kdg2 0103]（assets/kdg2_0103.png）
- en: Figure 1-3\. A metrics publish/subscribe system
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3。度量发布/订阅系统
- en: Individual Queue Systems
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 个人队列系统
- en: At the same time that you have been waging this war with metrics, one of your
    coworkers has been doing similar work with log messages. Another has been working
    on tracking user behavior on the frontend website and providing that information
    to developers who are working on machine learning, as well as creating some reports
    for management. You have all followed a similar path of building out systems that
    decouple the publishers of the information from the subscribers to that information.
    [Figure 1-4](#fig-4-multi-pubsub) shows such an infrastructure, with three separate
    pub/sub systems.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 与您使用指标进行战争的同时，您的一位同事正在使用日志消息进行类似的工作。另一位同事正在跟踪前端网站上用户行为，并将该信息提供给正在进行机器学习的开发人员，同时为管理层创建一些报告。您都遵循了构建系统的类似路径，这些系统将信息的发布者与订阅者解耦。[图1-4](#fig-4-multi-pubsub)显示了这样的基础设施，有三个独立的发布/订阅系统。
- en: '![kdg2 0104](assets/kdg2_0104.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![kdg2 0104](assets/kdg2_0104.png)'
- en: Figure 1-4\. Multiple publish/subscribe systems
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4. 多个发布/订阅系统
- en: This is certainly a lot better than utilizing point-to-point connections (as
    in [Figure 1-2](#fig-2-multiconn)), but there is a lot of duplication. Your company
    is maintaining multiple systems for queuing data, all of which have their own
    individual bugs and limitations. You also know that there will be more use cases
    for messaging coming soon. What you would like to have is a single centralized
    system that allows for publishing generic types of data, which will grow as your
    business grows.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这肯定比使用点对点连接要好得多（如[图1-2](#fig-2-multiconn)中所示），但存在很多重复。您的公司正在维护多个用于排队数据的系统，所有这些系统都有各自的错误和限制。您还知道将会有更多的消息传递用例即将到来。您希望拥有一个单一的集中式系统，允许发布通用类型的数据，随着业务的增长而增长。
- en: Enter Kafka
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进入Kafka
- en: Apache Kafka was developed as a publish/subscribe messaging system designed
    to solve this problem. It is often described as a “distributed commit log” or
    more recently as a “distributing streaming platform.” A filesystem or database
    commit log is designed to provide a durable record of all transactions so that
    they can be replayed to consistently build the state of a system. Similarly, data
    within Kafka is stored durably, in order, and can be read deterministically. In
    addition, the data can be distributed within the system to provide additional
    protections against failures, as well as significant opportunities for scaling
    performance.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Kafka被开发为一个发布/订阅消息系统，旨在解决这个问题。它经常被描述为“分布式提交日志”，或者最近被描述为“分布式流平台”。文件系统或数据库提交日志旨在提供所有事务的持久记录，以便可以重放它们以一致地构建系统的状态。同样，Kafka中的数据是持久存储的，有序的，并且可以被确定性地读取。此外，数据可以在系统内分布，以提供额外的故障保护，以及显著的性能扩展机会。
- en: Messages and Batches
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 消息和批次
- en: The unit of data within Kafka is called a *message*. If you are approaching
    Kafka from a database background, you can think of this as similar to a *row*
    or a *record*. A message is simply an array of bytes as far as Kafka is concerned,
    so the data contained within it does not have a specific format or meaning to
    Kafka. A message can have an optional piece of metadata, which is referred to
    as a *key*. The key is also a byte array and, as with the message, has no specific
    meaning to Kafka. Keys are used when messages are to be written to partitions
    in a more controlled manner. The simplest such scheme is to generate a consistent
    hash of the key and then select the partition number for that message by taking
    the result of the hash modulo the total number of partitions in the topic. This
    ensures that messages with the same key are always written to the same partition
    (provided that the partition count does not change).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka中的数据单元称为*消息*。如果您是从数据库背景接触Kafka，您可以将其视为类似于*行*或*记录*。就Kafka而言，消息只是一个字节数组，因此其中包含的数据对Kafka来说没有特定的格式或含义。消息可以有一个可选的元数据，称为*键*。键也是一个字节数组，与消息一样，对Kafka来说没有特定的含义。当消息需要以更受控制的方式写入分区时，会使用键。最简单的方案是生成键的一致哈希，然后通过取哈希结果对主题中分区总数取模来选择该消息的分区号。这确保具有相同键的消息始终写入相同的分区（前提是分区数不会改变）。
- en: 'For efficiency, messages are written into Kafka in batches. A *batch* is just
    a collection of messages, all of which are being produced to the same topic and
    partition. An individual round trip across the network for each message would
    result in excessive overhead, and collecting messages together into a batch reduces
    this. Of course, this is a trade-off between latency and throughput: the larger
    the batches, the more messages that can be handled per unit of time, but the longer
    it takes an individual message to propagate. Batches are also typically compressed,
    providing more efficient data transfer and storage at the cost of some processing
    power. Both keys and batches are discussed in more detail in [Chapter 3](ch03.html#writing_messages_to_kafka).'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高效率，消息被批量写入Kafka。*批量*只是一组消息，所有这些消息都被生产到相同的主题和分区。对于每条消息进行一次网络往返将导致过多的开销，将消息收集到一起形成批量可以减少这种开销。当然，这是延迟和吞吐量之间的权衡：批量越大，每单位时间可以处理的消息就越多，但单个消息传播所需的时间就越长。批次通常也会被压缩，提供更高效的数据传输和存储，但会消耗一些处理能力。关于键和批次的更多细节将在[第3章](ch03.html#writing_messages_to_kafka)中讨论。
- en: Schemas
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模式
- en: While messages are opaque byte arrays to Kafka itself, it is recommended that
    additional structure, or schema, be imposed on the message content so that it
    can be easily understood. There are many options available for message *schema*,
    depending on your application’s individual needs. Simplistic systems, such as
    JavaScript Object Notation (JSON) and Extensible Markup Language (XML), are easy
    to use and human readable. However, they lack features such as robust type handling
    and compatibility between schema versions. Many Kafka developers favor the use
    of Apache Avro, which is a serialization framework originally developed for Hadoop.
    Avro provides a compact serialization format, schemas that are separate from the
    message payloads and that do not require code to be generated when they change,
    and strong data typing and schema evolution, with both backward and forward compatibility.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然对于Kafka本身来说，消息是不透明的字节数组，但建议对消息内容施加额外的结构或模式，以便轻松理解。根据应用程序的个体需求，有许多可用的消息*模式*选项。像JavaScript对象表示法（JSON）和可扩展标记语言（XML）这样的简单系统易于使用且易于阅读。但是，它们缺乏诸如强大的类型处理和模式版本之间的兼容性等功能。许多Kafka开发人员青睐使用Apache
    Avro，这是最初为Hadoop开发的序列化框架。Avro提供了紧凑的序列化格式，模式与消息有效载荷分开，并且在更改时不需要生成代码，具有强大的数据类型和模式演变，具有向后和向前的兼容性。
- en: A consistent data format is important in Kafka, as it allows writing and reading
    messages to be decoupled. When these tasks are tightly coupled, applications that
    subscribe to messages must be updated to handle the new data format, in parallel
    with the old format. Only then can the applications that publish the messages
    be updated to utilize the new format. By using well-defined schemas and storing
    them in a common repository, the messages in Kafka can be understood without coordination.
    Schemas and serialization are covered in more detail in [Chapter 3](ch03.html#writing_messages_to_kafka).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kafka中，一致的数据格式很重要，因为它允许写入和读取消息解耦。当这些任务紧密耦合时，订阅消息的应用程序必须更新以处理新的数据格式，与旧格式并行。只有在这之后，发布消息的应用程序才能更新以利用新的格式。通过使用明确定义的模式并将其存储在共同的存储库中，Kafka中的消息可以在没有协调的情况下被理解。模式和序列化在[第3章](ch03.html#writing_messages_to_kafka)中有更详细的介绍。
- en: Topics and Partitions
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主题和分区
- en: Messages in Kafka are categorized into *topics*. The closest analogies for a
    topic are a database table or a folder in a filesystem. Topics are additionally
    broken down into a number of *partitions*. Going back to the “commit log” description,
    a partition is a single log. Messages are written to it in an append-only fashion
    and are read in order from beginning to end. Note that as a topic typically has
    multiple partitions, there is no guarantee of message ordering across the entire
    topic, just within a single partition. [Figure 1-5](#fig-5-partitions) shows a
    topic with four partitions, with writes being appended to the end of each one.
    Partitions are also the way that Kafka provides redundancy and scalability. Each
    partition can be hosted on a different server, which means that a single topic
    can be scaled horizontally across multiple servers to provide performance far
    beyond the ability of a single server. Additionally, partitions can be replicated,
    such that different servers will store a copy of the same partition in case one
    server fails.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka中的消息被分类为*主题*。主题的最接近类比是数据库表或文件系统中的文件夹。主题还可以进一步分为多个*分区*。回到“提交日志”的描述，分区就是一个单独的日志。消息以追加方式写入其中，并且按顺序从头到尾读取。请注意，由于主题通常具有多个分区，因此无法保证整个主题中的消息顺序，只能保证单个分区内的消息顺序。[图1-5](#fig-5-partitions)显示了一个具有四个分区的主题，写入被追加到每个分区的末尾。分区也是Kafka提供冗余和可伸缩性的方式。每个分区可以托管在不同的服务器上，这意味着单个主题可以横向扩展到多个服务器上，以提供远远超出单个服务器能力的性能。此外，分区可以被复制，以便不同的服务器将存储相同分区的副本，以防一个服务器发生故障。
- en: '![kdg2 0105](assets/kdg2_0105.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![kdg2 0105](assets/kdg2_0105.png)'
- en: Figure 1-5\. Representation of a topic with multiple partitions
  id: totrans-34
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-5\. 具有多个分区的主题的表示
- en: The term *stream* is often used when discussing data within systems like Kafka.
    Most often, a stream is considered to be a single topic of data, regardless of
    the number of partitions. This represents a single stream of data moving from
    the producers to the consumers. This way of referring to messages is most common
    when discussing stream processing, which is when frameworks—some of which are
    Kafka Streams, Apache Samza, and Storm—operate on the messages in real time. This
    method of operation can be compared to the way offline frameworks, namely Hadoop,
    are designed to work on bulk data at a later time. An overview of stream processing
    is provided in [Chapter 14](ch14.html#stream_processing).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论像Kafka这样的系统中的数据时，经常使用术语*流*。通常情况下，流被认为是单个数据主题，而不考虑分区的数量。这代表了一条从生产者到消费者的数据流。这种引用消息的方式在讨论流处理时最常见，即在实时操作消息的框架上进行操作，其中一些框架包括Kafka
    Streams、Apache Samza和Storm。这种操作方式可以与离线框架（如Hadoop）在以后的某个时间点上对大量数据进行操作进行比较。有关流处理的概述在[第14章](ch14.html#stream_processing)中提供。
- en: Producers and Consumers
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生产者和消费者
- en: 'Kafka clients are users of the system, and there are two basic types: producers
    and consumers. There are also advanced client APIs—Kafka Connect API for data
    integration and Kafka Streams for stream processing. The advanced clients use
    producers and consumers as building blocks and provide higher-level functionality
    on top.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka客户端是系统的用户，基本上有两种类型：生产者和消费者。还有高级客户端API——用于数据集成的Kafka Connect API和用于流处理的Kafka
    Streams。高级客户端使用生产者和消费者作为构建模块，并在其上提供更高级的功能。
- en: '*Producers* create new messages. In other publish/subscribe systems, these
    may be called *publishers* or *writers*. A message will be produced to a specific
    topic. By default, the producer will balance messages over all partitions of a
    topic evenly. In some cases, the producer will direct messages to specific partitions.
    This is typically done using the message key and a partitioner that will generate
    a hash of the key and map it to a specific partition. This ensures that all messages
    produced with a given key will get written to the same partition. The producer
    could also use a custom partitioner that follows other business rules for mapping
    messages to partitions. Producers are covered in more detail in [Chapter 3](ch03.html#writing_messages_to_kafka).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*生产者*创建新消息。在其他发布/订阅系统中，这些可能被称为*发布者*或*写者*。消息将被生产到特定主题。默认情况下，生产者将消息均匀地分布到主题的所有分区上。在某些情况下，生产者将消息定向到特定分区。这通常是使用消息键和分区器来生成键的哈希并将其映射到特定分区。这确保使用给定键生成的所有消息将被写入同一分区。生产者还可以使用遵循其他业务规则的自定义分区器将消息映射到分区。有关生产者的详细信息，请参阅[第3章](ch03.html#writing_messages_to_kafka)。'
- en: '*Consumers* read messages. In other publish/subscribe systems, these clients
    may be called *subscribers* or *readers*. The consumer subscribes to one or more
    topics and reads the messages in the order in which they were produced to each
    partition. The consumer keeps track of which messages it has already consumed
    by keeping track of the offset of messages. The *offset*—an integer value that
    continually increases—is another piece of metadata that Kafka adds to each message
    as it is produced. Each message in a given partition has a unique offset, and
    the following message has a greater offset (though not necessarily monotonically
    greater). By storing the next possible offset for each partition, typically in
    Kafka itself, a consumer can stop and restart without losing its place.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*消费者*读取消息。在其他发布/订阅系统中，这些客户端可能被称为*订阅者*或*读者*。消费者订阅一个或多个主题，并按照它们被生产到每个分区的顺序读取消息。消费者通过跟踪消息的偏移量来跟踪它已经消费的消息。*偏移量*——一个不断增加的整数值——是Kafka在每条消息被生产时添加的另一个元数据。给定分区中的每条消息都有一个唯一的偏移量，并且下一条消息有一个更大的偏移量（尽管不一定是单调递增的）。通过通常在Kafka本身中存储每个分区的下一个可能偏移量，消费者可以在不丢失位置的情况下停止和重新启动。'
- en: Consumers work as part of a *consumer group*, which is one or more consumers
    that work together to consume a topic. The group ensures that each partition is
    only consumed by one member. In [Figure 1-6](#fig-6-consumer), there are three
    consumers in a single group consuming a topic. Two of the consumers are working
    from one partition each, while the third consumer is working from two partitions.
    The mapping of a consumer to a partition is often called *ownership* of the partition
    by the consumer.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 消费者作为*消费者组*的一部分工作，这是一个或多个一起消费主题的消费者。该组确保每个分区只被一个成员消费。在[图1-6](#fig-6-consumer)中，有三个消费者在一个单一组中消费一个主题。其中两个消费者分别从一个分区工作，而第三个消费者从两个分区工作。消费者到分区的映射通常称为消费者对分区的*所有权*。
- en: In this way, consumers can horizontally scale to consume topics with a large
    number of messages. Additionally, if a single consumer fails, the remaining members
    of the group will reassign the partitions being consumed to take over for the
    missing member. Consumers and consumer groups are discussed in more detail in
    [Chapter 4](ch04.html#reading_data_from_kafka).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式，消费者可以水平扩展以消费具有大量消息的主题。此外，如果单个消费者失败，组的其余成员将重新分配正在消费的分区，以代替缺失的成员。有关消费者和消费者组的详细讨论，请参阅[第4章](ch04.html#reading_data_from_kafka)。
- en: '![kdg2 0106](assets/kdg2_0106.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![kdg2 0106](assets/kdg2_0106.png)'
- en: Figure 1-6\. A consumer group reading from a topic
  id: totrans-43
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-6\. 一个消费者组从一个主题中读取消息
- en: Brokers and Clusters
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 经纪人和集群
- en: A single Kafka server is called a *broker*. The broker receives messages from
    producers, assigns offsets to them, and writes the messages to storage on disk.
    It also services consumers, responding to fetch requests for partitions and responding
    with the messages that have been published. Depending on the specific hardware
    and its performance characteristics, a single broker can easily handle thousands
    of partitions and millions of messages per second.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 单个Kafka服务器称为*经纪人*。经纪人接收来自生产者的消息，为它们分配偏移量，并将消息写入磁盘存储。它还为消费者提供服务，响应对分区的获取请求，并用已发布的消息进行响应。根据特定硬件及其性能特征，单个经纪人可以轻松处理数千个分区和每秒数百万条消息。
- en: Kafka brokers are designed to operate as part of a *cluster*. Within a cluster
    of brokers, one broker will also function as the cluster *controller* (elected
    automatically from the live members of the cluster). The controller is responsible
    for administrative operations, including assigning partitions to brokers and monitoring
    for broker failures. A partition is owned by a single broker in the cluster, and
    that broker is called the *leader* of the partition. A replicated partition (as
    seen in [Figure 1-7](#fig-7-replication)) is assigned to additional brokers, called
    *followers* of the partition. Replication provides redundancy of messages in the
    partition, such that one of the followers can take over leadership if there is
    a broker failure. All producers must connect to the leader in order to publish
    messages, but consumers may fetch from either the leader or one of the followers.
    Cluster operations, including partition replication, are covered in detail in
    [Chapter 7](ch07.html#reliable_data_delivery).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka经纪人被设计为作为*集群*的一部分运行。在经纪人集群中，一个经纪人还将作为集群的*控制器*（从集群的活动成员中自动选举产生）。控制器负责管理操作，包括将分区分配给经纪人并监视经纪人故障。集群中的单个分区由集群中的单个经纪人拥有，并且该经纪人被称为分区的*领导者*。复制分区（如[图1-7](#fig-7-replication)中所示）分配给其他经纪人，称为分区的*跟随者*。复制提供了分区中消息的冗余，以便如果有经纪人故障，其中一个跟随者可以接管领导权。所有生产者必须连接到领导者才能发布消息，但消费者可以从领导者或其中一个跟随者获取消息。集群操作，包括分区复制，将在[第7章](ch07.html#reliable_data_delivery)中详细介绍。
- en: '![kdg2 0107](assets/kdg2_0107.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![kdg2 0107](assets/kdg2_0107.png)'
- en: Figure 1-7\. Replication of partitions in a cluster
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-7. 集群中分区的复制
- en: A key feature of Apache Kafka is that of *retention*, which is the durable storage
    of messages for some period of time. Kafka brokers are configured with a default
    retention setting for topics, either retaining messages for some period of time
    (e.g., 7 days) or until the partition reaches a certain size in bytes (e.g., 1
    GB). Once these limits are reached, messages are expired and deleted. In this
    way, the retention configuration defines a minimum amount of data available at
    any time. Individual topics can also be configured with their own retention settings
    so that messages are stored for only as long as they are useful. For example,
    a tracking topic might be retained for several days, whereas application metrics
    might be retained for only a few hours. Topics can also be configured as *log
    compacted*, which means that Kafka will retain only the last message produced
    with a specific key. This can be useful for changelog-type data, where only the
    last update is interesting.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Kafka的一个关键特性是*保留*，即一段时间内消息的持久存储。Kafka经纪人配置了主题的默认保留设置，可以保留一段时间的消息（例如7天），或者直到分区达到特定大小（例如1GB）。一旦达到这些限制，消息将过期并被删除。通过这种方式，保留配置定义了任何时间可用数据的最小量。个别主题也可以配置自己的保留设置，以便仅在有用时存储消息。例如，跟踪主题可能保留几天，而应用程序指标可能仅保留几个小时。主题还可以配置为*日志压缩*，这意味着Kafka将仅保留使用特定键生成的最后一条消息。这对于只有最后更新有趣的更改日志类型数据很有用。
- en: Multiple Clusters
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多个集群
- en: 'As Kafka deployments grow, it is often advantageous to have multiple clusters.
    There are several reasons why this can be useful:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 随着Kafka部署的增长，拥有多个集群通常是有利的。有几个原因可以解释为什么这样做是有用的：
- en: Segregation of types of data
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据类型的分离
- en: Isolation for security requirements
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 满足安全需求的隔离
- en: Multiple datacenters (disaster recovery)
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多个数据中心（灾难恢复）
- en: When working with multiple datacenters in particular, it is often required that
    messages be copied between them. In this way, online applications can have access
    to user activity at both sites. For example, if a user changes public information
    in their profile, that change will need to be visible regardless of the datacenter
    in which search results are displayed. Or, monitoring data can be collected from
    many sites into a single central location where the analysis and alerting systems
    are hosted. The replication mechanisms within the Kafka clusters are designed
    only to work within a single cluster, not between multiple clusters.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是在使用多个数据中心时，通常需要在它们之间复制消息。这样，在线应用程序可以访问两个站点的用户活动。例如，如果用户在其个人资料中更改公共信息，则无论在哪个数据中心显示搜索结果，该更改都需要可见。或者，监控数据可以从许多站点收集到单个中央位置，分析和警报系统在那里托管。Kafka集群内的复制机制仅设计为在单个集群内工作，而不是在多个集群之间工作。
- en: The Kafka project includes a tool called *MirrorMaker*, used for replicating
    data to other clusters. At its core, MirrorMaker is simply a Kafka consumer and
    producer, linked together with a queue. Messages are consumed from one Kafka cluster
    and produced to another. [Figure 1-8](#fig-8-tiers) shows an example of an architecture
    that uses MirrorMaker, aggregating messages from two local clusters into an aggregate
    cluster and then copying that cluster to other datacenters. The simple nature
    of the application belies its power in creating sophisticated data pipelines,
    which will be detailed further in [Chapter 9](ch09.html#building_data_pipelines).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka项目包括一个名为*MirrorMaker*的工具，用于将数据复制到其他集群。在其核心，MirrorMaker只是一个Kafka消费者和生产者，通过队列连接在一起。消息从一个Kafka集群中消耗，并在另一个集群中生成。[图1-8](#fig-8-tiers)显示了一个使用MirrorMaker的架构示例，将来自两个本地集群的消息聚合到一个聚合集群，然后将该集群复制到其他数据中心。该应用程序的简单性掩盖了它在创建复杂数据管道方面的强大功能，这将在[第9章](ch09.html#building_data_pipelines)中进一步详细介绍。
- en: '![kdg2 0108](assets/kdg2_0108.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![kdg2 0108](assets/kdg2_0108.png)'
- en: Figure 1-8\. Multiple datacenters architecture
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-8. 多数据中心架构
- en: Why Kafka?
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择Kafka？
- en: There are many choices for publish/subscribe messaging systems, so what makes
    Apache Kafka a good choice?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在发布/订阅消息系统中有很多选择，那么Apache Kafka为什么是一个好选择呢？
- en: Multiple Producers
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多个生产者
- en: Kafka is able to seamlessly handle multiple producers, whether those clients
    are using many topics or the same topic. This makes the system ideal for aggregating
    data from many frontend systems and making it consistent. For example, a site
    that serves content to users via a number of microservices can have a single topic
    for page views that all services can write to using a common format. Consumer
    applications can then receive a single stream of page views for all applications
    on the site without having to coordinate consuming from multiple topics, one for
    each application.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka能够无缝处理多个生产者，无论这些客户端是使用许多主题还是相同的主题。这使得系统非常适合从许多前端系统聚合数据并使其一致。例如，通过多个微服务为用户提供内容的站点可以有一个页面浏览的单个主题，所有服务都可以使用通用格式写入。消费应用程序可以接收站点上所有应用程序的页面浏览的单个流，而无需协调从多个主题消耗，每个应用程序一个。
- en: Multiple Consumers
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多个消费者
- en: In addition to multiple producers, Kafka is designed for multiple consumers
    to read any single stream of messages without interfering with each other client.
    This is in contrast to many queuing systems where once a message is consumed by
    one client, it is not available to any other. Multiple Kafka consumers can choose
    to operate as part of a group and share a stream, assuring that the entire group
    processes a given message only once.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 除了多个生产者外，Kafka还设计为多个消费者可以读取任何单个消息流，而不会干扰其他客户端。这与许多排队系统相反，其中一旦消息被一个客户端消耗，它就不可用于任何其他客户端。多个Kafka消费者可以选择作为一个组操作，并共享一个流，确保整个组仅处理给定消息一次。
- en: Disk-Based Retention
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于磁盘的保留
- en: Not only can Kafka handle multiple consumers, but durable message retention
    means that consumers do not always need to work in real time. Messages are written
    to disk and will be stored with configurable retention rules. These options can
    be selected on a per-topic basis, allowing for different streams of messages to
    have different amounts of retention depending on the consumer needs. Durable retention
    means that if a consumer falls behind, either due to slow processing or a burst
    in traffic, there is no danger of losing data. It also means that maintenance
    can be performed on consumers, taking applications offline for a short period
    of time, with no concern about messages backing up on the producer or getting
    lost. Consumers can be stopped, and the messages will be retained in Kafka. This
    allows them to restart and pick up processing messages where they left off with
    no data loss.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka不仅可以处理多个消费者，而且持久的消息保留意味着消费者不总是需要实时工作。消息被写入磁盘，并且将根据可配置的保留规则进行存储。这些选项可以根据主题选择，允许不同的消息流具有不同的保留量，以满足消费者的需求。持久的保留意味着如果消费者落后，无论是由于处理速度慢还是流量激增，都不会丢失数据。这也意味着可以对消费者进行维护，将应用程序离线一小段时间，而不用担心生产者上的消息积压或丢失。消费者可以停止，消息将被保留在Kafka中。这使它们可以重新启动并在离开时继续处理消息，而不会丢失数据。
- en: Scalable
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可扩展
- en: Kafka’s flexible scalability makes it easy to handle any amount of data. Users
    can start with a single broker as a proof of concept, expand to a small development
    cluster of three brokers, and move into production with a larger cluster of tens
    or even hundreds of brokers that grows over time as the data scales up. Expansions
    can be performed while the cluster is online, with no impact on the availability
    of the system as a whole. This also means that a cluster of multiple brokers can
    handle the failure of an individual broker and continue servicing clients. Clusters
    that need to tolerate more simultaneous failures can be configured with higher
    replication factors. Replication is discussed in more detail in [Chapter 7](ch07.html#reliable_data_delivery).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka的灵活可扩展性使其能够轻松处理任意数量的数据。用户可以从单个代理作为概念验证开始，扩展到由三个代理组成的小型开发集群，然后随着数据规模的扩大，进入由数十甚至数百个代理组成的生产集群。扩展可以在集群在线时进行，对整个系统的可用性没有影响。这也意味着多个代理组成的集群可以处理单个代理的故障并继续为客户提供服务。需要容忍更多同时故障的集群可以配置更高的复制因子。复制将在[第7章](ch07.html#reliable_data_delivery)中进行更详细的讨论。
- en: High Performance
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高性能
- en: All of these features come together to make Apache Kafka a publish/subscribe
    messaging system with excellent performance under high load. Producers, consumers,
    and brokers can all be scaled out to handle very large message streams with ease.
    This can be done while still providing subsecond message latency from producing
    a message to availability to consumers.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些功能共同使Apache Kafka成为一个在高负载下具有出色性能的发布/订阅消息系统。生产者、消费者和代理都可以扩展以轻松处理非常大的消息流。这可以在仍然提供从生成消息到可供消费者使用的亚秒级消息延迟的情况下完成。
- en: Platform Features
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平台功能
- en: The core Apache Kafka project has also added some streaming platform features
    that can make it much easier for developers to perform common types of work. While
    not full platforms, which typically include a structured runtime environment like
    YARN, these features are in the form of APIs and libraries that provide a solid
    foundation to build on and flexibility as to where they can be run. Kafka Connect
    assists with the task of pulling data from a source data system and pushing it
    into Kafka, or pulling data from Kafka and pushing it into a sink data system.
    Kafka Streams provides a library for easily developing stream processing applications
    that are scalable and fault tolerant. Connect is discussed in [Chapter 9](ch09.html#building_data_pipelines),
    while Streams is covered in great detail in [Chapter 14](ch14.html#stream_processing).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Kafka核心项目还添加了一些流平台功能，可以使开发人员更容易执行常见类型的工作。虽然不是完整的平台，通常包括像YARN这样的结构化运行时环境，但这些功能是以API和库的形式提供的，为构建和灵活性提供了坚实的基础，可以在其中运行。Kafka
    Connect帮助从源数据系统中提取数据并将其推送到Kafka，或者从Kafka中提取数据并将其推送到接收数据系统。Kafka Streams提供了一个库，用于轻松开发可扩展和容错的流处理应用程序。Connect在[第9章](ch09.html#building_data_pipelines)中讨论，而Streams在[第14章](ch14.html#stream_processing)中有详细介绍。
- en: The Data Ecosystem
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据生态系统
- en: Many applications participate in the environments we build for data processing.
    We have defined inputs in the form of applications that create data or otherwise
    introduce it to the system. We have defined outputs in the form of metrics, reports,
    and other data products. We create loops, with some components reading data from
    the system, transforming it using data from other sources, and then introducing
    it back into the data infrastructure to be used elsewhere. This is done for numerous
    types of data, with each having unique qualities of content, size, and usage.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 许多应用程序参与我们为数据处理构建的环境。我们已经定义了以应用程序形式的输入，这些应用程序创建数据或以其他方式将其引入系统。我们已经定义了以度量标准、报告和其他数据产品形式的输出。我们创建循环，一些组件从系统中读取数据，使用其他来源的数据进行转换，然后将其重新引入数据基础设施以供其他地方使用。这是针对多种类型的数据进行的，每种数据都具有独特的内容、大小和用途。
- en: Apache Kafka provides the circulatory system for the data ecosystem, as shown
    in [Figure 1-9](#fig-9-ecosystem). It carries messages between the various members
    of the infrastructure, providing a consistent interface for all clients. When
    coupled with a system to provide message schemas, producers and consumers no longer
    require tight coupling or direct connections of any sort. Components can be added
    and removed as business cases are created and dissolved, and producers do not
    need to be concerned about who is using the data or the number of consuming applications.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '![kdg2 0109](assets/kdg2_0109.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
- en: Figure 1-9\. A big data ecosystem
  id: totrans-77
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Use Cases
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Activity tracking
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The original use case for Kafka, as it was designed at LinkedIn, is that of
    user activity tracking. A website’s users interact with frontend applications,
    which generate messages regarding actions the user is taking. This can be passive
    information, such as page views and click tracking, or it can be more complex
    actions, such as information that a user adds to their profile. The messages are
    published to one or more topics, which are then consumed by applications on the
    backend. These applications may be generating reports, feeding machine learning
    systems, updating search results, or performing other operations that are necessary
    to provide a rich user experience.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Messaging
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Kafka is also used for messaging, where applications need to send notifications
    (such as emails) to users. Those applications can produce messages without needing
    to be concerned about formatting or how the messages will actually be sent. A
    single application can then read all the messages to be sent and handle them consistently,
    including:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Formatting the messages (also known as *decorating*) using a common look and
    feel
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collecting multiple messages into a single notification to be sent
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying a user’s preferences for how they want to receive messages
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a single application for this avoids the need to duplicate functionality
    in multiple applications, as well as allows operations like aggregation that would
    not otherwise be possible.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Metrics and logging
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Kafka is also ideal for collecting application and system metrics and logs.
    This is a use case in which the ability to have multiple applications producing
    the same type of message shines. Applications publish metrics on a regular basis
    to a Kafka topic, and those metrics can be consumed by systems for monitoring
    and alerting. They can also be used in an offline system like Hadoop to perform
    longer-term analysis, such as growth projections. Log messages can be published
    in the same way and can be routed to dedicated log search systems like Elasticsearch
    or security analysis applications. Another added benefit of Kafka is that when
    the destination system needs to change (e.g., it’s time to update the log storage
    system), there is no need to alter the frontend applications or the means of aggregation.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Commit log
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since Kafka is based on the concept of a commit log, database changes can be
    published to Kafka, and applications can easily monitor this stream to receive
    live updates as they happen. This changelog stream can also be used for replicating
    database updates to a remote system, or for consolidating changes from multiple
    applications into a single database view. Durable retention is useful here for
    providing a buffer for the changelog, meaning it can be replayed in the event
    of a failure of the consuming applications. Alternately, log-compacted topics
    can be used to provide longer retention by only retaining a single change per
    key.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Stream processing
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another area that provides numerous types of applications is stream processing.
    While almost all usage of Kafka can be thought of as stream processing, the term
    is typically used to refer to applications that provide similar functionality
    to map/reduce processing in Hadoop. Hadoop usually relies on aggregation of data
    over a long time frame, either hours or days. Stream processing operates on data
    in real time, as quickly as messages are produced. Stream frameworks allow users
    to write small applications to operate on Kafka messages, performing tasks such
    as counting metrics, partitioning messages for efficient processing by other applications,
    or transforming messages using data from multiple sources. Stream processing is
    covered in [Chapter 14](ch14.html#stream_processing).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Kafka’s Origin
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kafka was created to address the data pipeline problem at LinkedIn. It was designed
    to provide a high-performance messaging system that can handle many types of data
    and provide clean, structured data about user activity and system metrics in real
    time.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Data really powers everything that we do.
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '>'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Jeff Weiner, former CEO of LinkedIn
  id: totrans-97
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: LinkedIn’s Problem
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Similar to the example described at the beginning of this chapter, LinkedIn
    had a system for collecting system and application metrics that used custom collectors
    and open source tools for storing and presenting data internally. In addition
    to traditional metrics, such as CPU usage and application performance, there was
    a sophisticated request-tracing feature that used the monitoring system and could
    provide introspection into how a single user request propagated through internal
    applications. The monitoring system had many faults, however. This included metrics
    collection based on polling, large intervals between metrics, and no ability for
    application owners to manage their own metrics. The system was high-touch, requiring
    human intervention for most simple tasks, and inconsistent, with differing metric
    names for the same measurement across different systems.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, there was a system created for tracking user activity information.
    This was an HTTP service that frontend servers would connect to periodically and
    publish a batch of messages (in XML format) to the HTTP service. These batches
    were then moved to offline processing platforms, which is where the files were
    parsed and collated. This system had many faults. The XML formatting was inconsistent,
    and parsing it was computationally expensive. Changing the type of user activity
    that was tracked required a significant amount of coordinated work between frontends
    and offline processing. Even then, the system would break constantly due to changing
    schemas. Tracking was built on hourly batching, so it could not be used in real
    time.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring and user-activity tracking could not use the same backend service.
    The monitoring service was too clunky, the data format was not oriented for activity
    tracking, and the polling model for monitoring was not compatible with the push
    model for tracking. At the same time, the tracking service was too fragile to
    use for metrics, and the batch-oriented processing was not the right model for
    real-time monitoring and alerting. However, the monitoring and tracking data shared
    many traits, and correlation of the information (such as how specific types of
    user activity affected application performance) was highly desirable. A drop in
    specific types of user activity could indicate problems with the application that
    serviced it, but hours of delay in processing activity batches meant a slow response
    to these types of issues.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: At first, existing off-the-shelf open source solutions were thoroughly investigated
    to find a new system that would provide real-time access to the data and scale
    out to handle the amount of message traffic needed. Prototype systems were set
    up using ActiveMQ, but at the time it could not handle the scale. It was also
    a fragile solution for the way LinkedIn needed to use it, discovering many flaws
    in ActiveMQ that would cause the brokers to pause. These pauses would back up
    connections to clients and interfere with the ability of the applications to serve
    requests to users. The decision was made to move forward with a custom infrastructure
    for the data pipeline.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，对现有的开源解决方案进行了彻底调查，以找到一个能够提供对数据的实时访问并能够扩展以处理所需的消息流量的新系统。使用ActiveMQ建立了原型系统，但当时它无法处理这样的规模。对于LinkedIn需要使用的方式来说，它也是一个脆弱的解决方案，发现了ActiveMQ中许多会导致代理暂停的缺陷。这些暂停会导致连接到客户端的连接积压，并干扰应用程序为用户提供请求的能力。决定继续使用自定义基础架构进行数据管道。
- en: The Birth of Kafka
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kafka的诞生
- en: 'The development team at LinkedIn was led by Jay Kreps, a principal software
    engineer who was previously responsible for the development and open source release
    of Voldemort, a distributed key-value storage system. The initial team also included
    Neha Narkhede and, later, Jun Rao. Together, they set out to create a messaging
    system that could meet the needs of both the monitoring and tracking systems,
    and scale for the future. The primary goals were to:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: LinkedIn的开发团队由Jay Kreps领导，他是一名负责开发和开源发布分布式键值存储系统Voldemort的首席软件工程师。最初的团队还包括Neha
    Narkhede，后来又加入了Jun Rao。他们一起着手创建一个能够满足监控和跟踪系统需求并能够为未来扩展的消息系统。主要目标是：
- en: Decouple producers and consumers by using a push-pull model
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用推拉模型解耦生产者和消费者
- en: Provide persistence for message data within the messaging system to allow multiple
    consumers
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在消息系统内为消息数据提供持久性，以允许多个消费者
- en: Optimize for high throughput of messages
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化消息的高吞吐量
- en: Allow for horizontal scaling of the system to grow as the data streams grew
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许系统进行水平扩展，以随着数据流的增长而增长
- en: The result was a publish/subscribe messaging system that had an interface typical
    of messaging systems but a storage layer more like a log-aggregation system. Combined
    with the adoption of Apache Avro for message serialization, Kafka was effective
    for handling both metrics and user-activity tracking at a scale of billions of
    messages per day. The scalability of Kafka has helped LinkedIn’s usage grow in
    excess of seven trillion messages produced (as of February 2020) and over five
    petabytes of data consumed daily.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个发布/订阅消息系统，具有典型的消息系统接口，但存储层更像是日志聚合系统。结合采用Apache Avro进行消息序列化，Kafka能够有效处理每天数十亿条消息的指标和用户活动跟踪。Kafka的可扩展性帮助LinkedIn的使用量超过了每天产生的七万亿条消息（截至2020年2月），每天消耗超过五PB的数据。
- en: Open Source
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开源
- en: Kafka was released as an open source project on GitHub in late 2010\. As it
    started to gain attention in the open source community, it was proposed and accepted
    as an Apache Software Foundation incubator project in July of 2011\. Apache Kafka
    graduated from the incubator in October of 2012\. Since then, it has continuously
    been worked on and has found a robust community of contributors and committers
    outside of LinkedIn. Kafka is now used in some of the largest data pipelines in
    the world, including those at Netflix, Uber, and many other companies.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka于2010年末在GitHub上作为开源项目发布。随着它开始引起开源社区的关注，它于2011年7月被提议并接受为Apache软件基金会的孵化器项目。Apache
    Kafka于2012年10月从孵化器毕业。从那时起，它一直在不断地进行开发，并在LinkedIn之外找到了一个强大的贡献者和提交者社区。Kafka现在被用于世界上一些最大的数据管道，包括Netflix、Uber和许多其他公司。
- en: Widespread adoption of Kafka has created a healthy ecosystem around the core
    project as well. There are active meetup groups in dozens of countries around
    the world, providing local discussion and support of stream processing. There
    are also numerous open source projects related to Apache Kafka. LinkedIn continues
    to maintain several, including Cruise Control, Kafka Monitor, and Burrow. In addition
    to its commercial offerings, Confluent has released projects including ksqlDB,
    a schema registry, and a REST proxy under a community license (which is not strictly
    open source, as it includes use restrictions). Several of the most popular projects
    are listed in [Appendix B](app02.html#appendix_3rd_party_tools).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka的广泛采用也在核心项目周围形成了一个健康的生态系统。全球各地都有活跃的见面会小组，提供本地的流处理讨论和支持。还有许多与Apache Kafka相关的开源项目。LinkedIn继续维护其中一些，包括Cruise
    Control、Kafka Monitor和Burrow。除了商业产品，Confluent还发布了包括ksqlDB、模式注册表和REST代理在内的项目，采用社区许可证（不严格属于开源，因为它包含使用限制）。一些最受欢迎的项目列在[附录B](app02.html#appendix_3rd_party_tools)中。
- en: Commercial Engagement
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 商业参与
- en: In the fall of 2014, Jay Kreps, Neha Narkhede, and Jun Rao left LinkedIn to
    found Confluent, a company centered around providing development, enterprise support,
    and training for Apache Kafka. They also joined other companies (such as Heroku)
    in providing cloud services for Kafka. Confluent, through a partnership with Google,
    provides managed Kafka clusters on Google Cloud Platform, as well as similar services
    on Amazon Web Services and Azure. One of the other major initiatives of Confluent
    is to organize the Kafka Summit conference series. Started in 2016, with conferences
    held annually in the United States and London, Kafka Summit provides a place for
    the community to come together on a global scale and share knowledge about Apache
    Kafka and related projects.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 2014年秋天，杰伊·克雷普斯（Jay Kreps）、内哈·纳尔凯德（Neha Narkhede）和饶军（Jun Rao）离开领英，创立了Confluent，这是一家以提供Apache
    Kafka的开发、企业支持和培训为中心的公司。他们还与其他公司（如Heroku）合作，为Kafka提供云服务。Confluent通过与谷歌合作，在谷歌云平台上提供托管的Kafka集群，以及在亚马逊网络服务和Azure上提供类似的服务。Confluent的另一个重大举措是组织Kafka峰会系列会议。Kafka峰会始于2016年，每年在美国和伦敦举办，为社区提供了一个全球范围内共享关于Apache
    Kafka和相关项目知识的平台。
- en: The Name
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 名字
- en: 'People often ask how Kafka got its name and if it signifies anything specific
    about the application itself. Jay Kreps offered the following insight:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 人们经常问Kafka是如何得到它的名字，以及它是否代表了应用程序本身的特定含义。杰伊·克雷普斯提供了以下见解：
- en: I thought that since Kafka was a system optimized for writing, using a writer’s
    name would make sense. I had taken a lot of lit classes in college and liked Franz
    Kafka. Plus the name sounded cool for an open source project.
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我认为，由于Kafka是一个优化写作的系统，使用作家的名字是有道理的。我在大学时上了很多文学课，喜欢弗朗茨·卡夫卡。而且这个名字对于一个开源项目来说听起来很酷。
- en: '>'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '>'
- en: So basically there is not much of a relationship.
  id: totrans-119
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所以基本上没有太多关系。
- en: Getting Started with Kafka
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用Kafka
- en: Now that we know all about Kafka and its history, we can set it up and build
    our own data pipeline. In the next chapter, we will explore installing and configuring
    Kafka. We will also cover selecting the right hardware to run Kafka on, and some
    things to keep in mind when moving to production operations.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了Kafka及其历史，我们可以设置它并构建自己的数据管道。在下一章中，我们将探讨安装和配置Kafka。我们还将介绍在运行Kafka时选择合适的硬件，以及在转向生产运营时需要注意的一些事项。

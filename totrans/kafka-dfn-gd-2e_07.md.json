["```java\nProperties props = new Properties();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\");\nAdminClient admin = AdminClient.create(props);\n// TODO: Do something useful with AdminClient\nadmin.close(Duration.ofSeconds(30));\n```", "```java\nListTopicsResult topics = admin.listTopics();\ntopics.names().get().forEach(System.out::println);\n```", "```java\nDescribeTopicsResult demoTopic = admin.describeTopics(TOPIC_LIST); ![1](assets/1.png)\n\ntry {\n    topicDescription = demoTopic.values().get(TOPIC_NAME).get(); ![2](assets/2.png)\n    System.out.println(\"Description of demo topic:\" + topicDescription);\n\n    if (topicDescription.partitions().size() != NUM_PARTITIONS) { ![3](assets/3.png)\n      System.out.println(\"Topic has wrong number of partitions. Exiting.\");\n      System.exit(-1);\n    }\n} catch (ExecutionException e) { ![4](assets/4.png)\n    // exit early for almost all exceptions\n    if (! (e.getCause() instanceof UnknownTopicOrPartitionException)) {\n        e.printStackTrace();\n        throw e;\n    }\n\n    // if we are here, topic doesn't exist\n    System.out.println(\"Topic \" + TOPIC_NAME +\n        \" does not exist. Going to create it now\");\n    // Note that number of partitions and replicas is optional. If they are\n    // not specified, the defaults configured on the Kafka brokers will be used\n    CreateTopicsResult newTopic = admin.createTopics(Collections.singletonList(\n            new NewTopic(TOPIC_NAME, NUM_PARTITIONS, REP_FACTOR))); ![5](assets/5.png)\n\n    // Check that the topic was created correctly:\n    if (newTopic.numPartitions(TOPIC_NAME).get() != NUM_PARTITIONS) { ![6](assets/6.png)\n        System.out.println(\"Topic has wrong number of partitions.\");\n        System.exit(-1);\n    }\n}\n```", "```java\nadmin.deleteTopics(TOPIC_LIST).all().get();\n\n// Check that it is gone. Note that due to the async nature of deletes,\n// it is possible that at this point the topic still exists\ntry {\n    topicDescription = demoTopic.values().get(TOPIC_NAME).get();\n    System.out.println(\"Topic \" + TOPIC_NAME + \" is still around\");\n} catch (ExecutionException e) {\n    System.out.println(\"Topic \" + TOPIC_NAME + \" is gone\");\n}\n```", "```java\nvertx.createHttpServer().requestHandler(request -> { ![1](assets/1.png)\n    String topic = request.getParam(\"topic\"); ![2](assets/2.png)\n    String timeout = request.getParam(\"timeout\");\n    int timeoutMs = NumberUtils.toInt(timeout, 1000);\n\n    DescribeTopicsResult demoTopic = admin.describeTopics( ![3](assets/3.png)\n            Collections.singletonList(topic),\n            new DescribeTopicsOptions().timeoutMs(timeoutMs));\n\n    demoTopic.values().get(topic).whenComplete( ![4](assets/4.png)\n            new KafkaFuture.BiConsumer<TopicDescription, Throwable>() {\n                @Override\n                public void accept(final TopicDescription topicDescription,\n                                   final Throwable throwable) {\n                    if (throwable != null) {\n                      request.response().end(\"Error trying to describe topic \"\n                              + topic + \" due to \" + throwable.getMessage()); ![5](assets/5.png)\n                    } else {\n                        request.response().end(topicDescription.toString()); ![6](assets/6.png)\n                    }\n                }\n            });\n}).listen(8080);\n```", "```java\nConfigResource configResource =\n        new ConfigResource(ConfigResource.Type.TOPIC, TOPIC_NAME); ![1](assets/1.png)\nDescribeConfigsResult configsResult =\n        admin.describeConfigs(Collections.singleton(configResource));\nConfig configs = configsResult.all().get().get(configResource);\n\n// print nondefault configs\nconfigs.entries().stream().filter(\n        entry -> !entry.isDefault()).forEach(System.out::println); ![2](assets/2.png)\n\n// Check if topic is compacted\nConfigEntry compaction = new ConfigEntry(TopicConfig.CLEANUP_POLICY_CONFIG,\n        TopicConfig.CLEANUP_POLICY_COMPACT);\nif (!configs.entries().contains(compaction)) {\n    // if topic is not compacted, compact it\n    Collection<AlterConfigOp> configOp = new ArrayList<AlterConfigOp>();\n    configOp.add(new AlterConfigOp(compaction, AlterConfigOp.OpType.SET)); ![3](assets/3.png)\n    Map<ConfigResource, Collection<AlterConfigOp>> alterConf = new HashMap<>();\n    alterConf.put(configResource, configOp);\n    admin.incrementalAlterConfigs(alterConf).all().get();\n} else {\n    System.out.println(\"Topic \" + TOPIC_NAME + \" is compacted topic\");\n}\n```", "```java\nadmin.listConsumerGroups().valid().get().forEach(System.out::println);\n```", "```java\nConsumerGroupDescription groupDescription = admin\n        .describeConsumerGroups(CONSUMER_GRP_LIST)\n        .describedGroups().get(CONSUMER_GROUP).get();\n        System.out.println(\"Description of group \" + CONSUMER_GROUP\n                + \":\" + groupDescription);\n```", "```java\nMap<TopicPartition, OffsetAndMetadata> offsets =\n        admin.listConsumerGroupOffsets(CONSUMER_GROUP)\n                .partitionsToOffsetAndMetadata().get(); ![1](assets/1.png)\n\nMap<TopicPartition, OffsetSpec> requestLatestOffsets = new HashMap<>();\n\nfor(TopicPartition tp: offsets.keySet()) {\n    requestLatestOffsets.put(tp, OffsetSpec.latest()); ![2](assets/2.png)\n}\n\nMap<TopicPartition, ListOffsetsResult.ListOffsetsResultInfo> latestOffsets =\n        admin.listOffsets(requestLatestOffsets).all().get();\n\nfor (Map.Entry<TopicPartition, OffsetAndMetadata> e: offsets.entrySet()) { ![3](assets/3.png)\n    String topic = e.getKey().topic();\n    int partition =  e.getKey().partition();\n    long committedOffset = e.getValue().offset();\n    long latestOffset = latestOffsets.get(e.getKey()).offset();\n\n    System.out.println(\"Consumer group \" + CONSUMER_GROUP\n            + \" has committed offset \" + committedOffset\n            + \" to topic \" + topic + \" partition \" + partition\n            + \". The latest offset in the partition is \"\n            +  latestOffset + \" so consumer group is \"\n            + (latestOffset - committedOffset) + \" records behind\");\n}\n```", "```java\nMap<TopicPartition, ListOffsetsResult.ListOffsetsResultInfo> earliestOffsets =\n    admin.listOffsets(requestEarliestOffsets).all().get(); ![1](assets/1.png)\n\nMap<TopicPartition, OffsetAndMetadata> resetOffsets = new HashMap<>();\nfor (Map.Entry<TopicPartition, ListOffsetsResult.ListOffsetsResultInfo> e:\n        earliestOffsets.entrySet()) {\n  resetOffsets.put(e.getKey(), new OffsetAndMetadata(e.getValue().offset())); ![2](assets/2.png)\n}\n\ntry {\n  admin.alterConsumerGroupOffsets(CONSUMER_GROUP, resetOffsets).all().get(); ![3](assets/3.png)\n} catch (ExecutionException e) {\n  System.out.println(\"Failed to update the offsets committed by group \"\n            + CONSUMER_GROUP + \" with error \" + e.getMessage());\n  if (e.getCause() instanceof UnknownMemberIdException)\n      System.out.println(\"Check if consumer group is still active.\"); ![4](assets/4.png)\n}\n```", "```java\nDescribeClusterResult cluster = admin.describeCluster();\n\nSystem.out.println(\"Connected to cluster \" + cluster.clusterId().get()); ![1](assets/1.png)\nSystem.out.println(\"The brokers in the cluster are:\");\ncluster.nodes().get().forEach(node -> System.out.println(\"    * \" + node));\nSystem.out.println(\"The controller is: \" + cluster.controller().get());\n```", "```java\nMap<String, NewPartitions> newPartitions = new HashMap<>();\nnewPartitions.put(TOPIC_NAME, NewPartitions.increaseTo(NUM_PARTITIONS+2)); ![1](assets/1.png)\nadmin.createPartitions(newPartitions).all().get();\n```", "```java\nMap<TopicPartition, ListOffsetsResult.ListOffsetsResultInfo> olderOffsets =\n        admin.listOffsets(requestOlderOffsets).all().get();\nMap<TopicPartition, RecordsToDelete> recordsToDelete = new HashMap<>();\nfor (Map.Entry<TopicPartition, ListOffsetsResult.ListOffsetsResultInfo>  e:\n        olderOffsets.entrySet())\n    recordsToDelete.put(e.getKey(),\n            RecordsToDelete.beforeOffset(e.getValue().offset()));\n admin.deleteRecords(recordsToDelete).all().get();\n```", "```java\nSet<TopicPartition> electableTopics = new HashSet<>();\nelectableTopics.add(new TopicPartition(TOPIC_NAME, 0));\ntry {\n    admin.electLeaders(ElectionType.PREFERRED, electableTopics).all().get(); ![1](assets/1.png)\n} catch (ExecutionException e) {\n    if (e.getCause() instanceof ElectionNotNeededException) {\n        System.out.println(\"All leaders are preferred already\"); ![2](assets/2.png)\n    }\n}\n```", "```java\nMap<TopicPartition, Optional<NewPartitionReassignment>> reassignment = new HashMap<>();\nreassignment.put(new TopicPartition(TOPIC_NAME, 0),\n        Optional.of(new NewPartitionReassignment(Arrays.asList(0,1)))); ![1](assets/1.png)\nreassignment.put(new TopicPartition(TOPIC_NAME, 1),\n        Optional.of(new NewPartitionReassignment(Arrays.asList(1)))); ![2](assets/2.png)\nreassignment.put(new TopicPartition(TOPIC_NAME, 2),\n        Optional.of(new NewPartitionReassignment(Arrays.asList(1,0)))); ![3](assets/3.png)\nreassignment.put(new TopicPartition(TOPIC_NAME, 3), Optional.empty()); ![4](assets/4.png)\n\nadmin.alterPartitionReassignments(reassignment).all().get();\n\nSystem.out.println(\"currently reassigning: \" +\n        admin.listPartitionReassignments().reassignments().get()); ![5](assets/5.png)\ndemoTopic = admin.describeTopics(TOPIC_LIST);\ntopicDescription = demoTopic.values().get(TOPIC_NAME).get();\nSystem.out.println(\"Description of demo topic:\" + topicDescription); ![6](assets/6.png)\n```", "```java\npublic TopicCreator(AdminClient admin) {\n    this.admin = admin;\n}\n\n// Example of a method that will create a topic if its name starts with \"test\"\npublic void maybeCreateTopic(String topicName)\n        throws ExecutionException, InterruptedException {\n    Collection<NewTopic> topics = new ArrayList<>();\n    topics.add(new NewTopic(topicName, 1, (short) 1));\n    if (topicName.toLowerCase().startsWith(\"test\")) {\n        admin.createTopics(topics);\n\n        // alter configs just to demonstrate a point\n        ConfigResource configResource =\n                  new ConfigResource(ConfigResource.Type.TOPIC, topicName);\n        ConfigEntry compaction =\n                  new ConfigEntry(TopicConfig.CLEANUP_POLICY_CONFIG,\n                          TopicConfig.CLEANUP_POLICY_COMPACT);\n        Collection<AlterConfigOp> configOp = new ArrayList<AlterConfigOp>();\n        configOp.add(new AlterConfigOp(compaction, AlterConfigOp.OpType.SET));\n        Map<ConfigResource, Collection<AlterConfigOp>> alterConf =\n            new HashMap<>();\n        alterConf.put(configResource, configOp);\n        admin.incrementalAlterConfigs(alterConf).all().get();\n    }\n}\n```", "```java\n@Before\npublic void setUp() {\n    Node broker = new Node(0,\"localhost\",9092);\n    this.admin = spy(new MockAdminClient(Collections.singletonList(broker),\n        broker)); ![1](assets/1.png)\n\n    // without this, the tests will throw\n    // `java.lang.UnsupportedOperationException: Not implemented yet`\n    AlterConfigsResult emptyResult = mock(AlterConfigsResult.class);\n    doReturn(KafkaFuture.completedFuture(null)).when(emptyResult).all();\n    doReturn(emptyResult).when(admin).incrementalAlterConfigs(any()); ![2](assets/2.png)\n}\n```", "```java\n@Test\npublic void testCreateTestTopic()\n        throws ExecutionException, InterruptedException {\n    TopicCreator tc = new TopicCreator(admin);\n    tc.maybeCreateTopic(\"test.is.a.test.topic\");\n    verify(admin, times(1)).createTopics(any()); ![1](assets/1.png)\n}\n\n@Test\npublic void testNotTopic() throws ExecutionException, InterruptedException {\n    TopicCreator tc = new TopicCreator(admin);\n    tc.maybeCreateTopic(\"not.a.test\");\n    verify(admin, never()).createTopics(any()); ![2](assets/2.png)\n}\n```", "```java\n<dependency>\n    <groupId>org.apache.kafka</groupId>\n    <artifactId>kafka-clients</artifactId>\n    <version>2.5.0</version>\n    <classifier>test</classifier>\n    <scope>test</scope>\n</dependency>\n```"]
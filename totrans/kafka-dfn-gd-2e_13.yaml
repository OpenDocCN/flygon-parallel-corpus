- en: Chapter 11\. Securing Kafka
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章。保护Kafka
- en: Kafka is used for a variety of use cases ranging from website activity tracking
    and metrics pipelines to patient record management and online payments. Each use
    case has different requirements in terms of security, performance, reliability,
    and availability. While it is always preferable to use the strongest and latest
    security features available, trade-offs are often necessary since increased security
    impacts performance, cost, and user experience. Kafka supports several standard
    security technologies with a range of configuration options to tailor security
    to each use case.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka用于各种用例，从网站活动跟踪和指标管道到患者记录管理和在线支付。每种用例在安全性、性能、可靠性和可用性方面都有不同的要求。虽然始终最好使用最强大和最新的安全功能，但通常需要权衡，因为增加的安全性会影响性能、成本和用户体验。Kafka支持几种标准安全技术，并提供一系列配置选项，以将安全性调整到每种用例。
- en: Like performance and reliability, security is an aspect of the system that must
    be addressed for the system as a whole, rather than component by component. The
    security of a system is only as strong as the weakest link, and security processes
    and policies must be enforced across the system, including the underlying platform.
    The customizable security features in Kafka enable integration with existing security
    infrastructure to build a consistent security model that applies to the entire
    system.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 与性能和可靠性一样，安全是系统的一个方面，必须针对整个系统而不是逐个组件来解决。系统的安全性只有最薄弱的环节一样强大，安全流程和政策必须在整个系统中执行，包括底层平台。Kafka中可定制的安全功能使其能够与现有安全基础设施集成，构建一个适用于整个系统的一致安全模型。
- en: In this chapter, we will discuss the security features in Kafka and see how
    they address different aspects of security and contribute toward the overall security
    of the Kafka installation. Throughout the chapter, we will share best practices,
    potential threats, and techniques to mitigate these threats. We will also review
    additional measures that can be adopted to secure ZooKeeper and the rest of the
    platform.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论Kafka中的安全功能，并了解它们如何解决安全的不同方面，并为Kafka安装的整体安全做出贡献。在整个章节中，我们将分享最佳实践、潜在威胁以及减轻这些威胁的技术。我们还将审查可以采用的其他措施，以保护ZooKeeper和平台的其余部分。
- en: Locking Down Kafka
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 锁定Kafka
- en: 'Kafka uses a range of security procedures to establish and maintain confidentiality,
    integrity, and availability of data:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka使用一系列安全程序来建立和维护数据的机密性、完整性和可用性：
- en: Authentication establishes your identity and determines *who* you are.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 身份验证确定*您是谁*并确定您的身份。
- en: Authorization determines *what* you are allowed to do.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 授权确定*您被允许做什么*。
- en: Encryption protects your data from eavesdropping and tampering.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加密保护您的数据免受窃听和篡改。
- en: Auditing tracks what you have done or have attempted to do.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 审计跟踪您已经做过或尝试做过的事情。
- en: Quotas control how much resources you can utilize.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配额控制您可以利用多少资源。
- en: To understand how to lock down a Kafka deployment, let’s first look at how data
    flows through a Kafka cluster. [Figure 11-1](#fig-1-secure-flow) shows the main
    steps in an example data flow. In this chapter, we will use this example flow
    to examine the different ways in which Kafka can be configured to protect data
    at every step to guarantee security of the entire deployment.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何锁定Kafka部署，让我们首先看一下数据如何在Kafka集群中流动。[图11-1](#fig-1-secure-flow)显示了示例数据流中的主要步骤。在本章中，我们将使用这个示例流程来检查Kafka可以配置的不同方式，以保护每个步骤的数据，以确保整个部署的安全性。
- en: '![kdg2 1101](assets/kdg2_1101.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![kdg2 1101](assets/kdg2_1101.png)'
- en: Figure 11-1\. Data flow in a Kafka cluster
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-1\. Kafka集群中的数据流
- en: Alice produces a customer order record to a partition of the topic named `customerOrders`.
    The record is sent to the leader of the partition.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Alice向名为`customerOrders`的主题的一个分区生成客户订单记录。记录被发送到分区的领导者。
- en: The leader broker writes the record to its local log file.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 领导经纪人将记录写入其本地日志文件。
- en: A follower broker fetches the message from the leader and writes to its local
    replica log file.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 跟随者经纪人从领导者那里获取消息，并将其写入其本地副本日志文件。
- en: The leader broker updates the partition state in ZooKeeper to update in-sync
    replicas, if required.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 领导经纪人更新ZooKeeper中的分区状态，以更新同步副本（如果需要）。
- en: Bob consumes customer order records from the topic `customerOrders`. Bob receives
    the record produced by Alice.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Bob从主题`customerOrders`中消费客户订单记录。Bob接收到Alice生成的记录。
- en: An internal application processes all messages arriving in `customerOrders`
    to produce real-time metrics on popular products.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个内部应用程序处理到达`customerOrders`的所有消息，以生成热门产品的实时指标。
- en: 'A secure deployment must guarantee:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 安全部署必须保证：
- en: Client authenticity
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端真实性
- en: When Alice establishes a client connection to the broker, the broker should
    authenticate the client to ensure that the message is really coming from Alice.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 当Alice建立与经纪人的客户端连接时，经纪人应对客户进行身份验证，以确保消息确实来自Alice。
- en: Server authenticity
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器真实性
- en: Before sending a message to the leader broker, Alice’s client should verify
    that the connection is to the real broker.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在向领导经纪人发送消息之前，Alice的客户端应验证连接是否真实。
- en: Data privacy
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 数据隐私
- en: All connections where the message flows, as well as all disks where messages
    are stored, should be encrypted or physically secured to prevent eavesdroppers
    from reading the data and to ensure that data cannot be stolen.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 消息流动的所有连接以及存储消息的所有磁盘都应该加密或物理上保护，以防窃听者读取数据，并确保数据不会被窃取。
- en: Data integrity
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据完整性
- en: Message digests should be included for data transmitted over insecure networks
    to detect tampering.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 应在通过不安全网络传输的数据中包含消息摘要以检测篡改。
- en: Access control
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 访问控制
- en: Before writing the message to the log, the leader broker should verify that
    Alice is authorized to write to `customerOrders`. Before returning messages to
    Bob’s consumer, the broker should verify that Bob is authorized to read from the
    topic. If Bob’s consumer uses group management, the broker should also verify
    that Bob has access to the consumer group.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在将消息写入日志之前，领导经纪人应验证Alice是否有权写入`customerOrders`。在将消息返回给Bob的消费者之前，经纪人应验证Bob是否有权从主题中读取消息。如果Bob的消费者使用组管理，则经纪人还应验证Bob是否有权访问消费者组。
- en: Auditability
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 审计性
- en: An audit trail that shows all operations that were performed by brokers, Alice,
    Bob, and other clients should be logged.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 应记录经纪人、Alice、Bob和其他客户执行的所有操作的审计跟踪。
- en: Availability
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 可用性
- en: Brokers should apply quotas and limits to avoid some users hogging all the available
    bandwidth or overwhelming the broker with denial-of-service attacks. ZooKeeper
    should be locked down to ensure availability of the Kafka cluster since broker
    availability is dependent on ZooKeeper availability and the integrity of metadata
    stored in ZooKeeper.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 经纪人应该应用配额和限制，以避免一些用户占用所有可用带宽或用拒绝服务攻击压倒经纪人。应该锁定ZooKeeper以确保Kafka集群的可用性，因为经纪人的可用性取决于ZooKeeper的可用性和ZooKeeper中存储的元数据的完整性。
- en: In the following sections, we explore the Kafka security features that can be
    used to provide these guarantees. We first introduce the Kafka connection model
    and the security protocols associated with connections from clients to Kafka brokers.
    We then look at each security protocol in detail and examine the authentication
    capabilities of each protocol to ascertain client authenticity and server authenticity.
    We review options for encryption at different stages, including built-in encryption
    of data in transit in some security protocols to address data privacy and data
    integrity. Then, we explore customizable authorization in Kafka to manage access
    control and the main logs that contribute to auditability. Finally, we review
    security for the rest of the system, including ZooKeeper and the platform, which
    is necessary to maintain availability. For details on quotas that contribute to
    service availability through fair allocation of resources among users, refer to
    [Chapter 3](ch03.html#writing_messages_to_kafka).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '在接下来的章节中，我们将探讨Kafka安全功能，这些功能可用于提供这些保证。我们首先介绍Kafka连接模型以及与客户端到Kafka经纪人的连接相关的安全协议。然后，我们详细查看每个安全协议，并检查每个协议的身份验证能力，以确定客户端真实性和服务器真实性。我们审查了不同阶段的加密选项，包括某些安全协议中数据在传输过程中的内置加密，以解决数据隐私和数据完整性问题。然后，我们探讨了Kafka中可定制的授权，以管理访问控制和有助于审计的主要日志。最后，我们审查了系统的其他安全性，包括ZooKeeper和必须维护可用性的平台。有关配额的详细信息，配额有助于通过在用户之间公平分配资源来提供服务的可用性，请参阅[第3章](ch03.html#writing_messages_to_kafka)。 '
- en: Security Protocols
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安全协议
- en: Kafka brokers are configured with listeners on one or more endpoints and accept
    client connections on these listeners. Each listener can be configured with its
    own security settings. Security requirements on a private internal listener that
    is physically protected and only accessible to authorized personnel may be different
    from the security requirements of an external listener accessible over the public
    internet. The choice of security protocol determines the level of authentication
    and encryption of data in transit.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka经纪人配置了一个或多个端点的侦听器，并在这些侦听器上接受客户端连接。每个侦听器可以配置自己的安全设置。在物理上受保护并且只对授权人员可访问的私有内部侦听器的安全要求可能与可通过公共互联网访问的外部侦听器的安全要求不同。安全协议的选择确定了数据在传输过程中的身份验证和加密级别。
- en: 'Kafka supports four security protocols using two standard technologies, TLS
    and SASL. Transport Layer Security (TLS), commonly referred to by the name of
    its predecessor, Secure Sockets Layer (SSL), supports encryption as well as client
    and server authentication. Simple Authentication and Security Layer (SASL) is
    a framework for providing authentication using different mechanisms in connection-oriented
    protocols. Each Kafka security protocol combines a transport layer (PLAINTEXT
    or SSL) with an optional authentication layer (SSL or SASL):'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka使用两种标准技术支持四种安全协议，即TLS和SASL。传输层安全性（TLS），通常称为其前身安全套接字层（SSL），支持加密以及客户端和服务器身份验证。简单认证和安全层（SASL）是提供使用不同机制进行身份验证的框架，用于连接导向的协议。每个Kafka安全协议都将传输层（PLAINTEXT或SSL）与可选的身份验证层（SSL或SASL）结合在一起：
- en: PLAINTEXT
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: PLAINTEXT
- en: PLAINTEXT transport layer with no authentication. Is suitable only for use within
    private networks for processing data that is not sensitive since no authentication
    or encryption is used.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: PLAINTEXT传输层，无身份验证。仅适用于私有网络中处理非敏感数据，因为没有使用身份验证或加密。
- en: SSL
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: SSL
- en: SSL transport layer with optional SSL client authentication. Is suitable for
    use in insecure networks since client and server authentication as well as encryption
    are supported.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: SSL传输层，带有可选的SSL客户端身份验证。适用于在不安全的网络中使用，因为支持客户端和服务器身份验证以及加密。
- en: SASL_PLAINTEXT
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: SASL_PLAINTEXT
- en: PLAINTEXT transport layer with SASL client authentication. Some SASL mechanisms
    also support server authentication. Does not support encryption and hence is suitable
    only for use within private networks.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: PLAINTEXT传输层，带有SASL客户端身份验证。一些SASL机制也支持服务器身份验证。不支持加密，因此仅适用于私有网络中使用。
- en: SASL_SSL
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: SASL_SSL
- en: SSL transport layer with SASL authentication. Is suitable for use in insecure
    networks since client and server authentication as well as encryption are supported.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: SSL传输层，带有SASL身份验证。适用于在不安全的网络中使用，因为支持客户端和服务器身份验证以及加密。
- en: TLS/SSL
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TLS/SSL
- en: TLS is one of the most widely used cryptographic protocols on the public internet.
    Application protocols like HTTP, SMTP, and FTP rely on TLS to provide privacy
    and integrity of data in transit. TLS relies on a Public Key Infrastructure (PKI)
    to create, manage, and distribute digital certificates that can be used for asymmetric
    encryption, avoiding the need for distributing shared secrets between servers
    and clients. Session keys generated during the TLS handshake enable symmetric
    encryption with higher performance for subsequent data transfer.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: TLS是公共互联网上最广泛使用的加密协议之一。应用程序协议如HTTP、SMTP和FTP依赖于TLS来提供数据在传输过程中的隐私和完整性。TLS依赖于公钥基础设施（PKI）来创建、管理和分发数字证书，这些证书可用于非对称加密，避免了在服务器和客户端之间分发共享密钥的需要。TLS握手期间生成的会话密钥使得后续数据传输可以使用更高性能的对称加密。
- en: 'The listener used for inter-broker communication can be selected by configuring
    `inter.broker.listener.name` or `security.inter.broker.protocol`. Both server-side
    and client-side configuration options must be provided in the broker configuration
    for the security protocol used for inter-broker communication. This is because
    brokers need to establish client connections for that listener. The following
    example configures SSL for the inter-broker and internal listeners, and SASL_SSL
    for the external listener:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 用于经纪人间通信的侦听器可以通过配置`inter.broker.listener.name`或`security.inter.broker.protocol`来选择。对于用于经纪人间通信的安全协议，必须在经纪人配置中提供服务器端和客户端端的配置选项。这是因为经纪人需要为该侦听器建立客户端连接。以下示例配置了SSL用于经纪人间和内部侦听器，以及SASL_SSL用于外部侦听器：
- en: '[PRE0]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Clients are configured with a security protocol and bootstrap servers that
    determine the broker listener. Metadata returned to clients contains only the
    endpoints corresponding to the same listener as the bootstrap servers:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端配置了安全协议和引导服务器，确定经纪人侦听器。返回给客户端的元数据仅包含与引导服务器相同侦听器对应的端点：
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the next section on authentication, we review the protocol-specific configuration
    options for brokers and clients for each security protocol.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将审查经纪人和客户端针对每种安全协议的特定于协议的配置选项。
- en: Authentication
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 认证
- en: Authentication is the process of establishing the identity of the client and
    server to verify client authenticity and server authenticity. When Alice’s client
    connects to the leader broker to produce a customer order record, server authentication
    enables the client to establish that the server that the client is talking to
    is the actual broker. Client authentication verifies Alice’s identity by validating
    Alice’s credentials, like a password or digital certificate, to determine that
    the connection is from Alice and not an impersonator. Once authenticated, Alice’s
    identity is associated with the connection throughout the lifetime of the connection.
    Kafka uses an instance of `KafkaPrincipal` to represent client identity and uses
    this principal to grant access to resources and allocate quotas for connections
    with that client identity. The `KafkaPrincipal` for each connection is established
    during authentication based on the authentication protocol. For example, the principal
    `User:Alice` may be used for Alice based on the username provided for password-based
    authentication. `KafkaPrincipal` may be customized by configuring `principal.builder.class`
    for brokers.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 认证是建立客户端和服务器身份以验证客户端真实性和服务器真实性的过程。当爱丽丝的客户端连接到领导经纪人以生成客户订单记录时，服务器认证使客户端能够确定客户端正在与实际经纪人交谈的服务器。客户端认证通过验证爱丽丝的凭据（如密码或数字证书）来验证爱丽丝的身份，以确定连接是来自爱丽丝而不是冒名顶替者。一旦经过身份验证，爱丽丝的身份将与连接的整个生命周期相关联。Kafka使用`KafkaPrincipal`的实例来表示客户端身份，并使用此主体为具有该客户端身份的连接授予访问资源和分配配额。每个连接的`KafkaPrincipal`在身份验证期间基于身份验证协议进行建立。例如，基于基于密码的身份验证提供的用户名，可以为爱丽丝使用主体`User:Alice`。`KafkaPrincipal`可以通过为经纪人配置`principal.builder.class`来进行自定义。
- en: Anonymous Connections
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 匿名连接
- en: The principal `User:ANONYMOUS` is used for unauthenticated connections. This
    includes clients on PLAINTEXT listeners as well as unauthenticated clients on
    SSL listeners.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 主体`User:ANONYMOUS`用于未经身份验证的连接。这包括PLAINTEXT侦听器上的客户端以及SSL侦听器上的未经身份验证的客户端。
- en: SSL
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SSL
- en: When Kafka is configured with SSL or SASL_SSL as the security protocol for a
    listener, TLS is used as the secure transport layer for connections on that listener.
    When a connection is established over TLS, the TLS handshake process performs
    authentication, negotiates cryptographic parameters, and generates shared keys
    for encryption. The server’s digital certificate is verified by the client to
    establish the identity of the server. If client authentication using SSL is enabled,
    the server also verifies the client’s digital certificate to establish the identity
    of the client. All traffic over SSL is encrypted, making it suitable for use in
    insecure networks.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 当Kafka配置为SSL或SASL_SSL作为侦听器的安全协议时，TLS用作该侦听器上连接的安全传输层。建立TLS连接时，TLS握手过程执行身份验证，协商加密参数，并生成用于加密的共享密钥。客户端验证服务器的数字证书以建立服务器的身份。如果启用SSL进行客户端身份验证，则服务器还验证客户端的数字证书以建立客户端的身份。所有SSL流量都是加密的，适用于不安全的网络。
- en: SSL Performance
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SSL性能
- en: SSL channels are encrypted and hence introduce a noticeable overhead in terms
    of CPU usage. Zero-copy transfer is currently not supported for SSL. Depending
    on the traffic pattern, the overhead may be up to 20–30%.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: SSL通道是加密的，因此在CPU使用方面引入了明显的开销。目前不支持SSL的零拷贝传输。根据流量模式，开销可能高达20-30%。
- en: Configuring TLS
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置TLS
- en: When TLS is enabled for a broker listener using SSL or SASL_SSL, brokers should
    be configured with a key store containing the broker’s private key and certificate,
    and clients should be configured with a trust store containing the broker certificate
    or the certificate of the certificate authority (CA) that signed the broker certificate.
    Broker certificates should contain the broker hostname as a Subject Alternative
    Name (SAN) extension or as the Common Name (CN) to enable clients to verify the
    server hostname. Wildcard certificates can be used to simplify administration
    by using the same key store for all brokers in a domain.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '当使用SSL或SASL_SSL为经纪人侦听器启用TLS时，经纪人应配置具有经纪人私钥和证书的密钥库，客户端应配置具有经纪人证书或签署经纪人证书的证书颁发机构（CA）的信任库。经纪人证书应包含经纪人主机名作为主题替代名称（SAN）扩展或作为通用名称（CN），以使客户端能够验证服务器主机名。通配符证书可用于简化管理，方法是为域中的所有经纪人使用相同的密钥库。  '
- en: Server Hostname verification
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '服务器主机名验证  '
- en: By default, Kafka clients verify that the hostname of the server stored in the
    server certificate matches the host that the client is connecting to. The connection
    hostname may be a bootstrap server that the client is configured with or an advertised
    listener hostname that was returned by a broker in a metadata response. Hostname
    verification is a critical part of server authentication that protects against
    man-in-the-middle attacks and hence should not be disabled in production systems.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '默认情况下，Kafka客户端验证存储在服务器证书中的主机名是否与客户端正在连接的主机匹配。连接主机名可以是客户端配置的引导服务器，也可以是经纪人在元数据响应中返回的广告侦听器主机名。主机名验证是服务器身份验证的关键部分，可防止中间人攻击，因此在生产系统中不应禁用。  '
- en: Brokers can be configured to authenticate clients connecting over listeners
    using SSL as the security protocol by setting the broker configuration option
    `ssl.​cli⁠ent.auth=required`. Clients should be configured with a key store, and
    brokers should be configured with a trust store containing client certificates
    or the certificate of the CAs that signed the client certificates. If SSL is used
    for inter-broker communication, broker trust stores should include the CA of the
    broker certificates as well as the CA of the client certificates. By default,
    the distinguished name (DN) of the client certificate is used as the `KafkaPrincipal`
    for authorization and quotas. The configuration option `ssl.principal.mapping.rules`
    can be used to provide a list of rules to customize the principal. Listeners using
    SASL_SSL disable TLS client authentication and rely on SASL authentication and
    the `KafkaPrincipal` established by SASL.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '通过设置经纪人配置选项`ssl.​cli⁠ent.auth=required`，可以配置经纪人使用SSL作为安全协议对连接到侦听器的客户端进行身份验证。客户端应配置具有密钥库，经纪人应配置具有客户端证书或签署客户端证书的CA证书的信任库。如果SSL用于经纪人之间的通信，经纪人信任库应包括经纪人证书的CA以及客户端证书的CA。默认情况下，客户端证书的可分辨名称（DN）用作授权和配额的`KafkaPrincipal`。配置选项`ssl.principal.mapping.rules`可用于提供一系列规则以自定义主体。使用SASL_SSL的侦听器禁用TLS客户端身份验证，并依赖于SASL身份验证和由SASL建立的`KafkaPrincipal`。  '
- en: SSL Client Authentication
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'SSL客户端身份验证  '
- en: SSL client authentication may be made optional by setting `ssl.​cli⁠ent.auth=requested`.
    Clients that are not configured with key stores will complete the TLS handshake
    in this case, but will be assigned the principal `User:ANONYMOUS`.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '通过设置`ssl.​cli⁠ent.auth=requested`，可以将SSL客户端身份验证设置为可选。在这种情况下，未配置密钥库的客户端将完成TLS握手，但将被分配主体`User:ANONYMOUS`。  '
- en: The following examples show how to create key stores and trust stores for server
    and client authentication using a self-signed CA.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '以下示例显示了如何使用自签名CA为服务器和客户端身份验证创建密钥库和信任库。  '
- en: 'Generate self-signed CA key-pair for brokers:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '为经纪人生成自签名CA密钥对：  '
- en: '[PRE2]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO1-1)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_securing_kafka_CO2-1)  '
- en: Create a key-pair for the CA and store it in a PKCS12 file server.ca.p12\. We
    use this for signing certificates.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '为CA创建密钥对，并将其存储在PKCS12文件server.ca.p12中。我们将用它来签署证书。  '
- en: '[![2](assets/2.png)](#co_securing_kafka_CO1-2)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_securing_kafka_CO1-2)  '
- en: Export the CA’s public certificate to server.ca.crt. This will be included in
    trust stores and certificate chains.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '将CA的公共证书导出到server.ca.crt。这将包含在信任库和证书链中。  '
- en: 'Create key stores for brokers with a certificate signed by the self-signed
    CA. If using wildcard hostnames, the same key store can be used for all brokers.
    Otherwise, create a key store for each broker with its fully qualified domain
    name (FQDN):'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '使用由自签名CA签名的证书为经纪人创建密钥库。如果使用通配符主机名，可以为所有经纪人使用相同的密钥库。否则，为每个经纪人创建一个具有其完全限定域名（FQDN）的密钥库：  '
- en: '[PRE3]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO2-1)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)  '
- en: Generate a private key for a broker and store it in the PKCS12 file server.ks.p12.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '为经纪人生成私钥，并将其存储在PKCS12文件server.ks.p12中。  '
- en: '[![2](assets/2.png)](#co_securing_kafka_CO2-2)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_securing_kafka_CO2-2)  '
- en: Generate a certificate signing request.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 生成证书签名请求。
- en: '[![3](assets/3.png)](#co_securing_kafka_CO2-3)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_securing_kafka_CO2-3)  '
- en: Use the CA key store to sign the broker’s certificate. The signed certificate
    is stored in server.crt.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '使用CA密钥库签署经纪人的证书。签署的证书存储在server.crt中。  '
- en: '[![4](assets/4.png)](#co_securing_kafka_CO2-4)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_securing_kafka_CO2-4)  '
- en: Import the broker’s certificate chain into the broker’s key store.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '将经纪人的证书链导入经纪人的密钥库。  '
- en: 'If TLS is used for inter-broker communication, create a trust store for brokers
    with the broker’s CA certificate to enable brokers to authenticate one another:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '如果TLS用于经纪人之间的通信，请为经纪人创建一个信任库，其中包含经纪人的CA证书，以使经纪人能够相互进行身份验证：  '
- en: '[PRE4]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Generate a trust store for clients with the broker’s CA certificate:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '为客户端生成一个信任库，其中包含经纪人的CA证书：  '
- en: '[PRE5]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If TLS client authentication is enabled, clients must be configured with a
    key store. The following script generates a self-signed CA for clients and creates
    a key store for clients with a certificate signed by the client CA. The client
    CA is added to the broker trust store so that brokers can verify client authenticity:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果启用了TLS客户端身份验证，则必须为客户端配置密钥存储。以下脚本为客户端生成一个自签名的CA，并创建一个由客户端CA签名的客户端密钥存储。客户端CA被添加到经纪人信任存储中，以便经纪人可以验证客户端的真实性：
- en: '[PRE6]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO3-1)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_securing_kafka_CO3-1)'
- en: We create a new CA for clients in this example.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，我们为客户端创建了一个新的CA。
- en: '[![2](assets/2.png)](#co_securing_kafka_CO3-2)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_securing_kafka_CO3-2)'
- en: Clients authenticating with this certificate use `User:CN=Metrics ⁠App,​O=Con⁠flu⁠ent,C=GB`
    as the principal, by default.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此证书进行身份验证的客户端默认使用`User:CN=Metrics ⁠App,​O=Con⁠flu⁠ent,C=GB`作为主体。
- en: '[![3](assets/3.png)](#co_securing_kafka_CO3-3)'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_securing_kafka_CO3-3)'
- en: We add the client certificate chain to the client key store.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将客户端证书链添加到客户端密钥存储中。
- en: '[![4](assets/4.png)](#co_securing_kafka_CO3-4)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_securing_kafka_CO3-4)'
- en: The broker’s trust store should contain the CAs of all clients.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 经纪人的信任存储应包含所有客户端的CA。
- en: 'Once we have the key and trust stores, we can configure TLS for brokers. Brokers
    require a trust store only if TLS is used for inter-broker communication or if
    client authentication is enabled:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了密钥和信任存储，我们就可以为经纪人配置TLS。只有在TLS用于经纪人之间的通信或启用了客户端身份验证时，经纪人才需要信任存储：
- en: '[PRE7]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Clients are configured with the generated trust store. The key store should
    be configured for clients if client authentication is required.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端配置了生成的信任存储。如果需要客户端身份验证，则应为客户端配置密钥存储。
- en: '[PRE8]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Trust Stores
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 信任存储
- en: Trust store configuration can be omitted in brokers as well as clients when
    using certificates signed by well-known trusted authorities. The default trust
    stores in the Java installation will be sufficient to establish trust in this
    case. Installation steps are described in [Chapter 2](ch02.html#installing_kafka).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 信任存储配置在经过知名受信任的机构签名的证书的经纪人和客户端中可以省略。在这种情况下，Java安装中的默认信任存储将足以建立信任。安装步骤在[第2章](ch02.html#installing_kafka)中有描述。
- en: 'Key stores and trust stores must be updated periodically before certificates
    expire to avoid TLS handshake failures. Broker SSL stores can be dynamically updated
    by modifying the same file or setting the configuration option to a new versioned
    file. In both cases, the Admin API or the Kafka configs tool can be used to trigger
    the update. The following example updates the key store for the external listener
    of a broker with broker id `0` using the configs tool:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 必须定期更新密钥存储和信任存储，以避免TLS握手失败。经纪人SSL存储可以通过修改相同的文件或将配置选项设置为新的带版本的文件来动态更新。在这两种情况下，可以使用Admin
    API或Kafka配置工具来触发更新。以下示例使用配置工具更新经纪人ID为`0`的经纪人的外部侦听器的密钥存储：
- en: '[PRE9]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Security considerations
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安全注意事项
- en: TLS is widely used to provide transport layer security for several protocols,
    including HTTPS. As with any security protocol, it is important to understand
    the potential threats and mitigation strategies when adopting a protocol for mission-critical
    applications. Kafka enables only the newer protocols TLSv1.2 and TLSv1.3 by default,
    since older protocols like TLSv1.1 have known vulnerabilities. Due to issues with
    insecure renegotiation, Kafka does not support renegotiation for TLS connections.
    Hostname verification is enabled by default to prevent man-in-the-middle attacks.
    Security can be tightened further by restricting cipher suites. Strong ciphers
    with at least a 256-bit encryption key size protect against cryptographic attacks
    and ensure data integrity when transporting data over an insecure network. Some
    organizations require TLS protocol and ciphers to be restricted to comply with
    security standards like FIPS 140-2.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: TLS广泛用于为多种协议提供传输层安全性，包括HTTPS。与任何安全协议一样，重要的是在采用协议用于关键任务的应用程序时了解潜在的威胁和缓解策略。Kafka默认只启用较新的协议TLSv1.2和TLSv1.3，因为较旧的协议如TLSv1.1存在已知的漏洞。由于存在不安全的重新协商问题，Kafka不支持TLS连接的重新协商。默认情况下启用主机名验证以防止中间人攻击。可以通过限制密码套件进一步加强安全性。具有至少256位加密密钥大小的强密码套件可防止密码攻击，并在通过不安全网络传输数据时确保数据完整性。一些组织要求TLS协议和密码套件受限以符合FIPS
    140-2等安全标准。
- en: Since key stores containing private keys are stored on the filesystem by default,
    it is vital to limit access to key store files using filesystem permissions. Standard
    Java TLS features can be used to enable certificate revocation if a private key
    is compromised. Short-lived keys can be used to reduce exposure in this case.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 由于默认情况下包含私钥的密钥存储存储在文件系统上，因此通过文件系统权限限制对密钥存储文件的访问至关重要。标准Java TLS功能可用于在私钥受损时启用证书吊销。在这种情况下，可以使用短寿命密钥来减少风险。
- en: TLS handshakes are expensive and utilize a significant amount of time on network
    threads in brokers. Listeners using TLS on insecure networks should be protected
    against denial-of-service attacks using connection quotas and limits to protect
    availability of brokers. The broker configuration option `connection.failed.​aut⁠hen⁠tication.delay.ms`
    can be used to delay failed response on authentication failures to reduce the
    rate at which authentication failures are retried by clients.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: TLS握手在经纪人的网络线程上消耗大量时间，是昂贵的。在不安全的网络上使用TLS的侦听器应受到连接配额和限制的保护，以保护经纪人的可用性免受拒绝服务攻击。经纪人配置选项`connection.failed.​aut⁠hen⁠tication.delay.ms`可用于在身份验证失败时延迟失败响应，以减少客户端重试身份验证失败的速率。
- en: SASL
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SASL
- en: 'Kafka protocol supports authentication using SASL and has built-in support
    for several commonly used SASL mechanisms. SASL can be combined with TLS as the
    transport layer to provide a secure channel with authentication and encryption.
    SASL authentication is performed through a sequence of server challenges and client
    responses where the SASL mechanism defines the sequence and wire format of challenges
    and responses. Kafka brokers support the following SASL mechanisms out of the
    box with customizable callbacks to integrate with existing security infrastructure:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka协议支持使用SASL进行身份验证，并内置支持几种常用的SASL机制。SASL可以与TLS结合使用作为传输层，以提供具有身份验证和加密的安全通道。SASL身份验证通过服务器挑战和客户端响应的序列执行，其中SASL机制定义了挑战和响应的序列和线路格式。Kafka经纪人直接支持以下SASL机制，并具有可定制的回调，以与现有安全基础设施集成：
- en: GSSAPI
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: GSSAPI
- en: Kerberos authentication is supported using SASL/GSSAPI and can be used to integrate
    with Kerberos servers like Active Directory or OpenLDAP.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Kerberos身份验证使用SASL/GSSAPI进行支持，并可用于与Active Directory或OpenLDAP等Kerberos服务器集成。
- en: PLAIN
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: PLAIN
- en: Username/password authentication that is typically used with a custom server-side
    callback to verify passwords from an external password store.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 使用自定义服务器端回调来验证来自外部密码存储的密码的用户名/密码身份验证。
- en: SCRAM-SHA-256 and SCRAM-SHA-512
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: SCRAM-SHA-256和SCRAM-SHA-512
- en: Username/password authentication available out of the box with Kafka without
    the need for additional password stores.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka可以直接使用用户名/密码进行身份验证，无需额外的密码存储。
- en: OAUTHBEARER
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: OAUTHBEARER
- en: Authentication using OAuth bearer tokens that is typically used with custom
    callbacks to acquire and validate tokens granted by standard OAuth servers.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 使用OAuth令牌进行身份验证，通常与自定义回调一起使用，以获取和验证标准OAuth服务器授予的令牌。
- en: One or more SASL mechanisms may be enabled on each SASL-enabled listener in
    the broker by configuring `sasl.enabled.mechanisms` for that listener. Clients
    may choose any of the enabled mechanisms by configuring `sasl.mechanism`.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 每个启用SASL的监听器上可以通过为该监听器配置`sasl.enabled.mechanisms`来启用一个或多个SASL机制。客户端可以通过配置`sasl.mechanism`选择任何已启用的机制。
- en: Kafka uses the Java Authentication and Authorization Service (JAAS) for configuring
    SASL. The configuration option `sasl.jaas.config` contains a single JAAS configuration
    entry that specifies a login module and its options. Brokers use the `listener`
    and `mechanism` prefixes when configuring `sasl.jaas.config`. For example, `listener.name.external.gssapi.sasl.jaas.config`
    configures the JAAS configuration entry for SASL/GSSAPI on the listener named
    `EXTERNAL`. The login process on brokers and clients uses the JAAS configuration
    to determine the public and private credentials used for authentication.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka使用Java身份验证和授权服务（JAAS）来配置SASL。配置选项`sasl.jaas.config`包含一个单个JAAS配置条目，指定登录模块及其选项。在配置`sasl.jaas.config`时，经纪人使用`listener`和`mechanism`前缀。例如，`listener.name.external.gssapi.sasl.jaas.config`配置了名为`EXTERNAL`的监听器上SASL/GSSAPI的JAAS配置条目。经纪人和客户端上的登录过程使用JAAS配置来确定用于身份验证的公共和私有凭据。
- en: JAAS Configuration File
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: JAAS配置文件
- en: JAAS configuration may also be specified in configuration files using the Java
    system property `java.security.auth.login.​con⁠fig`. However, the Kafka option
    `sasl.jaas.config` is recommended since it supports password protection and separate
    configuration for each SASL mechanism when multiple mechanisms are enabled on
    a listener.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以使用Java系统属性`java.security.auth.login.​con⁠fig`在配置文件中指定JAAS配置。但是，建议使用Kafka选项`sasl.jaas.config`，因为它支持密码保护，并且在监听器上启用多个机制时为每个SASL机制单独配置。
- en: SASL mechanisms supported by Kafka can be customized to integrate with third-party
    authentication servers using callback handlers. A login callback handler may be
    provided for brokers or clients to customize the login process, for example, to
    acquire credentials to be used for authentication. A server callback handler may
    be provided to perform authentication of client credentials, for example, to verify
    passwords using an external password server. A client callback handler may be
    provided to inject client credentials instead of including them in the JAAS configuration.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka支持的SASL机制可以定制，以与第三方身份验证服务器集成，使用回调处理程序。可以为经纪人或客户端提供登录回调处理程序，以自定义登录过程，例如获取用于身份验证的凭据。可以提供服务器回调处理程序来执行客户端凭据的身份验证，例如使用外部密码服务器验证密码。可以提供客户端回调处理程序来注入客户端凭据，而不是将它们包含在JAAS配置中。
- en: In the following subsections, we explore the SASL mechanisms supported by Kafka
    in more detail.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的小节中，我们将更详细地探讨Kafka支持的SASL机制。
- en: SASL/GSSAPI
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SASL/GSSAPI
- en: Kerberos is a widely used network authentication protocol that uses strong cryptography
    to support secure mutual authentication over an insecure network. Generic Security
    Service Application Program Interface (GSS-API) is a framework for providing security
    services to applications using different authentication mechanisms. [RFC-4752](https://oreil.ly/wxTZt)
    introduces the SASL mechanism GSSAPI for authentication using GSS-API’s Kerberos
    V5 mechanism. The availability of open source as well as enterprise-grade commercial
    implementations of Kerberos servers has made Kerberos a popular choice for authentication
    across many sectors with strict security requirements. Kafka supports Kerberos
    authentication using SASL/GSSAPI.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Kerberos是一种广泛使用的网络身份验证协议，使用强加密来支持在不安全网络上进行安全的相互身份验证。通用安全服务应用程序接口（GSS-API）是一个框架，用于为使用不同身份验证机制的应用程序提供安全服务。[RFC-4752](https://oreil.ly/wxTZt)介绍了使用GSS-API的Kerberos
    V5机制进行身份验证的SASL机制GSSAPI。开源和企业级商业实现的Kerberos服务器的可用性使Kerberos成为许多具有严格安全要求的部门身份验证的流行选择。Kafka支持使用SASL/GSSAPI进行Kerberos身份验证。
- en: Configuring SASL/GSSAPI
  id: totrans-130
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 配置SASL/GSSAPI
- en: 'Kafka uses GSSAPI security providers included in the Java runtime environment
    to support secure authentication using Kerberos. JAAS configuration for GSSAPI
    includes the path of a keytab file that contains the mapping of principals to
    their long-term keys in encrypted form. To configure GSSAPI for brokers, create
    a keytab for each broker with a principal that includes the broker’s hostname.
    Broker hostnames are verified by clients to ensure server authenticity and prevent
    man-in-the-middle attacks. Kerberos requires a secure DNS service for host name
    lookup during authentication. In deployments where forward and reverse lookup
    do not match, the Kerberos configuration file *krb5.conf* on clients can be configured
    to set `rdns=false` to disable reverse lookup. JAAS configuration for each broker
    should include the Kerberos V5 login module from the Java runtime, the pathname
    of the keytab file, and the full broker principal:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka使用Java运行时环境中包含的GSSAPI安全提供程序来支持使用Kerberos进行安全认证。GSSAPI的JAAS配置包括包含主体与其长期密钥的映射的密钥表文件的路径。要为代理配置GSSAPI，需要为每个代理创建一个包含代理主机名的主体的密钥表。客户端通过验证代理主机名来确保服务器的真实性并防止中间人攻击。Kerberos在认证期间需要安全的DNS服务来查找主机名。在前向和反向查找不匹配的部署中，可以在客户端的Kerberos配置文件*
    krb5.conf *中配置`rdns=false`来禁用反向查找。每个代理的JAAS配置应包括Java运行时环境中的Kerberos V5登录模块，密钥表文件的路径和完整的代理主体：
- en: '[PRE10]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO4-1)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_securing_kafka_CO4-1)'
- en: We use `sasl.jaas.config` prefixed with the listener prefix, which contains
    the listener name and SASL mechanism in lowercase.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以侦听器前缀为前缀的`sasl.jaas.config`，其中包含侦听器名称和小写的SASL机制。
- en: '[![2](assets/2.png)](#co_securing_kafka_CO4-2)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_securing_kafka_CO4-2)'
- en: Keytab files must be readable by the broker process.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 代理进程必须能够读取密钥表文件。
- en: '[![3](assets/3.png)](#co_securing_kafka_CO4-3)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_securing_kafka_CO4-3)'
- en: Service principal for brokers should include the broker hostname.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 代理的服务主体应包括代理主机名。
- en: 'If SASL/GSSAPI is used for inter-broker communication, inter-broker SASL mechanism
    and the Kerberos service name should also be configured for brokers:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果SASL/GSSAPI用于代理间通信，则还应为代理配置代理间SASL机制和Kerberos服务名称：
- en: '[PRE11]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Clients should be configured with their own keytab and principal in the JAAS
    configuration and `sasl.kerberos.service.name` to indicate the name of the service
    they are connecting to:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端应在JAAS配置和`sasl.kerberos.service.name`中配置自己的密钥表和主体，以指示它们正在连接的服务的名称：
- en: '[PRE12]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO5-1)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_securing_kafka_CO5-1)'
- en: The service name for the Kafka service should be specified for clients.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka服务的服务名称应该为客户端指定。
- en: '[![2](assets/2.png)](#co_securing_kafka_CO5-2)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_securing_kafka_CO5-2)'
- en: Clients may use principals without hostname.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端可以在没有主机名的情况下使用主体。
- en: The short name of the principal is used as the client identity by default. For
    example, `User:Alice` is the client principal and `User:kafka` is the broker principal
    in the example. The broker configuration `sasl.kerberos.principal.to.local.rules`
    can be used to apply a list of rules to transform the fully qualified principal
    to a custom principal.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，主体的短名称用作客户端标识。例如，在示例中，`User:Alice`是客户端主体，`User:kafka`是代理主体。代理配置`sasl.kerberos.principal.to.local.rules`可用于应用一系列规则来将完全限定的主体转换为自定义主体。
- en: Security considerations
  id: totrans-148
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安全注意事项
- en: Use of SASL_SSL is recommended in production deployments using Kerberos to protect
    the authentication flow as well as data traffic on the connection after authentication.
    If TLS is not used to provide a secure transport layer, eavesdroppers on the network
    may gain enough information to mount a dictionary attack or brute-force attack
    to steal client credentials. It is safer to use randomly generated keys for brokers
    instead of keys generated from passwords that are easier to crack. Weak encryption
    algorithms like DES-MD5 should be avoided in favor of stronger algorithms. Access
    to keytab files must be restricted using filesystem permissions since any user
    in possession of the file may impersonate the user.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Kerberos保护认证流和认证后的连接数据流的生产部署中，建议使用SASL_SSL。如果不使用TLS提供安全传输层，网络上的窃听者可能会获得足够的信息来发动字典攻击或暴力攻击以窃取客户端凭据。与使用易于破解的密码生成的密钥相比，更安全的做法是为代理使用随机生成的密钥。应避免使用DES-MD5等弱加密算法，而应使用更强大的算法。必须使用文件系统权限限制对密钥表文件的访问，因为拥有该文件的任何用户都可以冒充用户。
- en: SASL/GSSAPI requires a secure DNS service for server authentication. Because
    denial-of-service attacks against the KDC or DNS service can result in authentication
    failures in clients, it is necessary to monitor the availability of these services.
    Kerberos also relies on loosely synchronized clocks with configurable variability
    to detect replay attacks. It is important to ensure that clock synchronization
    is secure.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: SASL/GSSAPI需要安全的DNS服务进行服务器认证。由于针对KDC或DNS服务的拒绝服务攻击可能导致客户端的认证失败，因此有必要监视这些服务的可用性。Kerberos还依赖于具有可配置变化性的宽松同步时钟来检测重放攻击。确保时钟同步安全非常重要。
- en: SASL/PLAIN
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SASL/PLAIN
- en: '[RFC-4616](https://oreil.ly/wZrxB) defines a simple username/password authentication
    mechanism that can be used with TLS to provide secure authentication. During authentication,
    the client sends a username and password to the server, and the server verifies
    the password using its password store. Kafka has built-in SASL/PLAIN support that
    can be integrated with a secure external password database using a custom callback
    handler.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[RFC-4616](https://oreil.ly/wZrxB)定义了一种简单的用户名/密码认证机制，可与TLS一起使用以提供安全认证。在认证期间，客户端向服务器发送用户名和密码，服务器使用其密码存储验证密码。Kafka具有内置的SASL/PLAIN支持，可以与安全的外部密码数据库集成，使用自定义回调处理程序。'
- en: Configuring SASL/PLAIN
  id: totrans-153
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 配置SASL/PLAIN
- en: 'The default implementation of SASL/PLAIN uses the broker’s JAAS configuration
    as the password store. All client usernames and passwords are included as login
    options, and the broker verifies that the password provided by a client during
    authentication matches one of these entries. A broker username and password are
    required only if SASL/PLAIN is used for inter-broker communication:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: SASL/PLAIN的默认实现使用经纪人的JAAS配置作为密码存储。所有客户端用户名和密码都包括在登录选项中，经纪人验证客户端在认证期间提供的密码是否与这些条目中的一个匹配。只有在用于经纪人间通信的SASL/PLAIN时才需要经纪人用户名和密码：
- en: '[PRE13]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO6-1)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_securing_kafka_CO6-1)'
- en: The username and password used for inter-broker connections initiated by the
    broker.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 经纪人发起的经纪人间连接所使用的用户名和密码。
- en: '[![2](assets/2.png)](#co_securing_kafka_CO6-2)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_securing_kafka_CO6-2)'
- en: When Alice’s client connects to the broker, the password provided by Alice is
    validated against this password in the broker’s config.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 当Alice的客户端连接到经纪人时，Alice提供的密码将与经纪人配置中的密码进行验证。
- en: 'Clients must be configured with username and password for authentication:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端必须配置用户名和密码进行身份验证：
- en: '[PRE14]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The built-in implementation that stores all passwords in every broker’s JAAS
    configuration is insecure and not very flexible since all brokers will need to
    be restarted to add or remove a user. When using SASL/PLAIN in production, a custom
    server callback handler can be used to integrate brokers with a secure third-party
    password server. Custom callback handlers can also be used to support password
    rotation. On the server side, a server callback handler should support both old
    and new passwords for an overlapping period until all clients switch to the new
    password. The following example shows a callback handler that verifies encrypted
    passwords from files generated using the Apache tool `htpasswd`:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 内置实现将所有密码存储在每个经纪人的JAAS配置中，这是不安全的，也不够灵活，因为所有经纪人都需要重新启动以添加或删除用户。在生产环境中使用SASL/PLAIN时，可以使用自定义服务器回调处理程序将经纪人与安全的第三方密码服务器集成。自定义回调处理程序还可以用于支持密码轮换。在服务器端，服务器回调处理程序应支持新旧密码在重叠期间的使用，直到所有客户端切换到新密码。以下示例显示了一个回调处理程序，用于验证使用Apache工具`htpasswd`生成的文件中的加密密码：
- en: '[PRE15]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO7-1)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_securing_kafka_CO7-1)'
- en: We use multiple password files so that we can support password rotation.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用多个密码文件，以便支持密码轮换。
- en: '[![2](assets/2.png)](#co_securing_kafka_CO7-2)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_securing_kafka_CO7-2)'
- en: We pass pathnames of password files as a JAAS option in the broker configuration.
    Custom broker configuration options may also be used.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在经纪人配置的JAAS选项中传递密码文件的路径名。也可以使用自定义经纪人配置选项。
- en: '[![3](assets/3.png)](#co_securing_kafka_CO7-3)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_securing_kafka_CO7-3)'
- en: We check if the password matches in any of the files, allowing both old and
    new passwords to be used for a period of time.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检查密码是否匹配任何文件，允许在一段时间内使用旧密码和新密码。
- en: '[![4](assets/4.png)](#co_securing_kafka_CO7-4)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_securing_kafka_CO7-4)'
- en: We use `htpasswd` for simplicity. A secure database can be used for production
    deployments.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`htpasswd`来简化。生产部署可以使用安全数据库。
- en: 'Brokers are configured with the password validation callback handler and its
    options:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 经纪人配置了密码验证回调处理程序及其选项：
- en: '[PRE16]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'On the client side, a client callback handler that implements `org.apache.kafka.​com⁠mon.security.auth.AuthenticateCallbackHandler`
    can be used to load passwords dynamically at runtime when a connection is established
    instead of loading statically from the JAAS configuration during startup. Passwords
    may be loaded from encrypted files or using an external secure server to improve
    security. The following example loads passwords dynamically from a file using
    configuration classes in Kafka:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在客户端端，可以使用实现`org.apache.kafka.​com⁠mon.security.auth.AuthenticateCallbackHandler`的客户端回调处理程序，在建立连接时动态加载密码，而不是在启动期间从JAAS配置中静态加载。密码可以从加密文件或使用外部安全服务器加载，以提高安全性。以下示例使用Kafka中的配置类动态从文件加载密码：
- en: '[PRE17]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO8-1)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_securing_kafka_CO8-1)'
- en: We load the config file within the callback to ensure we use the latest password
    to support password rotation.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在回调函数中加载配置文件，以确保我们使用最新的密码来支持密码轮换。
- en: '[![2](assets/2.png)](#co_securing_kafka_CO8-2)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_securing_kafka_CO8-2)'
- en: The underlying configuration library returns the actual password value even
    if the password is externalized.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 即使密码是外部化的，底层配置库也会返回实际的密码值。
- en: '[![3](assets/3.png)](#co_securing_kafka_CO8-3)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_securing_kafka_CO8-3)'
- en: We define password configs with the `PASSWORD` type to ensure that passwords
    are not included in log entries.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`PASSWORD`类型定义密码配置，以确保密码不包含在日志条目中。
- en: 'Clients as well as brokers that use SASL/PLAIN for inter-broker communication
    can be configured with the client-side callback:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端和经纪人都可以配置使用客户端回调来进行SASL/PLAIN的经纪人间通信：
- en: '[PRE18]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Security considerations
  id: totrans-184
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安全考虑
- en: Since SASL/PLAIN transmits clear-text passwords over the wire, the PLAIN mechanism
    should be enabled only with encryption using SASL_SSL to provide a secure transport
    layer. Passwords stored in clear text in the JAAS configuration of brokers and
    clients are not secure, so consider encrypting or externalizing these passwords
    in a secure password store. Instead of using the built-in password store that
    stores all client passwords in the broker JAAS configuration, use a secure external
    password server that stores passwords securely and enforces strong password policies.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 由于SASL/PLAIN在传输中传输明文密码，因此应仅在使用SASL_SSL进行加密时启用PLAIN机制，以提供安全的传输层。在经纪人和客户端的JAAS配置中存储的明文密码是不安全的，因此请考虑在安全密码存储中加密或外部化这些密码。不要使用内置密码存储，该存储将所有客户端密码存储在经纪人的JAAS配置中，而是使用安全的外部密码服务器，该服务器安全地存储密码并强制执行强密码策略。
- en: Clear-Text Passwords
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 明文密码
- en: Avoid clear-text passwords in configuration files even if the files can be protected
    using filesystem permissions. Consider externalizing or encrypting passwords to
    ensure that passwords are not inadvertently exposed. Kafka’s password protection
    feature is described later in this chapter.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 即使可以使用文件系统权限保护文件，也应避免在配置文件中使用明文密码。考虑将密码外部化或加密，以确保密码不会被意外暴露。Kafka的密码保护功能将在本章后面进行描述。
- en: SASL/SCRAM
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SASL/SCRAM
- en: '[RFC-5802](https://oreil.ly/dXe3y) introduces a secure username/password authentication
    mechanism that addresses the security concerns with password authentication mechanisms
    like SASL/PLAIN, which send passwords over the wire. The Salted Challenge Response
    Authentication Mechanism (SCRAM) avoids transmitting clear-text passwords and
    stores passwords in a format that makes it impractical to impersonate clients.
    Salting combines passwords with some random data before applying a one-way cryptographic
    hash function to store passwords securely. Kafka has a built-in SCRAM provider
    that can be used in deployments with secure ZooKeeper without the need for additional
    password servers. The SCRAM mechanisms `SCRAM-SHA-256` and `SCRAM-SHA-512` are
    supported by the Kafka provider.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[RFC-5802](https://oreil.ly/dXe3y)介绍了一种安全的用户名/密码身份验证机制，解决了像SASL/PLAIN这样的密码身份验证机制发送密码的安全问题。盐挑战响应身份验证机制（SCRAM）避免传输明文密码，并以一种使得冒充客户端变得不切实际的格式存储密码。盐化将密码与一些随机数据结合，然后应用单向加密哈希函数以安全地存储密码。Kafka具有内置的SCRAM提供程序，可在具有安全ZooKeeper的部署中使用，无需额外的密码服务器。Kafka提供者支持SCRAM机制`SCRAM-SHA-256`和`SCRAM-SHA-512`。'
- en: Configuring SASL/SCRAM
  id: totrans-190
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 配置SASL/SCRAM
- en: 'An initial set of users can be created after starting ZooKeeper prior to starting
    brokers. Brokers load SCRAM user metadata into an in-memory cache during startup,
    ensuring that all users, including the broker user for inter-broker communication,
    can authenticate successfully. Users can be added or deleted at any time. Brokers
    keep the cache up-to-date using notifications based on a ZooKeeper watcher. In
    this example, we create a user with the principal `User:Alice` and password `Alice-password`
    for SASL mechanism `SCRAM-SHA-512`:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动代理之前，可以在启动ZooKeeper之前创建一组初始用户。代理在启动期间将SCRAM用户元数据加载到内存缓存中，确保所有用户，包括代理用户进行代理间通信，都可以成功进行身份验证。用户可以随时添加或删除。代理使用基于ZooKeeper
    watcher的通知来保持缓存的最新状态。在此示例中，我们为SASL机制`SCRAM-SHA-512`创建一个具有主体`User:Alice`和密码`Alice-password`的用户：
- en: '[PRE19]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'One or more SCRAM mechanisms can be enabled on a listener by configuring the
    mechanisms on the broker. A username and password are required for brokers only
    if the listener is used for inter-broker communication:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过在代理上配置机制来启用一个或多个SCRAM机制。只有在监听器用于代理间通信时，才需要为代理配置用户名和密码：
- en: '[PRE20]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO9-1)'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_securing_kafka_CO9-1)'
- en: Username and password for inter-broker connections initiated by the broker.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 代理发起的代理间连接的用户名和密码。
- en: 'Clients must be configured to use one of the SASL mechanisms enabled in the
    broker, and the client JAAS configuration must include a username and password:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 必须配置客户端以使用代理上启用的SASL机制之一，并且客户端JAAS配置必须包括用户名和密码：
- en: '[PRE21]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'You can add new SCRAM users using `--add-config` and delete users using the
    `--delete-config` option of the configs tool. When an existing user is deleted,
    new connections cannot be established for that user, but existing connections
    of the user will continue to work. A reauthentication interval can be configured
    for the broker to limit the amount of time existing connections may continue to
    operate after a user is deleted. The following example deletes the `SCRAM-SHA-512`
    config for `Alice` to remove Alice’s credentials for that mechanism:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`--add-config`添加新的SCRAM用户，并使用`--delete-config`选项删除用户。删除现有用户后，无法为该用户建立新连接，但用户的现有连接将继续工作。可以为代理配置重新认证间隔，以限制用户删除后现有连接可以继续操作的时间。以下示例删除了`Alice`的`SCRAM-SHA-512`配置，以删除该机制的Alice凭据：
- en: '[PRE22]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Security considerations
  id: totrans-201
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安全注意事项
- en: SCRAM applies a one-way cryptographic hash function on the password combined
    with a random salt to avoid the actual password being transmitted over the wire
    or stored in a database. However, any password-based system is only as secure
    as the passwords. Strong password policies must be enforced to protect the system
    from brute-force or dictionary attacks. Kafka provides safeguards by supporting
    only the strong hashing algorithms SHA-256 and SHA-512 and avoiding weaker algorithms
    like SHA-1\. This is combined with a high default iteration count of 4,096 and
    unique random salts for every stored key to limit the impact if ZooKeeper security
    is compromised.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: SCRAM对密码应用单向加密哈希函数，结合随机盐，以避免实际密码在传输过程中或存储在数据库中。然而，任何基于密码的系统只有密码强度高时才是安全的。必须执行强密码策略，以保护系统免受暴力或字典攻击。Kafka通过仅支持强哈希算法SHA-256和SHA-512，并避免像SHA-1这样的较弱算法来提供保障。这与默认迭代次数为4,096和每个存储密钥的唯一随机盐相结合，以限制如果ZooKeeper安全性受到损害的影响。
- en: You should take additional precautions to protect the keys transmitted during
    handshake and the keys stored in ZooKeeper to protect against brute-force attacks.
    SCRAM must be used with `SASL_SSL` as the security protocol to avoid eavesdroppers
    from gaining access to hashed keys during authentication. ZooKeeper must also
    be SSL-enabled, and ZooKeeper data must be protected using disk encryption to
    ensure that stored keys cannot be retrieved even if the store is compromised.
    In deployments without a secure ZooKeeper, SCRAM callbacks can be used to integrate
    with a secure external credential store.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在握手期间传输的密钥和存储在ZooKeeper中的密钥需要采取额外的预防措施，以防止暴力攻击。SCRAM必须与`SASL_SSL`一起使用作为安全协议，以避免窃听者在身份验证期间获取对哈希密钥的访问。ZooKeeper还必须启用SSL，并且必须使用磁盘加密来保护ZooKeeper数据，以确保即使存储被破坏，也无法检索存储的密钥。在没有安全ZooKeeper的部署中，可以使用SCRAM回调来与安全的外部凭据存储集成。
- en: SASL/OAUTHBEARER
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SASL/OAUTHBEARER
- en: OAuth is an authorization framework that enables applications to obtain limited
    access to HTTP services. [RFC-7628](https://oreil.ly/sPBfv) defines the OAUTHBEARER
    SASL mechanism that enables credentials obtained using OAuth 2.0 to access protected
    resources in non-HTTP protocols. OAUTHBEARER avoids security vulnerabilities in
    mechanisms that use long-term passwords by using OAuth 2.0 bearer tokens with
    a shorter lifetime and limited resource access. Kafka supports SASL/OAUTHBEARER
    for client authentication, enabling integration with third-party OAuth servers.
    The built-in implementation of OAUTHBEARER uses unsecured JSON Web Tokens (JWTs)
    and is not suitable for production use. Custom callbacks can be added to integrate
    with standard OAuth servers to provide secure authentication using the OAUTHBEARER
    mechanism in production deployments.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: OAuth是一种授权框架，使应用程序能够获取对HTTP服务的有限访问权限。[RFC-7628](https://oreil.ly/sPBfv)定义了OAUTHBEARER
    SASL机制，该机制使得使用OAuth 2.0获取的凭据能够访问非HTTP协议中的受保护资源。OAUTHBEARER通过使用OAuth 2.0承载令牌，具有较短的生命周期和有限的资源访问权限，避免了使用长期密码的机制中的安全漏洞。Kafka支持SASL/OAUTHBEARER用于客户端身份验证，从而使其能够与第三方OAuth服务器集成。内置的OAUTHBEARER实现使用不安全的JSON
    Web令牌（JWT），不适合生产使用。可以添加自定义回调以与标准OAuth服务器集成，以在生产部署中使用OAUTHBEARER机制进行安全身份验证。
- en: Configuring SASL/OAUTHBEARER
  id: totrans-206
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 配置SASL/OAUTHBEARER
- en: 'The built-in implementation of SASL/OAUTHBEARER in Kafka does not validate
    tokens and hence only requires the login module to be specified in the JAAS configuration.
    If the listener is used for inter-broker communication, details of the token used
    for client connections initiated by brokers must also be provided. The option
    `unsecuredLoginStringClaim_sub` is the subject claim that determines the `KafkaPrincipal`
    for the connection by default:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka中的SASL/OAUTHBEARER的内置实现不验证令牌，因此只需要在JAAS配置中指定登录模块。如果监听器用于经纪人之间的通信，则还必须提供经纪人发起的客户端连接所使用的令牌的详细信息。选项`unsecuredLoginStringClaim_sub`是默认情况下确定连接的`KafkaPrincipal`的主题声明：
- en: '[PRE23]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO10-1)'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png) (#co_securing_kafka_CO10-1)'
- en: Subject claim for the token used for inter-broker connections.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 用于经纪人连接的令牌的主题声明。
- en: 'Clients must be configured with the subject claim option `unsecuredLoginStringClaim_sub`.
    Other claims and token lifetime may also be configured:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端必须配置主题声明选项`unsecuredLoginStringClaim_sub`。还可以配置其他声明和令牌的生命周期：
- en: '[PRE24]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO11-1)'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png) (#co_securing_kafka_CO11-1)'
- en: '`User:Alice` is the default `KafkaPrincipal` for connections using this configuration.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '`User:Alice`是使用此配置进行连接的默认`KafkaPrincipal`。'
- en: 'To integrate Kafka with third-party OAuth servers for using bearer tokens in
    production, Kafka clients must be configured with `sasl.login.callback.handler.class`
    to acquire tokens from the OAuth server using the long-term password or a refresh
    token. If OAUTHBEARER is used for inter-broker communication, brokers must also
    be configured with a login callback handler to acquire tokens for client connections
    created by the broker for inter-broker communication:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将Kafka与第三方OAuth服务器集成，以在生产中使用承载令牌，Kafka客户端必须配置`sasl.login.callback.handler.class`，以使用长期密码或刷新令牌从OAuth服务器获取令牌。如果OAUTHBEARER用于经纪人之间的通信，则还必须为经纪人配置登录回调处理程序，以获取经纪人为经纪人通信创建的客户端连接的令牌：
- en: '[PRE25]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO12-1)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png) (#co_securing_kafka_CO12-1)'
- en: Clients must acquire a token from the OAuth server and set a valid token on
    the callback.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端必须从OAuth服务器获取令牌，并在回调中设置有效的令牌。
- en: '[![2](assets/2.png)](#co_securing_kafka_CO12-2)'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png) (#co_securing_kafka_CO12-2)'
- en: The client may also include optional extensions.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端还可以包括可选的扩展。
- en: 'Brokers must also be configured with a server callback handler using `listener.name.<listener-name>.oauthbearer.sasl.server.callback.handler.​class`
    for validating tokens provided by the client:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 经纪人还必须配置使用`listener.name.<listener-name>.oauthbearer.sasl.server.callback.handler.​class`的服务器回调处理程序来验证客户端提供的令牌：
- en: '[PRE26]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO13-1)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png) (#co_securing_kafka_CO13-1)'
- en: '`OAuthBearerValidatorCallback` contains the token from the client. Brokers
    validate this token.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '`OAuthBearerValidatorCallback`包含来自客户端的令牌。经纪人验证此令牌。'
- en: '[![2](assets/2.png)](#co_securing_kafka_CO13-2)'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png) (#co_securing_kafka_CO13-2)'
- en: Brokers validate any optional extensions from the client.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 经纪人验证来自客户端的任何可选扩展。
- en: Security considerations
  id: totrans-227
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安全注意事项
- en: Since SASL/OAUTHBEARER clients send OAuth 2.0 bearer tokens over the network
    and these tokens may be used to impersonate clients, TLS must be enabled to encrypt
    authentication traffic. Short-lived tokens can be used to limit exposure if tokens
    are compromised. Reauthentication may be enabled for brokers to prevent connections
    outliving the tokens used for authentication. A reauthentication interval configured
    on brokers, combined with token revocation support, limit the amount of time an
    existing connection may continue to use a token after revocation.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 由于SASL/OAUTHBEARER客户端通过网络发送OAuth 2.0承载令牌，并且这些令牌可能被用于冒充客户端，因此必须启用TLS以加密身份验证流量。如果令牌泄露，可以使用短暂的令牌来限制暴露。可以在经纪人上配置重新验证以防止连接超过用于身份验证的令牌的生命周期。经纪人上配置的重新验证间隔，结合令牌吊销支持，限制了现有连接在吊销后继续使用令牌的时间。
- en: Delegation tokens
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 委托令牌
- en: Delegation tokens are shared secrets between Kafka brokers and clients that
    provide a lightweight configuration mechanism without the requirement to distribute
    SSL key stores or Kerberos keytabs to client applications. Delegation tokens can
    be used to reduce the load on authentication servers, like the Kerberos Key Distribution
    Center (KDC). Frameworks like Kafka Connect can use delegation tokens to simplify
    security configuration for workers. A client that has authenticated with Kafka
    brokers can create delegation tokens for the same user principal and distribute
    these tokens to workers, which can then authenticate directly with Kafka brokers.
    Each delegation token consists of a token identifier and a hash-based message
    authentication code (HMAC) used as a shared secret. Client authentication with
    delegation tokens is performed using SASL/SCRAM with the token identifier as username
    and HMAC as the password.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 委托令牌是Kafka代理和客户端之间的共享秘密，提供了一种轻量级的配置机制，无需将SSL密钥存储或Kerberos密钥表分发给客户端应用程序。委托令牌可用于减少身份验证服务器的负载，例如Kerberos密钥分发中心（KDC）。像Kafka
    Connect这样的框架可以使用委托令牌来简化工作人员的安全配置。已经使用Kafka代理进行身份验证的客户端可以为相同的用户主体创建委托令牌，并将这些令牌分发给工作人员，然后工作人员可以直接与Kafka代理进行身份验证。每个委托令牌由令牌标识符和用作共享秘密的基于哈希的消息认证码（HMAC）组成。使用委托令牌进行客户端身份验证时，使用令牌标识符作为用户名，HMAC作为密码，使用SASL/SCRAM进行身份验证。
- en: 'Delegation tokens can be created or renewed using the Kafka Admin API or the
    `delegation-tokens` command. To create delegation tokens for the principal `User:Alice`,
    the client must be authenticated using Alice’s credentials for any authentication
    protocol other than delegation tokens. Clients authenticated using delegation
    tokens cannot create other delegation tokens:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 委托令牌可以使用Kafka Admin API或`delegation-tokens`命令创建或更新。要为主体`User:Alice`创建委托令牌，客户端必须使用Alice的凭据进行身份验证，除了委托令牌以外的任何身份验证协议。使用委托令牌进行身份验证的客户端无法创建其他委托令牌：
- en: '[PRE27]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO14-1)'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_securing_kafka_CO14-1)'
- en: If Alice runs this command, the generated token can be used to impersonate Alice.
    The owner of this token is `User:Alice`. We also configure `User:Bob` as a token
    renewer.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 如果Alice运行此命令，则生成的令牌可用于冒充Alice。此令牌的所有者是`User:Alice`。我们还将`User:Bob`配置为令牌更新者。
- en: '[![2](assets/2.png)](#co_securing_kafka_CO14-2)'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_securing_kafka_CO14-2)'
- en: The renewal command can be run by the token owner (Alice) or the token renewer
    (Bob).
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 续订命令可以由令牌所有者（Alice）或令牌更新者（Bob）运行。
- en: Configuring delegation tokens
  id: totrans-237
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 配置委托令牌
- en: To create and validate delegation tokens, all brokers must be configured with
    the same master key using the configuration option `delegation.token.master.key`.
    This key can only be rotated by restarting all brokers. All existing tokens should
    be deleted before updating the master key since they can no longer be used, and
    new tokens should be created after the key is updated on all brokers.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建和验证委托令牌，所有代理必须使用配置选项`delegation.token.master.key`配置相同的主密钥。只有通过重新启动所有代理才能旋转此密钥。在更新主密钥之前，应删除所有现有令牌，因为它们将不再可用，并且在所有代理上更新密钥后应创建新令牌。
- en: 'At least one of the SASL/SCRAM mechanisms must be enabled on brokers to support
    authentication using delegation tokens. Clients should be configured to use SCRAM
    with a token identifier as username and token HMAC as the password. The `Kafka​P⁠rincipal`
    for the connections using this configuration will be the original principal associated
    with the token, e.g., `User:Alice`:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 至少必须在代理上启用SASL/SCRAM机制之一，以支持使用委托令牌进行身份验证。客户端应配置为使用带有令牌标识符的SCRAM作为用户名，令牌HMAC作为密码。使用此配置进行连接的`Kafka​P⁠rincipal`将是与令牌关联的原始主体，例如`User:Alice`：
- en: '[PRE28]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO15-1)'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_securing_kafka_CO15-1)'
- en: SCRAM configuration with `tokenauth` is used to configure delegation tokens.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`tokenauth`的SCRAM配置用于配置委托令牌。
- en: Security considerations
  id: totrans-243
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安全考虑
- en: Like the built-in SCRAM implementation, delegation tokens are suitable for production
    use only in deployments where ZooKeeper is secure. All the security considerations
    described under SCRAM also apply to delegation tokens.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 与内置SCRAM实现一样，委托令牌仅适用于ZooKeeper安全的部署中的生产使用。SCRAM下描述的所有安全考虑也适用于委托令牌。
- en: The master key used by brokers for generating tokens must be protected using
    encryption or by externalizing the key in a secure password store. Short-lived
    delegation tokens can be used to limit exposure if a token is compromised. Reauthentication
    can be enabled in brokers to prevent connections operating with expired tokens
    and to limit the amount of time existing connections may continue to operate after
    token deletion.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 代理用于生成令牌的主密钥必须使用加密或通过将密钥外部化到安全密码存储中进行保护。如果令牌泄露，可以使用短暂的委托令牌来限制暴露。可以在代理中启用重新认证，以防止使用过期令牌的连接，并限制删除令牌后现有连接继续运行的时间。
- en: Reauthentication
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重新认证
- en: 'As we saw earlier, Kafka brokers perform client authentication when a connection
    is established by the client. Client credentials are verified by the brokers,
    and the connection authenticates successfully if the credentials are valid at
    that time. Some security mechanisms like Kerberos and OAuth use credentials with
    a limited lifetime. Kafka uses a background login thread to acquire new credentials
    before the old ones expire, but the new credentials are used only to authenticate
    new connections by default. Existing connections that were authenticated with
    old credentials continue to process requests until disconnection occurs due to
    a request timeout, an idle timeout, or network errors. Long-lived connections
    may continue to process requests long after the credentials used to authenticate
    the connections expire. Kafka brokers support reauthentication for connections
    authenticated using SASL using the configuration option `connections.max.reauth.ms`.
    When this option is set to a positive integer, Kafka brokers determine the session
    lifetime for SASL connections and inform clients of this lifetime during the SASL
    handshake. Session lifetime is the lower of the remaining lifetime of the credential
    or `connections.max.reauth.ms`. Any connection that doesn’t reauthenticate within
    this interval is terminated by the broker. Clients perform reauthentication using
    the latest credentials acquired by the background login thread or injected using
    custom callbacks. Reauthentication can be used to tighten security in several
    scenarios:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所看到的，Kafka 代理在客户端建立连接时执行客户端身份验证。代理验证客户端凭据，并且如果凭据在那时是有效的，连接将成功进行身份验证。一些安全机制（如
    Kerberos 和 OAuth）使用具有有限生命周期的凭据。Kafka 使用后台登录线程在旧凭据到期之前获取新凭据，但默认情况下新凭据仅用于验证新连接。使用旧凭据进行身份验证的现有连接将继续处理请求，直到由于请求超时、空闲超时或网络错误而发生断开连接。长期存在的连接可能会在用于身份验证的凭据到期后继续处理请求。Kafka
    代理支持使用配置选项`connections.max.reauth.ms`对使用 SASL 进行身份验证的连接进行重新认证。当将此选项设置为正整数时，Kafka
    代理确定 SASL 连接的会话生命周期，并在 SASL 握手期间通知客户端此生命周期。会话生命周期是凭据剩余生命周期或`connections.max.reauth.ms`的较小值。在此间隔内不重新认证的任何连接都将被代理终止。客户端使用后台登录线程获取的最新凭据或使用自定义回调注入的凭据进行重新认证。重新认证可用于在几种情况下加强安全性：
- en: For SASL mechanisms like GSSAPI and OAUTHBEARER that use credentials with a
    limited lifetime, reauthentication guarantees that all active connections are
    associated with valid credentials. Short-lived credentials limit exposure in case
    credentials that are compromised.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于像 GSSAPI 和 OAUTHBEARER 这样使用具有有限生命周期凭据的 SASL 机制，重新认证可以保证所有活动连接都与有效凭据关联。短期凭据限制了在凭据受损的情况下的暴露。
- en: Password-based SASL mechanisms like PLAIN and SCRAM can support password rotation
    by adding periodic login. Reauthentication limits the amount of time requests
    are processed on connections authenticated with the old password. Custom server
    callback that allows both old and new passwords for a period of time can be used
    to avoid outages until all clients migrate to the new password.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于密码的 SASL 机制（如 PLAIN 和 SCRAM）可以通过添加定期登录来支持密码轮换。重新认证限制了使用旧密码进行身份验证的连接上处理请求的时间。自定义服务器回调可以在一段时间内同时使用旧密码和新密码，以避免所有客户端迁移到新密码之前的中断。
- en: '`connections.max.reauth.ms` forces reauthentication in all SASL mechanisms,
    including those with nonexpiring credentials. This limits the amount of time a
    credential may be associated with an active connection after it has been revoked.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`connections.max.reauth.ms` 强制所有 SASL 机制重新认证，包括那些具有永不过期凭据的机制。这限制了凭据在被吊销后与活动连接关联的时间。'
- en: Connections from clients without SASL reauthentication support are terminated
    on session expiry, forcing the clients to reconnect and authenticate again, thus
    providing the same security guarantees for expired or revoked credentials.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不支持 SASL 重新认证的客户端的连接在会话到期时终止，迫使客户端重新连接和重新进行身份验证，从而为过期或被吊销的凭据提供相同的安全保证。
- en: Compromised Users
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 受损用户
- en: If a user is compromised, action must be taken to remove the user from the system
    as soon as possible. All new connections will fail to authenticate with Kafka
    brokers once the user is removed from the authentication server. Existing connections
    will continue to process requests until the next reauthentication timeout. If
    `connections.max.reauth.ms` is not configured, no timeout is applied and existing
    connections may continue to use the compromised user’s identity for a long time.
    Kafka does not support SSL renegotiation due to known vulnerabilities during renegotiation
    in older SSL protocols. Newer protocols like TLSv1.3 do not support renegotiation.
    So, existing SSL connections may continue to use revoked or expired certificates.
    `Deny` ACLs for the user principal can be used to prevent these connections from
    performing any operation. Since ACL changes are applied with very small latencies
    across all brokers, this is the quickest way to disable access for compromised
    users.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 如果用户受到威胁，必须立即采取行动将用户从系统中移除。一旦用户从认证服务器中移除，所有新连接将无法通过 Kafka 代理进行身份验证。现有连接将继续处理请求，直到下一次重新认证超时。如果未配置`connections.max.reauth.ms`，则不会应用超时，并且现有连接可能会继续长时间使用受损用户的身份。Kafka
    不支持 SSL 重新协商，因为在旧的 SSL 协议中重新协商存在已知的漏洞。更新的协议如 TLSv1.3 不支持重新协商。因此，现有的 SSL 连接可能会继续使用已吊销或过期的证书。用户主体的“拒绝”ACL可以用于阻止这些连接执行任何操作。由于
    ACL 更改在所有代理中的延迟非常小，这是禁用受损用户访问的最快方法。
- en: Security Updates Without Downtime
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无停机的安全更新
- en: Kafka deployments need regular maintenance to rotate secrets, apply security
    fixes, and update to the latest security protocols. Many of these maintenance
    tasks are performed using rolling updates where one by one, brokers are shut down
    and restarted with an updated configuration. Some tasks like updating SSL key
    stores and trust stores can be performed using dynamic config updates without
    restarting brokers.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka部署需要定期维护以轮换密钥、应用安全修复程序并更新到最新的安全协议。许多这些维护任务是使用滚动更新来执行的，其中一个接一个地关闭经纪人，并使用更新的配置重新启动。一些任务，如更新SSL密钥存储和信任存储，可以使用动态配置更新而无需重新启动经纪人。
- en: 'When adding a new security protocol to an existing deployment, a new listener
    can be added to brokers with the new protocol while retaining the old listener
    with the old protocol to ensure that client applications can continue to function
    using the old listener during the update. For example, the following sequence
    can be used to switch from PLAINTEXT to SASL_SSL in an existing deployment:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在现有部署中添加新的安全协议时，可以在经纪人上添加一个新的监听器以使用新协议，同时保留旧协议的旧监听器，以确保客户端应用程序在更新期间可以继续使用旧监听器。例如，可以使用以下顺序从PLAINTEXT切换到SASL_SSL：
- en: Add a new listener on a new port to each broker using the Kafka configs tool.
    Use a single config update command to update `listeners` and `advertised.​lis⁠teners`
    to include the old listener as well as the new listener, and provide all the configuration
    options for the new SASL_SSL listener with the listener prefix.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Kafka配置工具在每个经纪人上添加一个新的监听器到一个新的端口。使用单个配置更新命令来更新`listeners`和`advertised.​listeners`，包括旧的监听器以及新的监听器，并提供新的SASL_SSL监听器的所有配置选项。
- en: Modify all client applications to use the new SASL_SSL listener.
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改所有客户端应用程序以使用新的SASL_SSL监听器。
- en: If inter-broker communication is being updated to use the new SASL_SSL listener,
    perform a rolling update of brokers with the new `inter.broker.​lis⁠tener.name`.
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果正在更新经纪人间通信以使用新的SASL_SSL监听器，请执行经纪人的滚动更新，使用新的`inter.broker.​listener.name`。
- en: Use the configs tool to remove the old listener from `listeners` and `advertised.listeners`
    and to remove any unused configuration options of the old listener.
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用配置工具从`listeners`和`advertised.listeners`中移除旧的监听器，并移除旧监听器的任何未使用的配置选项。
- en: 'SASL mechanisms can be added or removed from existing SASL listeners without
    downtime using rolling updates on the same listener port. The following sequence
    switches the mechanism from PLAIN to SCRAM-SHA-256:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在现有的SASL监听器上添加或移除SASL机制，而无需停机，使用相同的监听器端口进行滚动更新。以下顺序将机制从PLAIN切换到SCRAM-SHA-256：
- en: Add all existing users to the SCRAM store using the Kafka configs tool.
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Kafka配置工具将所有现有用户添加到SCRAM存储中。
- en: Set `sasl.enabled.mechanisms=PLAIN,SCRAM-SHA-256`, configure `list⁠ener.​name.<_listener-name_>.scram-sha-256.sasl.jaas.config`
    for the listener, and perform a rolling update of brokers.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置`sasl.enabled.mechanisms=PLAIN,SCRAM-SHA-256`，为监听器配置`listener.​name.<_listener-name_>.scram-sha-256.sasl.jaas.config`，并执行经纪人的滚动更新。
- en: Modify all client applications to use `sasl.mechanism=SCRAM-SHA-256` and update
    `sasl.jaas.config` to use SCRAM.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改所有客户端应用程序以使用`sasl.mechanism=SCRAM-SHA-256`，并更新`sasl.jaas.config`以使用SCRAM。
- en: If the listener is used for inter-broker communication, use a rolling update
    of brokers to set `sasl.mechanism.inter.broker.protocol=SCRAM-SHA-256`.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果监听器用于经纪人间通信，请使用滚动更新经纪人来设置`sasl.mechanism.inter.broker.protocol=SCRAM-SHA-256`。
- en: Perform another rolling update of brokers to remove the PLAIN mechanism. Set
    `sasl.enabled.mechanisms=SCRAM-SHA-256` and remove `listener.name.​<listener-name>.plain.sasl.jaas.config`
    and any other configuration options for PLAIN.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行经纪人的另一个滚动更新以移除PLAIN机制。设置`sasl.enabled.mechanisms=SCRAM-SHA-256`并移除`listener.name.​<listener-name>.plain.sasl.jaas.config`和任何其他PLAIN的配置选项。
- en: Encryption
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加密
- en: Encryption is used to preserve data privacy and data integrity. As we discussed
    earlier, Kafka listeners using SSL and SASL_SSL security protocols use TLS as
    the transport layer, providing secure encrypted channels that protect data transmitted
    over an insecure network. TLS cipher suites can be restricted to strengthen security
    and adhere to security requirements like the Federal Information Processing Standard
    (FIPS).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 加密用于保护数据隐私和数据完整性。正如我们之前讨论的那样，使用SSL和SASL_SSL安全协议的Kafka监听器使用TLS作为传输层，提供安全加密通道，保护在不安全网络上传输的数据。TLS密码套件可以受限以加强安全性，并符合诸如联邦信息处理标准（FIPS）之类的安全要求。
- en: Additional measures must be taken to protect data at rest to ensure that sensitive
    data cannot be retrieved even by users with physical access to the disk that stores
    Kafka logs. To avoid security breaches even if the disk is stolen, physical storage
    can be encrypted using whole disk encryption or volume encryption.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 必须采取额外措施来保护静态数据，以确保即使是具有物理访问权限的用户也无法检索敏感数据，即使磁盘被盗，也要避免安全漏洞，可以使用整个磁盘加密或卷加密来加密物理存储。
- en: While encryption of transport layer and data storage may provide adequate protection
    in many deployments, additional protection may be required to avoid granting automatic
    data access to platform administrators. Unencrypted data present in broker memory
    may appear in heap dumps, and administrators with direct access to the disk will
    be able to access these, as well as Kafka logs containing potentially sensitive
    data. In deployments with highly sensitive data or Personally Identifiable Information
    (PII), extra measures are required to preserve data privacy. To comply with regulatory
    requirements, especially in cloud deployments, it is necessary to guarantee that
    confidential data cannot be accessed by platform administrators or cloud providers
    by any means. Custom encryption providers can be plugged into Kafka clients to
    implement end-to-end encryption that guarantees that the entire data flow is encrypted.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在许多部署中，传输层和数据存储的加密可能提供足够的保护，但可能需要额外的保护措施，以避免自动授予平台管理员对数据的访问权限。存储在经纪人内存中的未加密数据可能会出现在堆转储中，直接访问磁盘的管理员将能够访问这些数据，以及包含潜在敏感数据的Kafka日志。在具有高度敏感数据或个人身份信息（PII）的部署中，需要额外的措施来保护数据隐私。为了符合监管要求，特别是在云部署中，有必要保证机密数据无论如何都不能被平台管理员或云提供商访问。可以将自定义加密提供程序插入Kafka客户端，以实现端到端加密，从而保证整个数据流都是加密的。
- en: End-to-End Encryption
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 端到端加密
- en: In [Chapter 3](ch03.html#writing_messages_to_kafka) on Kafka producers, we saw
    that *serializers* are used to convert messages into the byte array stored in
    Kafka logs, and in [Chapter 4](ch04.html#reading_data_from_kafka) on Kafka consumers,
    we saw that *deserializers* converted the byte array back to the message. Serializers
    and deserializers can be integrated with an encryption library to perform encryption
    of the message during serialization, and decryption during deserialization. Message
    encryption is typically performed using symmetric encryption algorithms like AES.
    A shared encryption key stored in a key management system (KMS) enables producers
    to encrypt the message and consumers to decrypt the message. Brokers do not require
    access to the encryption key and never see the unencrypted contents of the message,
    making this approach safe to use in cloud environments. Encryption parameters
    that are required to decrypt the message may be stored in message headers or in
    the message payload if older consumers without header support need access to the
    message. A digital signature may also be included in message headers to verify
    message integrity.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在[Kafka生产者](ch03.html#writing_messages_to_kafka)的第3章中，我们看到*序列化器*用于将消息转换为存储在Kafka日志中的字节数组，在[Kafka消费者](ch04.html#reading_data_from_kafka)的第4章中，我们看到*反序列化器*将字节数组转换回消息。序列化器和反序列化器可以与加密库集成，以在序列化期间对消息进行加密，并在反序列化期间进行解密。消息加密通常使用像AES这样的对称加密算法。存储在密钥管理系统（KMS）中的共享加密密钥使生产者能够加密消息，消费者能够解密消息。经纪人不需要访问加密密钥，也永远不会看到消息的未加密内容，使得这种方法在云环境中使用是安全的。解密消息所需的加密参数可以存储在消息头中，或者如果旧的消费者不支持头部支持，则可以存储在消息有效负载中。数字签名也可以包含在消息头中，以验证消息的完整性。
- en: '[Figure 11-2](#fig-2-end-to-end-encryption) shows a Kafka data flow with end-to-end
    encryption.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '[图11-2](#fig-2-end-to-end-encryption)显示了具有端到端加密的Kafka数据流。'
- en: '![kdg2 1102](assets/kdg2_1102.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![kdg2 1102](assets/kdg2_1102.png)'
- en: Figure 11-2\. End-to-end encryption
  id: totrans-275
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-2\. 端到端加密
- en: We send a message using a Kafka producer.
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用Kafka生产者发送消息。
- en: The producer uses an encryption key from KMS to encrypt the message.
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生产者使用来自KMS的加密密钥对消息进行加密。
- en: The encrypted message is sent to the broker. The broker stores the encrypted
    message in the partition logs.
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加密消息被发送到经纪人。经纪人将加密消息存储在分区日志中。
- en: The broker sends the encrypted message to consumers.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 经纪人将加密消息发送给消费者。
- en: The consumer uses the encryption key from KMS to decrypt the message.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 消费者使用来自KMS的加密密钥解密消息。
- en: Producers and consumers must be configured with credentials to obtain shared
    keys from KMS. Periodic key rotation is recommended to harden security, since
    frequent rotation limits the number of compromised messages in case of a breach
    and also protects against brute-force attacks. Consumption must be supported with
    both old and new keys during the retention period of messages encrypted with the
    old key. Many KMS systems support graceful key rotation out of the box for symmetric
    encryption without requiring any special handling in Kafka clients. For compacted
    topics, messages encrypted with old keys may be retained for a long time, and
    it may be necessary to re-encrypt old messages. To avoid interference with newer
    messages, producers and consumers must be offline during this process.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 生产者和消费者必须配置凭据，以从KMS获取共享密钥。建议定期进行密钥轮换以加强安全性，因为频繁的轮换限制了在发生违规时受损消息的数量，并且还可以防止暴力攻击。在旧密钥的保留期内，消费必须支持旧密钥和新密钥。许多KMS系统支持对称加密的优雅密钥轮换，无需在Kafka客户端中进行任何特殊处理。对于紧凑型主题，使用旧密钥加密的消息可能会被保留很长时间，可能需要重新加密旧消息。为了避免干扰较新的消息，在此过程中生产者和消费者必须处于离线状态。
- en: Compression of Encrypted Messages
  id: totrans-282
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加密消息的压缩
- en: Compressing messages after encryption is unlikely to provide any benefit in
    terms of space reduction compared to compressing prior to encryption. Serializers
    may be configured to perform compression before encrypting the message, or applications
    may be configured to perform compression prior to producing messages. In either
    case, it is better to disable compression in Kafka since it adds overhead without
    providing any additional benefit. For messages transmitted over an insecure transport
    layer, known security exploits of compressed encrypted messages must also be taken
    into account.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在加密后压缩消息不太可能在减少空间方面提供任何好处，与加密之前的压缩相比。 序列化器可以配置为在加密消息之前执行压缩，或者可以配置应用程序在生成消息之前执行压缩。
    在任何情况下，最好在Kafka中禁用压缩，因为它会增加开销而不提供任何额外的好处。 对于通过不安全的传输层传输的消息，还必须考虑压缩加密消息的已知安全漏洞。
- en: In many environments, especially when TLS is used as the transport layer, message
    keys do not require encryption since they typically do not contain sensitive data
    like message payloads. But in some cases, clear-text keys may not comply with
    regulatory requirements. Since message keys are used for partitioning and compaction,
    transformation of keys must preserve the required hash equivalence to ensure that
    a key retains the same hash value even if encryption parameters are altered. One
    approach would be to store a secure hash of the original key as the message key
    and store the encrypted message key in the message payload or in a header. Since
    Kafka serializes message key and value independently, a producer interceptor can
    be used to perform this transformation.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多环境中，特别是在使用TLS作为传输层时，消息键不需要加密，因为它们通常不包含像消息有效负载那样的敏感数据。 但在某些情况下，明文密钥可能不符合监管要求。
    由于消息键用于分区和压缩，因此必须保留密钥的所需哈希等价性，以确保即使更改加密参数，密钥仍保留相同的哈希值。 一种方法是将原始密钥的安全哈希存储为消息密钥，并将加密的消息密钥存储在消息有效负载或标头中。
    由于Kafka独立序列化消息键和值，因此可以使用生产者拦截器执行此转换。
- en: Authorization
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 授权
- en: Authorization is the process that determines what operations you are allowed
    to perform on which resources. Kafka brokers manage access control using a customizable
    authorizer. We saw earlier that whenever connections are established from a client
    to a broker, the broker authenticates the client and associates a `KafkaPrincipal`
    that represents the client identity with the connection. When a request is processed,
    the broker verifies that the principal associated with the connection is authorized
    to perform that request. For example, when Alice’s producer attempts to write
    a new customer order record to the topic `customerOrders`, the broker verifies
    that `User:Alice` is authorized to write to that topic.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 授权是确定您可以在哪些资源上执行哪些操作的过程。 Kafka代理使用可定制的授权器管理访问控制。 我们之前看到，每当从客户端到代理建立连接时，代理都会对客户端进行身份验证，并将代表客户端身份的`KafkaPrincipal`与连接关联起来。
    处理请求时，代理会验证与连接关联的主体是否被授权执行该请求。 例如，当Alice的生产者尝试将新的客户订单记录写入主题`customerOrders`时，代理会验证`User:Alice`是否被授权写入该主题。
- en: 'Kafka has a built-in authorizer, `AclAuthorizer`, that can be enabled by configuring
    the authorizer class name as follows:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka具有内置的授权器`AclAuthorizer`，可以通过配置授权器类名来启用，如下所示：
- en: '[PRE29]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: SimpleAclAuthorizer
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SimpleAclAuthorizer
- en: '`AclAuthorizer` was introduced in Apache Kafka 2.3\. Older versions from 0.9.0.0
    onward had a built-in authorizer, `kafka.security.auth.SimpleAclAuthorizer`, which
    has been deprecated but is still supported.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '`AclAuthorizer`在Apache Kafka 2.3中引入。 从0.9.0.0版本开始，旧版本具有内置的授权器`kafka.security.auth.SimpleAclAuthorizer`，该授权器已被弃用，但仍受支持。'
- en: AclAuthorizer
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AclAuthorizer
- en: '`AclAuthorizer` supports fine-grained access control for Kafka resources using
    access control lists (ACLs). ACLs are stored in ZooKeeper and cached in memory
    by every broker to enable high-performance lookup for authorizing requests. ACLs
    are loaded into the cache when the broker starts up, and the cache is kept up-to-date
    using notifications based on a ZooKeeper watcher. Every Kafka request is authorized
    by verifying that the `KafkaPrincipal` associated with the connection has permissions
    to perform the requested operation on the requested resources.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '`AclAuthorizer`支持使用访问控制列表（ACL）对Kafka资源进行细粒度访问控制。 ACL存储在ZooKeeper中，并且每个代理都会将其缓存在内存中，以便对请求进行授权进行高性能查找。
    当代理启动时，ACL将加载到缓存中，并且使用基于ZooKeeper watcher的通知来保持缓存的最新状态。 通过验证与连接关联的`KafkaPrincipal`是否具有执行所请求操作的权限来授权每个Kafka请求。'
- en: 'Each ACL binding consists of:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 每个ACL绑定包括：
- en: 'Resource type: `Cluster|Topic|Group|TransactionalId|DelegationToken`'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 资源类型：`Cluster|Topic|Group|TransactionalId|DelegationToken`
- en: 'Pattern type: `Literal|Prefixed`'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模式类型：`Literal|Prefixed`
- en: 'Resource name: Name of the resource or prefix, or the wildcard `*`'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 资源名称：资源或前缀的名称，或通配符`*`
- en: 'Operation: `Describe|Create|Delete|Alter|Read|Write|DescribeConfigs|AlterConfigs`'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作：`Describe|Create|Delete|Alter|Read|Write|DescribeConfigs|AlterConfigs`
- en: 'Permission type: `Allow|Deny`; `Deny` has higher precedence.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 权限类型：`Allow|Deny`；`Deny`具有更高的优先级。
- en: 'Principal: Kafka principal represented as <principalType>:<principalName>,
    e.g., `User:Bob` or `Group:Sales`. ACLs may use `User:*` to grant access to all
    users.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主体：Kafka主体表示为<principalType>:<principalName>，例如，`User:Bob`或`Group:Sales`。 ACL可以使用`User:*`来授予所有用户访问权限。
- en: 'Host: Source IP address of the client connection or `*` if all hosts are authorized.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主机：客户端连接的源IP地址，或者如果所有主机都被授权，则为`*`。
- en: 'For example, an ACL may specify:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，ACL可以指定：
- en: '[PRE30]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '`AclAuthorizer` authorizes an action if there are no `Deny` ACLs that match
    the action and there is at least one `Allow` ACL that matches the action. `Describe`
    permission is implicitly granted if `Read`, `Write`, `Alter`, or `Delete` permission
    is granted. `DescribeConfigs` permission is implicitly granted if `AlterConfigs`
    permission is granted.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有与操作匹配的`Deny` ACL，并且至少有一个与操作匹配的`Allow` ACL，则`AclAuthorizer`会授权操作。 如果授予`Read`、`Write`、`Alter`或`Delete`权限，则隐含授予`Describe`权限。
    如果授予`AlterConfigs`权限，则隐含授予`DescribeConfigs`权限。
- en: Wildcard ACLs
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通配符ACL
- en: ACLs with pattern type `Literal` and resource name `*` are used as wildcard
    ACLs that match all resource names of a resource type.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 使用模式类型`Literal`和资源名称`*`的ACL用作通配符ACL，匹配资源类型的所有资源名称。
- en: Brokers must be granted `Cluster:ClusterAction` access in order to authorize
    controller requests and replica fetch requests. Producers require `Topic:Write`
    for producing to a topic. For idempotent produce without transactions, producers
    must also be granted `Cluster:IdempotentWrite`. Transactional producers require
    `TransactionalId:Write` access to the transaction IS and `Group:Read` for consumer
    groups to commit offsets. Consumers require `Topic:Read` to consume from a topic
    and `Group:Read` for the consumer group if using group management or offset management.
    Administrative operations require appropriate `Create`, `Delete`, `Describe`,
    `Alter`, `DescribeConfigs`, or `AlterConfigs` access. [Table 11-1](#table-1-acls)
    shows the Kafka requests to which each ACL is applied.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 必须授予代理`Cluster:ClusterAction`访问权限，以授权控制器请求和副本获取请求。生产者需要`Topic:Write`来生产到主题。对于无事务的幂等生产，生产者还必须被授予`Cluster:IdempotentWrite`。事务性生产者需要对事务IS的`TransactionalId:Write`访问以及对消费者组的`Group:Read`以提交偏移量。消费者需要`Topic:Read`来从主题中消费，以及使用组管理或偏移管理时的消费者组的`Group:Read`。管理操作需要适当的`Create`，`Delete`，`Describe`，`Alter`，`DescribeConfigs`或`AlterConfigs`访问权限。[表11-1](#table-1-acls)显示了每个ACL应用的Kafka请求。
- en: Table 11-1\. Access granted for each Kafka ACL
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 表11-1. 每个Kafka ACL授予的访问权限
- en: '| ACL | Kafka requests | Notes |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: ACL | Kafka请求 | 备注 |
- en: '| --- | --- | --- |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `Cluster:ClusterAction` | Inter-broker requests, including controller requests
    and follower fetch requests for replication | Should only be granted to brokers.
    |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| `Cluster:ClusterAction` | 代理间请求，包括控制器请求和用于复制的追随者获取请求 | 只应授予代理。 |'
- en: '| `Cluster:Create` | `CreateTopics` and auto-topic creation | Use `Topic:Create`
    for fine-grained access control to create specific topics. |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| `Cluster:Create` | `CreateTopics` 和自动主题创建 | 使用`Topic:Create`进行细粒度访问控制以创建特定主题。
    |'
- en: '| `Cluster:Alter` | `CreateAcls`, `DeleteAcls`, `AlterReplicaLogDirs`, `ElectReplicaLeader`,
    `Alter​PartitionReassignments` |  |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| `Cluster:Alter` | `CreateAcls`，`DeleteAcls`，`AlterReplicaLogDirs`，`ElectReplicaLeader`，`Alter​PartitionReassignments`
    |  |'
- en: '| `Cluster:AlterConfigs` | `AlterConfigs` and `IncrementalAlterConfigs` for
    broker and broker logger, `AlterClientQuotas` |  |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| `Cluster:AlterConfigs` | 代理和代理记录器的`AlterConfigs` 和 `IncrementalAlterConfigs`，`AlterClientQuotas`
    |  |'
- en: '| `Cluster:Describe` | `DescribeAcls`, `DescribeLogDirs`, `ListGroups`, `ListPartitionReassignments`,
    describing authorized operations for cluster in Metadata request | Use `Group:Describe`
    for fine-grained access control for ListGroups. |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| `Cluster:Describe` | `DescribeAcls`，`DescribeLogDirs`，`ListGroups`，`ListPartitionReassignments`，描述元数据请求中集群的授权操作
    | 使用`Group:Describe`进行细粒度访问控制以列出组。 |'
- en: '| `Cluster:DescribeConfigs` | `DescribeConfigs` for broker and broker logger,
    `DescribeClientQuotas` |  |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| `Cluster:DescribeConfigs` | 代理和代理记录器的`DescribeConfigs`，`DescribeClientQuotas`
    |  |'
- en: '| `Cluster:IdempotentWrite` | Idempotent `InitProducerId` and `Produce` requests
    | Only required for nontransactional idempotent producers. |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| `Cluster:IdempotentWrite` | 幂等的`InitProducerId` 和 `Produce` 请求 | 仅对非事务幂等生产者需要。
    |'
- en: '| `Topic:Create` | `CreateTopics` and auto-topic creation |  |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| `Topic:Create` | `CreateTopics` 和自动主题创建 |  |'
- en: '| `Topic:Delete` | `DeleteTopics`, `DeleteRecords` |  |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| `Topic:Delete` | `DeleteTopics`，`DeleteRecords` |  |'
- en: '| `Topic:Alter` | `CreatePartitions` |  |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| `Topic:Alter` | `CreatePartitions` |  |'
- en: '| `Topic:AlterConfigs` | `AlterConfigs` and `IncrementalAlterConfigs` for topics
    |  |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| `Topic:AlterConfigs` | 主题的`AlterConfigs` 和 `IncrementalAlterConfigs` |  |'
- en: '| `Topic:Describe` | Metadata request for topic, `OffsetForLeaderEpoch`, `ListOffset`,
    `OffsetFetch` |  |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| `Topic:Describe` | 主题的元数据请求，`OffsetForLeaderEpoch`，`ListOffset`，`OffsetFetch`
    |  |'
- en: '| `Topic:DescribeConfigs` | `DescribeConfigs` for topics, for returning configs
    in `CreateTopics` response |  |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| `Topic:DescribeConfigs` | 主题的`DescribeConfigs`，用于在`CreateTopics`响应中返回配置 |  |'
- en: '| `Topic:Read` | `Consumer Fetch`, `OffsetCommit`, `TxnOffsetCommit`, `OffsetDelete`
    | Should be granted to consumers. |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| `Topic:Read` | `Consumer Fetch`，`OffsetCommit`，`TxnOffsetCommit`，`OffsetDelete`
    | 应授予消费者。 |'
- en: '| `Topic:Write` | `Produce`, `AddPartitionToTxn` | Should be granted to producers.
    |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| `Topic:Write` | `Produce`，`AddPartitionToTxn` | 应授予生产者。 |'
- en: '| `Group:Read` | `JoinGroup`, `SyncGroup`, `LeaveGroup`, `Heartbeat`, `OffsetCommit`,
    `AddOffsetsToTxn`, `TxnOffsetCommit` | Required for consumers using consumer group
    management or Kafka-based offset management. Also required for transactional producers
    to commit offsets within a transaction. |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| `Group:Read` | `JoinGroup`，`SyncGroup`，`LeaveGroup`，`Heartbeat`，`OffsetCommit`，`AddOffsetsToTxn`，`TxnOffsetCommit`
    | 消费者使用消费者组管理或基于Kafka的偏移管理时需要。事务性生产者在事务中提交偏移量时也需要。 |'
- en: '| `Group:Describe` | `FindCoordinator`, `DescribeGroup`, `ListGroups`, `OffsetFetch`
    |  |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| `Group:Describe` | `FindCoordinator`，`DescribeGroup`，`ListGroups`，`OffsetFetch`
    |  |'
- en: '| `Group:Delete` | `DeleteGroups`, `OffsetDelete` |  |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| `Group:Delete` | `DeleteGroups`，`OffsetDelete` |  |'
- en: '| `TransactionalId:Write` | `Produce` and `InitProducerId` with transactions,
    `AddPartitionToTxn`, `AddOffsetsToTxn`, `TxnOffsetCommit`, `EndTxn` | Required
    for transactional producers. |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| `TransactionalId:Write` | `Produce` 和 `InitProducerId` 与事务，`AddPartitionToTxn`，`AddOffsetsToTxn`，`TxnOffsetCommit`，`EndTxn`
    | 事务性生产者所需。 |'
- en: '| `TransactionalId:​Describe` | `FindCoordinator` for transaction coordinator
    |  |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| `TransactionalId:​Describe` | 事务协调器的`FindCoordinator` |  |'
- en: '| `DelegationToken:​Describe` | `DescribeTokens` |  |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| `DelegationToken:​Describe` | `DescribeTokens` |  |'
- en: 'Kafka provides a tool for managing ACLs using the authorizer configured in
    brokers. ACLs can be created directly in ZooKeeper as well. This is useful to
    create broker ACLs prior to starting brokers:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka提供了一个工具，用于使用在代理中配置的授权者来管理ACL。 ACL也可以直接在ZooKeeper中创建。这对于在启动代理之前创建代理ACL非常有用：
- en: '[PRE31]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO16-1)'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_securing_kafka_CO16-1)'
- en: ACLs for broker user are created directly in ZooKeeper.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 代理用户的ACL直接在ZooKeeper中创建。
- en: '[![2](assets/2.png)](#co_securing_kafka_CO16-2)'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_securing_kafka_CO16-2)'
- en: By default, the ACLs command grants literal ACLs. `User:Alice` is granted access
    to write to the topic `customerOrders`.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，ACLs命令授予文字ACLs。`User:Alice`被授予对主题`customerOrders`的写入访问权限。
- en: '[![3](assets/3.png)](#co_securing_kafka_CO16-3)'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_securing_kafka_CO16-3)'
- en: The prefixed ACL grants permission for Bob to read all topics starting with
    `customer`.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 前缀ACL授予Bob读取以`customer`开头的所有主题的权限。
- en: '`AclAuthorizer` has two configuration options to grant broad access to resources
    or principals in order to simplify management of ACLs, especially when adding
    authorization to existing clusters for the first time:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '`AclAuthorizer`有两个配置选项，用于授予资源或主体广泛访问权限，以简化ACL的管理，特别是在首次向现有集群添加授权时：'
- en: '[PRE32]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Super users are granted access for all operations on all resources without any
    restrictions and cannot be denied access using `Deny` ACLs. If Carol’s credentials
    are compromised, Carol must be removed from `super.users`, and brokers must be
    restarted to apply the changes. It is safer to grant specific access using ACLs
    to users in production systems to ensure access can be revoked easily, if required.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 超级用户被授予对所有资源的所有操作的访问权限，没有任何限制，并且不能使用“拒绝”ACL拒绝访问。如果Carol的凭据被泄露，必须将Carol从`super.users`中移除，并且必须重新启动代理以应用更改。在生产系统中更安全的做法是使用ACL向用户授予特定访问权限，以确保可以轻松地撤销访问权限（如果需要）。
- en: Super User Separator
  id: totrans-342
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超级用户分隔符
- en: Unlike other list configurations in Kafka that are comma-separated, `super.users`
    are separated by a semicolon since user principals such as distinguished names
    from SSL certificates often contain commas.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 与Kafka中的其他列表配置不同，`super.users`是用分号分隔的，因为用户主体（例如来自SSL证书的可分辨名称）通常包含逗号。
- en: If `allow.everyone.if.no.acl.found` is enabled, all users are granted access
    to resources without any ACLs. This option may be useful when enabling authorization
    for the first time in a cluster or during development, but is not suitable for
    production use since access may be granted unintentionally to new resources. Access
    may also be unexpectedly removed when ACLs for a matching prefix or wildcard are
    added if the condition for `no.acl.found` no longer applies.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '如果启用了`allow.everyone.if.no.acl.found`，则所有用户都将被授予对资源的访问权限，而无需任何ACL。此选项在首次在集群中启用授权或在开发过程中可能会有用，但不适用于生产环境，因为可能会意外地向新资源授予访问权限。如果不再满足`no.acl.found`条件，则当为匹配前缀或通配符添加ACL时，访问权限也可能会意外地被移除。 '
- en: Customizing Authorization
  id: totrans-345
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自定义授权
- en: Authorization can be customized in Kafka to implement additional restrictions
    or add new types of access control, like role-based access control.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka中的授权可以定制以实现额外的限制或添加新类型的访问控制，如基于角色的访问控制。
- en: 'The following custom authorizer restricts usage of some requests to the internal
    listener alone. For simplicity, the requests and listener name are hard-coded
    here, but they can be configured using custom authorizer properties instead for
    flexibility:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 以下自定义授权器将某些请求的使用限制在内部侦听器上。为简单起见，这里将请求和侦听器名称硬编码，但可以改为使用自定义授权器属性进行配置，以实现灵活性：
- en: '[PRE33]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO17-1)'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_securing_kafka_CO17-1)'
- en: Authorizers are given the request context with metadata that includes listener
    names, security protocol, request types, etc., enabling custom authorizers to
    add or remove restrictions based on the context.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 授权器使用包含侦听器名称、安全协议、请求类型等元数据的请求上下文，使得自定义授权器可以根据上下文添加或删除限制。
- en: '[![2](assets/2.png)](#co_securing_kafka_CO17-2)'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_securing_kafka_CO17-2)'
- en: We reuse functionality from the built-in Kafka authorizer using the public API.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重复使用内置Kafka授权器的功能，使用公共API。
- en: 'Kafka authorizer can also be integrated with external systems to support group-based
    access control or role-based access control. Different principal types can be
    used to create ACLs for group principals or role principals. For instance, roles
    and groups from an LDAP server can be used to periodically populate `groups` and
    `roles` in the Scala class below to support `Allow` ACLs at different levels:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka授权器还可以与外部系统集成，以支持基于组的访问控制或基于角色的访问控制。可以使用不同的主体类型为组主体或角色主体创建ACL。例如，下面的Scala类中的角色和组可以定期从LDAP服务器中填充，以支持不同级别的`Allow`
    ACL：
- en: '[PRE34]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO18-1)'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_securing_kafka_CO18-1)'
- en: Groups to which each user belongs, populated from an external source like LDAP.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 每个用户所属的组，从LDAP等外部来源填充。
- en: '[![2](assets/2.png)](#co_securing_kafka_CO18-2)'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_securing_kafka_CO18-2)'
- en: Roles associated with each user, populated from an external source like LDAP.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 每个用户关联的角色，从LDAP等外部来源填充。
- en: '[![3](assets/3.png)](#co_securing_kafka_CO18-3)'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_securing_kafka_CO18-3)'
- en: We perform authorization for the user as well as for all the groups and roles
    of the user.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为用户以及用户的所有组和角色执行授权。
- en: '[![4](assets/4.png)](#co_securing_kafka_CO18-4)'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_securing_kafka_CO18-4)'
- en: If any of the contexts are authorized, we return `ALLOWED`. Note that this example
    doesn’t support `Deny` ACLs for groups or roles.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 如果任何上下文得到授权，我们返回`ALLOWED`。请注意，此示例不支持对组或角色的`Deny` ACL。
- en: '[![5](assets/5.png)](#co_securing_kafka_CO18-5)'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_securing_kafka_CO18-5)'
- en: We create an authorization context for each principal with the same metadata
    as the original context.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为每个主体创建一个授权上下文，其元数据与原始上下文相同。
- en: 'ACLs can be assigned for the group `Sales` or the role `Operator` using the
    standard Kafka ACL tool:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用标准Kafka ACL工具为组`Sales`或角色`Operator`分配ACL。
- en: '[PRE35]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO19-1)'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_securing_kafka_CO19-1)'
- en: We use the principal `Group:Sales` with the custom principal type `Group` to
    create an ACL that applies to users belonging to the group `Sales`.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用主体`Group:Sales`和自定义主体类型`Group`创建一个适用于属于组`Sales`的用户的ACL。
- en: '[![2](assets/2.png)](#co_securing_kafka_CO19-2)'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_securing_kafka_CO19-2)'
- en: We use the principal `Role:Operator` with the custom principal type `Role` to
    create an ACL that applies to users with the role `Operator`.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用主体`Role:Operator`和自定义主体类型`Role`创建一个适用于具有角色`Operator`的用户的ACL。
- en: Security Considerations
  id: totrans-371
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安全考虑
- en: Since `AclAuthorizer` stores ACLs in ZooKeeper, access to ZooKeeper should be
    restricted. Deployments without a secure ZooKeeper can implement custom authorizers
    to store ACLs in a secure external database.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`AclAuthorizer`将ACL存储在ZooKeeper中，因此应限制对ZooKeeper的访问。没有安全ZooKeeper的部署可以实现自定义授权者，将ACL存储在安全的外部数据库中。
- en: In large organizations with a large number of users, managing ACLs for individual
    resources may become very cumbersome. Reserving different resource prefixes for
    different departments enables the use of prefixed ACLs that minimize the number
    of ACLs required. This can be combined with group- or role-based ACLs, as shown
    in the example earlier, to further simplify access control in large deployments.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 在拥有大量用户的大型组织中，管理单个资源的ACL可能变得非常繁琐。为不同部门保留不同的资源前缀可以使用前缀ACL，从而最小化所需的ACL数量。这可以与基于组或角色的ACL结合使用，如前面的示例所示，以进一步简化大型部署中的访问控制。
- en: Restricting user access using the principle of least privilege can limit exposure
    if a user is compromised. This means granting access only to the resources necessary
    for each user principal to perform their operations, and removing ACLs when they
    are no longer required. ACLs should be removed immediately when a user principal
    is no longer in use, for instance, when a person leaves the organization. Long-running
    applications can be configured with service credentials rather than credentials
    associated with a specific user to avoid any disruption when employees leave the
    organization. Since long-lived connections with a user principal may continue
    to process requests even after the user has been removed from the system, `Deny`
    ACLs can be used to ensure that the principal is not unintentionally granted access
    through ACLs with wildcard principals. Reuse of principals must be avoided if
    possible to prevent access from being granted to connections using the older version
    of a principal.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 使用最小特权原则限制用户访问可以在用户受到威胁时限制暴露。这意味着仅授予每个用户主体执行其操作所需的资源的访问权限，并在不再需要时删除ACL。例如，当一个人离开组织时，应立即删除ACL。长时间运行的应用程序可以配置为使用服务凭据而不是与特定用户关联的凭据，以避免员工离开组织时的任何中断。由于长时间运行的连接可能会在用户从系统中删除后继续处理请求，因此可以使用`Deny`
    ACL来确保不会通过带有通配符主体的ACL意外授予主体访问权限。如果可能的话，应避免重用主体，以防止使用旧版本的主体授予连接访问权限。
- en: Auditing
  id: totrans-375
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 审计
- en: Kafka brokers can be configured to generate comprehensive *log4j* logs for auditing
    and debugging. The logging level as well as the appenders used for logging and
    their configuration options can be specified in *log4j.properties*. The logger
    instances `kafka.authorizer.logger` used for authorization logging and kafka.request.​log⁠ger
    used for request logging can be configured independently to customize the log
    level and retention for audit logging. Production systems can use frameworks like
    the Elastic Stack to analyze and visualize these logs.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka经纪人可以配置为生成用于审计和调试的全面*log4j*日志。日志级别以及用于记录日志的appender及其配置选项可以在*log4j.properties*中指定。用于授权日志记录的logger实例`kafka.authorizer.logger`和用于请求日志记录的kafka.request.​logger可以独立配置，以定制日志级别和审计日志的保留。生产系统可以使用Elastic
    Stack等框架来分析和可视化这些日志。
- en: 'Authorizers generate `INFO`-level log entries for every attempted operation
    for which access was denied, and log entries at the `DEBUG` level for every operation
    for which access was granted. For example:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 授权者为每次被拒绝访问的操作生成`INFO`级别的日志条目，并为每次被授予访问权限的操作生成`DEBUG`级别的日志条目。例如：
- en: '[PRE36]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Request logging generated at the `DEBUG` level also includes details of the
    user principal and client host. Full details of the request are included if the
    request logger is configured to log at the `TRACE` level. For example:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 以`DEBUG`级别生成的请求日志还包括用户主体和客户端主机的详细信息。如果请求记录器配置为以`TRACE`级别记录日志，则还包括请求的完整详细信息。例如：
- en: '[PRE37]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Authorizer and request logs can be analyzed to detect suspicious activities.
    Metrics that track authentication failures, as well as authorization failure logs,
    can be extremely useful for auditing and provide valuable information in the event
    of an attack or unauthorized access. For end-to-end auditability and traceability
    of messages, audit metadata can be included in message headers when messages are
    produced. End-to-end encryption can be used to protect the integrity of this metadata.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 可以分析授权者和请求日志以检测可疑活动。跟踪身份验证失败的指标以及授权失败日志可能对审计非常有用，并在发生攻击或未经授权的访问事件时提供有价值的信息。为了实现端到端的审计性和消息的可追溯性，当消息被生产时，审计元数据可以包含在消息头中。端到端加密可用于保护此元数据的完整性。
- en: Securing ZooKeeper
  id: totrans-382
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护ZooKeeper
- en: ZooKeeper stores Kafka metadata that is critical for maintaining the availability
    of Kafka clusters, and hence it is vital to secure ZooKeeper in addition to securing
    Kafka. ZooKeeper supports authentication using SASL/GSSAPI for Kerberos authentication
    and SASL/DIGEST-MD5 for username/password authentication. ZooKeeper also added
    TLS support in 3.5.0, enabling mutual authentication as well as encryption of
    data in transit. Note that SASL/DIGEST-MD5 should only be used with TLS encryption
    and is not suitable for production use due to known security vulnerabilities.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: ZooKeeper存储对于维护Kafka集群的可用性至关重要的Kafka元数据，因此除了保护Kafka外，还必须保护ZooKeeper。ZooKeeper支持使用SASL/GSSAPI进行Kerberos身份验证和使用SASL/DIGEST-MD5进行用户名/密码身份验证。ZooKeeper在3.5.0中还添加了TLS支持，实现了数据在传输过程中的相互认证和加密。请注意，SASL/DIGEST-MD5应仅与TLS加密一起使用，并且由于已知的安全漏洞，不适合生产使用。
- en: SASL
  id: totrans-384
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SASL
- en: 'SASL configuration for ZooKeeper is provided using the Java system property
    `java.security.auth.login.config`. The property must be set to a JAAS configuration
    file that contains a login section with the appropriate login module and its options
    for the ZooKeeper server. Kafka brokers must be configured with the client-side
    login section for ZooKeeper clients to talk to SASL-enabled ZooKeeper servers.
    The `Server` section that follows provides the JAAS configuration for the ZooKeeper
    server to enable Kerberos authentication:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: ZooKeeper的SASL配置使用Java系统属性`java.security.auth.login.config`提供。该属性必须设置为包含具有适当登录模块及其选项的ZooKeeper服务器的登录部分的JAAS配置文件。Kafka经纪人必须配置具有用于与启用SASL的ZooKeeper服务器通信的ZooKeeper客户端的客户端登录部分。随后的`Server`部分提供了用于启用Kerberos身份验证的ZooKeeper服务器的JAAS配置：
- en: '[PRE38]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'To enable SASL authentication on ZooKeeper servers, configure authentication
    providers in the ZooKeeper configuration file:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 要在ZooKeeper服务器上启用SASL身份验证，需要在ZooKeeper配置文件中配置身份验证提供程序：
- en: '[PRE39]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Broker Principal
  id: totrans-389
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 经纪人主体
- en: By default, ZooKeeper uses the full Kerberos principal, e.g., `kafka/broker1.example.com@EXAMPLE.COM`,
    as the client identity. When ACLs are enabled for ZooKeeper authorization, ZooKeeper
    servers should be configured with `kerberos.removeHostFromPrincipal=​true` and
    `kerberos.removeRealmFromPrincipal=true` to ensure that all brokers have the same
    principal.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，ZooKeeper使用完整的Kerberos主体，例如，`kafka/broker1.example.com@EXAMPLE.COM`，作为客户端身份。当为ZooKeeper授权启用ACL时，应该配置ZooKeeper服务器为`kerberos.removeHostFromPrincipal=true`和`kerberos.removeRealmFromPrincipal=true`，以确保所有经纪人都具有相同的主体。
- en: 'Kafka brokers must be configured to authenticate to ZooKeeper using SASL with
    a JAAS configuration file that provides client credentials for the broker:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka经纪人必须配置为使用具有为经纪人提供客户端凭据的JAAS配置文件的SASL进行对ZooKeeper进行身份验证：
- en: '[PRE40]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: SSL
  id: totrans-393
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SSL
- en: SSL may be enabled on any ZooKeeper endpoint, including those that use SASL
    authentication. Like Kafka, SSL may be configured to enable client authentication,
    but unlike Kafka, connections with both SASL and SSL client authentication authenticate
    using both protocols and associate multiple principals with the connection. ZooKeeper
    authorizer grants access to a resource if any of the principals associated with
    the connection have access.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: SSL可以在任何使用SASL身份验证的ZooKeeper端点上启用。与Kafka一样，SSL可以配置为启用客户端身份验证，但与Kafka不同，同时使用SASL和SSL客户端身份验证的连接使用两种协议进行身份验证，并将多个主体与连接关联。如果与连接关联的任何主体具有访问权限，则ZooKeeper授权程序将授予对资源的访问权限。
- en: 'To configure SSL on a ZooKeeper server, a key store with the hostname of the
    server or a wildcarded host should be configured. If client authentication is
    enabled, a trust store to validate client certificates is also required:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 要为ZooKeeper服务器配置SSL，应该配置具有服务器主机名或通配符主机的密钥存储。如果启用了客户端身份验证，则还需要一个用于验证客户端证书的信任存储：
- en: '[PRE41]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'To configure SSL for Kafka connections to ZooKeeper, brokers should be configured
    with a trust store to validate ZooKeeper certificates. If client authentication
    is enabled, a key store is also required:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 要为Kafka连接到ZooKeeper配置SSL，经纪人应该配置信任存储以验证ZooKeeper证书。如果启用了客户端身份验证，则还需要一个密钥存储：
- en: '[PRE42]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Authorization
  id: totrans-399
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 授权
- en: Authorization can be enabled for ZooKeeper nodes by setting ACLs for the path.
    When brokers are configured with `zookeeper.set.acl=true`, the broker sets ACLs
    for ZooKeeper nodes when creating the node. By default, metadata nodes are readable
    by everyone but modifiable only by brokers. Additional ACLs may be added if required
    for internal admin users who may need to update metadata directly in ZooKeeper.
    Sensitive paths, like nodes containing SCRAM credentials, are not world-readable
    by default.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过为路径设置ACL来为ZooKeeper节点启用授权。当经纪人配置为`zookeeper.set.acl=true`时，经纪人在创建节点时为ZooKeeper节点设置ACL。默认情况下，元数据节点对所有人都是可读的，但只有经纪人才能修改。如果需要，可以为可能需要直接在ZooKeeper中更新元数据的内部管理员用户添加其他ACL。默认情况下，诸如包含SCRAM凭据的节点等敏感路径不是默认情况下对所有人可读的。
- en: Securing the Platform
  id: totrans-401
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护平台
- en: In the previous sections, we discussed the options for locking down access to
    Kafka and ZooKeeper in order to safeguard Kafka deployments. Security design for
    a production system should use a threat model that addresses security threats
    not just for individual components but also for the system as a whole. Threat
    models build an abstraction of the system and identify potential threats and the
    associated risks. Once the threats are evaluated, documented, and prioritized
    based on risks, mitigation strategies must be implemented for each potential threat
    to ensure that the whole system is protected. When assessing potential threats,
    it is important to consider external threats as well as insider threats. For systems
    that store Personally Identifiable Information (PII) or other sensitive data,
    additional measures to comply with regulatory policies must also be implemented.
    An in-depth discussion of standard threat modeling techniques is outside the scope
    of this chapter.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分中，我们讨论了锁定对Kafka和ZooKeeper的访问权限的选项，以保护Kafka部署。生产系统的安全设计应该使用威胁模型，不仅解决单个组件的安全威胁，还要解决整个系统的安全威胁。威胁模型构建了系统的抽象，并确定潜在的威胁和相关的风险。一旦评估、记录并根据风险进行优先排序，必须为每个潜在的威胁实施缓解策略，以确保整个系统受到保护。在评估潜在威胁时，重要的是要考虑外部威胁以及内部威胁。对于存储个人身份信息（PII）或其他敏感数据的系统，还必须实施符合监管政策的额外措施。本章不涉及标准威胁建模技术的深入讨论。
- en: In addition to protecting data in Kafka and metadata in ZooKeeper using secure
    authentication, authorization, and encryption, extra steps must be taken to ensure
    that the platform is secure. Defenses may include network firewall solutions to
    protect the network and encryption to protect physical storage. Key stores, trust
    stores, and Kerberos keytab files that contain credentials used for authentication
    must be protected using filesystem permissions. Access to configuration files
    containing security-critical information like credentials must be restricted.
    Since passwords stored in clear-text in configuration files are insecure even
    if access is restricted, Kafka supports externalizing passwords in a secure store.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用安全认证、授权和加密保护Kafka中的数据和ZooKeeper中的元数据之外，还必须采取额外的步骤来确保平台的安全。防御措施可能包括网络防火墙解决方案以保护网络和加密以保护物理存储。包含用于认证的凭据的密钥库、信任库和Kerberos密钥表文件必须使用文件系统权限进行保护。对包含安全关键信息（如凭据）的配置文件的访问必须受到限制。由于即使访问受限，明文存储在配置文件中的密码也是不安全的，因此Kafka支持将密码外部化存储在安全存储中。
- en: Password Protection
  id: totrans-404
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 密码保护
- en: Customizable configuration providers can be configured for Kafka brokers and
    clients to retrieve passwords from a secure third-party password store. Passwords
    may also be stored in encrypted form in configuration files with custom configuration
    providers that perform decryption.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 可以为Kafka经纪人和客户端配置可定制的配置提供程序，以从安全的第三方密码存储中检索密码。密码也可以以加密形式存储在配置文件中，使用自定义配置提供程序执行解密。
- en: 'The custom configuration provider that follows uses the tool `gpg` to decrypt
    broker or client properties stored in a file:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的自定义配置提供程序使用工具`gpg`来解密存储在文件中的经纪人或客户端属性：
- en: '[PRE43]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[![1](assets/1.png)](#co_securing_kafka_CO20-1)'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_securing_kafka_CO20-1)'
- en: We provide the passphrase for decoding passwords to the process in the environment
    variable `PASSPHRASE`.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将解码密码的密码短语提供给进程的环境变量`PASSPHRASE`。
- en: '[![2](assets/2.png)](#co_securing_kafka_CO20-2)'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_securing_kafka_CO20-2)'
- en: We decrypt the configs using `gpg`. The return value contains the full set of
    decrypted configs.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`gpg`解密配置。返回值包含完整的解密配置集。
- en: '[![3](assets/3.png)](#co_securing_kafka_CO20-3)'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_securing_kafka_CO20-3)'
- en: We parse the configs in `data` as Java properties.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将`data`中的配置解析为Java属性。
- en: '[![4](assets/4.png)](#co_securing_kafka_CO20-4)'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_securing_kafka_CO20-4)'
- en: We fail fast with a `RuntimeException` if an error is encountered.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 如果遇到错误，我们会使用`RuntimeException`快速失败。
- en: '[![5](assets/5.png)](#co_securing_kafka_CO20-5)'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_securing_kafka_CO20-5)'
- en: Caller may request a subset of keys from the path; here we get all values and
    return the requested subset.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 调用者可以从路径中请求密钥的子集；在这里，我们获取所有值并返回请求的子集。
- en: 'You may recall that in the section on SASL/PLAIN, we used standard Kafka configuration
    classes to load credentials from an external file. We can now encrypt that file
    using `gpg`:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还记得在SASL/PLAIN部分，我们使用标准的Kafka配置类从外部文件加载凭据。现在我们可以使用`gpg`加密该文件：
- en: '[PRE44]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We now add indirect configs and config provider options to the original properties
    file so that Kafka clients load their credentials from the encrypted file:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将间接配置和配置提供程序选项添加到原始属性文件中，以便Kafka客户端从加密文件中加载其凭据：
- en: '[PRE45]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Sensitive broker configuration options can also be stored encrypted in ZooKeeper
    using the Kafka configs tool without using custom providers. The following command
    can be executed before starting brokers to store encrypted SSL key store passwords
    for brokers in ZooKeeper. The password encoder secret must be configured in each
    broker’s configuration file to decrypt the value:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以使用Kafka配置工具将敏感的经纪人配置选项加密存储在ZooKeeper中，而无需使用自定义提供程序。在启动经纪人之前，可以执行以下命令将经纪人在ZooKeeper中的SSL密钥库密码存储为加密形式。密码编码器秘钥必须在每个经纪人的配置文件中配置以解密该值：
- en: '[PRE46]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Summary
  id: totrans-424
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: The frequency and scale of data breaches have been increasing over the last
    decade as cyberattacks have become increasingly sophisticated. In addition to
    the significant cost of isolating and resolving breaches and the cost of outages
    until security fixes have been applied, data breaches may also result in regulatory
    penalties and long-term damage to brand reputation. In this chapter, we explored
    the vast array of options available to guarantee the confidentiality, integrity,
    and availability of data stored in Kafka.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '随着过去十年中数据泄露的频率和规模不断增加，网络攻击变得越来越复杂。除了隔离和解决泄露的巨大成本以及在应用安全修复之前的停机成本之外，数据泄露还可能导致监管处罚和品牌声誉的长期损害。在本章中，我们探讨了为保证Kafka中存储的数据的机密性、完整性和可用性而提供的广泛选择。 '
- en: 'Going back to the example data flow at the start of this chapter, we reviewed
    the options available for different aspects of security throughout the flow:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 本章开始时的示例数据流，我们回顾了整个流程中可用的安全性方面的选项：
- en: Client authenticity
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端真实性
- en: When Alice’s client establishes connection to a Kafka broker, a listener using
    SASL or SSL with client authentication can verify that the connection is really
    from Alice and not an imposter. Reauthentication can configured to limit exposure
    in case a user is compromised.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 当Alice的客户端与Kafka经纪人建立连接时，使用SASL或SSL进行客户端认证的侦听器可以验证连接是否真的来自Alice而不是冒名顶替者。可以配置重新认证以限制用户受到威胁的暴露。
- en: Server authenticity
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器真实性
- en: Alice’s client can verify that its connection is to the genuine broker using
    SSL with hostname validation or using SASL mechanisms with mutual authentication,
    like Kerberos or SCRAM.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: Alice的客户端可以通过使用SSL进行主机名验证或使用具有相互认证的SASL机制（如Kerberos或SCRAM）来验证其连接是否真实连接到经纪人。
- en: Data privacy
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 数据隐私
- en: Use of SSL to encrypt data in transit protects data from eavesdroppers. Disk
    or volume encryption protects data at rest even if the disk is stolen. For highly
    sensitive data, end-to-end encryption provides fine-grained data access control
    and ensures that cloud providers and platform administrators with physical access
    to network and disks cannot access the data.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 使用SSL加密数据传输可以保护数据免受窃听者。磁盘或卷加密即使磁盘被盗也可以保护静态数据。对于高度敏感的数据，端到端加密提供了细粒度的数据访问控制，并确保云提供商和具有网络和磁盘物理访问权限的平台管理员无法访问数据。
- en: Data integrity
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 数据完整性
- en: SSL can be used to detect tampering of data over an insecure network. Digital
    signatures can be included in messages to verify integrity when using end-to-end
    encryption.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: SSL可用于检测在不安全网络上的数据篡改。数字签名可以包含在消息中，以在使用端到端加密时验证完整性。
- en: Access control
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 访问控制
- en: Every operation performed by Alice, Bob, and even brokers is authorized using
    a customizable authorizer. Kafka has a built-in authorizer that enables fine-grained
    access control using ACLs.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: Alice、Bob甚至经纪人执行的每个操作都是使用可自定义的授权器进行授权的。Kafka具有内置的授权器，可以使用ACL进行细粒度的访问控制。
- en: Auditability
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 可审计性
- en: Authorizer logs and request logs can be used to track operations and attempted
    operations for auditing and anomaly detection.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 授权器日志和请求日志可用于跟踪操作和尝试的操作，用于审计和异常检测。
- en: Availability
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 可用性
- en: A combination of quotas and configuration options to manage connections can
    be used to protect brokers from denial-of-service attacks. ZooKeeper can be secured
    using SSL, SASL, and ACLs to ensure that the metadata needed to ensure the availability
    of Kafka brokers is secure.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用配额和配置选项的组合来管理连接，以保护经纪人免受拒绝服务攻击。可以使用SSL、SASL和ACL来保护ZooKeeper，以确保确保Kafka经纪人的可用性所需的元数据是安全的。
- en: With the wide choice of options available for security, choosing the appropriate
    options for each use case can be a daunting task. We reviewed the security concerns
    to consider for each security mechanism, and the controls and policies that can
    be adopted to limit the potential attack surface. We also reviewed the additional
    measures required to lock down ZooKeeper and the rest of the platform. The standard
    security technologies supported by Kafka and the various extension points to integrate
    with the existing security infrastructure in your organization enable you to build
    consistent security solutions to protect the whole platform.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 在安全领域有很多选择，为每种情况选择合适的选项可能是一项艰巨的任务。我们审查了每种安全机制需要考虑的安全问题，以及可以采用的控制和政策，以限制潜在的攻击面。我们还审查了锁定ZooKeeper和平台其余部分所需的额外措施。Kafka支持的标准安全技术以及与组织现有安全基础设施集成的各种扩展点，使您能够构建一致的安全解决方案，以保护整个平台。

- en: Chapter 12\. Administering Kafka
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章。管理Kafka
- en: Managing a Kafka cluster requires additional tooling to perform administrative
    changes to topics, configurations, and more. Kafka provides several command-line
    interface (CLI) utilities that are useful for making administrative changes to
    your clusters. The tools are implemented in Java classes, and a set of scripts
    are provided natively to call those classes properly. While these tools provide
    basic functions, you may find they are lacking for more complex operations or
    are unwieldy to use at larger scales. This chapter will describe only the basic
    tools that are available as part of the Apache Kafka open source project. More
    information about advanced tools that have been developed in the community, outside
    of the core project, can be found on the [Apache Kafka website](https://kafka.apache.org).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 管理Kafka集群需要额外的工具来执行对主题、配置等的管理更改。Kafka提供了几个命令行接口（CLI）实用程序，用于对集群进行管理更改。这些工具是以Java类实现的，并且提供了一组本地脚本来正确调用这些类。虽然这些工具提供了基本功能，但您可能会发现它们在更复杂的操作或在更大规模上使用时存在不足。本章将仅描述作为Apache
    Kafka开源项目一部分提供的基本工具。有关社区中开发的高级工具的更多信息，可以在[Apache Kafka网站](https://kafka.apache.org)上找到。
- en: Authorizing Admin Operations
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 授权管理操作
- en: While Apache Kafka implements authentication and authorization to control topic
    operations, default configurations do not restrict the use of these tools. This
    means that these CLI tools can be used without any authentication required, which
    will allow operations such as topic changes to be executed with no security check
    or audit. Always ensure that access to this tooling on your deployments is restricted
    to administrators only to prevent unauthorized changes.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Apache Kafka实现了身份验证和授权来控制主题操作，但默认配置不限制这些工具的使用。这意味着这些CLI工具可以在不需要任何身份验证的情况下使用，这将允许执行诸如主题更改之类的操作，而无需进行安全检查或审计。始终确保对部署中的此工具的访问受到限制，仅限管理员才能防止未经授权的更改。
- en: Topic Operations
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主题操作
- en: The `kafka-topics.sh` tool provides easy access to most topic operations. It
    allows you to create, modify, delete, and list information about topics in the
    cluster. While some topic configurations are possible through this command, they
    have been deprecated, and it is recommended to use the more robust method of using
    the `kafka-config.sh` tool for configuration changes. To use the `kafka-topics.sh`
    command, you must provide the cluster connection string and port through the `--bootstrap-server`
    option. In the examples that follow, the cluster connect string is being run locally
    on one of the hosts in the Kafka cluster, and we will be using `localhost:9092`.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '`kafka-topics.sh`工具提供了对大多数主题操作的简单访问。它允许您在集群中创建、修改、删除和列出有关主题的信息。虽然通过此命令可能可以进行一些主题配置，但这些配置已被弃用，建议使用更健壮的方法使用`kafka-config.sh`工具进行配置更改。要使用`kafka-topics.sh`命令，必须通过`--bootstrap-server`选项提供集群连接字符串和端口。在接下来的示例中，集群连接字符串在Kafka集群中的一个主机上本地运行，并且我们将使用`localhost:9092`。'
- en: Throughout this chapter, all the tools will be located in the directory */usr/local/kafka/bin/*.
    The example commands in this section will assume you are in this directory or
    have added the directory to your `$PATH`.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，所有工具都将位于目录*/usr/local/kafka/bin/*中。本节中的示例命令将假定您在此目录中，或者已将该目录添加到您的`$PATH`中。
- en: Check the Version
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查版本
- en: Many of the command-line tools for Kafka have a dependency on the version of
    Kafka running to operate correctly. This includes some commands that may store
    data in ZooKeeper rather than connecting to the brokers themselves. For this reason,
    it is important to make sure the version of the tools that you are using matches
    the version of the brokers in the cluster. The safest approach is to run the tools
    on the Kafka brokers themselves, using the deployed version.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka的许多命令行工具对Kafka运行的版本有依赖，以正确运行。这包括一些命令可能会将数据存储在ZooKeeper中，而不是直接连接到经纪人本身。因此，重要的是确保您使用的工具版本与集群中经纪人的版本匹配。最安全的方法是在Kafka经纪人上运行工具，使用部署的版本。
- en: Creating a New Topic
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建新主题
- en: 'When creating a new topic through the `--create` command, there are several
    required arguments to create a new topic in a cluster. These arguments must be
    provided when using this command even though some of them may have broker-level
    defaults configured already. Additional arguments and configuration overrides
    are possible at this time, as well using the `--config` option, but are covered
    later in the chapter. Here is a list of the three required arguments:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`--create`命令创建新主题时，在集群中创建新主题需要几个必需的参数。使用此命令时必须提供这些参数，即使其中一些可能已经配置了经纪人级别的默认值。此时还可以使用`--config`选项进行其他参数和配置覆盖，但这将在本章后面进行介绍。以下是三个必需参数的列表：
- en: '`--topic`'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '`--topic`'
- en: The name of the topic that you wish to create.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望创建的主题名称。
- en: '`--replication-factor`'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '`--replication-factor`'
- en: The number of replicas of the topic to maintain within the cluster.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 主题在集群中维护的副本数量。
- en: '`--partitions`'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '`--partitions`'
- en: The number of partitions to create for the topic.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为主题创建的分区数。
- en: Good Topic Naming Practices
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 良好的主题命名实践
- en: Topic names may contain alphanumeric characters, underscores, dashes, and periods;
    however, it is not recommended to use periods in topic names. Internal metrics
    inside of Kafka convert period characters to underscore characters (e.g., “topic.1”
    becomes “topic_1” in metrics calculations), which can result in conflicts in topic
    names.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 主题名称可以包含字母数字字符、下划线、破折号和句点；但不建议在主题名称中使用句点。Kafka内部度量标准将句点字符转换为下划线字符（例如，“topic.1”在度量计算中变为“topic_1”），这可能导致主题名称冲突。
- en: Another recommendation is to avoid using a double underscore to start your topic
    name. By convention, topics internal to Kafka operations are created with a double
    underscore naming convention (like the `__consumer_offsets` topic, which tracks
    consumer group offset storage). As such it is not recommended to have topic names
    that begin with the double underscore naming convention to prevent confusion.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个建议是避免使用双下划线来开始你的主题名称。按照惯例，Kafka操作内部的主题使用双下划线命名约定创建（比如`__consumer_offsets`主题，用于跟踪消费者组偏移存储）。因此，不建议使用以双下划线命名约定开头的主题名称，以防混淆。
- en: 'Creating a new topic is simple. Run `kafka-topics.sh` as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新主题很简单。运行`kafka-topics.sh`如下：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The command will cause the cluster to create a topic with the specified name
    and number of partitions. For each partition, the cluster will select the specified
    number of replicas appropriately. This means that if the cluster is set up for
    rack-aware replica assignment, the replicas for each partition will be in separate
    racks. If rack-aware assignment is not desired, specify the `--disable-rack-aware`
    command-line argument.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将导致集群创建一个具有指定名称和分区数的主题。对于每个分区，集群将适当地选择指定数量的副本。这意味着如果集群设置为机架感知副本分配，每个分区的副本将位于不同的机架上。如果不希望使用机架感知分配，指定`--disable-rack-aware`命令行参数。
- en: 'For example, create a topic named “my-topic” with eight partitions that have
    two replicas each:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，创建一个名为“my-topic”的主题，其中每个有两个副本的八个分区：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Using if-exists and if-not-exists Arguments Properly
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正确使用if-exists和if-not-exists参数
- en: When using `kafka-topics.sh` in automation, you may want to use the `--if-not-exists`
    argument while creating new topics that will not return an error if the topic
    already exists.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在自动化中使用`kafka-topics.sh`时，创建新主题时可能希望使用`--if-not-exists`参数，如果主题已经存在，则不返回错误。
- en: While an `--if-exists` argument is provided for the `--alter` command, using
    it is not recommended. Using this argument will cause the command to not return
    an error if the topic being changed does not exist. This can mask problems where
    a topic does not exist that should have been created.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`--alter`命令提供了一个`--if-exists`参数，但不建议使用它。使用这个参数会导致命令在被更改的主题不存在时不返回错误。这可能掩盖了应该创建但不存在的主题的问题。
- en: Listing All Topics in a Cluster
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 列出集群中的所有主题
- en: The `--list` command lists all topics in a cluster. The list is formatted with
    one topic per line, in no particular order, which is useful for generating a full
    list of topics.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`--list`命令列出集群中的所有主题。列表格式化为每行一个主题，没有特定顺序，这对于生成完整的主题列表很有用。'
- en: 'Here’s an example of the `--list` option listing all topics in the cluster:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用`--list`选项列出集群中所有主题的示例：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You’ll notice the internal `__consumer_offsets` topic is listed here. Running
    the command with `--exclude-internal` will remove all topics from the list that
    begin with the double underscore mentioned earlier, which can be beneficial.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到内部的`__consumer_offsets`主题在这里列出。使用`--exclude-internal`运行命令将从列表中删除所有以前提到的双下划线开头的主题，这可能是有益的。
- en: Describing Topic Details
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 描述主题详细信息
- en: It is also possible to get detailed information on one or more topics in the
    cluster. The output includes the partition count, topic configuration overrides,
    and a listing of each partition with its replica assignments. This can be limited
    to a single topic by providing a `--topic` argument to the command.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以获取集群中一个或多个主题的详细信息。输出包括分区计数、主题配置覆盖，以及每个分区及其副本分配的列表。通过向命令提供`--topic`参数，可以将其限制为单个主题。
- en: 'For example, describing our recently created “my-topic” in the cluster:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在集群中描述我们最近创建的“my-topic”：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The `--describe` command also has several useful options for filtering the
    output. These can be helpful for diagnosing cluster issues more easily. For these
    commands we generally do not specify the `--topic` argument because the intention
    is to find all topics or partitions in a cluster that match the criteria. These
    options will not work with the `list` command. Here is a list of useful pairings
    to use:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`--describe`命令还有几个有用的选项用于过滤输出。这些对于更容易诊断集群问题很有帮助。对于这些命令，我们通常不指定`--topic`参数，因为意图是找到所有符合条件的集群中的主题或分区。这些选项不适用于`list`命令。以下是一些有用的配对列表：'
- en: '`--topics-with-overrides`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`--topics-with-overrides`'
- en: This will describe only the topics that have configurations that differ from
    the cluster defaults.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这将仅描述与集群默认配置不同的主题。
- en: '`--exclude-internal`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`--exclude-internal`'
- en: The previously mentioned command will remove all topics from the list that begin
    with the double underscore naming convention.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 前面提到的命令将从列表中删除所有以双下划线命名约定开头的主题。
- en: 'The following commands are used to help find topic partitions that may have
    problems:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令用于帮助查找可能存在问题的主题分区：
- en: '`--under-replicated-partitions`'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`--under-replicated-partitions`'
- en: This shows all partitions where one or more of the replicas are not in sync
    with the leader. This isn’t necessarily bad, as cluster maintenance, deployments,
    and rebalances will cause under-replicated partitions (or URPs) but is something
    to be aware of.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了所有副本中有一个或多个与领导者不同步的所有分区。这不一定是坏事，因为集群维护、部署和重新平衡会导致副本不足的分区（或URP），但需要注意。
- en: '`--at-min-isr-partitions`'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`--at-min-isr-partitions`'
- en: This shows all partitions where the number of replicas, including the leader,
    exactly match the setting for minimum in-sync replicas (ISRs). These topics are
    still available for producer or consumer clients, but all redundancy has been
    lost, and they are in danger of becoming unavailable.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了所有副本数（包括领导者）与最小同步副本（ISRs）设置完全匹配的所有分区。这些主题仍然可供生产者或消费者客户端使用，但所有冗余已经丢失，它们有可能变得不可用。
- en: '`--under-min-isr-partitions`'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`--under-min-isr-partitions`'
- en: This shows all partitions where the number of ISRs is below the configured minimum
    for successful produce actions. These partitions are effectively in read-only
    mode and cannot be produced to.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了所有ISR数量低于成功生产操作所需的最小配置的所有分区。这些分区实际上处于只读模式，无法进行生产操作。
- en: '`--unavailable-partitions`'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`--unavailable-partitions`'
- en: This shows all topic partitions without a leader. This is a serious situation
    and indicates that the partition is offline and unavailable for producer or consumer
    clients.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了所有没有领导者的主题分区。这是一个严重的情况，表明该分区已脱机，对生产者或消费者客户端不可用。
- en: 'Here’s an example of finding topics that are at the minimum ISR setttings.
    In this example, the topic is configured for a min-ISR of 1 and has a replication
    factor (RF) of 2\. Host 0 is online, and host 1 has gone down for maintenance:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个查找处于最小ISR设置的主题的示例。在此示例中，主题配置为最小ISR为1，并且副本因子（RF）为2。主机0在线，主机1已停机进行维护：
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Adding Partitions
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加分区
- en: It is sometimes necessary to increase the number of partitions for a topic.
    Partitions are the way topics are scaled and replicated across a cluster. The
    most common reason to increase the partition count is to horizontally scale a
    topic across more brokers by decreasing the throughput for a single partition.
    Topics may also be increased if a consumer needs to expand to run more copies
    in a single consumer group since a partition can only be consumed by a single
    member in the group.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 有时需要增加主题的分区数。分区是主题在集群中扩展和复制的方式。增加分区计数的最常见原因是通过减少单个分区的吞吐量来横向扩展主题跨多个经纪人。如果消费者需要扩展以在单个消费者组中运行更多副本，则还可以增加主题。因为一个分区只能被消费者组中的一个成员消费。
- en: 'Following is an example of increasing the number of partitions for a topic
    named “my-topic” to 16 using the `--alter` command, followed by a verification
    that it worked:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例，使用`--alter`命令将名为“my-topic”的主题的分区数增加到16，然后验证它是否起作用：
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Adjusting Keyed Topics
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调整带键主题
- en: Topics that are produced with keyed messages can be very difficult to add partitions
    to from a consumer’s point of view. This is because the mapping of keys to partitions
    will change when the number of partitions is changed. For this reason, it is advisable
    to set the number of partitions for a topic that will contain keyed messages once,
    when the topic is created, and avoid resizing the topic.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用带有键消息的主题可能非常难以从消费者的角度添加分区。这是因为当分区数更改时，键到分区的映射将发生变化。因此，建议在创建主题时为包含键消息的主题设置分区数一次，并避免调整主题的大小。
- en: Reducing Partitions
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 减少分区
- en: It is not possible to reduce the number of partitions for a topic. Deleting
    a partition from a topic would cause part of the data in that topic to be deleted
    as well, which would be inconsistent from a client point of view. In addition,
    trying to redistribute the data to the remaining partitions would be difficult
    and result in out-of-order messages. Should you need to reduce the number of partitions,
    it is recommended to delete the topic and re-create it or (if deletion is not
    possible) create a new version of the existing topic and move all produce traffic
    to the new topic (e.g., “my-topic-v2”).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 不可能减少主题的分区数。从主题中删除一个分区也会导致该主题中的部分数据被删除，这在客户端的角度来看是不一致的。此外，尝试将数据重新分配到剩余的分区将会很困难，并导致消息的顺序混乱。如果需要减少分区数，建议删除主题并重新创建它，或者（如果无法删除）创建现有主题的新版本，并将所有生产流量转移到新主题（例如“my-topic-v2”）。
- en: Deleting a Topic
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除主题
- en: Even a topic with no messages uses cluster resources such as disk space, open
    filehandles, and memory. The controller also has junk metadata that it must retain
    knowledge of, which can hinder performance at large scale. If a topic is no longer
    needed, it can be deleted to free up these resources. To perform this action,
    the brokers in the cluster must be configured with the `delete.topic.enable` option
    set to `true`. If it’s set to `false`, then the request to delete the topic will
    be ignored and will not succeed.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 即使没有消息的主题也会使用磁盘空间、打开文件句柄和内存等集群资源。控制器还必须保留其必须了解的垃圾元数据，这可能会在大规模时影响性能。如果不再需要主题，则可以删除以释放这些资源。要执行此操作，集群中的经纪人必须配置`delete.topic.enable`选项设置为`true`。如果设置为`false`，则将忽略删除主题的请求，并且不会成功。
- en: Topic deletion is an asynchronous operation. This means that running this command
    will mark a topic for deletion, but the deletion may not happen immediately, depending
    on the amount of data and cleanup needed. The controller will notify the brokers
    of the pending deletion as soon as possible (after existing controller tasks complete),
    and the brokers will then invalidate the metadata for the topic and delete the
    files from disk. It is highly recommended that operators not delete more than
    one or two topics at a time, and give those ample time to complete before deleting
    other topics, due to limitations in the way the controller executes these operations.
    In the small cluster shown in the examples in this book, topic deletion will happen
    almost immediately, but in larger clusters it may take longer.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 主题删除是一个异步操作。这意味着运行此命令将标记一个主题以进行删除，但删除可能不会立即发生，这取决于所需的数据量和清理。控制器将尽快通知经纪人有关即将删除的信息（在现有控制器任务完成后），然后经纪人将使主题的元数据无效并从磁盘中删除文件。强烈建议操作员不要一次删除一个或两个以上的主题，并且在删除其他主题之前给予充分的时间来完成，因为控制器执行这些操作的方式存在限制。在本书示例中显示的小集群中，主题删除几乎会立即发生，但在较大的集群中可能需要更长的时间。
- en: Data Loss Ahead
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据丢失
- en: Deleting a topic will also delete all its messages. This is not a reversible
    operation. Make sure it is executed carefully.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 删除主题也将删除其所有消息。这是一个不可逆的操作。请确保谨慎执行。
- en: 'Here is an example of deleting the topic named “my-topic” using the `--delete`
    argument. Depending on the version of Kafka, there will be a note letting you
    know that the argument will not work if another config is not set:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用`--delete`参数删除名为“my-topic”的主题的示例。根据Kafka的版本，将会有一条说明，让您知道如果没有设置其他配置，则该参数将不起作用：
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: You will notice there is no visible feedback that the topic deletion was completed
    successfully or not. Verify that deletion was successful by running the `--list`
    or `--describe` options to see that the topic is no longer in the cluster.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到没有明显的反馈表明主题删除是否成功完成。通过运行`--list`或`--describe`选项来验证删除是否成功，以查看主题是否不再存在于集群中。
- en: Consumer Groups
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消费者组
- en: Consumer groups are coordinated groups of Kafka consumers consuming from topics
    or multiple partitions of a single topic. The `kafka-consumer-groups.sh` tool
    helps manage and gain insight into the consumer groups that are consuming from
    topics in the cluster. It can be used to list consumer groups, describe specific
    groups, delete consumer groups or specific group info, or reset consumer group
    offset information.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 消费者组是协调的Kafka消费者组，从主题或单个主题的多个分区中消费。`kafka-consumer-groups.sh`工具有助于管理和了解从集群中的主题中消费的消费者组。它可用于列出消费者组，描述特定组，删除消费者组或特定组信息，或重置消费者组偏移信息。
- en: ZooKeeper-Based Consumer Groups
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于ZooKeeper的消费者组
- en: In older versions of Kafka, consumer groups could be managed and maintained
    in ZooKeeper. This behavior was deprecated in versions 0.11.0.* and later, and
    old consumer groups are no longer used. Some versions of the provided scripts
    may still show deprecated `--zookeeper` connection string commands, but it is
    not recommended to use them unless you have an old environment with some consumer
    groups that have not upgraded to later versions of Kafka.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在较旧版本的Kafka中，可以在ZooKeeper中管理和维护消费者组。此行为在0.11.0.*版本及更高版本中已弃用，不再使用旧的消费者组。提供的某些脚本的某些版本可能仍然显示已弃用的`--zookeeper`连接字符串命令，但不建议使用它们，除非您的旧环境中有一些消费者组尚未升级到Kafka的较新版本。
- en: List and Describe Groups
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 列出和描述组
- en: 'To list consumer groups, use the `--bootstrap-server` and `--list` parameters.
    Ad hoc consumers utilizing the `kafka-consumer-groups.sh` script will show up
    as `console-consumer-*<generated_id>*` in the consumer list:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 要列出消费者组，请使用`--bootstrap-server`和`--list`参数。使用`kafka-consumer-groups.sh`脚本的特定消费者将显示为消费者列表中的`console-consumer-*<generated_id>*`：
- en: '[PRE7]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: For any group listed, you can get more details by changing the `--list` parameter
    to `--describe` and adding the `--group` parameter. This will list all the topics
    and partitions that the group is consuming from, as well as additional information
    such as the offsets for each topic partition. [Table 12-1](#table0901) has a full
    description of all the fields provided in the output.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于列出的任何组，可以通过将`--list`参数更改为`--describe`并添加`--group`参数来获取更多详细信息。这将列出该组正在从中消费的所有主题和分区，以及其他信息，例如每个主题分区的偏移量。[表12-1](#table0901)对输出中提供的所有字段进行了全面描述。
- en: 'For example, get consumer group details for the ad hoc group named “my-consumer”:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，获取名为“my-consumer”的特定组的消费者组详细信息：
- en: '[PRE8]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Table 12-1\. Fields provided for group named “my-consumer”
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 表12-1。为名为“my-consumer”的组提供的字段
- en: '| Field | Description |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 字段 | 描述 |'
- en: '| --- | --- |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| GROUP | The name of the consumer group. |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| GROUP | 消费者组的名称。'
- en: '| TOPIC | The name of the topic being consumed. |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| TOPIC | 正在消费的主题的名称。'
- en: '| PARTITION | The ID number of the partition being consumed. |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| PARTITION | 正在消费的分区的ID号。'
- en: '| CURRENT-OFFSET | The next offset to be consumed by the consumer group for
    this topic partition. This is the position of the consumer within the partition.
    |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| CURRENT-OFFSET | 消费者组为此主题分区要消费的下一个偏移量。这是消费者在分区内的位置。'
- en: '| LOG-END-OFFSET | The current high-water mark offset from the broker for the
    topic partition. This is the offset of the next message to be produced to this
    partition. |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| LOG-END-OFFSET | 主题分区的经纪人的当前高水位偏移。这是下一条消息要被生产到这个分区的偏移量。'
- en: '| LAG | The difference between the consumer Current-Offset and the broker Log-End-Offset
    for this topic partition. |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| LAG | 消费者当前偏移和经纪人日志结束偏移之间的差异，用于此主题分区。'
- en: '| CONSUMER-ID | A generated unique consumer-id based on the provided client-id.
    |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| CONSUMER-ID | 基于提供的客户端ID生成的唯一消费者ID。'
- en: '| HOST | Address of the host the consumer group is reading from. |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| HOST | 消费者组正在读取的主机的地址。'
- en: '| CLIENT-ID | String provided by the client identifying the client that is
    consuming from the group. |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| CLIENT-ID | 客户端提供的标识客户端的字符串。'
- en: Delete Group
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除组
- en: Deletion of consumer groups can be performed with the `--delete` argument. This
    will remove the entire group, including all stored offsets for all topics that
    the group is consuming. To perform this action, all consumers in the group should
    be shut down as the consumer group must not have any active members. If you attempt
    to delete a group that is not empty, an error stating “The group is not empty”
    will be thrown and nothing will happen. It is also possible to use the same command
    to delete offsets for a single topic that the group is consuming without deleting
    the entire group by adding the `--topic` argument and specifying which topic offsets
    to delete.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`--delete`参数执行消费者组的删除。这将删除整个组，包括该组正在消费的所有主题的所有存储偏移量。要执行此操作，组中的所有消费者都应该关闭，因为消费者组不应该有任何活跃成员。如果尝试删除一个不为空的组，将抛出一个错误，指出“该组不为空”，并且不会发生任何事情。还可以使用相同的命令通过添加`--topic`参数并指定要删除的主题偏移量来删除组正在消费的单个主题的偏移量，而不删除整个组。
- en: 'Here is an example of deleting the entire consumer group named “my-consumer”:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是删除名为“my-consumer”的整个消费者组的示例：
- en: '[PRE9]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Offset Management
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏移管理
- en: In addition to displaying and deleting the offsets for a consumer group, it
    is also possible to retrieve the offsets and store new offsets in a batch. This
    is useful for resetting the offsets for a consumer when there is a problem that
    requires messages to be reread, or for advancing offsets and skipping past a message
    that the consumer is having a problem with (e.g., if there is a badly formatted
    message that the consumer cannot handle).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 除了显示和删除消费者组的偏移量之外，还可以批量检索偏移量并存储新的偏移量。当消费者出现需要重新读取消息的问题时，或者需要推进偏移量并跳过消费者无法处理的消息时（例如，如果有一条格式错误的消息），这对于重置消费者的偏移量非常有用。
- en: Export offsets
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 导出偏移量
- en: 'To export offsets from a consumer group to a CSV file, use the `--reset-offsets`
    argument with the `--dry-run` option. This will allow us to create an export of
    the current offsets in a file format that can be reused for importing or rolling
    back the offsets later. The CSV format export will be in the following configuration:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要将消费者组的偏移量导出到CSV文件中，请使用`--reset-offsets`参数和`--dry-run`选项。这将允许我们创建当前偏移量的导出文件格式，以便以后可以重用导入或回滚偏移量。CSV格式的导出将采用以下配置：
- en: '*<topic-name>,<partition-number>,<offset>*'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '*<topic-name>,<partition-number>,<offset>*'
- en: Running the same command without the `--dry-run` option will reset the offsets
    completely, so be careful.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在不使用`--dry-run`选项运行相同命令将完全重置偏移量，因此要小心。
- en: 'Here is an example of exporting the offsets for the topic “my-topic” that is
    being consumed by the consumer group named “my-consumer” to a file named *offsets.csv*:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是导出主题“my-topic”被消费者组“my-consumer”消费的偏移量的示例，导出到名为*offsets.csv*的文件中：
- en: '[PRE10]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Import offsets
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 导入偏移量
- en: The import offset tool is the opposite of exporting. It takes the file produced
    by exporting offsets in the previous section and uses it to set the current offsets
    for the consumer group. A common practice is to export the current offsets for
    the consumer group, make a copy of the file (so that you preserve a backup), and
    edit the copy to replace the offsets with the desired values.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 导入偏移量工具是导出的相反。它接受导出上一节中偏移量生成的文件，并使用它来设置消费者组的当前偏移量。一种常见做法是导出消费者组的当前偏移量，复制文件（以便保留备份），并编辑副本以替换偏移量为所需值。
- en: Stop Consumers First
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 首先停止消费者
- en: Before performing this step, it is important that all consumers in the group
    are stopped. They will not read the new offsets if they are written while the
    consumer group is active. The consumers will just overwrite the imported offsets.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行此步骤之前，重要的是停止组中的所有消费者。如果在消费者组处于活动状态时编写，它们将不会读取新的偏移量。消费者将只覆盖导入的偏移量。
- en: 'In the following example, we import the offsets for the consumer group named
    “my-consumer” from the file we created in the last example named *offsets.csv*:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们从上一个示例中创建的名为*offsets.csv*的文件中导入名为“my-consumer”的消费者组的偏移量：
- en: '[PRE11]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Dynamic Configuration Changes
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动态配置更改
- en: 'There is a plethora of configurations for topics, clients, brokers, and more
    that can be updated dynamically during runtime without having to shut down or
    redeploy a cluster. The `kafka-configs.sh` is the main tool for modifying these
    configs. Currently there are four main categories, or *entity-types*, of dynamic
    config changes that can be made: *topics*, *brokers*, *users*, and *clients*.
    For each entity-type there are specific configurations that can be overridden.
    New dynamic configs are being added constantly with each release of Kafka, so
    it is good to ensure you have the same version of this tool that matches the version
    of Kafka you are running. For ease of setting up these configs consistently via
    automation, the `--add-config-file` argument can be used with a preformatted file
    of all the configs you want to manage and update.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有大量的配置适用于主题、客户端、代理等，可以在运行时动态更新，而无需关闭或重新部署集群。`kafka-configs.sh`是修改这些配置的主要工具。目前有四种主要的动态配置更改的实体类型，即*entity-types*：*topics*、*brokers*、*users*和*clients*。对于每种实体类型，都有可以覆盖的特定配置。随着每个Kafka版本的发布，不断添加新的动态配置，因此最好确保您使用与运行的Kafka版本相匹配的工具版本。为了通过自动化方便地设置这些配置，可以使用`--add-config-file`参数，并使用预先格式化的文件来管理和更新所有要管理和更新的配置。
- en: Overriding Topic Configuration Defaults
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 覆盖主题配置默认值
- en: There are many configurations that are set by default for topics that are defined
    in the static broker configuration files (e.g., retention time policy). With dynamic
    configurations, we can override the cluster0level defaults for individual topics
    to accommodate different use cases within a single cluster. [Table 12-2](#table0902)
    shows the valid configuration keys for topics that can be altered dynamically.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多配置是为主题默认设置的，这些配置在静态代理配置文件中定义（例如，保留时间策略）。通过动态配置，我们可以覆盖集群级别的默认值，以适应单个集群中不同用例的不同主题。[表12-2](#table0902)显示了可以动态更改的主题的有效配置键。
- en: 'The format of the command to change a topic configuration is:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 更改主题配置的命令格式如下：
- en: '[PRE12]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here is an example of setting the retention for the topic named “my-topic”
    to 1 hour (3,600,000 ms):'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是将名为“my-topic”的主题保留设置为1小时（3,600,000毫秒）的示例：
- en: '[PRE13]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Table 12-2\. Valid keys for topics
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 表12-2\. 主题的有效键
- en: '| Configuration key | Description |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 配置键 | 描述 |'
- en: '| --- | --- |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `cleanup.policy` | If set to `compact`, the messages in this topic will be
    discarded and only the most recent message with a given key is retained (log compacted).
    |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| `cleanup.policy` | 如果设置为`compact`，则此主题中的消息将被丢弃，只保留具有给定键的最新消息（日志压缩）。 |'
- en: '| `compression.type` | The compression type used by the broker when writing
    message batches for this topic to disk. |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| `compression.type` | 代理在将此主题的消息批次写入磁盘时使用的压缩类型。 |'
- en: '| `delete.retention.ms` | How long, in milliseconds, deleted tombstones will
    be retained for this topic. Only valid for log compacted topics. |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| `delete.retention.ms` | 以毫秒为单位，删除的墓碑将保留在此主题中的时间。仅适用于日志压缩主题。 |'
- en: '| `file.delete.delay.ms` | How long, in milliseconds, to wait before deleting
    log segments and indices for this topic from disk. |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| `file.delete.delay.ms` | 从磁盘中删除此主题的日志段和索引之前等待的时间，以毫秒为单位。 |'
- en: '| `flush.messages` | How many messages are received before forcing a flush
    of this topic’s messages to disk. |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| `flush.messages` | 在强制将此主题的消息刷新到磁盘之前接收多少消息。 |'
- en: '| `flush.ms` | How long, in milliseconds, before forcing a flush of this topic’s
    messages to disk. |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| `flush.ms` | 强制将此主题的消息刷新到磁盘之前的时间，以毫秒为单位。 |'
- en: '| `follower.replication.​throt⁠tled.replicas` | A list of replicas for which
    log replication should be throttled by the follower. |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| `follower.replication.​throt⁠tled.replicas` | 应该由追随者限制日志复制的副本列表。 |'
- en: '| `index.interval.bytes` | How many bytes of messages can be produced between
    entries in the log segment’s index. |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| `index.interval.bytes` | 日志段索引中可以在消息之间产生多少字节。 |'
- en: '| `leader.replication.​throt⁠tled.replica` | A list of replicas for which log
    replication should be throttled by the leader. |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| `leader.replication.​throt⁠tled.replica` | 领导者应该限制日志复制的副本列表。 |'
- en: '| `max.compaction.lag.ms` | Maximum time limit a message won’t be eligible
    for compaction in the log. |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| `max.compaction.lag.ms` | 消息在日志中不符合压缩的最长时间限制。 |'
- en: '| `max.message.bytes` | The maximum size of a single message for this topic,
    in bytes. |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| `max.message.bytes` | 此主题单个消息的最大大小，以字节为单位。 |'
- en: '| `message.downconversion.enable` | Allows the message format version to be
    down-converted to the previous version if enabled with some overhead. |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| `message.downconversion.enable` | 如果启用，允许将消息格式版本降级为上一个版本，但会带来一些开销。 |'
- en: '| `message.format.version` | The message format version that the broker will
    use when writing messages to disk. Must be a valid API version number. |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| `message.format.version` | 经纪人在将消息写入磁盘时将使用的消息格式版本。必须是有效的API版本号。 |'
- en: '| `message.timestamp.​dif⁠fer⁠ence.max.ms` | The maximum allowed difference,
    in milliseconds, between the message timestamp and the broker timestamp when the
    message is received. This is only valid if the `message.timestamp.type` is set
    to `CreateTime`. |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| `message.timestamp.​dif⁠fer⁠ence.max.ms` | 消息时间戳和经纪人时间戳之间的最大允许差异，以毫秒为单位。仅当`message.timestamp.type`设置为`CreateTime`时有效。
    |'
- en: '| `message.timestamp.type` | Which timestamp to use when writing messages to
    disk. Current values are `CreateTime` for the timestamp specified by the client
    and `LogAppendTime` for the time when the message is written to the partition
    by the broker. |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| `message.timestamp.type` | 写入磁盘时要使用的时间戳。当前值为`CreateTime`表示客户端指定的时间戳，`LogAppendTime`表示经纪人将消息写入分区的时间。
    |'
- en: '| `min.clean⁠able.​dirty.ratio` | How frequently the log compactor will attempt
    to compact partitions for this topic, expressed as a ratio of the number of uncompacted
    log segments to the total number of log segments. Only valid for log compacted
    topics. |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| `min.clean⁠able.​dirty.ratio` | 日志压缩器尝试压缩此主题分区的频率，表示为未压缩日志段数与总日志段数的比率。仅适用于日志压缩主题。
    |'
- en: '| `min.compaction.lag.ms` | Minimum time a message will remain uncompacted
    in the log. |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| `min.compaction.lag.ms` | 消息在日志中保持未压缩的最短时间。 |'
- en: '| `min.insync.replicas` | The minimum number of replicas that must be in sync
    for a partition of the topic to be considered available. |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| `min.insync.replicas` | 必须同步的最小副本数，才能认为主题的分区可用。 |'
- en: '| `preallocate` | If set to `true`, log segments for this topic should be preallocated
    when a new segment is rolled. |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| `preallocate` | 如果设置为`true`，则在滚动新段时应预先分配此主题的日志段。 |'
- en: '| `retention.bytes` | The amount of messages, in bytes, to retain for this
    topic. |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| `retention.bytes` | 保留此主题的消息字节数。 |'
- en: '| `retention.ms` | How long messages should be retained for this topic, in
    milliseconds. |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| `retention.ms` | 此主题的消息应保留的时间，以毫秒为单位。 |'
- en: '| `segment.bytes` | The amount of messages, in bytes, that should be written
    to a single log segment in a partition. |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| `segment.bytes` | 应该写入分区中单个日志段的消息字节数。 |'
- en: '| `segment.index.bytes` | The maximum size, in bytes, of a single log segment
    index. |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| `segment.index.bytes` | 单个日志段索引的最大大小，以字节为单位。 |'
- en: '| `segment.jitter.ms` | A maximum number of milliseconds that is randomized
    and added to `segment.ms` when rolling log segments. |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| `segment.jitter.ms` | 在滚动日志段时，随机添加到`segment.ms`的最大毫秒数。 |'
- en: '| `segment.ms` | How frequently, in milliseconds, the log segment for each
    partition should be rotated. |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| `segment.ms` | 每个分区的日志段应该旋转的频率，以毫秒为单位。 |'
- en: '| `unclean.leader.​elec⁠tion.enable` | If set to `false`, unclean leader elections
    will not be permitted for this topic. |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| `unclean.leader.​elec⁠tion.enable` | 如果设置为`false`，则不允许为此主题进行不干净的领导者选举。 |'
- en: Overriding Client and User Configuration Defaults
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 覆盖客户端和用户配置默认值
- en: For Kafka clients and users, there are only a few configurations that can be
    overridden, which are all essentially types of quotas. Two of the more common
    configurations to change are the bytes/sec rates allowed for producers and consumers
    with a specified client ID on a per-broker basis. The full list of shared configurations
    that can be modified for both *users* and *clients* is shown in [Table 12-3](#table0903).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Kafka客户端和用户，只有少数配置可以被覆盖，它们基本上都是配额的类型。更常见的两个要更改的配置是允许每个经纪人的特定客户端ID的生产者和消费者的字节/秒速率。可以为*用户*和*客户端*修改的共享配置的完整列表显示在[表12-3](#table0903)中。
- en: Uneven Throttling Behavior in Poorly Balanced Clusters
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在负载不平衡的集群中不均匀的限流行为
- en: Because throttling occurs on a per-broker basis, even balance of leadership
    of partitions across a cluster becomes particularly important to enforce this
    properly. If you have 5 brokers in a cluster and you specify a producer quota
    of 10 MBps for a client, that client will be allowed to produce 10 MBps *on each*
    broker at the same time for a total of 50 MBps, assuming a balanced leadership
    across all 5 hosts. However, if leadership for every partition is all on broker
    1, the same producer will only be able to produce a max of 10 MBps.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 因为限流是基于每个代理的基础，所以跨集群的分区领导权的平衡变得尤为重要，以便正确执行这一点。如果您在集群中有5个代理，并且为客户端指定了10 MBps的生产者配额，那么该客户端将被允许同时在每个代理上生产10
    MBps，总共50 MBps，假设所有5个主机上的领导权是平衡的。但是，如果每个分区的领导权都在代理1上，那么同一个生产者只能生产最大10 MBps。
- en: Table 12-3\. The configurations (keys) for clients
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 表12-3。客户端的配置（键）
- en: '| Configuration key | Description |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 配置键 | 描述 |'
- en: '| --- | --- |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `consumer_bytes_rate` | The amount of messages, in bytes, that a single client
    ID is allowed to consume from a single broker in one second. |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| `consumer_bytes_rate` | 允许单个客户端ID在一秒内从单个代理消费的字节数。 |'
- en: '| `producer_bytes_rate` | The amount of messages, in bytes, that a single client
    ID is allowed to produce to a single broker in one second. |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| `producer_bytes_rate` | 允许单个客户端ID在一秒内向单个代理生产的字节数。 |'
- en: '| `controller_mutations_rate` | The rate at which mutations are accepted for
    the create topics request, the create partitions request, and the delete topics
    request. The rate is accumulated by the number of partitions created or deleted.
    |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| `controller_mutations_rate` | 接受创建主题请求、创建分区请求和删除主题请求的变异速率。速率是由创建或删除的分区数量累积而成。
    |'
- en: '| `request_percentage` | The percentage per quota window (out of a total of
    (num.io.threads + num.network.threads) × 100%) for requests from the user or client.
    |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| `request_percentage` | 用户或客户端请求在配额窗口内的百分比（总数为（num.io.threads + num.network.threads）×
    100%）。 |'
- en: Client ID Versus Consumer Group
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 客户端ID与消费者组
- en: The client ID is not necessarily the same as the consumer group name. Consumers
    can set their own client ID, and you may have many consumers that are in different
    groups that specify the same client ID. It is considered a best practice to set
    the client ID for each consumer group to something unique that identifies that
    group. This allows a single consumer group to share a quota, and it makes it easier
    to identify in logs what group is responsible for requests.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端ID不一定与消费者组名称相同。消费者可以设置自己的客户端ID，您可能有许多消费者在不同的组中指定相同的客户端ID。为每个消费者组设置唯一标识该组的客户端ID被认为是最佳实践。这允许单个消费者组共享配额，并且更容易在日志中识别负责请求的组。
- en: 'Compatible user and client config changes can be specified together for compatible
    configs that apply to both. Here is an example of the command to change the controller
    mutation rate for both a user and client in one configuration step:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 可以一次指定兼容的用户和客户端配置更改，以适用于两者的兼容配置。以下是一种在一个配置步骤中更改用户和客户端的控制器变异速率的命令示例：
- en: '[PRE14]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Overriding Broker Configuration Defaults
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 覆盖代理配置默认值
- en: 'Broker- and cluster-level configs will primarily be configured statically in
    the cluster configuration files, but there is a plethora of configs that can be
    overridden during runtime without needing to redeploy Kafka. More than 80 overrides
    can be altered with *kafka-configs.sh* for brokers. As such, we will not list
    them all in this book, but they can be referenced by the `--help` command or found
    in the [open source documentation](https://oreil.ly/R8hhb). A few important configs
    worth pointing out specifically are:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 主题和集群级别的配置主要在集群配置文件中静态配置，但是有大量的配置可以在运行时进行覆盖，而无需重新部署Kafka。超过80个覆盖可以使用*kafka-configs.sh*进行更改。因此，我们不会在本书中列出所有这些配置，但可以通过`--help`命令进行引用，或者在[开源文档](https://oreil.ly/R8hhb)中找到。特别值得指出的一些重要配置是：
- en: '`min.insync.replicas`'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`min.insync.replicas`'
- en: Adjusts the minimum number of replicas that need to acknowledge a write for
    a produce request to be successful when producers have set acks to `all` (or `–1`).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 调整需要确认写入的最小副本数，以使生产请求在生产者将acks设置为`all`（或`–1`）时成功。
- en: '`unclean.leader.election.enable`'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`unclean.leader.election.enable`'
- en: Allows replicas to be elected as leader even if it results in data loss. This
    is useful when it is permissible to have some lossy data, or to turn on for short
    times to unstick a Kafka cluster if unrecoverable data loss cannot be avoided.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 即使导致数据丢失，也允许副本被选举为领导者。当允许有一些有损数据或者在短时间内无法避免不可恢复的数据丢失时，这是有用的。
- en: '`max.connections`'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`max.connections`'
- en: The maximum number of connections allowed to a broker at any time. We can also
    use `max.connections.per.ip` and `max.connections.per.ip.overrides` for more fine-tuned
    throttling.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 任何时候允许连接到代理的最大连接数。我们还可以使用`max.connections.per.ip`和`max.connections.per.ip.overrides`进行更精细的限制。
- en: Describing Configuration Overrides
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 描述配置覆盖
- en: All configuration overrides can be listed using the `kafka-config.sh` tool.
    This will allow you to examine the specific configuration for a topic, broker,
    or client. Similar to other tools, this is done using the `--describe` command.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 所有配置覆盖都可以使用`kafka-config.sh`工具列出。这将允许您检查主题、代理或客户端的具体配置。与其他工具类似，这是使用`--describe`命令完成的。
- en: 'In the following example, we can get all the configuration overrides for the
    topic named “my-topic,” which we observe is only the retention time:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们可以获取名为“my-topic”的主题的所有配置覆盖，我们观察到只有保留时间：
- en: '[PRE15]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Topic Overrides Only
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 仅主题覆盖
- en: The configuration description will only show overrides—it does not include the
    cluster default configurations. There is not a way to dynamically discover the
    configuration of the brokers themselves. This means that when using this tool
    to discover topic or client settings in automation, the user must have separate
    knowledge of the cluster default configuration.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 配置描述仅显示覆盖项-不包括集群默认配置。没有办法动态发现经纪人自己的配置。这意味着在使用此工具自动发现主题或客户端设置时，用户必须单独了解集群默认配置。
- en: Removing Configuration Overrides
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除配置覆盖
- en: Dynamic configurations can be removed entirely, which will cause the entity
    to revert back to the cluster defaults. To delete a configuration override, use
    the `--alter` command along with the `--delete-config` parameter.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 动态配置可以完全删除，这将导致实体恢复到集群默认设置。要删除配置覆盖，使用`--alter`命令以及`--delete-config`参数。
- en: 'For example, delete a configuration override for `retention.ms` for a topic
    named “my-topic”:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，删除名为“my-topic”的主题的`retention.ms`的配置覆盖：
- en: '[PRE16]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Producing and Consuming
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生产和消费
- en: While working with Kafka, you will often find it is necessary to manually produce
    or consume some sample messages in order to validate what’s going on with your
    applications. Two utilities are provided to help with this, `kafka-console-consumer.sh`
    and `kafka-console-producer.sh`, which were touched upon briefly in [Chapter 2](ch02.html#installing_kafka)
    to verify our installation. These tools are wrappers around the main Java client
    libraries that allow you to interact with Kafka topics without having to write
    an entire application to do it.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Kafka时，通常需要手动生产或消费一些样本消息，以验证应用程序的运行情况。提供了两个实用程序来帮助处理这个问题，`kafka-console-consumer.sh`和`kafka-console-producer.sh`，这在[第2章](ch02.html#installing_kafka)中简要提到过，用于验证我们的安装。这些工具是主要Java客户端库的包装器，允许您与Kafka主题进行交互，而无需编写整个应用程序来完成。
- en: Piping Output to Another Application
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将输出导入另一个应用程序
- en: While it is possible to write applications that wrap around the console consumer
    or producer (e.g., to consume messages and pipe them to another application for
    processing), this type of application is quite fragile and should be avoided.
    It is difficult to interact with the console consumer in a way that does not lose
    messages. Likewise, the console producer does not allow for using all features,
    and properly sending bytes is tricky. It is best to use either the Java client
    libraries directly or a third-party client library for other languages that use
    the Kafka protocol directly.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可以编写包装控制台消费者或生产者的应用程序（例如，消费消息并将其导入另一个应用程序进行处理），但这种类型的应用程序非常脆弱，应该避免使用。很难与控制台消费者进行交互而不丢失消息。同样，控制台生产者不允许使用所有功能，并且正确发送字节很棘手。最好直接使用Java客户端库或使用Kafka协议的其他语言的第三方客户端库。
- en: Console Producer
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 控制台生产者
- en: The `kakfa-console-producer.sh` tool can be used to write messages into a Kafka
    topic in your cluster. By default, messages are read one per line, with a tab
    character separating the key and the value (if no tab character is present, the
    key is null). As with the console consumer, the producer reads in and produces
    raw bytes using the default serializer (which is `DefaultEncoder`).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`kakfa-console-producer.sh`工具可用于将消息写入集群中的Kafka主题。默认情况下，消息每行读取一条，键和值之间用制表符分隔（如果没有制表符，则键为null）。与控制台消费者一样，生产者使用默认序列化器读取和生成原始字节（即`DefaultEncoder`）。'
- en: The console producer requires that a minimum of two arguments are provided to
    know what Kafka cluster to connect to and which topic to produce to within that
    cluster. The first is the customary `--bootstrap-server` connection string we
    are used to using. When you are done producing, send an end-of-file (EOF) character
    to close the client. In most common terminals, this is done with Control-D.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 控制台生产者要求提供至少两个参数，以知道要连接到哪个Kafka集群以及在该集群中要生产到哪个主题。第一个是我们习惯使用的`--bootstrap-server`连接字符串。在完成生产后，发送文件结束（EOF）字符以关闭客户端。在大多数常见的终端中，可以使用Control-D来完成这个操作。
- en: 'Here we can see an example of producing four messages to a topic named “my-topic”:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到一个将四条消息发送到名为“my-topic”的主题的示例：
- en: '[PRE17]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Using producer configuration options
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用生产者配置选项
- en: It is possible to pass normal producer configuration options to the console
    producer as well. This can be done in two ways, depending on how many options
    you need to pass and how you prefer to do it. The first is to provide a producer
    configuration file by specifying `--producer.config` `*<config-file>*`, where
    `*<config-file>*` is the full path to a file that contains the configuration options.
    The other way is to specify the options on the command line with one or more arguments
    of the form `--producer-property` `*<key>*`=`*<value>*`, where `*<key>*` is the
    configuration option name and `*<value>*` is the value to set it to. This can
    be useful for producer options like message-batching configurations (such as `linger.ms`
    or `batch.size`).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 可以将普通生产者配置选项传递给控制台生产者。有两种方法可以做到这一点，取决于您需要传递多少选项以及您喜欢如何传递。第一种方法是通过指定`--producer.config`
    `*<config-file>*`来提供生产者配置文件，其中`*<config-file>*`是包含配置选项的文件的完整路径。另一种方法是在命令行上指定选项，格式为`--producer-property`
    `*<key>*`=`*<value>*`，其中`*<key>*`是配置选项名称，`*<value>*`是要设置的值。这对于生产者选项（如`linger.ms`或`batch.size`）可能很有用。
- en: Confusing Command-Line Options
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混淆的命令行选项
- en: The `--property` command-line option is available for both the console producer
    and the console consumer, but this should not be confused with the `--producer-property`
    or `--consumer-property` options, respectively. The `--property` option is only
    used for passing configurations to the message formatter, and not the client itself.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '`--property`命令行选项适用于控制台生产者和控制台消费者，但这不应与`--producer-property`或`--consumer-property`选项混淆。`--property`选项仅用于将配置传递给消息格式化程序，而不是客户端本身。'
- en: 'The console producer has many command-line arguments available to use with
    the `--producer-property` option for adjusting its behavior. Some of the more
    useful options are:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '`--batch-size`'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: Specifies the number of messages sent in a single batch if they are not being
    sent synchronously.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '`--timeout`'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: If a producer is running in asynchronous mode, this provides the max amount
    of time waiting for the batch size before producing to avoid long waits on low-producing
    topics.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '`--compression-codec <string>`'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: 'Specify the type of compression to be used when producing messages. Valid types
    can be one of the following: `none`, `gzip`, `snappy`, `zstd`, or `lz4`. The default
    value is `gzip`.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '`--sync`'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Produce messages synchronously, waiting for each message to be acknowledged
    before sending the next one.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Line-reader options
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `kafka.tools.ConsoleProducer$LineMessageReader` class, which is responsible
    for reading standard input and creating producer records, also has several useful
    options that can be passed to the console producer using the `--property` command-line
    option:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '`ignore.error`'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Set to `false` to throw an exception when `parse.key` is set to `true` and a
    key separator is not present. Defaults to `true`.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '`parse.key`'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Set to `false` to always set the key to null. Defaults to `true`.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '`key.separator`'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Specify the delimiter character to use between the message key and message value
    when reading. Defaults to a tab character.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Changing Line-Reading Behavior
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can provide your own class to Kafka for customized methods of reading lines.
    The class that you create must extend `kafka.​com⁠mon.MessageReader` and will
    be responsible for creating the `ProducerRecord`. Specify your class on the command
    line with the `--line-reader` option, and make sure the JAR containing your class
    is in the classpath. The default is `kafka.tools.Console​Pro⁠ducer$LineMessageReader`.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: When producing messages, the `LineMessageReader` will split the input on the
    first instance of the `key.separator`. If there are no characters remaining after
    that, the value of the message will be empty. If no key separator character is
    present on the line, or if `parse.key` is false, the key will be null.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Console Consumer
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `kafka-console-consumer.sh` tool provides a means to consume messages out
    of one or more topics in your Kafka cluster. The messages are printed in standard
    output, delimited by a new line. By default, it outputs the raw bytes in the message,
    without the key, with no formatting (using the `DefaultFormatter`). Similar to
    the producer, there are a few basic options needed to get started: a connection
    string to the cluster, which topic you want to consume from, and the timeframe
    you want to consume.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: Checking Tool Versions
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is very important to use a consumer that is the same version as your Kafka
    cluster. Older console consumers can potentially damage the cluster by interacting
    with the cluster or ZooKeeper in incorrect ways.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: 'As in other commands, the connection string to the cluster will be the `--bootstrap-server`
    option; however, you can choose from two options for selecting the topics to consume:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '`--topic`'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Specifies a single topic to consume from.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '`--whitelist`'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: A regular expression matching all topics to consume from (remember to properly
    escape the regex so that it is not processed improperly by the shell).
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: 'Only one of the previous options should be selected and used. Once the console
    consumer has started, the tool will continue to try and consume until the shell
    escape command is given (in this case, Ctrl-C). Here is an example of consuming
    all topics from our cluster that match the prefix *my* (of which there is only
    one in this example, “my-topic”):'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Using consumer configuration options
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In addition to these basic command-line options, it is possible to pass normal
    consumer configuration options to the console consumer as well. Similar to the
    `kafka-console-producer.sh` tool, this can be done in two ways, depending on how
    many options you need to pass and how you prefer to do it. The first is to provide
    a consumer configuration file by specifying `--consumer.config` `*<config-file>*`,
    where `*<config-file>*` is the full path to a file that contains the configuration
    options. The other way is to specify the options on the command line with one
    or more arguments of the form `--consumer-property` `*<key>*`=`*<value>*`, where
    `*<key>*` is the configuration option name and `*<value>*` is the value to set
    it to.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few other commonly used options for the console consumer that are
    helpful to know and be familiar with:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '`--formatter` `*<classname>*`'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Specifies a message formatter class to be used to decode the messages. This
    defaults to `kafka.tools.DefaultMessageFormatter`.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '`--from-beginning`'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Consume messages in the topic(s) specified from the oldest offset. Otherwise,
    consumption starts from the latest offset.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '`--max-messages <int>`'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: The maximum number of messages to consume before exiting.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '`--partition <int>`'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: Consume only from the partition with the ID given.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '`--offset`'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: The offset ID to consume from, if provided (`<int>`). Other valid options are
    `earliest`, which will consume from the beginning, and `latest`, which will start
    consuming from the most recent offset.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '`--skip-message-on-error`'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: Skip a message if there is an error when processing instead of halting. Useful
    for debugging.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: Message formatter options
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are three message formatters available to use besides the default:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '`kafka.tools.LoggingMessageFormatter`'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: Outputs messages using the logger, rather than standard out. Messages are printed
    at the INFO level and include the timestamp, key, and value.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '`kafka.tools.ChecksumMessageFormatter`'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: Prints only message checksums.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '`kafka.tools.NoOpMessageFormatter`'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: Consumes messages but does not output them at all.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of consuming the same messages from before but
    with the `kafka.tools.ChecksumMessageFormatter` being used rather than the default:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The `kafka.tools.DefaultMessageFormatter` also has several useful options that
    can be passed using the `--property` command-line option, shown in [Table 12-4](#table0904).
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: Table 12-4\. Message formatter properties
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '| Property | Description |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
- en: '| `print.timestamp` | Set to `true` to display the timestamp of each message
    (if available). |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
- en: '| `print.key` | Set to `true` to display the message key in addition to the
    value. |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
- en: '| `print.offset` | Set to `true` to display the message offset in addition
    to the value. |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
- en: '| `print.partition` | Set to `true` to display the topic partition a message
    is consumed from. |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
- en: '| `key.separator` | Specify the delimiter character to use between the message
    key and message value when printing. |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
- en: '| `line.separator` | Specify the delimiter character to use between messages.
    |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
- en: '| `key.deserializer` | Provide a class name that is used to deserialize the
    message key before printing. |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
- en: '| `value.deserializer` | Provide a class name that is used to deserialize the
    message value before printing. |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
- en: The deserializer classes must implement `org.apache.kafka.common.​ser⁠ial⁠iza⁠tion.Deserializer`,
    and the console consumer will call the `toString` method on them to get the output
    to display. Typically, you would implement these deserializers as a Java class
    that you would insert into the classpath for the console consumer by setting the
    `CLASSPATH` environment variable before executing `kafka_​con⁠sole_consumer.sh`.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: Consuming the offsets topics
  id: totrans-261
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is sometimes useful to see what offsets are being committed for the cluster’s
    consumer groups. You may want to see if a particular group is committing offsets
    at all, or how often offsets are being committed. This can be done by using the
    console consumer to consume the special internal topic called `__consumer_offsets`.
    All consumer offsets are written as messages to this topic. In order to decode
    the messages in this topic, you must use the formatter class `kafka.coordinator.group.Group​Met⁠ada⁠taManager$OffsetsMessageFormatter`.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: 'Putting all we have learned together, the following is an example of consuming
    the earliest message from the `__consumer_offsets` topic:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Partition Management
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A default Kafka installation also contains a few scripts for working with the
    management of partitions. One of these tools allows for the reelection of leader
    replicas; another is a low-level utility for assigning partitions to brokers.
    Together these tools can assist in situations where a more manual hands-on approach
    to balance message traffic within a cluster of Kafka brokers is needed.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: Preferred Replica Election
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As described in [Chapter 7](ch07.html#reliable_data_delivery), partitions can
    have multiple replicas for reliability. It is important to understand that only
    one of these replicas can be the leader for the partition at any given point in
    time, and all produce and consume operations happen on that broker. Maintaining
    a balance of which partition’s replicas have leadership on which broker is necessary
    to ensure the load is spread out through a full Kafka cluster.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: Leadership is defined within Kafka as the first in-sync replica in the replica
    list. However, when a broker is stopped or loses connectivity to the rest of the
    cluster, leadership is transferred to another in-sync replica, and the original
    does not resume leadership of any partitions automatically. This can cause wildly
    inefficient balance after a deployment across a full cluster if automatic leader
    balancing is not enabled. As such it is recommended to ensure that this setting
    is enabled or to use other open source tooling such as Cruise Control to ensure
    that a good balance is maintained at all times.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: If you find that your Kafka cluster has a poor balance, a lightweight, generally
    non-impacting procedure can be performed called *preferred leader election*. This
    tells the cluster controller to select the ideal leader for partitions. Clients
    can track leadership changes automatically, so they will be able to move to the
    new broker in the cluster in which leadership is transferred. This operation can
    be manually triggered using the `kafka-leader-election.sh` utility. An older version
    of this tool called `kafka-preferred-replica-election.sh` is also available but
    has been deprecated in favor of the new tool, which allows for more customization,
    such as specifying whether we want a “preferred” or “unclean” election type.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, starting a preferred leader election for all topics in a cluster
    can be executed with the following command:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'It is also possible to start elections on specific partitions or topics. This
    can be done by passing in a topic name with the `--topic` option and a partition
    with the `--partition` option directly. It is also possible to pass in a list
    of several partitions to be elected. This is done by configuring a JSON file that
    we will call *partitions.json*:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'In this example, we will start a preferred replica election with a specified
    list of partitions in a file named *partitions.json*:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Changing a Partition’s Replicas
  id: totrans-277
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Occasionally it may be necessary to change the replica assignments manually
    for a partition. Some examples of when this might be needed are:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: There is an uneven load on brokers that the automatic leader distribution is
    not correctly handling.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a broker is taken offline and the partition is under replicated.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a new broker is added and we want to more quickly balance new partitions
    on it.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You want to adjust the replication factor of a topic.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `kafka-reassign-partitions.sh` can be used to perform this operation. This
    is a multistep process to generate a move set and then execute on the provided
    move set proposal. First, we want to use a broker list and a topic list to generate
    a proposal for the set of moves. This will require the generation of a JSON file
    with a list of topics to be supplied. The next step executes the moves that were
    generated by the previous proposal. Finally, the tool can be used with the generated
    list to track and verify the progress or completion of the partition reassignments.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: Let’s generate a hypothetical scenario in which you have a four-broker Kafka
    cluster. You’ve recently added two new brokers, bringing the total up to six,
    and you want to move two of your topics onto brokers 5 and 6.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: 'To generate a set of partition moves, you must first create a file that contains
    a JSON object listing the topics. The JSON object is formatted as follows (the
    version number is currently always 1):'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Once we’ve defined our JSON file, we can use it to generate a set of partition
    moves to move the topics listed in the file *topics.json* to the brokers with
    IDs 5 and 6:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The output proposed here is formatted correctly, to which we can save two new
    JSON files that we will call *revert-reassignment.json* and *expand-cluster-reassignment.json*.
    The first file can be used to move partitions back to where they were originally
    if you need to roll back for some reason. The second file can be used for the
    next step, as this is just a proposal and hasn’t executed anything yet. You’ll
    notice in the output that there isn’t a good balance of leadership, as the proposal
    will result in all leadership moving to broker 5\. We will ignore this for now
    and presume the cluster automatic leadership balancing is enabled, which will
    help distribute it later. It should be noted that the first step can be skipped
    if you know exactly where you want to move your partitions to and you manually
    craft the JSON to move partitions.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: 'To execute the proposed partition reassignment from the file *expand-cluster-reassignment.json*,
    run the following command:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This will start the reassignment of the specified partition replicas to the
    new brokers. The output is the same as the generated proposal verification. The
    cluster controller performs this reassignment action by adding the new replicas
    to the replica list for each partition, which will temporarily increase the replication
    factor of these topics. The new replicas will then copy all existing messages
    for each partition from the current leader. Depending on the size of the partitions
    on disk, this can take a significant amount of time as the data is copied across
    the network to the new replicas. Once replication is complete, the controller
    removes the old replicas from the replica list by reducing the replication factor
    to the original size with the old replicas removed.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few other useful features of the command you could take advantage
    of:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: '`--additional`'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: This option will allow you to add to the existing reassignments so they can
    continue to be performed without interruption and without the need to wait until
    the original movements have completed in order to start a new batch.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '`--disable-rack-aware`'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: There may be times when, due to rack awareness settings, the end-state of a
    proposal may not be possible. This can be overridden with this command if necessary.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '`--throttle`'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: This value is in units of bytes/sec. Partition reassignments have a big impact
    on the performance of your cluster, as they will cause changes in the consistency
    of the memory page cache and use network and disk I/O. Throttling the movement
    of partitions can be useful to prevent this issue. This can be combined with the
    `--additional` tag to throttle an already-started reassignment process that may
    be causing issues.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: Improving Network Utilization When Reassigning Replicas
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When removing many partitions from a single broker, such as if that broker is
    being removed from the cluster, it may be useful to remove all leadership from
    the broker first. This can be done by manually moving leaderships off the broker;
    however, using the preceding tooling to do this is arduous. Other open source
    tools such as Cruise Control include features like broker “demotion,” which safely
    moves leadership off a broker and is probably the simplest way to do this.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: However, if you do not have access to such tools, a simple restart of a broker
    will suffice. As a broker is preparing to shut down, all leadership for the partitions
    on that particular broker will move to other brokers in the clusters. This can
    significantly increase the performance of reassignments and reduce the impact
    on the cluster, as the replication traffic will be distributed to many brokers.
    However, if automatic leader reassignment is enabled after the broker is bounced,
    leadership may return to this broker, so it may be beneficial to temporarily disable
    this feature.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: To check on the progress of the partition moves, the tool can be used to verify
    the status of the reassignment. This will show which reassignments are currently
    in progress, which reassignments have completed, and (if there was an error) which
    reassignments have failed. To do this, you must have the file with the JSON object
    that was used in the execute step.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of potential results using the `--verify` option when running
    the preceding partition reassignment from the file *expand-cluster-reassignment.json*:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Changing the replication factor
  id: totrans-306
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `kafka-reassign-partitions.sh` tool can also be used to increase or decrease
    the replication factor (RF) for a partition. This may be necessary in situations
    where a partition was created with the wrong RF, you want increased redundancy
    as you expand your cluster, or you want to decrease redundancy for cost savings.
    One clear example is that if a cluster RF default setting is adjusted, existing
    topics will not automatically be increased. The tool can be used to increase RF
    on the existing partitions.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, if we wanted to increase topic “foo1” from the previous example
    from an RF = 2 to RF = 3, then we could craft a JSON similar to the execution
    proposal we used before, except we’d add in an additional broker ID to the replica
    set. For example, we could construct a JSON called *increase-foo1-RF.json* in
    which we add broker 4 to the existing set of 5,6 that we already have:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We’d then use the commands shown earlier to execute on this proposal. When
    it completes, we can verify the RF has been increased by either using the `--verify`
    flag or using the `kafka-topics.sh` script to describe the topic:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Canceling replica reassignments
  id: totrans-312
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Canceling a replica reassignment in the past was a dangerous process that required
    unsafe manual manipulation of ZooKeeper nodes (or znodes) by deleting the `/admin/reassign_partitions`
    znode. Fortunately, this is no longer the case. The `kafka-reassign-partitions.sh`
    script (as well as the AdminClient it is a wrapper for) now supports the `--cancel`
    option, which will cancel the active reassignments that are ongoing in a cluster.
    When stopping an in-progress partition move, the `--cancel` command is designed
    to restore the replica set to the one it was prior to reassignment being initiated.
    As such, if replicas are being removed from a dead broker or an overloaded broker,
    it may leave the cluster in an undesirable state. There is also no guarantee that
    the reverted replica set will be in the same order as it was previously.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: Dumping Log Segments
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: On occasion you may have the need to read the specific content of a message,
    perhaps because you ended up with a “poison pill” message in your topic that is
    corrupted and your consumer cannot handle it. The `kafka-dump-log.sh` tool is
    provided to decode the log segments for a partition. This will allow you to view
    individual messages without needing to consume and decode them. The tool takes
    a comma-separated list of log segment files as an argument and can print out either
    message summary information or detailed message data.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we will dump the logs from a sample topic, “my-topic,” which
    is a new topic with only four messages in it. First, we will simply decode the
    log segment file named *00000000000000000000.log* and retrieve basic metadata
    info about each message without actually printing the message contents. In our
    example Kafka installation, the Kafka data directory is set up in */tmp/kafka-logs*.
    As such, our directory for finding the log segments will be */tmp/kafka-logs/<topic-name>-<partition>*,
    in this case, */tmp/kafka-logs/my-topic-0/*:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'In the next example, we add the `--print-data-log` option, which will provide
    us the actual payload information and more:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The tool also contains a few other useful options, such as validating the index
    file that goes along with a log segment. The index is used for finding messages
    within a log segment, and if corrupted, will cause errors in consumption. Validation
    is performed whenever a broker starts up in an unclean state (i.e., it was not
    stopped normally), but it can be performed manually as well. There are two options
    for checking indices, depending on how much checking you want to do. The option
    `--index-sanity-check` will just check that the index is in a usable state, while
    `--verify-index-only` will check for mismatches in the index without printing
    out all the index entries. Another useful option, `--value-decoder-class`, allows
    serialized messages to be deserialized by passing in a decoder.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: Replica Verification
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Partition replication works similar to a regular Kafka consumer client: the
    follower broker starts replicating at the oldest offset and checkpoints the current
    offset to disk periodically. When replication stops and restarts, it picks up
    from the last checkpoint. It is possible for previously replicated log segments
    to get deleted from a broker, and the follower will not fill in the gaps in this
    case.'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: To validate that the replicas for a topic’s partitions are the same across the
    cluster, you can use the `kafka-replica-verification.sh` tool for verification.
    This tool will fetch messages from all the replicas for a given set of topic partitions,
    check that all messages exist on all replicas, and print out the max lag for given
    partitions. This process will operate continuously in a loop until canceled. To
    do this, you must provide an explicit comma-separated list of brokers to connect
    to. By default, all topics are validated; however, you may also provide the tool
    a regular expression that matches the topics you wish to validate.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: 'Caution: Cluster Impact Ahead'
  id: totrans-324
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The replica verification tool will have an impact on your cluster similar to
    reassigning partitions, as it must read all messages from the oldest offset in
    order to verify the replica. In addition, it reads from all replicas for a partition
    in parallel, so it should be used with caution.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, verify the replicas for the topics starting with *my* on kafka
    brokers 1 and 2, which contain partition 0 of “my-topic”:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Other Tools
  id: totrans-328
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Several more tools are included in the Kafka distribution that are not covered
    in depth in this book that can be useful in administering your Kafka cluster for
    specific use cases. Further information about them can be found on the [Apache
    Kafka website](https://kafka.apache.org):'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: Client ACLs
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: A command-line tool, `kafka-acls.sh`, is provided for interacting with access
    controls for Kafka clients. This includes full features for authorizer properties,
    set up for deny or allow principles, cluster- or topic-level restrictions, ZooKeeper
    TLS file configuration, and much more.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: Lightweight MirrorMaker
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: A lightweight `kafka-mirror-maker.sh` script is available for mirroring data.
    A more in-depth look at replication can be found in [Chapter 10](ch10.html#cross_cluster_mirroring).
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: Testing tools
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: There are several other scripts used for testing Kafka or helping to perform
    upgrades of features. `kafka-broker-api-versions.sh` helps to easily identify
    different versions of usable API elements when upgrading from one Kafka version
    to another and check for compatibility issues. There are producer and consumer
    performance tests scripts. There are several scripts to help administer ZooKeeper
    as well. There is also `trogdor.sh`, which is a test framework designed to run
    benchmarks and other workloads to attempt to stress test the system.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: Unsafe Operations
  id: totrans-336
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are some administrative tasks that are technically possible to do but
    should not be attempted except in the most extreme situations. Often this is when
    you are diagnosing a problem and have run out of options, or you have found a
    specific bug that you need to work around temporarily. These tasks are usually
    undocumented, unsupported, and pose some amount of risk to your application.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: Several of the more common of these tasks are documented here so that in an
    emergency situation, there is a potential option for recovery. Their use is not
    recommended under normal cluster operations and should be considered carefully
    before being executed.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: 'Danger: Here Be Dragons'
  id: totrans-339
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The operations in this section often involve working with the cluster metadata
    stored in ZooKeeper directly. This can be a very dangerous operation, so you must
    be very careful to not modify the information in ZooKeeper directly, except as
    noted.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: Moving the Cluster Controller
  id: totrans-341
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every Kafka cluster has a single broker that is designated as a controller.
    The controller has a special thread that is responsible for overseeing cluster
    operations in addition to normal broker work. Normally, controller election is
    done automatically through ephemeral ZooKeeper znode monitoring. When a controller
    turns off or becomes unavailable, other brokers nominate themselves as soon as
    possible, since once the controller shuts down, the znode is removed.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: On occasion, when troubleshooting a misbehaving cluster or broker, it may be
    useful to forcibly move the controller to a different broker without shutting
    down the host. One such example is when the controller has suffered an exception
    or other problem that has left it running but not functional. Moving the controller
    in these situations does not normally have a high risk, but as it is not a normal
    task, it should not be performed regularly.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: To forcibly move a controller, deleting the ZooKeeper znode at */admin/controller*
    manually will cause the current controller to resign, and the cluster will randomly
    select a new controller. There is currently no way to specify a specific broker
    to be controller in Apache Kafka.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: Removing Topics to Be Deleted
  id: totrans-345
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When attempting to delete a topic in Kafka, a ZooKeeper node requests that
    the deletion is created. Once every replica completes deletion of the topic and
    acknowledges deletion is complete, the znode will be removed. Under normal circumstances,
    this is executed by the cluster very quickly. However, sometimes things can go
    wrong with this process. Here are some scenarios in which a deletion request may
    become stuck:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: A requester has no way of knowing whether topic deletion is enabled in the cluster
    and can request deletion of a topic from a cluster in which deletion is disabled.
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A very large topic is requested to be deleted, but before the request is handled,
    one or more of the replica sets goes offline due to hardware failures, and the
    deletion cannot complete as the controller cannot ack that the deletion was completed
    successfully.
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To “unstick” topic deletion, first delete the */admin/delete_topic/<topic>*
    znode. Deleting the topic ZooKeeper nodes (but not the parent */admin/delete_topic*
    node) will remove the pending requests. If the deletion is re-queued by cached
    requests in the controller, it may be necessary to also forcibly move the controller
    as shown earlier immediately after removing the topic znode to ensure that no
    cached requests are pending in the controller.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: Deleting Topics Manually
  id: totrans-350
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you are running a cluster with delete topics disabled, or if you find yourself
    needing to delete some topics outside of the normal flow of operations, it is
    possible to manually delete them from the cluster. This requires a full shutdown
    of all brokers in the cluster, however, and cannot be done while any of the brokers
    in the cluster are running.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: Shut Down Brokers First
  id: totrans-352
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Modifying the cluster metadata in ZooKeeper when the cluster is online is a
    very dangerous operation and can put the cluster into an unstable state. Never
    attempt to delete or modify topic metadata in ZooKeeper while the cluster is online.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: 'To delete a topic from the cluster:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: Shut down all brokers in the cluster.
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Remove the ZooKeeper path */brokers/topics/<topic>* from the Kafka cluster path.
    Note that this node has child nodes that must be deleted first.
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Remove the partition directories from the log directories on each broker. These
    will be named `<topic>-<int>`, where `<int>` is the partition ID.
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Restart all brokers.
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  id: totrans-359
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Running a Kafka cluster can be a daunting endeavor, with numerous configurations
    and maintenance tasks to keep the systems running at peak performance. In this
    chapter, we discussed many of the routine tasks, such as managing topic and client
    configurations, that you will need to handle frequently. We also covered some
    of the more esoteric tasks that you’ll need for debugging problems, like examining
    log segments. Finally, we covered a few of the operations that, while not safe
    or routine, can be used to get you out of a sticky situation. All together, these
    tools will help you to manage your Kafka cluster. As you begin to scale your Kafka
    clusters larger, even the use of these tools may become arduous and difficult
    to manage. It is highly recommended to engage with the open source Kafka community
    and take advantage of the many other open source projects in the ecosystem to
    help automate many of the tasks outlined in this chapter.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: Now that we are confident in the tools needed to administer and manage our cluster,
    it is still impossible without proper monitoring in place. [Chapter 13](ch13.html#monitoring_kafka)
    will discuss ways to monitor broker and cluster health and operations so you can
    be sure Kafka is working well (and know when it isn’t). We will also offer best
    practices for monitoring your clients, including both producers and consumers.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL

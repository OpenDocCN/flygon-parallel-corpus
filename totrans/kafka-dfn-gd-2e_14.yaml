- en: Chapter 12\. Administering Kafka
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章。管理Kafka
- en: Managing a Kafka cluster requires additional tooling to perform administrative
    changes to topics, configurations, and more. Kafka provides several command-line
    interface (CLI) utilities that are useful for making administrative changes to
    your clusters. The tools are implemented in Java classes, and a set of scripts
    are provided natively to call those classes properly. While these tools provide
    basic functions, you may find they are lacking for more complex operations or
    are unwieldy to use at larger scales. This chapter will describe only the basic
    tools that are available as part of the Apache Kafka open source project. More
    information about advanced tools that have been developed in the community, outside
    of the core project, can be found on the [Apache Kafka website](https://kafka.apache.org).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 管理Kafka集群需要额外的工具来执行对主题、配置等的管理更改。Kafka提供了几个命令行接口（CLI）实用程序，用于对集群进行管理更改。这些工具是以Java类实现的，并且提供了一组本地脚本来正确调用这些类。虽然这些工具提供了基本功能，但您可能会发现它们在更复杂的操作或在更大规模上使用时存在不足。本章将仅描述作为Apache
    Kafka开源项目一部分提供的基本工具。有关社区中开发的高级工具的更多信息，可以在[Apache Kafka网站](https://kafka.apache.org)上找到。
- en: Authorizing Admin Operations
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 授权管理操作
- en: While Apache Kafka implements authentication and authorization to control topic
    operations, default configurations do not restrict the use of these tools. This
    means that these CLI tools can be used without any authentication required, which
    will allow operations such as topic changes to be executed with no security check
    or audit. Always ensure that access to this tooling on your deployments is restricted
    to administrators only to prevent unauthorized changes.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Apache Kafka实现了身份验证和授权来控制主题操作，但默认配置不限制这些工具的使用。这意味着这些CLI工具可以在不需要任何身份验证的情况下使用，这将允许执行诸如主题更改之类的操作，而无需进行安全检查或审计。始终确保对部署中的此工具的访问受到限制，仅限管理员才能防止未经授权的更改。
- en: Topic Operations
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主题操作
- en: The `kafka-topics.sh` tool provides easy access to most topic operations. It
    allows you to create, modify, delete, and list information about topics in the
    cluster. While some topic configurations are possible through this command, they
    have been deprecated, and it is recommended to use the more robust method of using
    the `kafka-config.sh` tool for configuration changes. To use the `kafka-topics.sh`
    command, you must provide the cluster connection string and port through the `--bootstrap-server`
    option. In the examples that follow, the cluster connect string is being run locally
    on one of the hosts in the Kafka cluster, and we will be using `localhost:9092`.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '`kafka-topics.sh`工具提供了对大多数主题操作的简单访问。它允许您在集群中创建、修改、删除和列出有关主题的信息。虽然通过此命令可能可以进行一些主题配置，但这些配置已被弃用，建议使用更健壮的方法使用`kafka-config.sh`工具进行配置更改。要使用`kafka-topics.sh`命令，必须通过`--bootstrap-server`选项提供集群连接字符串和端口。在接下来的示例中，集群连接字符串在Kafka集群中的一个主机上本地运行，并且我们将使用`localhost:9092`。'
- en: Throughout this chapter, all the tools will be located in the directory */usr/local/kafka/bin/*.
    The example commands in this section will assume you are in this directory or
    have added the directory to your `$PATH`.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，所有工具都将位于目录*/usr/local/kafka/bin/*中。本节中的示例命令将假定您在此目录中，或者已将该目录添加到您的`$PATH`中。
- en: Check the Version
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查版本
- en: Many of the command-line tools for Kafka have a dependency on the version of
    Kafka running to operate correctly. This includes some commands that may store
    data in ZooKeeper rather than connecting to the brokers themselves. For this reason,
    it is important to make sure the version of the tools that you are using matches
    the version of the brokers in the cluster. The safest approach is to run the tools
    on the Kafka brokers themselves, using the deployed version.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka的许多命令行工具对Kafka运行的版本有依赖，以正确运行。这包括一些命令可能会将数据存储在ZooKeeper中，而不是直接连接到经纪人本身。因此，重要的是确保您使用的工具版本与集群中经纪人的版本匹配。最安全的方法是在Kafka经纪人上运行工具，使用部署的版本。
- en: Creating a New Topic
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建新主题
- en: 'When creating a new topic through the `--create` command, there are several
    required arguments to create a new topic in a cluster. These arguments must be
    provided when using this command even though some of them may have broker-level
    defaults configured already. Additional arguments and configuration overrides
    are possible at this time, as well using the `--config` option, but are covered
    later in the chapter. Here is a list of the three required arguments:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`--create`命令创建新主题时，在集群中创建新主题需要几个必需的参数。使用此命令时必须提供这些参数，即使其中一些可能已经配置了经纪人级别的默认值。此时还可以使用`--config`选项进行其他参数和配置覆盖，但这将在本章后面进行介绍。以下是三个必需参数的列表：
- en: '`--topic`'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '`--topic`'
- en: The name of the topic that you wish to create.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望创建的主题名称。
- en: '`--replication-factor`'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '`--replication-factor`'
- en: The number of replicas of the topic to maintain within the cluster.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 主题在集群中维护的副本数量。
- en: '`--partitions`'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '`--partitions`'
- en: The number of partitions to create for the topic.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为主题创建的分区数。
- en: Good Topic Naming Practices
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 良好的主题命名实践
- en: Topic names may contain alphanumeric characters, underscores, dashes, and periods;
    however, it is not recommended to use periods in topic names. Internal metrics
    inside of Kafka convert period characters to underscore characters (e.g., “topic.1”
    becomes “topic_1” in metrics calculations), which can result in conflicts in topic
    names.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 主题名称可以包含字母数字字符、下划线、破折号和句点；但不建议在主题名称中使用句点。Kafka内部度量标准将句点字符转换为下划线字符（例如，“topic.1”在度量计算中变为“topic_1”），这可能导致主题名称冲突。
- en: Another recommendation is to avoid using a double underscore to start your topic
    name. By convention, topics internal to Kafka operations are created with a double
    underscore naming convention (like the `__consumer_offsets` topic, which tracks
    consumer group offset storage). As such it is not recommended to have topic names
    that begin with the double underscore naming convention to prevent confusion.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个建议是避免使用双下划线来开始你的主题名称。按照惯例，Kafka操作内部的主题使用双下划线命名约定创建（比如`__consumer_offsets`主题，用于跟踪消费者组偏移存储）。因此，不建议使用以双下划线命名约定开头的主题名称，以防混淆。
- en: 'Creating a new topic is simple. Run `kafka-topics.sh` as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新主题很简单。运行`kafka-topics.sh`如下：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The command will cause the cluster to create a topic with the specified name
    and number of partitions. For each partition, the cluster will select the specified
    number of replicas appropriately. This means that if the cluster is set up for
    rack-aware replica assignment, the replicas for each partition will be in separate
    racks. If rack-aware assignment is not desired, specify the `--disable-rack-aware`
    command-line argument.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将导致集群创建一个具有指定名称和分区数的主题。对于每个分区，集群将适当地选择指定数量的副本。这意味着如果集群设置为机架感知副本分配，每个分区的副本将位于不同的机架上。如果不希望使用机架感知分配，指定`--disable-rack-aware`命令行参数。
- en: 'For example, create a topic named “my-topic” with eight partitions that have
    two replicas each:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，创建一个名为“my-topic”的主题，其中每个有两个副本的八个分区：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Using if-exists and if-not-exists Arguments Properly
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正确使用if-exists和if-not-exists参数
- en: When using `kafka-topics.sh` in automation, you may want to use the `--if-not-exists`
    argument while creating new topics that will not return an error if the topic
    already exists.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在自动化中使用`kafka-topics.sh`时，创建新主题时可能希望使用`--if-not-exists`参数，如果主题已经存在，则不返回错误。
- en: While an `--if-exists` argument is provided for the `--alter` command, using
    it is not recommended. Using this argument will cause the command to not return
    an error if the topic being changed does not exist. This can mask problems where
    a topic does not exist that should have been created.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`--alter`命令提供了一个`--if-exists`参数，但不建议使用它。使用这个参数会导致命令在被更改的主题不存在时不返回错误。这可能掩盖了应该创建但不存在的主题的问题。
- en: Listing All Topics in a Cluster
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 列出集群中的所有主题
- en: The `--list` command lists all topics in a cluster. The list is formatted with
    one topic per line, in no particular order, which is useful for generating a full
    list of topics.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`--list`命令列出集群中的所有主题。列表格式化为每行一个主题，没有特定顺序，这对于生成完整的主题列表很有用。'
- en: 'Here’s an example of the `--list` option listing all topics in the cluster:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用`--list`选项列出集群中所有主题的示例：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You’ll notice the internal `__consumer_offsets` topic is listed here. Running
    the command with `--exclude-internal` will remove all topics from the list that
    begin with the double underscore mentioned earlier, which can be beneficial.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到内部的`__consumer_offsets`主题在这里列出。使用`--exclude-internal`运行命令将从列表中删除所有以前提到的双下划线开头的主题，这可能是有益的。
- en: Describing Topic Details
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 描述主题详细信息
- en: It is also possible to get detailed information on one or more topics in the
    cluster. The output includes the partition count, topic configuration overrides,
    and a listing of each partition with its replica assignments. This can be limited
    to a single topic by providing a `--topic` argument to the command.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以获取集群中一个或多个主题的详细信息。输出包括分区计数、主题配置覆盖，以及每个分区及其副本分配的列表。通过向命令提供`--topic`参数，可以将其限制为单个主题。
- en: 'For example, describing our recently created “my-topic” in the cluster:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在集群中描述我们最近创建的“my-topic”：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The `--describe` command also has several useful options for filtering the
    output. These can be helpful for diagnosing cluster issues more easily. For these
    commands we generally do not specify the `--topic` argument because the intention
    is to find all topics or partitions in a cluster that match the criteria. These
    options will not work with the `list` command. Here is a list of useful pairings
    to use:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`--describe`命令还有几个有用的选项用于过滤输出。这些对于更容易诊断集群问题很有帮助。对于这些命令，我们通常不指定`--topic`参数，因为意图是找到所有符合条件的集群中的主题或分区。这些选项不适用于`list`命令。以下是一些有用的配对列表：'
- en: '`--topics-with-overrides`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`--topics-with-overrides`'
- en: This will describe only the topics that have configurations that differ from
    the cluster defaults.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这将仅描述与集群默认配置不同的主题。
- en: '`--exclude-internal`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`--exclude-internal`'
- en: The previously mentioned command will remove all topics from the list that begin
    with the double underscore naming convention.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 前面提到的命令将从列表中删除所有以双下划线命名约定开头的主题。
- en: 'The following commands are used to help find topic partitions that may have
    problems:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令用于帮助查找可能存在问题的主题分区：
- en: '`--under-replicated-partitions`'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`--under-replicated-partitions`'
- en: This shows all partitions where one or more of the replicas are not in sync
    with the leader. This isn’t necessarily bad, as cluster maintenance, deployments,
    and rebalances will cause under-replicated partitions (or URPs) but is something
    to be aware of.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了所有副本中有一个或多个与领导者不同步的所有分区。这不一定是坏事，因为集群维护、部署和重新平衡会导致副本不足的分区（或URP），但需要注意。
- en: '`--at-min-isr-partitions`'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`--at-min-isr-partitions`'
- en: This shows all partitions where the number of replicas, including the leader,
    exactly match the setting for minimum in-sync replicas (ISRs). These topics are
    still available for producer or consumer clients, but all redundancy has been
    lost, and they are in danger of becoming unavailable.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了所有副本数（包括领导者）与最小同步副本（ISRs）设置完全匹配的所有分区。这些主题仍然可供生产者或消费者客户端使用，但所有冗余已经丢失，它们有可能变得不可用。
- en: '`--under-min-isr-partitions`'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`--under-min-isr-partitions`'
- en: This shows all partitions where the number of ISRs is below the configured minimum
    for successful produce actions. These partitions are effectively in read-only
    mode and cannot be produced to.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了所有ISR数量低于成功生产操作所需的最小配置的所有分区。这些分区实际上处于只读模式，无法进行生产操作。
- en: '`--unavailable-partitions`'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`--unavailable-partitions`'
- en: This shows all topic partitions without a leader. This is a serious situation
    and indicates that the partition is offline and unavailable for producer or consumer
    clients.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了所有没有领导者的主题分区。这是一个严重的情况，表明该分区已脱机，对生产者或消费者客户端不可用。
- en: 'Here’s an example of finding topics that are at the minimum ISR setttings.
    In this example, the topic is configured for a min-ISR of 1 and has a replication
    factor (RF) of 2\. Host 0 is online, and host 1 has gone down for maintenance:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个查找处于最小ISR设置的主题的示例。在此示例中，主题配置为最小ISR为1，并且副本因子（RF）为2。主机0在线，主机1已停机进行维护：
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Adding Partitions
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加分区
- en: It is sometimes necessary to increase the number of partitions for a topic.
    Partitions are the way topics are scaled and replicated across a cluster. The
    most common reason to increase the partition count is to horizontally scale a
    topic across more brokers by decreasing the throughput for a single partition.
    Topics may also be increased if a consumer needs to expand to run more copies
    in a single consumer group since a partition can only be consumed by a single
    member in the group.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 有时需要增加主题的分区数。分区是主题在集群中扩展和复制的方式。增加分区计数的最常见原因是通过减少单个分区的吞吐量来横向扩展主题跨多个经纪人。如果消费者需要扩展以在单个消费者组中运行更多副本，则还可以增加主题。因为一个分区只能被消费者组中的一个成员消费。
- en: 'Following is an example of increasing the number of partitions for a topic
    named “my-topic” to 16 using the `--alter` command, followed by a verification
    that it worked:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例，使用`--alter`命令将名为“my-topic”的主题的分区数增加到16，然后验证它是否起作用：
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Adjusting Keyed Topics
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调整带键主题
- en: Topics that are produced with keyed messages can be very difficult to add partitions
    to from a consumer’s point of view. This is because the mapping of keys to partitions
    will change when the number of partitions is changed. For this reason, it is advisable
    to set the number of partitions for a topic that will contain keyed messages once,
    when the topic is created, and avoid resizing the topic.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用带有键消息的主题可能非常难以从消费者的角度添加分区。这是因为当分区数更改时，键到分区的映射将发生变化。因此，建议在创建主题时为包含键消息的主题设置分区数一次，并避免调整主题的大小。
- en: Reducing Partitions
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 减少分区
- en: It is not possible to reduce the number of partitions for a topic. Deleting
    a partition from a topic would cause part of the data in that topic to be deleted
    as well, which would be inconsistent from a client point of view. In addition,
    trying to redistribute the data to the remaining partitions would be difficult
    and result in out-of-order messages. Should you need to reduce the number of partitions,
    it is recommended to delete the topic and re-create it or (if deletion is not
    possible) create a new version of the existing topic and move all produce traffic
    to the new topic (e.g., “my-topic-v2”).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 不可能减少主题的分区数。从主题中删除一个分区也会导致该主题中的部分数据被删除，这在客户端的角度来看是不一致的。此外，尝试将数据重新分配到剩余的分区将会很困难，并导致消息的顺序混乱。如果需要减少分区数，建议删除主题并重新创建它，或者（如果无法删除）创建现有主题的新版本，并将所有生产流量转移到新主题（例如“my-topic-v2”）。
- en: Deleting a Topic
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除主题
- en: Even a topic with no messages uses cluster resources such as disk space, open
    filehandles, and memory. The controller also has junk metadata that it must retain
    knowledge of, which can hinder performance at large scale. If a topic is no longer
    needed, it can be deleted to free up these resources. To perform this action,
    the brokers in the cluster must be configured with the `delete.topic.enable` option
    set to `true`. If it’s set to `false`, then the request to delete the topic will
    be ignored and will not succeed.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 即使没有消息的主题也会使用磁盘空间、打开文件句柄和内存等集群资源。控制器还必须保留其必须了解的垃圾元数据，这可能会在大规模时影响性能。如果不再需要主题，则可以删除以释放这些资源。要执行此操作，集群中的经纪人必须配置`delete.topic.enable`选项设置为`true`。如果设置为`false`，则将忽略删除主题的请求，并且不会成功。
- en: Topic deletion is an asynchronous operation. This means that running this command
    will mark a topic for deletion, but the deletion may not happen immediately, depending
    on the amount of data and cleanup needed. The controller will notify the brokers
    of the pending deletion as soon as possible (after existing controller tasks complete),
    and the brokers will then invalidate the metadata for the topic and delete the
    files from disk. It is highly recommended that operators not delete more than
    one or two topics at a time, and give those ample time to complete before deleting
    other topics, due to limitations in the way the controller executes these operations.
    In the small cluster shown in the examples in this book, topic deletion will happen
    almost immediately, but in larger clusters it may take longer.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 主题删除是一个异步操作。这意味着运行此命令将标记一个主题以进行删除，但删除可能不会立即发生，这取决于所需的数据量和清理。控制器将尽快通知经纪人有关即将删除的信息（在现有控制器任务完成后），然后经纪人将使主题的元数据无效并从磁盘中删除文件。强烈建议操作员不要一次删除一个或两个以上的主题，并且在删除其他主题之前给予充分的时间来完成，因为控制器执行这些操作的方式存在限制。在本书示例中显示的小集群中，主题删除几乎会立即发生，但在较大的集群中可能需要更长的时间。
- en: Data Loss Ahead
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据丢失
- en: Deleting a topic will also delete all its messages. This is not a reversible
    operation. Make sure it is executed carefully.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 删除主题也将删除其所有消息。这是一个不可逆的操作。请确保谨慎执行。
- en: 'Here is an example of deleting the topic named “my-topic” using the `--delete`
    argument. Depending on the version of Kafka, there will be a note letting you
    know that the argument will not work if another config is not set:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用`--delete`参数删除名为“my-topic”的主题的示例。根据Kafka的版本，将会有一条说明，让您知道如果没有设置其他配置，则该参数将不起作用：
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: You will notice there is no visible feedback that the topic deletion was completed
    successfully or not. Verify that deletion was successful by running the `--list`
    or `--describe` options to see that the topic is no longer in the cluster.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到没有明显的反馈表明主题删除是否成功完成。通过运行`--list`或`--describe`选项来验证删除是否成功，以查看主题是否不再存在于集群中。
- en: Consumer Groups
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消费者组
- en: Consumer groups are coordinated groups of Kafka consumers consuming from topics
    or multiple partitions of a single topic. The `kafka-consumer-groups.sh` tool
    helps manage and gain insight into the consumer groups that are consuming from
    topics in the cluster. It can be used to list consumer groups, describe specific
    groups, delete consumer groups or specific group info, or reset consumer group
    offset information.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 消费者组是协调的Kafka消费者组，从主题或单个主题的多个分区中消费。`kafka-consumer-groups.sh`工具有助于管理和了解从集群中的主题中消费的消费者组。它可用于列出消费者组，描述特定组，删除消费者组或特定组信息，或重置消费者组偏移信息。
- en: ZooKeeper-Based Consumer Groups
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于ZooKeeper的消费者组
- en: In older versions of Kafka, consumer groups could be managed and maintained
    in ZooKeeper. This behavior was deprecated in versions 0.11.0.* and later, and
    old consumer groups are no longer used. Some versions of the provided scripts
    may still show deprecated `--zookeeper` connection string commands, but it is
    not recommended to use them unless you have an old environment with some consumer
    groups that have not upgraded to later versions of Kafka.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在较旧版本的Kafka中，可以在ZooKeeper中管理和维护消费者组。此行为在0.11.0.*版本及更高版本中已弃用，不再使用旧的消费者组。提供的某些脚本的某些版本可能仍然显示已弃用的`--zookeeper`连接字符串命令，但不建议使用它们，除非您的旧环境中有一些消费者组尚未升级到Kafka的较新版本。
- en: List and Describe Groups
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 列出和描述组
- en: 'To list consumer groups, use the `--bootstrap-server` and `--list` parameters.
    Ad hoc consumers utilizing the `kafka-consumer-groups.sh` script will show up
    as `console-consumer-*<generated_id>*` in the consumer list:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 要列出消费者组，请使用`--bootstrap-server`和`--list`参数。使用`kafka-consumer-groups.sh`脚本的特定消费者将显示为消费者列表中的`console-consumer-*<generated_id>*`：
- en: '[PRE7]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: For any group listed, you can get more details by changing the `--list` parameter
    to `--describe` and adding the `--group` parameter. This will list all the topics
    and partitions that the group is consuming from, as well as additional information
    such as the offsets for each topic partition. [Table 12-1](#table0901) has a full
    description of all the fields provided in the output.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于列出的任何组，可以通过将`--list`参数更改为`--describe`并添加`--group`参数来获取更多详细信息。这将列出该组正在从中消费的所有主题和分区，以及其他信息，例如每个主题分区的偏移量。[表12-1](#table0901)对输出中提供的所有字段进行了全面描述。
- en: 'For example, get consumer group details for the ad hoc group named “my-consumer”:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，获取名为“my-consumer”的特定组的消费者组详细信息：
- en: '[PRE8]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Table 12-1\. Fields provided for group named “my-consumer”
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 表12-1。为名为“my-consumer”的组提供的字段
- en: '| Field | Description |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 字段 | 描述 |'
- en: '| --- | --- |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| GROUP | The name of the consumer group. |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| GROUP | 消费者组的名称。'
- en: '| TOPIC | The name of the topic being consumed. |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| TOPIC | 正在消费的主题的名称。'
- en: '| PARTITION | The ID number of the partition being consumed. |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| PARTITION | 正在消费的分区的ID号。'
- en: '| CURRENT-OFFSET | The next offset to be consumed by the consumer group for
    this topic partition. This is the position of the consumer within the partition.
    |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| CURRENT-OFFSET | 消费者组为此主题分区要消费的下一个偏移量。这是消费者在分区内的位置。'
- en: '| LOG-END-OFFSET | The current high-water mark offset from the broker for the
    topic partition. This is the offset of the next message to be produced to this
    partition. |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| LOG-END-OFFSET | 主题分区的经纪人的当前高水位偏移。这是下一条消息要被生产到这个分区的偏移量。'
- en: '| LAG | The difference between the consumer Current-Offset and the broker Log-End-Offset
    for this topic partition. |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| LAG | 消费者当前偏移和经纪人日志结束偏移之间的差异，用于此主题分区。'
- en: '| CONSUMER-ID | A generated unique consumer-id based on the provided client-id.
    |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| CONSUMER-ID | 基于提供的客户端ID生成的唯一消费者ID。'
- en: '| HOST | Address of the host the consumer group is reading from. |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| HOST | 消费者组正在读取的主机的地址。'
- en: '| CLIENT-ID | String provided by the client identifying the client that is
    consuming from the group. |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| CLIENT-ID | 客户端提供的标识客户端的字符串。'
- en: Delete Group
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除组
- en: Deletion of consumer groups can be performed with the `--delete` argument. This
    will remove the entire group, including all stored offsets for all topics that
    the group is consuming. To perform this action, all consumers in the group should
    be shut down as the consumer group must not have any active members. If you attempt
    to delete a group that is not empty, an error stating “The group is not empty”
    will be thrown and nothing will happen. It is also possible to use the same command
    to delete offsets for a single topic that the group is consuming without deleting
    the entire group by adding the `--topic` argument and specifying which topic offsets
    to delete.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`--delete`参数执行消费者组的删除。这将删除整个组，包括该组正在消费的所有主题的所有存储偏移量。要执行此操作，组中的所有消费者都应该关闭，因为消费者组不应该有任何活跃成员。如果尝试删除一个不为空的组，将抛出一个错误，指出“该组不为空”，并且不会发生任何事情。还可以使用相同的命令通过添加`--topic`参数并指定要删除的主题偏移量来删除组正在消费的单个主题的偏移量，而不删除整个组。
- en: 'Here is an example of deleting the entire consumer group named “my-consumer”:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是删除名为“my-consumer”的整个消费者组的示例：
- en: '[PRE9]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Offset Management
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏移管理
- en: In addition to displaying and deleting the offsets for a consumer group, it
    is also possible to retrieve the offsets and store new offsets in a batch. This
    is useful for resetting the offsets for a consumer when there is a problem that
    requires messages to be reread, or for advancing offsets and skipping past a message
    that the consumer is having a problem with (e.g., if there is a badly formatted
    message that the consumer cannot handle).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 除了显示和删除消费者组的偏移量之外，还可以批量检索偏移量并存储新的偏移量。当消费者出现需要重新读取消息的问题时，或者需要推进偏移量并跳过消费者无法处理的消息时（例如，如果有一条格式错误的消息），这对于重置消费者的偏移量非常有用。
- en: Export offsets
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 导出偏移量
- en: 'To export offsets from a consumer group to a CSV file, use the `--reset-offsets`
    argument with the `--dry-run` option. This will allow us to create an export of
    the current offsets in a file format that can be reused for importing or rolling
    back the offsets later. The CSV format export will be in the following configuration:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要将消费者组的偏移量导出到CSV文件中，请使用`--reset-offsets`参数和`--dry-run`选项。这将允许我们创建当前偏移量的导出文件格式，以便以后可以重用导入或回滚偏移量。CSV格式的导出将采用以下配置：
- en: '*<topic-name>,<partition-number>,<offset>*'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '*<topic-name>,<partition-number>,<offset>*'
- en: Running the same command without the `--dry-run` option will reset the offsets
    completely, so be careful.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在不使用`--dry-run`选项运行相同命令将完全重置偏移量，因此要小心。
- en: 'Here is an example of exporting the offsets for the topic “my-topic” that is
    being consumed by the consumer group named “my-consumer” to a file named *offsets.csv*:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是导出主题“my-topic”被消费者组“my-consumer”消费的偏移量的示例，导出到名为*offsets.csv*的文件中：
- en: '[PRE10]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Import offsets
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 导入偏移量
- en: The import offset tool is the opposite of exporting. It takes the file produced
    by exporting offsets in the previous section and uses it to set the current offsets
    for the consumer group. A common practice is to export the current offsets for
    the consumer group, make a copy of the file (so that you preserve a backup), and
    edit the copy to replace the offsets with the desired values.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 导入偏移量工具是导出的相反。它接受导出上一节中偏移量生成的文件，并使用它来设置消费者组的当前偏移量。一种常见做法是导出消费者组的当前偏移量，复制文件（以便保留备份），并编辑副本以替换偏移量为所需值。
- en: Stop Consumers First
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 首先停止消费者
- en: Before performing this step, it is important that all consumers in the group
    are stopped. They will not read the new offsets if they are written while the
    consumer group is active. The consumers will just overwrite the imported offsets.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行此步骤之前，重要的是停止组中的所有消费者。如果在消费者组处于活动状态时编写，它们将不会读取新的偏移量。消费者将只覆盖导入的偏移量。
- en: 'In the following example, we import the offsets for the consumer group named
    “my-consumer” from the file we created in the last example named *offsets.csv*:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们从上一个示例中创建的名为*offsets.csv*的文件中导入名为“my-consumer”的消费者组的偏移量：
- en: '[PRE11]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Dynamic Configuration Changes
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动态配置更改
- en: 'There is a plethora of configurations for topics, clients, brokers, and more
    that can be updated dynamically during runtime without having to shut down or
    redeploy a cluster. The `kafka-configs.sh` is the main tool for modifying these
    configs. Currently there are four main categories, or *entity-types*, of dynamic
    config changes that can be made: *topics*, *brokers*, *users*, and *clients*.
    For each entity-type there are specific configurations that can be overridden.
    New dynamic configs are being added constantly with each release of Kafka, so
    it is good to ensure you have the same version of this tool that matches the version
    of Kafka you are running. For ease of setting up these configs consistently via
    automation, the `--add-config-file` argument can be used with a preformatted file
    of all the configs you want to manage and update.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有大量的配置适用于主题、客户端、代理等，可以在运行时动态更新，而无需关闭或重新部署集群。`kafka-configs.sh`是修改这些配置的主要工具。目前有四种主要的动态配置更改的实体类型，即*entity-types*：*topics*、*brokers*、*users*和*clients*。对于每种实体类型，都有可以覆盖的特定配置。随着每个Kafka版本的发布，不断添加新的动态配置，因此最好确保您使用与运行的Kafka版本相匹配的工具版本。为了通过自动化方便地设置这些配置，可以使用`--add-config-file`参数，并使用预先格式化的文件来管理和更新所有要管理和更新的配置。
- en: Overriding Topic Configuration Defaults
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 覆盖主题配置默认值
- en: There are many configurations that are set by default for topics that are defined
    in the static broker configuration files (e.g., retention time policy). With dynamic
    configurations, we can override the cluster0level defaults for individual topics
    to accommodate different use cases within a single cluster. [Table 12-2](#table0902)
    shows the valid configuration keys for topics that can be altered dynamically.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多配置是为主题默认设置的，这些配置在静态代理配置文件中定义（例如，保留时间策略）。通过动态配置，我们可以覆盖集群级别的默认值，以适应单个集群中不同用例的不同主题。[表12-2](#table0902)显示了可以动态更改的主题的有效配置键。
- en: 'The format of the command to change a topic configuration is:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 更改主题配置的命令格式如下：
- en: '[PRE12]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here is an example of setting the retention for the topic named “my-topic”
    to 1 hour (3,600,000 ms):'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是将名为“my-topic”的主题保留设置为1小时（3,600,000毫秒）的示例：
- en: '[PRE13]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Table 12-2\. Valid keys for topics
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 表12-2\. 主题的有效键
- en: '| Configuration key | Description |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 配置键 | 描述 |'
- en: '| --- | --- |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `cleanup.policy` | If set to `compact`, the messages in this topic will be
    discarded and only the most recent message with a given key is retained (log compacted).
    |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| `cleanup.policy` | 如果设置为`compact`，则此主题中的消息将被丢弃，只保留具有给定键的最新消息（日志压缩）。 |'
- en: '| `compression.type` | The compression type used by the broker when writing
    message batches for this topic to disk. |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| `compression.type` | 代理在将此主题的消息批次写入磁盘时使用的压缩类型。 |'
- en: '| `delete.retention.ms` | How long, in milliseconds, deleted tombstones will
    be retained for this topic. Only valid for log compacted topics. |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| `delete.retention.ms` | 以毫秒为单位，删除的墓碑将保留在此主题中的时间。仅适用于日志压缩主题。 |'
- en: '| `file.delete.delay.ms` | How long, in milliseconds, to wait before deleting
    log segments and indices for this topic from disk. |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| `file.delete.delay.ms` | 从磁盘中删除此主题的日志段和索引之前等待的时间，以毫秒为单位。 |'
- en: '| `flush.messages` | How many messages are received before forcing a flush
    of this topic’s messages to disk. |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| `flush.messages` | 在强制将此主题的消息刷新到磁盘之前接收多少消息。 |'
- en: '| `flush.ms` | How long, in milliseconds, before forcing a flush of this topic’s
    messages to disk. |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| `flush.ms` | 强制将此主题的消息刷新到磁盘之前的时间，以毫秒为单位。 |'
- en: '| `follower.replication.​throt⁠tled.replicas` | A list of replicas for which
    log replication should be throttled by the follower. |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| `follower.replication.​throt⁠tled.replicas` | 应该由追随者限制日志复制的副本列表。 |'
- en: '| `index.interval.bytes` | How many bytes of messages can be produced between
    entries in the log segment’s index. |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| `index.interval.bytes` | 日志段索引中可以在消息之间产生多少字节。 |'
- en: '| `leader.replication.​throt⁠tled.replica` | A list of replicas for which log
    replication should be throttled by the leader. |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| `leader.replication.​throt⁠tled.replica` | 领导者应该限制日志复制的副本列表。 |'
- en: '| `max.compaction.lag.ms` | Maximum time limit a message won’t be eligible
    for compaction in the log. |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| `max.compaction.lag.ms` | 消息在日志中不符合压缩的最长时间限制。 |'
- en: '| `max.message.bytes` | The maximum size of a single message for this topic,
    in bytes. |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| `max.message.bytes` | 此主题单个消息的最大大小，以字节为单位。 |'
- en: '| `message.downconversion.enable` | Allows the message format version to be
    down-converted to the previous version if enabled with some overhead. |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| `message.downconversion.enable` | 如果启用，允许将消息格式版本降级为上一个版本，但会带来一些开销。 |'
- en: '| `message.format.version` | The message format version that the broker will
    use when writing messages to disk. Must be a valid API version number. |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| `message.format.version` | 经纪人在将消息写入磁盘时将使用的消息格式版本。必须是有效的API版本号。 |'
- en: '| `message.timestamp.​dif⁠fer⁠ence.max.ms` | The maximum allowed difference,
    in milliseconds, between the message timestamp and the broker timestamp when the
    message is received. This is only valid if the `message.timestamp.type` is set
    to `CreateTime`. |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| `message.timestamp.​dif⁠fer⁠ence.max.ms` | 消息时间戳和经纪人时间戳之间的最大允许差异，以毫秒为单位。仅当`message.timestamp.type`设置为`CreateTime`时有效。
    |'
- en: '| `message.timestamp.type` | Which timestamp to use when writing messages to
    disk. Current values are `CreateTime` for the timestamp specified by the client
    and `LogAppendTime` for the time when the message is written to the partition
    by the broker. |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| `message.timestamp.type` | 写入磁盘时要使用的时间戳。当前值为`CreateTime`表示客户端指定的时间戳，`LogAppendTime`表示经纪人将消息写入分区的时间。
    |'
- en: '| `min.clean⁠able.​dirty.ratio` | How frequently the log compactor will attempt
    to compact partitions for this topic, expressed as a ratio of the number of uncompacted
    log segments to the total number of log segments. Only valid for log compacted
    topics. |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| `min.clean⁠able.​dirty.ratio` | 日志压缩器尝试压缩此主题分区的频率，表示为未压缩日志段数与总日志段数的比率。仅适用于日志压缩主题。
    |'
- en: '| `min.compaction.lag.ms` | Minimum time a message will remain uncompacted
    in the log. |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| `min.compaction.lag.ms` | 消息在日志中保持未压缩的最短时间。 |'
- en: '| `min.insync.replicas` | The minimum number of replicas that must be in sync
    for a partition of the topic to be considered available. |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| `min.insync.replicas` | 必须同步的最小副本数，才能认为主题的分区可用。 |'
- en: '| `preallocate` | If set to `true`, log segments for this topic should be preallocated
    when a new segment is rolled. |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| `preallocate` | 如果设置为`true`，则在滚动新段时应预先分配此主题的日志段。 |'
- en: '| `retention.bytes` | The amount of messages, in bytes, to retain for this
    topic. |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| `retention.bytes` | 保留此主题的消息字节数。 |'
- en: '| `retention.ms` | How long messages should be retained for this topic, in
    milliseconds. |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| `retention.ms` | 此主题的消息应保留的时间，以毫秒为单位。 |'
- en: '| `segment.bytes` | The amount of messages, in bytes, that should be written
    to a single log segment in a partition. |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| `segment.bytes` | 应该写入分区中单个日志段的消息字节数。 |'
- en: '| `segment.index.bytes` | The maximum size, in bytes, of a single log segment
    index. |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| `segment.index.bytes` | 单个日志段索引的最大大小，以字节为单位。 |'
- en: '| `segment.jitter.ms` | A maximum number of milliseconds that is randomized
    and added to `segment.ms` when rolling log segments. |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| `segment.jitter.ms` | 在滚动日志段时，随机添加到`segment.ms`的最大毫秒数。 |'
- en: '| `segment.ms` | How frequently, in milliseconds, the log segment for each
    partition should be rotated. |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| `segment.ms` | 每个分区的日志段应该旋转的频率，以毫秒为单位。 |'
- en: '| `unclean.leader.​elec⁠tion.enable` | If set to `false`, unclean leader elections
    will not be permitted for this topic. |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| `unclean.leader.​elec⁠tion.enable` | 如果设置为`false`，则不允许为此主题进行不干净的领导者选举。 |'
- en: Overriding Client and User Configuration Defaults
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 覆盖客户端和用户配置默认值
- en: For Kafka clients and users, there are only a few configurations that can be
    overridden, which are all essentially types of quotas. Two of the more common
    configurations to change are the bytes/sec rates allowed for producers and consumers
    with a specified client ID on a per-broker basis. The full list of shared configurations
    that can be modified for both *users* and *clients* is shown in [Table 12-3](#table0903).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Kafka客户端和用户，只有少数配置可以被覆盖，它们基本上都是配额的类型。更常见的两个要更改的配置是允许每个经纪人的特定客户端ID的生产者和消费者的字节/秒速率。可以为*用户*和*客户端*修改的共享配置的完整列表显示在[表12-3](#table0903)中。
- en: Uneven Throttling Behavior in Poorly Balanced Clusters
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在负载不平衡的集群中不均匀的限流行为
- en: Because throttling occurs on a per-broker basis, even balance of leadership
    of partitions across a cluster becomes particularly important to enforce this
    properly. If you have 5 brokers in a cluster and you specify a producer quota
    of 10 MBps for a client, that client will be allowed to produce 10 MBps *on each*
    broker at the same time for a total of 50 MBps, assuming a balanced leadership
    across all 5 hosts. However, if leadership for every partition is all on broker
    1, the same producer will only be able to produce a max of 10 MBps.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 因为限流是基于每个代理的基础，所以跨集群的分区领导权的平衡变得尤为重要，以便正确执行这一点。如果您在集群中有5个代理，并且为客户端指定了10 MBps的生产者配额，那么该客户端将被允许同时在每个代理上生产10
    MBps，总共50 MBps，假设所有5个主机上的领导权是平衡的。但是，如果每个分区的领导权都在代理1上，那么同一个生产者只能生产最大10 MBps。
- en: Table 12-3\. The configurations (keys) for clients
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 表12-3。客户端的配置（键）
- en: '| Configuration key | Description |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 配置键 | 描述 |'
- en: '| --- | --- |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `consumer_bytes_rate` | The amount of messages, in bytes, that a single client
    ID is allowed to consume from a single broker in one second. |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| `consumer_bytes_rate` | 允许单个客户端ID在一秒内从单个代理消费的字节数。 |'
- en: '| `producer_bytes_rate` | The amount of messages, in bytes, that a single client
    ID is allowed to produce to a single broker in one second. |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| `producer_bytes_rate` | 允许单个客户端ID在一秒内向单个代理生产的字节数。 |'
- en: '| `controller_mutations_rate` | The rate at which mutations are accepted for
    the create topics request, the create partitions request, and the delete topics
    request. The rate is accumulated by the number of partitions created or deleted.
    |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| `controller_mutations_rate` | 接受创建主题请求、创建分区请求和删除主题请求的变异速率。速率是由创建或删除的分区数量累积而成。
    |'
- en: '| `request_percentage` | The percentage per quota window (out of a total of
    (num.io.threads + num.network.threads) × 100%) for requests from the user or client.
    |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| `request_percentage` | 用户或客户端请求在配额窗口内的百分比（总数为（num.io.threads + num.network.threads）×
    100%）。 |'
- en: Client ID Versus Consumer Group
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 客户端ID与消费者组
- en: The client ID is not necessarily the same as the consumer group name. Consumers
    can set their own client ID, and you may have many consumers that are in different
    groups that specify the same client ID. It is considered a best practice to set
    the client ID for each consumer group to something unique that identifies that
    group. This allows a single consumer group to share a quota, and it makes it easier
    to identify in logs what group is responsible for requests.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端ID不一定与消费者组名称相同。消费者可以设置自己的客户端ID，您可能有许多消费者在不同的组中指定相同的客户端ID。为每个消费者组设置唯一标识该组的客户端ID被认为是最佳实践。这允许单个消费者组共享配额，并且更容易在日志中识别负责请求的组。
- en: 'Compatible user and client config changes can be specified together for compatible
    configs that apply to both. Here is an example of the command to change the controller
    mutation rate for both a user and client in one configuration step:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 可以一次指定兼容的用户和客户端配置更改，以适用于两者的兼容配置。以下是一种在一个配置步骤中更改用户和客户端的控制器变异速率的命令示例：
- en: '[PRE14]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Overriding Broker Configuration Defaults
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 覆盖代理配置默认值
- en: 'Broker- and cluster-level configs will primarily be configured statically in
    the cluster configuration files, but there is a plethora of configs that can be
    overridden during runtime without needing to redeploy Kafka. More than 80 overrides
    can be altered with *kafka-configs.sh* for brokers. As such, we will not list
    them all in this book, but they can be referenced by the `--help` command or found
    in the [open source documentation](https://oreil.ly/R8hhb). A few important configs
    worth pointing out specifically are:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 主题和集群级别的配置主要在集群配置文件中静态配置，但是有大量的配置可以在运行时进行覆盖，而无需重新部署Kafka。超过80个覆盖可以使用*kafka-configs.sh*进行更改。因此，我们不会在本书中列出所有这些配置，但可以通过`--help`命令进行引用，或者在[开源文档](https://oreil.ly/R8hhb)中找到。特别值得指出的一些重要配置是：
- en: '`min.insync.replicas`'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`min.insync.replicas`'
- en: Adjusts the minimum number of replicas that need to acknowledge a write for
    a produce request to be successful when producers have set acks to `all` (or `–1`).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 调整需要确认写入的最小副本数，以使生产请求在生产者将acks设置为`all`（或`–1`）时成功。
- en: '`unclean.leader.election.enable`'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`unclean.leader.election.enable`'
- en: Allows replicas to be elected as leader even if it results in data loss. This
    is useful when it is permissible to have some lossy data, or to turn on for short
    times to unstick a Kafka cluster if unrecoverable data loss cannot be avoided.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 即使导致数据丢失，也允许副本被选举为领导者。当允许有一些有损数据或者在短时间内无法避免不可恢复的数据丢失时，这是有用的。
- en: '`max.connections`'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`max.connections`'
- en: The maximum number of connections allowed to a broker at any time. We can also
    use `max.connections.per.ip` and `max.connections.per.ip.overrides` for more fine-tuned
    throttling.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 任何时候允许连接到代理的最大连接数。我们还可以使用`max.connections.per.ip`和`max.connections.per.ip.overrides`进行更精细的限制。
- en: Describing Configuration Overrides
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 描述配置覆盖
- en: All configuration overrides can be listed using the `kafka-config.sh` tool.
    This will allow you to examine the specific configuration for a topic, broker,
    or client. Similar to other tools, this is done using the `--describe` command.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 所有配置覆盖都可以使用`kafka-config.sh`工具列出。这将允许您检查主题、代理或客户端的具体配置。与其他工具类似，这是使用`--describe`命令完成的。
- en: 'In the following example, we can get all the configuration overrides for the
    topic named “my-topic,” which we observe is only the retention time:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们可以获取名为“my-topic”的主题的所有配置覆盖，我们观察到只有保留时间：
- en: '[PRE15]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Topic Overrides Only
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 仅主题覆盖
- en: The configuration description will only show overrides—it does not include the
    cluster default configurations. There is not a way to dynamically discover the
    configuration of the brokers themselves. This means that when using this tool
    to discover topic or client settings in automation, the user must have separate
    knowledge of the cluster default configuration.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 配置描述仅显示覆盖项-不包括集群默认配置。没有办法动态发现经纪人自己的配置。这意味着在使用此工具自动发现主题或客户端设置时，用户必须单独了解集群默认配置。
- en: Removing Configuration Overrides
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除配置覆盖
- en: Dynamic configurations can be removed entirely, which will cause the entity
    to revert back to the cluster defaults. To delete a configuration override, use
    the `--alter` command along with the `--delete-config` parameter.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 动态配置可以完全删除，这将导致实体恢复到集群默认设置。要删除配置覆盖，使用`--alter`命令以及`--delete-config`参数。
- en: 'For example, delete a configuration override for `retention.ms` for a topic
    named “my-topic”:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，删除名为“my-topic”的主题的`retention.ms`的配置覆盖：
- en: '[PRE16]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Producing and Consuming
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生产和消费
- en: While working with Kafka, you will often find it is necessary to manually produce
    or consume some sample messages in order to validate what’s going on with your
    applications. Two utilities are provided to help with this, `kafka-console-consumer.sh`
    and `kafka-console-producer.sh`, which were touched upon briefly in [Chapter 2](ch02.html#installing_kafka)
    to verify our installation. These tools are wrappers around the main Java client
    libraries that allow you to interact with Kafka topics without having to write
    an entire application to do it.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Kafka时，通常需要手动生产或消费一些样本消息，以验证应用程序的运行情况。提供了两个实用程序来帮助处理这个问题，`kafka-console-consumer.sh`和`kafka-console-producer.sh`，这在[第2章](ch02.html#installing_kafka)中简要提到过，用于验证我们的安装。这些工具是主要Java客户端库的包装器，允许您与Kafka主题进行交互，而无需编写整个应用程序来完成。
- en: Piping Output to Another Application
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将输出导入另一个应用程序
- en: While it is possible to write applications that wrap around the console consumer
    or producer (e.g., to consume messages and pipe them to another application for
    processing), this type of application is quite fragile and should be avoided.
    It is difficult to interact with the console consumer in a way that does not lose
    messages. Likewise, the console producer does not allow for using all features,
    and properly sending bytes is tricky. It is best to use either the Java client
    libraries directly or a third-party client library for other languages that use
    the Kafka protocol directly.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可以编写包装控制台消费者或生产者的应用程序（例如，消费消息并将其导入另一个应用程序进行处理），但这种类型的应用程序非常脆弱，应该避免使用。很难与控制台消费者进行交互而不丢失消息。同样，控制台生产者不允许使用所有功能，并且正确发送字节很棘手。最好直接使用Java客户端库或使用Kafka协议的其他语言的第三方客户端库。
- en: Console Producer
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 控制台生产者
- en: The `kakfa-console-producer.sh` tool can be used to write messages into a Kafka
    topic in your cluster. By default, messages are read one per line, with a tab
    character separating the key and the value (if no tab character is present, the
    key is null). As with the console consumer, the producer reads in and produces
    raw bytes using the default serializer (which is `DefaultEncoder`).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`kakfa-console-producer.sh`工具可用于将消息写入集群中的Kafka主题。默认情况下，消息每行读取一条，键和值之间用制表符分隔（如果没有制表符，则键为null）。与控制台消费者一样，生产者使用默认序列化器读取和生成原始字节（即`DefaultEncoder`）。'
- en: The console producer requires that a minimum of two arguments are provided to
    know what Kafka cluster to connect to and which topic to produce to within that
    cluster. The first is the customary `--bootstrap-server` connection string we
    are used to using. When you are done producing, send an end-of-file (EOF) character
    to close the client. In most common terminals, this is done with Control-D.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 控制台生产者要求提供至少两个参数，以知道要连接到哪个Kafka集群以及在该集群中要生产到哪个主题。第一个是我们习惯使用的`--bootstrap-server`连接字符串。在完成生产后，发送文件结束（EOF）字符以关闭客户端。在大多数常见的终端中，可以使用Control-D来完成这个操作。
- en: 'Here we can see an example of producing four messages to a topic named “my-topic”:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到一个将四条消息发送到名为“my-topic”的主题的示例：
- en: '[PRE17]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Using producer configuration options
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用生产者配置选项
- en: It is possible to pass normal producer configuration options to the console
    producer as well. This can be done in two ways, depending on how many options
    you need to pass and how you prefer to do it. The first is to provide a producer
    configuration file by specifying `--producer.config` `*<config-file>*`, where
    `*<config-file>*` is the full path to a file that contains the configuration options.
    The other way is to specify the options on the command line with one or more arguments
    of the form `--producer-property` `*<key>*`=`*<value>*`, where `*<key>*` is the
    configuration option name and `*<value>*` is the value to set it to. This can
    be useful for producer options like message-batching configurations (such as `linger.ms`
    or `batch.size`).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 可以将普通生产者配置选项传递给控制台生产者。有两种方法可以做到这一点，取决于您需要传递多少选项以及您喜欢如何传递。第一种方法是通过指定`--producer.config`
    `*<config-file>*`来提供生产者配置文件，其中`*<config-file>*`是包含配置选项的文件的完整路径。另一种方法是在命令行上指定选项，格式为`--producer-property`
    `*<key>*`=`*<value>*`，其中`*<key>*`是配置选项名称，`*<value>*`是要设置的值。这对于生产者选项（如`linger.ms`或`batch.size`）可能很有用。
- en: Confusing Command-Line Options
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混淆的命令行选项
- en: The `--property` command-line option is available for both the console producer
    and the console consumer, but this should not be confused with the `--producer-property`
    or `--consumer-property` options, respectively. The `--property` option is only
    used for passing configurations to the message formatter, and not the client itself.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '`--property`命令行选项适用于控制台生产者和控制台消费者，但这不应与`--producer-property`或`--consumer-property`选项混淆。`--property`选项仅用于将配置传递给消息格式化程序，而不是客户端本身。'
- en: 'The console producer has many command-line arguments available to use with
    the `--producer-property` option for adjusting its behavior. Some of the more
    useful options are:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 控制台生产者有许多命令行参数可用于与`--producer-property`选项一起使用，以调整其行为。一些更有用的选项包括：
- en: '`--batch-size`'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '`--batch-size`'
- en: Specifies the number of messages sent in a single batch if they are not being
    sent synchronously.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 指定如果不同步发送，则在单个批次中发送的消息数。
- en: '`--timeout`'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '`--timeout`'
- en: If a producer is running in asynchronous mode, this provides the max amount
    of time waiting for the batch size before producing to avoid long waits on low-producing
    topics.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如果生产者以异步模式运行，则在生产以避免在低产出主题上长时间等待之前等待批处理大小的最大时间。
- en: '`--compression-codec <string>`'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '`--compression-codec <string>`'
- en: 'Specify the type of compression to be used when producing messages. Valid types
    can be one of the following: `none`, `gzip`, `snappy`, `zstd`, or `lz4`. The default
    value is `gzip`.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 指定在生成消息时要使用的压缩类型。有效类型可以是以下之一：`none`，`gzip`，`snappy`，`zstd`或`lz4`。默认值为`gzip`。
- en: '`--sync`'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`--sync`'
- en: Produce messages synchronously, waiting for each message to be acknowledged
    before sending the next one.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 同步生成消息，等待每条消息在发送下一条消息之前得到确认。
- en: Line-reader options
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 行读取器选项
- en: 'The `kafka.tools.ConsoleProducer$LineMessageReader` class, which is responsible
    for reading standard input and creating producer records, also has several useful
    options that can be passed to the console producer using the `--property` command-line
    option:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '`kafka.tools.ConsoleProducer$LineMessageReader`类负责读取标准输入并创建生产者记录，还有一些有用的选项可以通过`--property`命令行选项传递给控制台生产者：'
- en: '`ignore.error`'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '`ignore.error`'
- en: Set to `false` to throw an exception when `parse.key` is set to `true` and a
    key separator is not present. Defaults to `true`.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 将`parse.key`设置为`true`时，设置为`false`以在不存在键分隔符时抛出异常。默认为`true`。
- en: '`parse.key`'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '`parse.key`'
- en: Set to `false` to always set the key to null. Defaults to `true`.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 将键始终设置为null时，设置为`false`。默认为`true`。
- en: '`key.separator`'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '`key.separator`'
- en: Specify the delimiter character to use between the message key and message value
    when reading. Defaults to a tab character.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 指定在读取时在消息键和消息值之间使用的分隔符字符。默认为制表符。
- en: Changing Line-Reading Behavior
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更改行读取行为
- en: You can provide your own class to Kafka for customized methods of reading lines.
    The class that you create must extend `kafka.​com⁠mon.MessageReader` and will
    be responsible for creating the `ProducerRecord`. Specify your class on the command
    line with the `--line-reader` option, and make sure the JAR containing your class
    is in the classpath. The default is `kafka.tools.Console​Pro⁠ducer$LineMessageReader`.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以为Kafka提供自己的类，用于自定义读取行的方法。您创建的类必须扩展`kafka.​com⁠mon.MessageReader`，并将负责创建`ProducerRecord`。在命令行上使用`--line-reader`选项指定您的类，并确保包含您的类的JAR在类路径中。默认值为`kafka.tools.Console​Pro⁠ducer$LineMessageReader`。
- en: When producing messages, the `LineMessageReader` will split the input on the
    first instance of the `key.separator`. If there are no characters remaining after
    that, the value of the message will be empty. If no key separator character is
    present on the line, or if `parse.key` is false, the key will be null.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成消息时，`LineMessageReader`将在第一个`key.separator`的实例上拆分输入。如果在此之后没有剩余字符，则消息的值将为空。如果行上不存在键分隔符字符，或者`parse.key`为false，则键将为null。
- en: Console Consumer
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 控制台消费者
- en: 'The `kafka-console-consumer.sh` tool provides a means to consume messages out
    of one or more topics in your Kafka cluster. The messages are printed in standard
    output, delimited by a new line. By default, it outputs the raw bytes in the message,
    without the key, with no formatting (using the `DefaultFormatter`). Similar to
    the producer, there are a few basic options needed to get started: a connection
    string to the cluster, which topic you want to consume from, and the timeframe
    you want to consume.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '`kafka-console-consumer.sh`工具提供了一种从Kafka集群中的一个或多个主题中消费消息的方法。消息以标准输出形式打印，以新行分隔。默认情况下，它输出消息中的原始字节，不包括键，没有格式（使用`DefaultFormatter`）。与生产者类似，需要一些基本选项才能开始：连接到集群的连接字符串，要从中消费的主题以及要消费的时间范围。'
- en: Checking Tool Versions
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查工具版本
- en: It is very important to use a consumer that is the same version as your Kafka
    cluster. Older console consumers can potentially damage the cluster by interacting
    with the cluster or ZooKeeper in incorrect ways.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 使用与Kafka集群相同版本的消费者非常重要。较旧的控制台消费者可能通过与集群或ZooKeeper的不正确交互来损坏集群。
- en: 'As in other commands, the connection string to the cluster will be the `--bootstrap-server`
    option; however, you can choose from two options for selecting the topics to consume:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他命令一样，连接到集群的连接字符串将是`--bootstrap-server`选项；但是，您可以从两个选项中选择要消费的主题：
- en: '`--topic`'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '`--topic`'
- en: Specifies a single topic to consume from.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 指定要从中消费的单个主题。
- en: '`--whitelist`'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '`--whitelist`'
- en: A regular expression matching all topics to consume from (remember to properly
    escape the regex so that it is not processed improperly by the shell).
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 匹配要从中消费的所有主题的正则表达式（记得正确转义正则表达式，以免被shell错误处理）。
- en: 'Only one of the previous options should be selected and used. Once the console
    consumer has started, the tool will continue to try and consume until the shell
    escape command is given (in this case, Ctrl-C). Here is an example of consuming
    all topics from our cluster that match the prefix *my* (of which there is only
    one in this example, “my-topic”):'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 先前的选项中只能选择并使用一个。一旦控制台消费者启动，工具将继续尝试消费，直到给出shell转义命令（在这种情况下为Ctrl-C）。以下是一个示例，消费与前缀*my*匹配的集群中的所有主题（在此示例中只有一个，“my-topic”）：
- en: '[PRE18]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Using consumer configuration options
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用消费者配置选项
- en: In addition to these basic command-line options, it is possible to pass normal
    consumer configuration options to the console consumer as well. Similar to the
    `kafka-console-producer.sh` tool, this can be done in two ways, depending on how
    many options you need to pass and how you prefer to do it. The first is to provide
    a consumer configuration file by specifying `--consumer.config` `*<config-file>*`,
    where `*<config-file>*` is the full path to a file that contains the configuration
    options. The other way is to specify the options on the command line with one
    or more arguments of the form `--consumer-property` `*<key>*`=`*<value>*`, where
    `*<key>*` is the configuration option name and `*<value>*` is the value to set
    it to.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些基本的命令行选项之外，还可以将普通的消费者配置选项传递给控制台消费者。与 `kafka-console-producer.sh` 工具类似，可以通过两种方式来实现，具体取决于需要传递多少选项以及您更喜欢的方式。第一种是通过指定
    `--consumer.config` `*<config-file>*` 来提供一个消费者配置文件，其中 `*<config-file>*` 是包含配置选项的文件的完整路径。另一种方式是在命令行上指定选项，格式为
    `--consumer-property` `*<key>*`=`*<value>*`，其中 `*<key>*` 是配置选项名称，`*<value>*` 是要设置的值。
- en: 'There are a few other commonly used options for the console consumer that are
    helpful to know and be familiar with:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些常用的控制台消费者选项，对于了解和熟悉它们很有帮助：
- en: '`--formatter` `*<classname>*`'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '`--formatter` `*<classname>*`'
- en: Specifies a message formatter class to be used to decode the messages. This
    defaults to `kafka.tools.DefaultMessageFormatter`.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 指定要用于解码消息的消息格式化类。默认为 `kafka.tools.DefaultMessageFormatter`。
- en: '`--from-beginning`'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '`--from-beginning`'
- en: Consume messages in the topic(s) specified from the oldest offset. Otherwise,
    consumption starts from the latest offset.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 从最旧的偏移量开始消费指定主题中的消息。否则，消费将从最新的偏移量开始。
- en: '`--max-messages <int>`'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '`--max-messages <int>`'
- en: The maximum number of messages to consume before exiting.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在退出之前要消费的最大消息数。
- en: '`--partition <int>`'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '`--partition <int>`'
- en: Consume only from the partition with the ID given.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 仅从具有给定 ID 的分区中消费。
- en: '`--offset`'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '`--offset`'
- en: The offset ID to consume from, if provided (`<int>`). Other valid options are
    `earliest`, which will consume from the beginning, and `latest`, which will start
    consuming from the most recent offset.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 要从中消费的偏移量 ID（如果提供）（`<int>`）。其他有效选项是 `earliest`，它将从开头消费，以及 `latest`，它将从最新的偏移量开始消费。
- en: '`--skip-message-on-error`'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '`--skip-message-on-error`'
- en: Skip a message if there is an error when processing instead of halting. Useful
    for debugging.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在处理时出现错误，则跳过消息而不是停止。用于调试。
- en: Message formatter options
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 消息格式化选项
- en: 'There are three message formatters available to use besides the default:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 除了默认值之外，还有三种可用的消息格式化器：
- en: '`kafka.tools.LoggingMessageFormatter`'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '`kafka.tools.LoggingMessageFormatter`'
- en: Outputs messages using the logger, rather than standard out. Messages are printed
    at the INFO level and include the timestamp, key, and value.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 使用记录器输出消息，而不是标准输出。消息以 INFO 级别打印，并包括时间戳、键和值。
- en: '`kafka.tools.ChecksumMessageFormatter`'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '`kafka.tools.ChecksumMessageFormatter`'
- en: Prints only message checksums.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 仅打印消息校验和。
- en: '`kafka.tools.NoOpMessageFormatter`'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '`kafka.tools.NoOpMessageFormatter`'
- en: Consumes messages but does not output them at all.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 消费消息但不输出它们。
- en: 'The following is an example of consuming the same messages from before but
    with the `kafka.tools.ChecksumMessageFormatter` being used rather than the default:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例，消费与之前相同的消息，但使用 `kafka.tools.ChecksumMessageFormatter` 而不是默认值：
- en: '[PRE19]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The `kafka.tools.DefaultMessageFormatter` also has several useful options that
    can be passed using the `--property` command-line option, shown in [Table 12-4](#table0904).
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '`kafka.tools.DefaultMessageFormatter` 还有一些有用的选项，可以使用 `--property` 命令行选项传递，如
    [表12-4](#table0904) 中所示。'
- en: Table 12-4\. Message formatter properties
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 表12-4。消息格式化属性
- en: '| Property | Description |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 属性 | 描述 |'
- en: '| --- | --- |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `print.timestamp` | Set to `true` to display the timestamp of each message
    (if available). |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| `print.timestamp` | 设置为 `true` 以显示每条消息的时间戳（如果可用）。 |'
- en: '| `print.key` | Set to `true` to display the message key in addition to the
    value. |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| `print.key` | 设置为 `true` 以显示消息键以及值。 |'
- en: '| `print.offset` | Set to `true` to display the message offset in addition
    to the value. |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| `print.offset` | 设置为 `true` 以显示消息偏移量以及值。 |'
- en: '| `print.partition` | Set to `true` to display the topic partition a message
    is consumed from. |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| `print.partition` | 设置为 `true` 以显示消息所消费的主题分区。 |'
- en: '| `key.separator` | Specify the delimiter character to use between the message
    key and message value when printing. |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| `key.separator` | 指定在打印时在消息键和消息值之间使用的分隔符字符。 |'
- en: '| `line.separator` | Specify the delimiter character to use between messages.
    |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| `line.separator` | 指定在消息之间使用的分隔符字符。 |'
- en: '| `key.deserializer` | Provide a class name that is used to deserialize the
    message key before printing. |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| `key.deserializer` | 提供一个类名，用于在打印之前对消息键进行反序列化。 |'
- en: '| `value.deserializer` | Provide a class name that is used to deserialize the
    message value before printing. |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| `value.deserializer` | 提供一个类名，用于在打印之前对消息值进行反序列化。 |'
- en: The deserializer classes must implement `org.apache.kafka.common.​ser⁠ial⁠iza⁠tion.Deserializer`,
    and the console consumer will call the `toString` method on them to get the output
    to display. Typically, you would implement these deserializers as a Java class
    that you would insert into the classpath for the console consumer by setting the
    `CLASSPATH` environment variable before executing `kafka_​con⁠sole_consumer.sh`.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 反序列化类必须实现 `org.apache.kafka.common.​ser⁠ial⁠iza⁠tion.Deserializer`，控制台消费者将调用它们的
    `toString` 方法来获取要显示的输出。通常，您会将这些反序列化器实现为一个 Java 类，然后通过在执行 `kafka_​con⁠sole_consumer.sh`
    之前设置 `CLASSPATH` 环境变量来将其插入到控制台消费者的类路径中。
- en: Consuming the offsets topics
  id: totrans-261
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 消费偏移量主题
- en: It is sometimes useful to see what offsets are being committed for the cluster’s
    consumer groups. You may want to see if a particular group is committing offsets
    at all, or how often offsets are being committed. This can be done by using the
    console consumer to consume the special internal topic called `__consumer_offsets`.
    All consumer offsets are written as messages to this topic. In order to decode
    the messages in this topic, you must use the formatter class `kafka.coordinator.group.Group​Met⁠ada⁠taManager$OffsetsMessageFormatter`.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候查看集群的消费者组提交了哪些偏移量是有用的。您可能想要查看特定组是否根本没有提交偏移量，或者偏移量提交的频率如何。这可以通过使用控制台消费者来消费名为`__consumer_offsets`的特殊内部主题来完成。所有消费者偏移量都被写入此主题作为消息。为了解码此主题中的消息，必须使用格式化类`kafka.coordinator.group.Group​Met⁠ada⁠taManager$OffsetsMessageFormatter`。
- en: 'Putting all we have learned together, the following is an example of consuming
    the earliest message from the `__consumer_offsets` topic:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 将我们学到的所有知识整合在一起，以下是从`__consumer_offsets`主题中消费最早消息的示例：
- en: '[PRE20]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Partition Management
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分区管理
- en: A default Kafka installation also contains a few scripts for working with the
    management of partitions. One of these tools allows for the reelection of leader
    replicas; another is a low-level utility for assigning partitions to brokers.
    Together these tools can assist in situations where a more manual hands-on approach
    to balance message traffic within a cluster of Kafka brokers is needed.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的Kafka安装还包含一些用于管理分区的脚本。其中一个工具允许重新选举领导副本；另一个是一个用于将分区分配给经纪人的低级实用程序。这些工具共同可以帮助在需要更多手动干预来平衡Kafka经纪人集群中的消息流量的情况下进行操作。
- en: Preferred Replica Election
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 首选副本选举
- en: As described in [Chapter 7](ch07.html#reliable_data_delivery), partitions can
    have multiple replicas for reliability. It is important to understand that only
    one of these replicas can be the leader for the partition at any given point in
    time, and all produce and consume operations happen on that broker. Maintaining
    a balance of which partition’s replicas have leadership on which broker is necessary
    to ensure the load is spread out through a full Kafka cluster.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第7章](ch07.html#reliable_data_delivery)所述，为了可靠性，分区可以具有多个副本。重要的是要理解，在任何给定时间点，这些副本中只有一个可以成为分区的领导者，并且所有的生产和消费操作都发生在该经纪人上。保持分区的副本在哪个经纪人上拥有领导权的平衡对于确保负载通过整个Kafka集群的分布是必要的。
- en: Leadership is defined within Kafka as the first in-sync replica in the replica
    list. However, when a broker is stopped or loses connectivity to the rest of the
    cluster, leadership is transferred to another in-sync replica, and the original
    does not resume leadership of any partitions automatically. This can cause wildly
    inefficient balance after a deployment across a full cluster if automatic leader
    balancing is not enabled. As such it is recommended to ensure that this setting
    is enabled or to use other open source tooling such as Cruise Control to ensure
    that a good balance is maintained at all times.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kafka中，领导者被定义为副本列表中的第一个同步副本。但是，当经纪人停止或失去与集群其余部分的连接时，领导权将转移到另一个同步副本，并且原始副本不会自动恢复任何分区的领导权。如果未启用自动领导平衡，这可能会导致在整个集群上部署后出现极其低效的平衡。因此，建议确保启用此设置，或者使用其他开源工具（如Cruise
    Control）来确保始终保持良好的平衡。
- en: If you find that your Kafka cluster has a poor balance, a lightweight, generally
    non-impacting procedure can be performed called *preferred leader election*. This
    tells the cluster controller to select the ideal leader for partitions. Clients
    can track leadership changes automatically, so they will be able to move to the
    new broker in the cluster in which leadership is transferred. This operation can
    be manually triggered using the `kafka-leader-election.sh` utility. An older version
    of this tool called `kafka-preferred-replica-election.sh` is also available but
    has been deprecated in favor of the new tool, which allows for more customization,
    such as specifying whether we want a “preferred” or “unclean” election type.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 如果发现Kafka集群的平衡不佳，可以执行一个轻量级、通常不会产生影响的过程，称为*首选领导者选举*。这告诉集群控制器选择分区的理想领导者。客户端可以自动跟踪领导权的变化，因此它们将能够移动到领导权被转移的集群中的新经纪人。可以使用`kafka-leader-election.sh`实用程序手动触发此操作。这个工具的旧版本称为`kafka-preferred-replica-election.sh`也可用，但已被弃用，而新工具允许更多的自定义，比如指定我们是否需要“首选”或“不洁选举”类型。
- en: 'As an example, starting a preferred leader election for all topics in a cluster
    can be executed with the following command:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个例子，在集群中为所有主题启动首选领导者选举可以使用以下命令执行：
- en: '[PRE21]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'It is also possible to start elections on specific partitions or topics. This
    can be done by passing in a topic name with the `--topic` option and a partition
    with the `--partition` option directly. It is also possible to pass in a list
    of several partitions to be elected. This is done by configuring a JSON file that
    we will call *partitions.json*:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以在特定分区或主题上启动选举。这可以通过使用`--topic`选项和`--partition`选项直接传入主题名称和分区来完成。还可以传入要选举的多个分区的列表。这可以通过配置一个我们称之为*partitions.json*的JSON文件来完成：
- en: '[PRE22]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'In this example, we will start a preferred replica election with a specified
    list of partitions in a file named *partitions.json*:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用名为*partitions.json*的文件启动首选副本选举，指定了一个分区列表：
- en: '[PRE23]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Changing a Partition’s Replicas
  id: totrans-277
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更改分区的副本
- en: 'Occasionally it may be necessary to change the replica assignments manually
    for a partition. Some examples of when this might be needed are:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 偶尔可能需要手动更改分区的副本分配。可能需要这样做的一些例子是：
- en: There is an uneven load on brokers that the automatic leader distribution is
    not correctly handling.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经纪人的负载不均匀，自动领导者分配处理不正确。
- en: If a broker is taken offline and the partition is under replicated.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果经纪人被下线并且分区处于副本不足状态。
- en: If a new broker is added and we want to more quickly balance new partitions
    on it.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果添加了新的经纪人，并且我们希望更快地平衡新的分区。
- en: You want to adjust the replication factor of a topic.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你想要调整主题的复制因子。
- en: The `kafka-reassign-partitions.sh` can be used to perform this operation. This
    is a multistep process to generate a move set and then execute on the provided
    move set proposal. First, we want to use a broker list and a topic list to generate
    a proposal for the set of moves. This will require the generation of a JSON file
    with a list of topics to be supplied. The next step executes the moves that were
    generated by the previous proposal. Finally, the tool can be used with the generated
    list to track and verify the progress or completion of the partition reassignments.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '`kafka-reassign-partitions.sh`可用于执行此操作。这是一个多步过程，用于生成移动集并执行提供的移动集提议。首先，我们要使用经纪人列表和主题列表生成一组移动的提议。这将需要生成一个JSON文件，其中包含要提供的主题列表。下一步执行先前提议生成的移动。最后，该工具可以与生成的列表一起使用，以跟踪和验证分区重新分配的进度或完成情况。'
- en: Let’s generate a hypothetical scenario in which you have a four-broker Kafka
    cluster. You’ve recently added two new brokers, bringing the total up to six,
    and you want to move two of your topics onto brokers 5 and 6.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们假设一个场景，你有一个由四个经纪人组成的Kafka集群。最近，你添加了两个新的经纪人，总数增加到了六个，你想把两个主题移动到第五和第六个经纪人上。
- en: 'To generate a set of partition moves, you must first create a file that contains
    a JSON object listing the topics. The JSON object is formatted as follows (the
    version number is currently always 1):'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成一组分区移动，首先必须创建一个包含列出主题的JSON对象的文件。JSON对象的格式如下（版本号目前始终为1）：
- en: '[PRE24]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Once we’ve defined our JSON file, we can use it to generate a set of partition
    moves to move the topics listed in the file *topics.json* to the brokers with
    IDs 5 and 6:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们定义了JSON文件，我们可以使用它来生成一组分区移动，将文件*topics.json*中列出的主题移动到ID为5和6的经纪人：
- en: '[PRE25]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The output proposed here is formatted correctly, to which we can save two new
    JSON files that we will call *revert-reassignment.json* and *expand-cluster-reassignment.json*.
    The first file can be used to move partitions back to where they were originally
    if you need to roll back for some reason. The second file can be used for the
    next step, as this is just a proposal and hasn’t executed anything yet. You’ll
    notice in the output that there isn’t a good balance of leadership, as the proposal
    will result in all leadership moving to broker 5\. We will ignore this for now
    and presume the cluster automatic leadership balancing is enabled, which will
    help distribute it later. It should be noted that the first step can be skipped
    if you know exactly where you want to move your partitions to and you manually
    craft the JSON to move partitions.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 这里提出的输出格式正确，我们可以保存两个新的JSON文件，我们将它们称为*revert-reassignment.json*和*expand-cluster-reassignment.json*。第一个文件可用于将分区移动回原始位置，如果有必要进行回滚。第二个文件可用于下一步，因为这只是一个提议，尚未执行任何操作。你会注意到输出中领导权的平衡不够好，因为提议将导致所有领导权移动到经纪人5。我们现在将忽略这一点，并假设集群自动领导权平衡已启用，这将有助于稍后进行分发。值得注意的是，如果你确切地知道要将分区移动到哪里，并且手动编写JSON来移动分区，第一步可以跳过。
- en: 'To execute the proposed partition reassignment from the file *expand-cluster-reassignment.json*,
    run the following command:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行文件*expand-cluster-reassignment.json*中提出的分区重新分配，运行以下命令：
- en: '[PRE26]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This will start the reassignment of the specified partition replicas to the
    new brokers. The output is the same as the generated proposal verification. The
    cluster controller performs this reassignment action by adding the new replicas
    to the replica list for each partition, which will temporarily increase the replication
    factor of these topics. The new replicas will then copy all existing messages
    for each partition from the current leader. Depending on the size of the partitions
    on disk, this can take a significant amount of time as the data is copied across
    the network to the new replicas. Once replication is complete, the controller
    removes the old replicas from the replica list by reducing the replication factor
    to the original size with the old replicas removed.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 这将开始将指定分区副本重新分配到新的经纪人。输出与生成的提议验证相同。集群控制器通过将新副本添加到每个分区的副本列表来执行此重新分配操作，这将暂时增加这些主题的复制因子。然后，新副本将从当前领导者复制每个分区的所有现有消息。根据磁盘上分区的大小，这可能需要大量时间，因为数据通过网络复制到新副本。复制完成后，控制器通过将旧副本从副本列表中删除来将复制因子减少到原始大小，并删除旧副本。
- en: 'Here are a few other useful features of the command you could take advantage
    of:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是命令的其他一些有用功能，你可以利用：
- en: '`--additional`'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '`--additional`'
- en: This option will allow you to add to the existing reassignments so they can
    continue to be performed without interruption and without the need to wait until
    the original movements have completed in order to start a new batch.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 这个选项允许你添加到现有的重新分配中，这样它们可以继续执行而不中断，并且无需等待原始移动完成才能开始新的批处理。
- en: '`--disable-rack-aware`'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '`--disable-rack-aware`'
- en: There may be times when, due to rack awareness settings, the end-state of a
    proposal may not be possible. This can be overridden with this command if necessary.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，由于机架感知设置，提案的最终状态可能是不可能的。如果有必要，可以使用此命令覆盖。
- en: '`--throttle`'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '`--throttle`'
- en: This value is in units of bytes/sec. Partition reassignments have a big impact
    on the performance of your cluster, as they will cause changes in the consistency
    of the memory page cache and use network and disk I/O. Throttling the movement
    of partitions can be useful to prevent this issue. This can be combined with the
    `--additional` tag to throttle an already-started reassignment process that may
    be causing issues.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 这个值以字节/秒为单位。重新分配分区对集群的性能有很大影响，因为它们会导致内存页缓存的一致性发生变化，并使用网络和磁盘I/O。限制分区移动可以有助于防止这个问题。这可以与`--additional`标记结合使用，以限制可能导致问题的已启动重新分配过程。
- en: Improving Network Utilization When Reassigning Replicas
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在重新分配副本时改善网络利用率
- en: When removing many partitions from a single broker, such as if that broker is
    being removed from the cluster, it may be useful to remove all leadership from
    the broker first. This can be done by manually moving leaderships off the broker;
    however, using the preceding tooling to do this is arduous. Other open source
    tools such as Cruise Control include features like broker “demotion,” which safely
    moves leadership off a broker and is probably the simplest way to do this.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 当从单个代理中删除许多分区时，例如如果该代理正在从集群中移除，首先从代理中删除所有领导可能是有用的。这可以通过手动将领导权移出代理来完成；然而，使用前面的工具来做这件事是很困难的。其他开源工具，如Cruise
    Control，包括代理“降级”等功能，可以安全地将领导权从代理转移出去，这可能是最简单的方法。
- en: However, if you do not have access to such tools, a simple restart of a broker
    will suffice. As a broker is preparing to shut down, all leadership for the partitions
    on that particular broker will move to other brokers in the clusters. This can
    significantly increase the performance of reassignments and reduce the impact
    on the cluster, as the replication traffic will be distributed to many brokers.
    However, if automatic leader reassignment is enabled after the broker is bounced,
    leadership may return to this broker, so it may be beneficial to temporarily disable
    this feature.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果您没有访问这样的工具，简单地重新启动代理就足够了。当代理准备关闭时，该特定代理上的所有分区的领导权将移动到集群中的其他代理。这可以显著提高重新分配的性能，并减少对集群的影响，因为复制流量将分布到许多代理中。但是，如果在代理弹出后启用了自动领导重新分配，领导权可能会返回到该代理，因此暂时禁用此功能可能是有益的。
- en: To check on the progress of the partition moves, the tool can be used to verify
    the status of the reassignment. This will show which reassignments are currently
    in progress, which reassignments have completed, and (if there was an error) which
    reassignments have failed. To do this, you must have the file with the JSON object
    that was used in the execute step.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查分区移动的进度，可以使用该工具来验证重新分配的状态。这将显示当前正在进行的重新分配，已完成的重新分配以及（如果有错误）失败的重新分配。为此，您必须拥有在执行步骤中使用的JSON对象的文件。
- en: 'Here is an example of potential results using the `--verify` option when running
    the preceding partition reassignment from the file *expand-cluster-reassignment.json*:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在运行前面的分区重新分配时使用`--verify`选项时的潜在结果的示例，文件名为*expand-cluster-reassignment.json*：
- en: '[PRE27]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Changing the replication factor
  id: totrans-306
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更改复制因子
- en: The `kafka-reassign-partitions.sh` tool can also be used to increase or decrease
    the replication factor (RF) for a partition. This may be necessary in situations
    where a partition was created with the wrong RF, you want increased redundancy
    as you expand your cluster, or you want to decrease redundancy for cost savings.
    One clear example is that if a cluster RF default setting is adjusted, existing
    topics will not automatically be increased. The tool can be used to increase RF
    on the existing partitions.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '`kafka-reassign-partitions.sh`工具也可以用于增加或减少分区的复制因子（RF）。在分区使用错误的RF创建时，扩展集群时需要增加冗余性，或者为了节省成本而减少冗余性的情况下，可能需要这样做。一个明显的例子是，如果调整了集群RF默认设置，现有主题将不会自动增加。该工具可用于增加现有分区的RF。'
- en: 'As an example, if we wanted to increase topic “foo1” from the previous example
    from an RF = 2 to RF = 3, then we could craft a JSON similar to the execution
    proposal we used before, except we’d add in an additional broker ID to the replica
    set. For example, we could construct a JSON called *increase-foo1-RF.json* in
    which we add broker 4 to the existing set of 5,6 that we already have:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们想要将上一个示例中的主题“foo1”从RF = 2增加到RF = 3，那么我们可以制作一个类似于之前使用的执行提案的JSON，只是我们会在副本集中添加一个额外的代理ID。例如，我们可以构造一个名为*increase-foo1-RF.json*的JSON，在其中我们将代理4添加到我们已经拥有的5,6的现有集合中：
- en: '[PRE28]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We’d then use the commands shown earlier to execute on this proposal. When
    it completes, we can verify the RF has been increased by either using the `--verify`
    flag or using the `kafka-topics.sh` script to describe the topic:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用之前显示的命令来执行此提案。当完成时，我们可以使用`--verify`标志或使用`kafka-topics.sh`脚本来描述主题来验证RF是否已经增加：
- en: '[PRE29]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Canceling replica reassignments
  id: totrans-312
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 取消副本重新分配
- en: Canceling a replica reassignment in the past was a dangerous process that required
    unsafe manual manipulation of ZooKeeper nodes (or znodes) by deleting the `/admin/reassign_partitions`
    znode. Fortunately, this is no longer the case. The `kafka-reassign-partitions.sh`
    script (as well as the AdminClient it is a wrapper for) now supports the `--cancel`
    option, which will cancel the active reassignments that are ongoing in a cluster.
    When stopping an in-progress partition move, the `--cancel` command is designed
    to restore the replica set to the one it was prior to reassignment being initiated.
    As such, if replicas are being removed from a dead broker or an overloaded broker,
    it may leave the cluster in an undesirable state. There is also no guarantee that
    the reverted replica set will be in the same order as it was previously.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 过去取消副本重新分配是一个危险的过程，需要通过删除`/admin/reassign_partitions` znode来不安全地手动操作ZooKeeper节点（或znode）。幸运的是，现在不再是这种情况。`kafka-reassign-partitions.sh`脚本（以及它作为包装器的AdminClient）现在支持`--cancel`选项，该选项将取消正在进行的集群中的活动重新分配。在停止正在进行的分区移动时，`--cancel`命令旨在将副本集恢复到重新分配启动之前的状态。因此，如果从死掉的代理或负载过重的代理中删除副本，可能会使集群处于不良状态。还不能保证恢复的副本集将与以前的顺序相同。
- en: Dumping Log Segments
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转储日志段
- en: On occasion you may have the need to read the specific content of a message,
    perhaps because you ended up with a “poison pill” message in your topic that is
    corrupted and your consumer cannot handle it. The `kafka-dump-log.sh` tool is
    provided to decode the log segments for a partition. This will allow you to view
    individual messages without needing to consume and decode them. The tool takes
    a comma-separated list of log segment files as an argument and can print out either
    message summary information or detailed message data.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 偶尔您可能需要读取消息的特定内容，也许是因为您的主题中出现了一个损坏的“毒丸”消息，您的消费者无法处理它。提供了`kafka-dump-log.sh`工具来解码分区的日志段。这将允许您查看单个消息，而无需消费和解码它们。该工具将作为参数接受一个逗号分隔的日志段文件列表，并可以打印出消息摘要信息或详细消息数据。
- en: 'In this example, we will dump the logs from a sample topic, “my-topic,” which
    is a new topic with only four messages in it. First, we will simply decode the
    log segment file named *00000000000000000000.log* and retrieve basic metadata
    info about each message without actually printing the message contents. In our
    example Kafka installation, the Kafka data directory is set up in */tmp/kafka-logs*.
    As such, our directory for finding the log segments will be */tmp/kafka-logs/<topic-name>-<partition>*,
    in this case, */tmp/kafka-logs/my-topic-0/*:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，我们将从一个名为“my-topic”的示例主题中转储日志，其中只有四条消息。首先，我们将简单地解码名为*00000000000000000000.log*的日志段文件，并检索有关每条消息的基本元数据信息，而不实际打印消息内容。在我们的示例Kafka安装中，Kafka数据目录设置为*/tmp/kafka-logs*。因此，我们用于查找日志段的目录将是*/tmp/kafka-logs/<topic-name>-<partition>*，在这种情况下是*/tmp/kafka-logs/my-topic-0/*：
- en: '[PRE30]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'In the next example, we add the `--print-data-log` option, which will provide
    us the actual payload information and more:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个示例中，我们添加了`--print-data-log`选项，这将为我们提供实际的有效载荷信息和更多内容：
- en: '[PRE31]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The tool also contains a few other useful options, such as validating the index
    file that goes along with a log segment. The index is used for finding messages
    within a log segment, and if corrupted, will cause errors in consumption. Validation
    is performed whenever a broker starts up in an unclean state (i.e., it was not
    stopped normally), but it can be performed manually as well. There are two options
    for checking indices, depending on how much checking you want to do. The option
    `--index-sanity-check` will just check that the index is in a usable state, while
    `--verify-index-only` will check for mismatches in the index without printing
    out all the index entries. Another useful option, `--value-decoder-class`, allows
    serialized messages to be deserialized by passing in a decoder.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 该工具还包含一些其他有用的选项，例如验证与日志段一起使用的索引文件。索引用于在日志段中查找消息，如果损坏，将导致消费中的错误。验证是在代理以不洁净状态启动时执行的（即，它没有正常停止），但也可以手动执行。有两个选项用于检查索引，取决于您想要进行多少检查。选项“--index-sanity-check”将仅检查索引是否处于可用状态，而“--verify-index-only”将检查索引中的不匹配项，而不打印出所有索引条目。另一个有用的选项“--value-decoder-class”允许通过传递解码器对序列化消息进行反序列化。
- en: Replica Verification
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 副本验证
- en: 'Partition replication works similar to a regular Kafka consumer client: the
    follower broker starts replicating at the oldest offset and checkpoints the current
    offset to disk periodically. When replication stops and restarts, it picks up
    from the last checkpoint. It is possible for previously replicated log segments
    to get deleted from a broker, and the follower will not fill in the gaps in this
    case.'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 分区复制类似于常规Kafka消费者客户端：跟随者代理从最旧的偏移开始复制，并定期将当前偏移检查点到磁盘。当复制停止并重新启动时，它将从上次检查点继续。以前复制的日志段可能会从代理中删除，在这种情况下，跟随者不会填补这些间隙。
- en: To validate that the replicas for a topic’s partitions are the same across the
    cluster, you can use the `kafka-replica-verification.sh` tool for verification.
    This tool will fetch messages from all the replicas for a given set of topic partitions,
    check that all messages exist on all replicas, and print out the max lag for given
    partitions. This process will operate continuously in a loop until canceled. To
    do this, you must provide an explicit comma-separated list of brokers to connect
    to. By default, all topics are validated; however, you may also provide the tool
    a regular expression that matches the topics you wish to validate.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 要验证主题分区的副本在集群中是否相同，可以使用`kafka-replica-verification.sh`工具进行验证。此工具将从给定一组主题分区的所有副本中获取消息，检查所有消息是否存在于所有副本中，并打印出给定分区的最大滞后。此过程将在循环中持续运行，直到取消。为此，您必须提供一个显式的逗号分隔的代理列表以连接到。默认情况下，将验证所有主题；但是，您还可以提供一个正则表达式，以匹配您希望验证的主题。
- en: 'Caution: Cluster Impact Ahead'
  id: totrans-324
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 注意：集群影响
- en: The replica verification tool will have an impact on your cluster similar to
    reassigning partitions, as it must read all messages from the oldest offset in
    order to verify the replica. In addition, it reads from all replicas for a partition
    in parallel, so it should be used with caution.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 副本验证工具将对您的集群产生与重新分配分区类似的影响，因为它必须从最旧的偏移读取所有消息以验证副本。此外，它会并行从分区的所有副本中读取，因此应谨慎使用。
- en: 'For example, verify the replicas for the topics starting with *my* on kafka
    brokers 1 and 2, which contain partition 0 of “my-topic”:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在kafka代理1和2上验证以*my*开头的主题的副本，其中包含“my-topic”的分区0：
- en: '[PRE32]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Other Tools
  id: totrans-328
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他工具
- en: 'Several more tools are included in the Kafka distribution that are not covered
    in depth in this book that can be useful in administering your Kafka cluster for
    specific use cases. Further information about them can be found on the [Apache
    Kafka website](https://kafka.apache.org):'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka发行版中还包含了几个未在本书中深入介绍的工具，这些工具可以用于管理Kafka集群以满足特定用例。有关它们的更多信息可以在[Apache Kafka网站](https://kafka.apache.org)上找到：
- en: Client ACLs
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端ACL
- en: A command-line tool, `kafka-acls.sh`, is provided for interacting with access
    controls for Kafka clients. This includes full features for authorizer properties,
    set up for deny or allow principles, cluster- or topic-level restrictions, ZooKeeper
    TLS file configuration, and much more.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 提供了一个命令行工具`kafka-acls.sh`，用于与Kafka客户端的访问控制进行交互。这包括了完整的授权者属性功能，设置拒绝或允许原则，集群或主题级别的限制，ZooKeeper
    TLS文件配置等等。
- en: Lightweight MirrorMaker
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 轻量级MirrorMaker
- en: A lightweight `kafka-mirror-maker.sh` script is available for mirroring data.
    A more in-depth look at replication can be found in [Chapter 10](ch10.html#cross_cluster_mirroring).
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 提供了一个轻量级的`kafka-mirror-maker.sh`脚本用于数据镜像。关于复制的更深入的内容可以在[第10章](ch10.html#cross_cluster_mirroring)中找到。
- en: Testing tools
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 测试工具
- en: There are several other scripts used for testing Kafka or helping to perform
    upgrades of features. `kafka-broker-api-versions.sh` helps to easily identify
    different versions of usable API elements when upgrading from one Kafka version
    to another and check for compatibility issues. There are producer and consumer
    performance tests scripts. There are several scripts to help administer ZooKeeper
    as well. There is also `trogdor.sh`, which is a test framework designed to run
    benchmarks and other workloads to attempt to stress test the system.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些其他用于测试Kafka或帮助执行功能升级的脚本。`kafka-broker-api-versions.sh`有助于在从一个Kafka版本升级到另一个版本时轻松识别可用API元素的不同版本，并检查兼容性问题。还有生产者和消费者性能测试脚本。还有一些脚本用于帮助管理ZooKeeper。还有`trogdor.sh`，这是一个旨在运行基准测试和其他工作负载以尝试对系统进行压力测试的测试框架。
- en: Unsafe Operations
  id: totrans-336
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不安全的操作
- en: There are some administrative tasks that are technically possible to do but
    should not be attempted except in the most extreme situations. Often this is when
    you are diagnosing a problem and have run out of options, or you have found a
    specific bug that you need to work around temporarily. These tasks are usually
    undocumented, unsupported, and pose some amount of risk to your application.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些管理任务在技术上是可能的，但除非在极端情况下，不应尝试执行。通常情况下，这是在诊断问题并且已经没有其他选择时，或者发现了需要临时解决的特定错误时。这些任务通常是未记录的，不受支持的，并对应用程序造成一定风险。
- en: Several of the more common of these tasks are documented here so that in an
    emergency situation, there is a potential option for recovery. Their use is not
    recommended under normal cluster operations and should be considered carefully
    before being executed.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 这里记录了一些常见的任务，以便在紧急情况下有可能进行恢复。在正常的集群操作下，不建议使用它们，并且在执行之前应仔细考虑。
- en: 'Danger: Here Be Dragons'
  id: totrans-339
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 危险：这里有危险
- en: The operations in this section often involve working with the cluster metadata
    stored in ZooKeeper directly. This can be a very dangerous operation, so you must
    be very careful to not modify the information in ZooKeeper directly, except as
    noted.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的操作通常涉及直接使用存储在ZooKeeper中的集群元数据。这可能是非常危险的操作，因此除非另有说明，否则必须非常小心，不要直接修改ZooKeeper中的信息。
- en: Moving the Cluster Controller
  id: totrans-341
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 移动集群控制器
- en: Every Kafka cluster has a single broker that is designated as a controller.
    The controller has a special thread that is responsible for overseeing cluster
    operations in addition to normal broker work. Normally, controller election is
    done automatically through ephemeral ZooKeeper znode monitoring. When a controller
    turns off or becomes unavailable, other brokers nominate themselves as soon as
    possible, since once the controller shuts down, the znode is removed.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 每个Kafka集群都有一个被指定为控制器的单个代理。控制器有一个特殊的线程负责监督集群操作以及正常的代理工作。通常情况下，控制器选举是通过短暂的ZooKeeper
    znode监视自动完成的。当控制器关闭或不可用时，其他代理会尽快自我提名，因为一旦控制器关闭，znode就会被删除。
- en: On occasion, when troubleshooting a misbehaving cluster or broker, it may be
    useful to forcibly move the controller to a different broker without shutting
    down the host. One such example is when the controller has suffered an exception
    or other problem that has left it running but not functional. Moving the controller
    in these situations does not normally have a high risk, but as it is not a normal
    task, it should not be performed regularly.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在偶尔的情况下，当排除集群或代理的故障时，可能有必要强制将控制器移动到另一个代理，而不关闭主机。一个这样的例子是当控制器遇到异常或其他问题导致其运行但不起作用时。在这些情况下移动控制器通常不会有很高的风险，但由于这不是正常的任务，不应经常执行。
- en: To forcibly move a controller, deleting the ZooKeeper znode at */admin/controller*
    manually will cause the current controller to resign, and the cluster will randomly
    select a new controller. There is currently no way to specify a specific broker
    to be controller in Apache Kafka.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 要强制移动控制器，需要手动删除*/admin/controller*下的ZooKeeper znode，这将导致当前控制器辞职，并且集群将随机选择一个新的控制器。目前在Apache
    Kafka中没有办法指定特定的代理作为控制器。
- en: Removing Topics to Be Deleted
  id: totrans-345
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除待删除的主题
- en: 'When attempting to delete a topic in Kafka, a ZooKeeper node requests that
    the deletion is created. Once every replica completes deletion of the topic and
    acknowledges deletion is complete, the znode will be removed. Under normal circumstances,
    this is executed by the cluster very quickly. However, sometimes things can go
    wrong with this process. Here are some scenarios in which a deletion request may
    become stuck:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试删除Kafka中的主题时，ZooKeeper节点会请求创建删除。一旦每个副本完成主题的删除并确认删除完成，znode将被删除。在正常情况下，集群会非常快地执行此操作。然而，有时这个过程可能出现问题。以下是一些删除请求可能被卡住的情况：
- en: A requester has no way of knowing whether topic deletion is enabled in the cluster
    and can request deletion of a topic from a cluster in which deletion is disabled.
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请求者无法知道集群中是否启用了主题删除，并且可以请求从禁用删除的集群中删除主题。
- en: A very large topic is requested to be deleted, but before the request is handled,
    one or more of the replica sets goes offline due to hardware failures, and the
    deletion cannot complete as the controller cannot ack that the deletion was completed
    successfully.
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有一个非常大的主题要求被删除，但在处理请求之前，一个或多个副本集由于硬件故障而下线，删除无法完成，因为控制器无法确认删除是否成功完成。
- en: To “unstick” topic deletion, first delete the */admin/delete_topic/<topic>*
    znode. Deleting the topic ZooKeeper nodes (but not the parent */admin/delete_topic*
    node) will remove the pending requests. If the deletion is re-queued by cached
    requests in the controller, it may be necessary to also forcibly move the controller
    as shown earlier immediately after removing the topic znode to ensure that no
    cached requests are pending in the controller.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 要“解除”主题删除，首先删除*/admin/delete_topic/<topic>* znode。删除主题ZooKeeper节点（但不删除父节点*/admin/delete_topic*）将删除待处理的请求。如果删除被控制器中的缓存请求重新排队，可能还需要在删除主题znode后立即强制移动控制器，以确保控制器中没有挂起的缓存请求。
- en: Deleting Topics Manually
  id: totrans-350
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 手动删除主题
- en: If you are running a cluster with delete topics disabled, or if you find yourself
    needing to delete some topics outside of the normal flow of operations, it is
    possible to manually delete them from the cluster. This requires a full shutdown
    of all brokers in the cluster, however, and cannot be done while any of the brokers
    in the cluster are running.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您运行的是禁用删除主题的集群，或者发现自己需要在正常操作流程之外删除一些主题，那么可以手动从集群中删除它们。但是，这需要完全关闭集群中的所有经纪人，并且不能在集群中的任何经纪人运行时执行。
- en: Shut Down Brokers First
  id: totrans-352
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 首先关闭经纪人
- en: Modifying the cluster metadata in ZooKeeper when the cluster is online is a
    very dangerous operation and can put the cluster into an unstable state. Never
    attempt to delete or modify topic metadata in ZooKeeper while the cluster is online.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 在集群在线时修改ZooKeeper中的集群元数据是非常危险的操作，可能会使集群处于不稳定状态。永远不要在集群在线时尝试删除或修改ZooKeeper中的主题元数据。
- en: 'To delete a topic from the cluster:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 从集群中删除主题：
- en: Shut down all brokers in the cluster.
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关闭集群中的所有经纪人。
- en: Remove the ZooKeeper path */brokers/topics/<topic>* from the Kafka cluster path.
    Note that this node has child nodes that must be deleted first.
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Kafka集群路径中删除ZooKeeper路径*/brokers/topics/<topic>*。请注意，此节点有必须首先删除的子节点。
- en: Remove the partition directories from the log directories on each broker. These
    will be named `<topic>-<int>`, where `<int>` is the partition ID.
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从每个经纪人的日志目录中删除分区目录。这些目录将被命名为`<topic>-<int>`，其中`<int>`是分区ID。
- en: Restart all brokers.
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新启动所有经纪人。
- en: Summary
  id: totrans-359
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Running a Kafka cluster can be a daunting endeavor, with numerous configurations
    and maintenance tasks to keep the systems running at peak performance. In this
    chapter, we discussed many of the routine tasks, such as managing topic and client
    configurations, that you will need to handle frequently. We also covered some
    of the more esoteric tasks that you’ll need for debugging problems, like examining
    log segments. Finally, we covered a few of the operations that, while not safe
    or routine, can be used to get you out of a sticky situation. All together, these
    tools will help you to manage your Kafka cluster. As you begin to scale your Kafka
    clusters larger, even the use of these tools may become arduous and difficult
    to manage. It is highly recommended to engage with the open source Kafka community
    and take advantage of the many other open source projects in the ecosystem to
    help automate many of the tasks outlined in this chapter.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 运行Kafka集群可能是一项艰巨的任务，需要进行大量配置和维护任务，以确保系统以最佳性能运行。在本章中，我们讨论了许多常规任务，比如管理主题和客户端配置，这些是您经常需要处理的。我们还涵盖了一些更神秘的任务，这些任务是您需要用来调试问题的，比如检查日志段。最后，我们涵盖了一些操作，虽然不安全或常规，但可以帮助您摆脱困境。总的来说，这些工具将帮助您管理Kafka集群。随着您开始扩展Kafka集群的规模，即使使用这些工具也可能变得艰难和难以管理。强烈建议与开源Kafka社区合作，并利用生态系统中的许多其他开源项目，以帮助自动化本章中概述的许多任务。
- en: Now that we are confident in the tools needed to administer and manage our cluster,
    it is still impossible without proper monitoring in place. [Chapter 13](ch13.html#monitoring_kafka)
    will discuss ways to monitor broker and cluster health and operations so you can
    be sure Kafka is working well (and know when it isn’t). We will also offer best
    practices for monitoring your clients, including both producers and consumers.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对管理和管理我们的集群所需的工具有信心，但是如果没有适当的监控，这仍然是不可能的。[第13章](ch13.html#monitoring_kafka)将讨论监控经纪人和集群健康和运行状况的方法，以便您可以确保Kafka运行良好（并知道何时不是）。我们还将提供监控客户端的最佳实践，包括生产者和消费者。

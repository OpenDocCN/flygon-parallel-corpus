- en: Chapter 12\. Administering Kafka
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Managing a Kafka cluster requires additional tooling to perform administrative
    changes to topics, configurations, and more. Kafka provides several command-line
    interface (CLI) utilities that are useful for making administrative changes to
    your clusters. The tools are implemented in Java classes, and a set of scripts
    are provided natively to call those classes properly. While these tools provide
    basic functions, you may find they are lacking for more complex operations or
    are unwieldy to use at larger scales. This chapter will describe only the basic
    tools that are available as part of the Apache Kafka open source project. More
    information about advanced tools that have been developed in the community, outside
    of the core project, can be found on the [Apache Kafka website](https://kafka.apache.org).
  prefs: []
  type: TYPE_NORMAL
- en: Authorizing Admin Operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While Apache Kafka implements authentication and authorization to control topic
    operations, default configurations do not restrict the use of these tools. This
    means that these CLI tools can be used without any authentication required, which
    will allow operations such as topic changes to be executed with no security check
    or audit. Always ensure that access to this tooling on your deployments is restricted
    to administrators only to prevent unauthorized changes.
  prefs: []
  type: TYPE_NORMAL
- en: Topic Operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `kafka-topics.sh` tool provides easy access to most topic operations. It
    allows you to create, modify, delete, and list information about topics in the
    cluster. While some topic configurations are possible through this command, they
    have been deprecated, and it is recommended to use the more robust method of using
    the `kafka-config.sh` tool for configuration changes. To use the `kafka-topics.sh`
    command, you must provide the cluster connection string and port through the `--bootstrap-server`
    option. In the examples that follow, the cluster connect string is being run locally
    on one of the hosts in the Kafka cluster, and we will be using `localhost:9092`.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this chapter, all the tools will be located in the directory */usr/local/kafka/bin/*.
    The example commands in this section will assume you are in this directory or
    have added the directory to your `$PATH`.
  prefs: []
  type: TYPE_NORMAL
- en: Check the Version
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many of the command-line tools for Kafka have a dependency on the version of
    Kafka running to operate correctly. This includes some commands that may store
    data in ZooKeeper rather than connecting to the brokers themselves. For this reason,
    it is important to make sure the version of the tools that you are using matches
    the version of the brokers in the cluster. The safest approach is to run the tools
    on the Kafka brokers themselves, using the deployed version.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a New Topic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When creating a new topic through the `--create` command, there are several
    required arguments to create a new topic in a cluster. These arguments must be
    provided when using this command even though some of them may have broker-level
    defaults configured already. Additional arguments and configuration overrides
    are possible at this time, as well using the `--config` option, but are covered
    later in the chapter. Here is a list of the three required arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--topic`'
  prefs: []
  type: TYPE_NORMAL
- en: The name of the topic that you wish to create.
  prefs: []
  type: TYPE_NORMAL
- en: '`--replication-factor`'
  prefs: []
  type: TYPE_NORMAL
- en: The number of replicas of the topic to maintain within the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: '`--partitions`'
  prefs: []
  type: TYPE_NORMAL
- en: The number of partitions to create for the topic.
  prefs: []
  type: TYPE_NORMAL
- en: Good Topic Naming Practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Topic names may contain alphanumeric characters, underscores, dashes, and periods;
    however, it is not recommended to use periods in topic names. Internal metrics
    inside of Kafka convert period characters to underscore characters (e.g., “topic.1”
    becomes “topic_1” in metrics calculations), which can result in conflicts in topic
    names.
  prefs: []
  type: TYPE_NORMAL
- en: Another recommendation is to avoid using a double underscore to start your topic
    name. By convention, topics internal to Kafka operations are created with a double
    underscore naming convention (like the `__consumer_offsets` topic, which tracks
    consumer group offset storage). As such it is not recommended to have topic names
    that begin with the double underscore naming convention to prevent confusion.
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating a new topic is simple. Run `kafka-topics.sh` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The command will cause the cluster to create a topic with the specified name
    and number of partitions. For each partition, the cluster will select the specified
    number of replicas appropriately. This means that if the cluster is set up for
    rack-aware replica assignment, the replicas for each partition will be in separate
    racks. If rack-aware assignment is not desired, specify the `--disable-rack-aware`
    command-line argument.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, create a topic named “my-topic” with eight partitions that have
    two replicas each:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Using if-exists and if-not-exists Arguments Properly
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When using `kafka-topics.sh` in automation, you may want to use the `--if-not-exists`
    argument while creating new topics that will not return an error if the topic
    already exists.
  prefs: []
  type: TYPE_NORMAL
- en: While an `--if-exists` argument is provided for the `--alter` command, using
    it is not recommended. Using this argument will cause the command to not return
    an error if the topic being changed does not exist. This can mask problems where
    a topic does not exist that should have been created.
  prefs: []
  type: TYPE_NORMAL
- en: Listing All Topics in a Cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `--list` command lists all topics in a cluster. The list is formatted with
    one topic per line, in no particular order, which is useful for generating a full
    list of topics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of the `--list` option listing all topics in the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You’ll notice the internal `__consumer_offsets` topic is listed here. Running
    the command with `--exclude-internal` will remove all topics from the list that
    begin with the double underscore mentioned earlier, which can be beneficial.
  prefs: []
  type: TYPE_NORMAL
- en: Describing Topic Details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is also possible to get detailed information on one or more topics in the
    cluster. The output includes the partition count, topic configuration overrides,
    and a listing of each partition with its replica assignments. This can be limited
    to a single topic by providing a `--topic` argument to the command.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, describing our recently created “my-topic” in the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `--describe` command also has several useful options for filtering the
    output. These can be helpful for diagnosing cluster issues more easily. For these
    commands we generally do not specify the `--topic` argument because the intention
    is to find all topics or partitions in a cluster that match the criteria. These
    options will not work with the `list` command. Here is a list of useful pairings
    to use:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--topics-with-overrides`'
  prefs: []
  type: TYPE_NORMAL
- en: This will describe only the topics that have configurations that differ from
    the cluster defaults.
  prefs: []
  type: TYPE_NORMAL
- en: '`--exclude-internal`'
  prefs: []
  type: TYPE_NORMAL
- en: The previously mentioned command will remove all topics from the list that begin
    with the double underscore naming convention.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following commands are used to help find topic partitions that may have
    problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--under-replicated-partitions`'
  prefs: []
  type: TYPE_NORMAL
- en: This shows all partitions where one or more of the replicas are not in sync
    with the leader. This isn’t necessarily bad, as cluster maintenance, deployments,
    and rebalances will cause under-replicated partitions (or URPs) but is something
    to be aware of.
  prefs: []
  type: TYPE_NORMAL
- en: '`--at-min-isr-partitions`'
  prefs: []
  type: TYPE_NORMAL
- en: This shows all partitions where the number of replicas, including the leader,
    exactly match the setting for minimum in-sync replicas (ISRs). These topics are
    still available for producer or consumer clients, but all redundancy has been
    lost, and they are in danger of becoming unavailable.
  prefs: []
  type: TYPE_NORMAL
- en: '`--under-min-isr-partitions`'
  prefs: []
  type: TYPE_NORMAL
- en: This shows all partitions where the number of ISRs is below the configured minimum
    for successful produce actions. These partitions are effectively in read-only
    mode and cannot be produced to.
  prefs: []
  type: TYPE_NORMAL
- en: '`--unavailable-partitions`'
  prefs: []
  type: TYPE_NORMAL
- en: This shows all topic partitions without a leader. This is a serious situation
    and indicates that the partition is offline and unavailable for producer or consumer
    clients.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of finding topics that are at the minimum ISR setttings.
    In this example, the topic is configured for a min-ISR of 1 and has a replication
    factor (RF) of 2\. Host 0 is online, and host 1 has gone down for maintenance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Adding Partitions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is sometimes necessary to increase the number of partitions for a topic.
    Partitions are the way topics are scaled and replicated across a cluster. The
    most common reason to increase the partition count is to horizontally scale a
    topic across more brokers by decreasing the throughput for a single partition.
    Topics may also be increased if a consumer needs to expand to run more copies
    in a single consumer group since a partition can only be consumed by a single
    member in the group.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following is an example of increasing the number of partitions for a topic
    named “my-topic” to 16 using the `--alter` command, followed by a verification
    that it worked:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Adjusting Keyed Topics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Topics that are produced with keyed messages can be very difficult to add partitions
    to from a consumer’s point of view. This is because the mapping of keys to partitions
    will change when the number of partitions is changed. For this reason, it is advisable
    to set the number of partitions for a topic that will contain keyed messages once,
    when the topic is created, and avoid resizing the topic.
  prefs: []
  type: TYPE_NORMAL
- en: Reducing Partitions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is not possible to reduce the number of partitions for a topic. Deleting
    a partition from a topic would cause part of the data in that topic to be deleted
    as well, which would be inconsistent from a client point of view. In addition,
    trying to redistribute the data to the remaining partitions would be difficult
    and result in out-of-order messages. Should you need to reduce the number of partitions,
    it is recommended to delete the topic and re-create it or (if deletion is not
    possible) create a new version of the existing topic and move all produce traffic
    to the new topic (e.g., “my-topic-v2”).
  prefs: []
  type: TYPE_NORMAL
- en: Deleting a Topic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Even a topic with no messages uses cluster resources such as disk space, open
    filehandles, and memory. The controller also has junk metadata that it must retain
    knowledge of, which can hinder performance at large scale. If a topic is no longer
    needed, it can be deleted to free up these resources. To perform this action,
    the brokers in the cluster must be configured with the `delete.topic.enable` option
    set to `true`. If it’s set to `false`, then the request to delete the topic will
    be ignored and will not succeed.
  prefs: []
  type: TYPE_NORMAL
- en: Topic deletion is an asynchronous operation. This means that running this command
    will mark a topic for deletion, but the deletion may not happen immediately, depending
    on the amount of data and cleanup needed. The controller will notify the brokers
    of the pending deletion as soon as possible (after existing controller tasks complete),
    and the brokers will then invalidate the metadata for the topic and delete the
    files from disk. It is highly recommended that operators not delete more than
    one or two topics at a time, and give those ample time to complete before deleting
    other topics, due to limitations in the way the controller executes these operations.
    In the small cluster shown in the examples in this book, topic deletion will happen
    almost immediately, but in larger clusters it may take longer.
  prefs: []
  type: TYPE_NORMAL
- en: Data Loss Ahead
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deleting a topic will also delete all its messages. This is not a reversible
    operation. Make sure it is executed carefully.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of deleting the topic named “my-topic” using the `--delete`
    argument. Depending on the version of Kafka, there will be a note letting you
    know that the argument will not work if another config is not set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: You will notice there is no visible feedback that the topic deletion was completed
    successfully or not. Verify that deletion was successful by running the `--list`
    or `--describe` options to see that the topic is no longer in the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Consumer Groups
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Consumer groups are coordinated groups of Kafka consumers consuming from topics
    or multiple partitions of a single topic. The `kafka-consumer-groups.sh` tool
    helps manage and gain insight into the consumer groups that are consuming from
    topics in the cluster. It can be used to list consumer groups, describe specific
    groups, delete consumer groups or specific group info, or reset consumer group
    offset information.
  prefs: []
  type: TYPE_NORMAL
- en: ZooKeeper-Based Consumer Groups
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In older versions of Kafka, consumer groups could be managed and maintained
    in ZooKeeper. This behavior was deprecated in versions 0.11.0.* and later, and
    old consumer groups are no longer used. Some versions of the provided scripts
    may still show deprecated `--zookeeper` connection string commands, but it is
    not recommended to use them unless you have an old environment with some consumer
    groups that have not upgraded to later versions of Kafka.
  prefs: []
  type: TYPE_NORMAL
- en: List and Describe Groups
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To list consumer groups, use the `--bootstrap-server` and `--list` parameters.
    Ad hoc consumers utilizing the `kafka-consumer-groups.sh` script will show up
    as `console-consumer-*<generated_id>*` in the consumer list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: For any group listed, you can get more details by changing the `--list` parameter
    to `--describe` and adding the `--group` parameter. This will list all the topics
    and partitions that the group is consuming from, as well as additional information
    such as the offsets for each topic partition. [Table 12-1](#table0901) has a full
    description of all the fields provided in the output.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, get consumer group details for the ad hoc group named “my-consumer”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Table 12-1\. Fields provided for group named “my-consumer”
  prefs: []
  type: TYPE_NORMAL
- en: '| Field | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| GROUP | The name of the consumer group. |'
  prefs: []
  type: TYPE_TB
- en: '| TOPIC | The name of the topic being consumed. |'
  prefs: []
  type: TYPE_TB
- en: '| PARTITION | The ID number of the partition being consumed. |'
  prefs: []
  type: TYPE_TB
- en: '| CURRENT-OFFSET | The next offset to be consumed by the consumer group for
    this topic partition. This is the position of the consumer within the partition.
    |'
  prefs: []
  type: TYPE_TB
- en: '| LOG-END-OFFSET | The current high-water mark offset from the broker for the
    topic partition. This is the offset of the next message to be produced to this
    partition. |'
  prefs: []
  type: TYPE_TB
- en: '| LAG | The difference between the consumer Current-Offset and the broker Log-End-Offset
    for this topic partition. |'
  prefs: []
  type: TYPE_TB
- en: '| CONSUMER-ID | A generated unique consumer-id based on the provided client-id.
    |'
  prefs: []
  type: TYPE_TB
- en: '| HOST | Address of the host the consumer group is reading from. |'
  prefs: []
  type: TYPE_TB
- en: '| CLIENT-ID | String provided by the client identifying the client that is
    consuming from the group. |'
  prefs: []
  type: TYPE_TB
- en: Delete Group
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deletion of consumer groups can be performed with the `--delete` argument. This
    will remove the entire group, including all stored offsets for all topics that
    the group is consuming. To perform this action, all consumers in the group should
    be shut down as the consumer group must not have any active members. If you attempt
    to delete a group that is not empty, an error stating “The group is not empty”
    will be thrown and nothing will happen. It is also possible to use the same command
    to delete offsets for a single topic that the group is consuming without deleting
    the entire group by adding the `--topic` argument and specifying which topic offsets
    to delete.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of deleting the entire consumer group named “my-consumer”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Offset Management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In addition to displaying and deleting the offsets for a consumer group, it
    is also possible to retrieve the offsets and store new offsets in a batch. This
    is useful for resetting the offsets for a consumer when there is a problem that
    requires messages to be reread, or for advancing offsets and skipping past a message
    that the consumer is having a problem with (e.g., if there is a badly formatted
    message that the consumer cannot handle).
  prefs: []
  type: TYPE_NORMAL
- en: Export offsets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To export offsets from a consumer group to a CSV file, use the `--reset-offsets`
    argument with the `--dry-run` option. This will allow us to create an export of
    the current offsets in a file format that can be reused for importing or rolling
    back the offsets later. The CSV format export will be in the following configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '*<topic-name>,<partition-number>,<offset>*'
  prefs: []
  type: TYPE_NORMAL
- en: Running the same command without the `--dry-run` option will reset the offsets
    completely, so be careful.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of exporting the offsets for the topic “my-topic” that is
    being consumed by the consumer group named “my-consumer” to a file named *offsets.csv*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Import offsets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The import offset tool is the opposite of exporting. It takes the file produced
    by exporting offsets in the previous section and uses it to set the current offsets
    for the consumer group. A common practice is to export the current offsets for
    the consumer group, make a copy of the file (so that you preserve a backup), and
    edit the copy to replace the offsets with the desired values.
  prefs: []
  type: TYPE_NORMAL
- en: Stop Consumers First
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before performing this step, it is important that all consumers in the group
    are stopped. They will not read the new offsets if they are written while the
    consumer group is active. The consumers will just overwrite the imported offsets.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we import the offsets for the consumer group named
    “my-consumer” from the file we created in the last example named *offsets.csv*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Dynamic Configuration Changes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There is a plethora of configurations for topics, clients, brokers, and more
    that can be updated dynamically during runtime without having to shut down or
    redeploy a cluster. The `kafka-configs.sh` is the main tool for modifying these
    configs. Currently there are four main categories, or *entity-types*, of dynamic
    config changes that can be made: *topics*, *brokers*, *users*, and *clients*.
    For each entity-type there are specific configurations that can be overridden.
    New dynamic configs are being added constantly with each release of Kafka, so
    it is good to ensure you have the same version of this tool that matches the version
    of Kafka you are running. For ease of setting up these configs consistently via
    automation, the `--add-config-file` argument can be used with a preformatted file
    of all the configs you want to manage and update.'
  prefs: []
  type: TYPE_NORMAL
- en: Overriding Topic Configuration Defaults
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many configurations that are set by default for topics that are defined
    in the static broker configuration files (e.g., retention time policy). With dynamic
    configurations, we can override the cluster0level defaults for individual topics
    to accommodate different use cases within a single cluster. [Table 12-2](#table0902)
    shows the valid configuration keys for topics that can be altered dynamically.
  prefs: []
  type: TYPE_NORMAL
- en: 'The format of the command to change a topic configuration is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an example of setting the retention for the topic named “my-topic”
    to 1 hour (3,600,000 ms):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Table 12-2\. Valid keys for topics
  prefs: []
  type: TYPE_NORMAL
- en: '| Configuration key | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `cleanup.policy` | If set to `compact`, the messages in this topic will be
    discarded and only the most recent message with a given key is retained (log compacted).
    |'
  prefs: []
  type: TYPE_TB
- en: '| `compression.type` | The compression type used by the broker when writing
    message batches for this topic to disk. |'
  prefs: []
  type: TYPE_TB
- en: '| `delete.retention.ms` | How long, in milliseconds, deleted tombstones will
    be retained for this topic. Only valid for log compacted topics. |'
  prefs: []
  type: TYPE_TB
- en: '| `file.delete.delay.ms` | How long, in milliseconds, to wait before deleting
    log segments and indices for this topic from disk. |'
  prefs: []
  type: TYPE_TB
- en: '| `flush.messages` | How many messages are received before forcing a flush
    of this topic’s messages to disk. |'
  prefs: []
  type: TYPE_TB
- en: '| `flush.ms` | How long, in milliseconds, before forcing a flush of this topic’s
    messages to disk. |'
  prefs: []
  type: TYPE_TB
- en: '| `follower.replication.​throt⁠tled.replicas` | A list of replicas for which
    log replication should be throttled by the follower. |'
  prefs: []
  type: TYPE_TB
- en: '| `index.interval.bytes` | How many bytes of messages can be produced between
    entries in the log segment’s index. |'
  prefs: []
  type: TYPE_TB
- en: '| `leader.replication.​throt⁠tled.replica` | A list of replicas for which log
    replication should be throttled by the leader. |'
  prefs: []
  type: TYPE_TB
- en: '| `max.compaction.lag.ms` | Maximum time limit a message won’t be eligible
    for compaction in the log. |'
  prefs: []
  type: TYPE_TB
- en: '| `max.message.bytes` | The maximum size of a single message for this topic,
    in bytes. |'
  prefs: []
  type: TYPE_TB
- en: '| `message.downconversion.enable` | Allows the message format version to be
    down-converted to the previous version if enabled with some overhead. |'
  prefs: []
  type: TYPE_TB
- en: '| `message.format.version` | The message format version that the broker will
    use when writing messages to disk. Must be a valid API version number. |'
  prefs: []
  type: TYPE_TB
- en: '| `message.timestamp.​dif⁠fer⁠ence.max.ms` | The maximum allowed difference,
    in milliseconds, between the message timestamp and the broker timestamp when the
    message is received. This is only valid if the `message.timestamp.type` is set
    to `CreateTime`. |'
  prefs: []
  type: TYPE_TB
- en: '| `message.timestamp.type` | Which timestamp to use when writing messages to
    disk. Current values are `CreateTime` for the timestamp specified by the client
    and `LogAppendTime` for the time when the message is written to the partition
    by the broker. |'
  prefs: []
  type: TYPE_TB
- en: '| `min.clean⁠able.​dirty.ratio` | How frequently the log compactor will attempt
    to compact partitions for this topic, expressed as a ratio of the number of uncompacted
    log segments to the total number of log segments. Only valid for log compacted
    topics. |'
  prefs: []
  type: TYPE_TB
- en: '| `min.compaction.lag.ms` | Minimum time a message will remain uncompacted
    in the log. |'
  prefs: []
  type: TYPE_TB
- en: '| `min.insync.replicas` | The minimum number of replicas that must be in sync
    for a partition of the topic to be considered available. |'
  prefs: []
  type: TYPE_TB
- en: '| `preallocate` | If set to `true`, log segments for this topic should be preallocated
    when a new segment is rolled. |'
  prefs: []
  type: TYPE_TB
- en: '| `retention.bytes` | The amount of messages, in bytes, to retain for this
    topic. |'
  prefs: []
  type: TYPE_TB
- en: '| `retention.ms` | How long messages should be retained for this topic, in
    milliseconds. |'
  prefs: []
  type: TYPE_TB
- en: '| `segment.bytes` | The amount of messages, in bytes, that should be written
    to a single log segment in a partition. |'
  prefs: []
  type: TYPE_TB
- en: '| `segment.index.bytes` | The maximum size, in bytes, of a single log segment
    index. |'
  prefs: []
  type: TYPE_TB
- en: '| `segment.jitter.ms` | A maximum number of milliseconds that is randomized
    and added to `segment.ms` when rolling log segments. |'
  prefs: []
  type: TYPE_TB
- en: '| `segment.ms` | How frequently, in milliseconds, the log segment for each
    partition should be rotated. |'
  prefs: []
  type: TYPE_TB
- en: '| `unclean.leader.​elec⁠tion.enable` | If set to `false`, unclean leader elections
    will not be permitted for this topic. |'
  prefs: []
  type: TYPE_TB
- en: Overriding Client and User Configuration Defaults
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For Kafka clients and users, there are only a few configurations that can be
    overridden, which are all essentially types of quotas. Two of the more common
    configurations to change are the bytes/sec rates allowed for producers and consumers
    with a specified client ID on a per-broker basis. The full list of shared configurations
    that can be modified for both *users* and *clients* is shown in [Table 12-3](#table0903).
  prefs: []
  type: TYPE_NORMAL
- en: Uneven Throttling Behavior in Poorly Balanced Clusters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Because throttling occurs on a per-broker basis, even balance of leadership
    of partitions across a cluster becomes particularly important to enforce this
    properly. If you have 5 brokers in a cluster and you specify a producer quota
    of 10 MBps for a client, that client will be allowed to produce 10 MBps *on each*
    broker at the same time for a total of 50 MBps, assuming a balanced leadership
    across all 5 hosts. However, if leadership for every partition is all on broker
    1, the same producer will only be able to produce a max of 10 MBps.
  prefs: []
  type: TYPE_NORMAL
- en: Table 12-3\. The configurations (keys) for clients
  prefs: []
  type: TYPE_NORMAL
- en: '| Configuration key | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `consumer_bytes_rate` | The amount of messages, in bytes, that a single client
    ID is allowed to consume from a single broker in one second. |'
  prefs: []
  type: TYPE_TB
- en: '| `producer_bytes_rate` | The amount of messages, in bytes, that a single client
    ID is allowed to produce to a single broker in one second. |'
  prefs: []
  type: TYPE_TB
- en: '| `controller_mutations_rate` | The rate at which mutations are accepted for
    the create topics request, the create partitions request, and the delete topics
    request. The rate is accumulated by the number of partitions created or deleted.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `request_percentage` | The percentage per quota window (out of a total of
    (num.io.threads + num.network.threads) × 100%) for requests from the user or client.
    |'
  prefs: []
  type: TYPE_TB
- en: Client ID Versus Consumer Group
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The client ID is not necessarily the same as the consumer group name. Consumers
    can set their own client ID, and you may have many consumers that are in different
    groups that specify the same client ID. It is considered a best practice to set
    the client ID for each consumer group to something unique that identifies that
    group. This allows a single consumer group to share a quota, and it makes it easier
    to identify in logs what group is responsible for requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Compatible user and client config changes can be specified together for compatible
    configs that apply to both. Here is an example of the command to change the controller
    mutation rate for both a user and client in one configuration step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Overriding Broker Configuration Defaults
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Broker- and cluster-level configs will primarily be configured statically in
    the cluster configuration files, but there is a plethora of configs that can be
    overridden during runtime without needing to redeploy Kafka. More than 80 overrides
    can be altered with *kafka-configs.sh* for brokers. As such, we will not list
    them all in this book, but they can be referenced by the `--help` command or found
    in the [open source documentation](https://oreil.ly/R8hhb). A few important configs
    worth pointing out specifically are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`min.insync.replicas`'
  prefs: []
  type: TYPE_NORMAL
- en: Adjusts the minimum number of replicas that need to acknowledge a write for
    a produce request to be successful when producers have set acks to `all` (or `–1`).
  prefs: []
  type: TYPE_NORMAL
- en: '`unclean.leader.election.enable`'
  prefs: []
  type: TYPE_NORMAL
- en: Allows replicas to be elected as leader even if it results in data loss. This
    is useful when it is permissible to have some lossy data, or to turn on for short
    times to unstick a Kafka cluster if unrecoverable data loss cannot be avoided.
  prefs: []
  type: TYPE_NORMAL
- en: '`max.connections`'
  prefs: []
  type: TYPE_NORMAL
- en: The maximum number of connections allowed to a broker at any time. We can also
    use `max.connections.per.ip` and `max.connections.per.ip.overrides` for more fine-tuned
    throttling.
  prefs: []
  type: TYPE_NORMAL
- en: Describing Configuration Overrides
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All configuration overrides can be listed using the `kafka-config.sh` tool.
    This will allow you to examine the specific configuration for a topic, broker,
    or client. Similar to other tools, this is done using the `--describe` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we can get all the configuration overrides for the
    topic named “my-topic,” which we observe is only the retention time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Topic Overrides Only
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The configuration description will only show overrides—it does not include the
    cluster default configurations. There is not a way to dynamically discover the
    configuration of the brokers themselves. This means that when using this tool
    to discover topic or client settings in automation, the user must have separate
    knowledge of the cluster default configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Removing Configuration Overrides
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Dynamic configurations can be removed entirely, which will cause the entity
    to revert back to the cluster defaults. To delete a configuration override, use
    the `--alter` command along with the `--delete-config` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, delete a configuration override for `retention.ms` for a topic
    named “my-topic”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Producing and Consuming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While working with Kafka, you will often find it is necessary to manually produce
    or consume some sample messages in order to validate what’s going on with your
    applications. Two utilities are provided to help with this, `kafka-console-consumer.sh`
    and `kafka-console-producer.sh`, which were touched upon briefly in [Chapter 2](ch02.html#installing_kafka)
    to verify our installation. These tools are wrappers around the main Java client
    libraries that allow you to interact with Kafka topics without having to write
    an entire application to do it.
  prefs: []
  type: TYPE_NORMAL
- en: Piping Output to Another Application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While it is possible to write applications that wrap around the console consumer
    or producer (e.g., to consume messages and pipe them to another application for
    processing), this type of application is quite fragile and should be avoided.
    It is difficult to interact with the console consumer in a way that does not lose
    messages. Likewise, the console producer does not allow for using all features,
    and properly sending bytes is tricky. It is best to use either the Java client
    libraries directly or a third-party client library for other languages that use
    the Kafka protocol directly.
  prefs: []
  type: TYPE_NORMAL
- en: Console Producer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `kakfa-console-producer.sh` tool can be used to write messages into a Kafka
    topic in your cluster. By default, messages are read one per line, with a tab
    character separating the key and the value (if no tab character is present, the
    key is null). As with the console consumer, the producer reads in and produces
    raw bytes using the default serializer (which is `DefaultEncoder`).
  prefs: []
  type: TYPE_NORMAL
- en: The console producer requires that a minimum of two arguments are provided to
    know what Kafka cluster to connect to and which topic to produce to within that
    cluster. The first is the customary `--bootstrap-server` connection string we
    are used to using. When you are done producing, send an end-of-file (EOF) character
    to close the client. In most common terminals, this is done with Control-D.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we can see an example of producing four messages to a topic named “my-topic”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Using producer configuration options
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is possible to pass normal producer configuration options to the console
    producer as well. This can be done in two ways, depending on how many options
    you need to pass and how you prefer to do it. The first is to provide a producer
    configuration file by specifying `--producer.config` `*<config-file>*`, where
    `*<config-file>*` is the full path to a file that contains the configuration options.
    The other way is to specify the options on the command line with one or more arguments
    of the form `--producer-property` `*<key>*`=`*<value>*`, where `*<key>*` is the
    configuration option name and `*<value>*` is the value to set it to. This can
    be useful for producer options like message-batching configurations (such as `linger.ms`
    or `batch.size`).
  prefs: []
  type: TYPE_NORMAL
- en: Confusing Command-Line Options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `--property` command-line option is available for both the console producer
    and the console consumer, but this should not be confused with the `--producer-property`
    or `--consumer-property` options, respectively. The `--property` option is only
    used for passing configurations to the message formatter, and not the client itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'The console producer has many command-line arguments available to use with
    the `--producer-property` option for adjusting its behavior. Some of the more
    useful options are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--batch-size`'
  prefs: []
  type: TYPE_NORMAL
- en: Specifies the number of messages sent in a single batch if they are not being
    sent synchronously.
  prefs: []
  type: TYPE_NORMAL
- en: '`--timeout`'
  prefs: []
  type: TYPE_NORMAL
- en: If a producer is running in asynchronous mode, this provides the max amount
    of time waiting for the batch size before producing to avoid long waits on low-producing
    topics.
  prefs: []
  type: TYPE_NORMAL
- en: '`--compression-codec <string>`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Specify the type of compression to be used when producing messages. Valid types
    can be one of the following: `none`, `gzip`, `snappy`, `zstd`, or `lz4`. The default
    value is `gzip`.'
  prefs: []
  type: TYPE_NORMAL
- en: '`--sync`'
  prefs: []
  type: TYPE_NORMAL
- en: Produce messages synchronously, waiting for each message to be acknowledged
    before sending the next one.
  prefs: []
  type: TYPE_NORMAL
- en: Line-reader options
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `kafka.tools.ConsoleProducer$LineMessageReader` class, which is responsible
    for reading standard input and creating producer records, also has several useful
    options that can be passed to the console producer using the `--property` command-line
    option:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ignore.error`'
  prefs: []
  type: TYPE_NORMAL
- en: Set to `false` to throw an exception when `parse.key` is set to `true` and a
    key separator is not present. Defaults to `true`.
  prefs: []
  type: TYPE_NORMAL
- en: '`parse.key`'
  prefs: []
  type: TYPE_NORMAL
- en: Set to `false` to always set the key to null. Defaults to `true`.
  prefs: []
  type: TYPE_NORMAL
- en: '`key.separator`'
  prefs: []
  type: TYPE_NORMAL
- en: Specify the delimiter character to use between the message key and message value
    when reading. Defaults to a tab character.
  prefs: []
  type: TYPE_NORMAL
- en: Changing Line-Reading Behavior
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can provide your own class to Kafka for customized methods of reading lines.
    The class that you create must extend `kafka.​com⁠mon.MessageReader` and will
    be responsible for creating the `ProducerRecord`. Specify your class on the command
    line with the `--line-reader` option, and make sure the JAR containing your class
    is in the classpath. The default is `kafka.tools.Console​Pro⁠ducer$LineMessageReader`.
  prefs: []
  type: TYPE_NORMAL
- en: When producing messages, the `LineMessageReader` will split the input on the
    first instance of the `key.separator`. If there are no characters remaining after
    that, the value of the message will be empty. If no key separator character is
    present on the line, or if `parse.key` is false, the key will be null.
  prefs: []
  type: TYPE_NORMAL
- en: Console Consumer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `kafka-console-consumer.sh` tool provides a means to consume messages out
    of one or more topics in your Kafka cluster. The messages are printed in standard
    output, delimited by a new line. By default, it outputs the raw bytes in the message,
    without the key, with no formatting (using the `DefaultFormatter`). Similar to
    the producer, there are a few basic options needed to get started: a connection
    string to the cluster, which topic you want to consume from, and the timeframe
    you want to consume.'
  prefs: []
  type: TYPE_NORMAL
- en: Checking Tool Versions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is very important to use a consumer that is the same version as your Kafka
    cluster. Older console consumers can potentially damage the cluster by interacting
    with the cluster or ZooKeeper in incorrect ways.
  prefs: []
  type: TYPE_NORMAL
- en: 'As in other commands, the connection string to the cluster will be the `--bootstrap-server`
    option; however, you can choose from two options for selecting the topics to consume:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--topic`'
  prefs: []
  type: TYPE_NORMAL
- en: Specifies a single topic to consume from.
  prefs: []
  type: TYPE_NORMAL
- en: '`--whitelist`'
  prefs: []
  type: TYPE_NORMAL
- en: A regular expression matching all topics to consume from (remember to properly
    escape the regex so that it is not processed improperly by the shell).
  prefs: []
  type: TYPE_NORMAL
- en: 'Only one of the previous options should be selected and used. Once the console
    consumer has started, the tool will continue to try and consume until the shell
    escape command is given (in this case, Ctrl-C). Here is an example of consuming
    all topics from our cluster that match the prefix *my* (of which there is only
    one in this example, “my-topic”):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Using consumer configuration options
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In addition to these basic command-line options, it is possible to pass normal
    consumer configuration options to the console consumer as well. Similar to the
    `kafka-console-producer.sh` tool, this can be done in two ways, depending on how
    many options you need to pass and how you prefer to do it. The first is to provide
    a consumer configuration file by specifying `--consumer.config` `*<config-file>*`,
    where `*<config-file>*` is the full path to a file that contains the configuration
    options. The other way is to specify the options on the command line with one
    or more arguments of the form `--consumer-property` `*<key>*`=`*<value>*`, where
    `*<key>*` is the configuration option name and `*<value>*` is the value to set
    it to.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few other commonly used options for the console consumer that are
    helpful to know and be familiar with:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--formatter` `*<classname>*`'
  prefs: []
  type: TYPE_NORMAL
- en: Specifies a message formatter class to be used to decode the messages. This
    defaults to `kafka.tools.DefaultMessageFormatter`.
  prefs: []
  type: TYPE_NORMAL
- en: '`--from-beginning`'
  prefs: []
  type: TYPE_NORMAL
- en: Consume messages in the topic(s) specified from the oldest offset. Otherwise,
    consumption starts from the latest offset.
  prefs: []
  type: TYPE_NORMAL
- en: '`--max-messages <int>`'
  prefs: []
  type: TYPE_NORMAL
- en: The maximum number of messages to consume before exiting.
  prefs: []
  type: TYPE_NORMAL
- en: '`--partition <int>`'
  prefs: []
  type: TYPE_NORMAL
- en: Consume only from the partition with the ID given.
  prefs: []
  type: TYPE_NORMAL
- en: '`--offset`'
  prefs: []
  type: TYPE_NORMAL
- en: The offset ID to consume from, if provided (`<int>`). Other valid options are
    `earliest`, which will consume from the beginning, and `latest`, which will start
    consuming from the most recent offset.
  prefs: []
  type: TYPE_NORMAL
- en: '`--skip-message-on-error`'
  prefs: []
  type: TYPE_NORMAL
- en: Skip a message if there is an error when processing instead of halting. Useful
    for debugging.
  prefs: []
  type: TYPE_NORMAL
- en: Message formatter options
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are three message formatters available to use besides the default:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kafka.tools.LoggingMessageFormatter`'
  prefs: []
  type: TYPE_NORMAL
- en: Outputs messages using the logger, rather than standard out. Messages are printed
    at the INFO level and include the timestamp, key, and value.
  prefs: []
  type: TYPE_NORMAL
- en: '`kafka.tools.ChecksumMessageFormatter`'
  prefs: []
  type: TYPE_NORMAL
- en: Prints only message checksums.
  prefs: []
  type: TYPE_NORMAL
- en: '`kafka.tools.NoOpMessageFormatter`'
  prefs: []
  type: TYPE_NORMAL
- en: Consumes messages but does not output them at all.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of consuming the same messages from before but
    with the `kafka.tools.ChecksumMessageFormatter` being used rather than the default:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The `kafka.tools.DefaultMessageFormatter` also has several useful options that
    can be passed using the `--property` command-line option, shown in [Table 12-4](#table0904).
  prefs: []
  type: TYPE_NORMAL
- en: Table 12-4\. Message formatter properties
  prefs: []
  type: TYPE_NORMAL
- en: '| Property | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `print.timestamp` | Set to `true` to display the timestamp of each message
    (if available). |'
  prefs: []
  type: TYPE_TB
- en: '| `print.key` | Set to `true` to display the message key in addition to the
    value. |'
  prefs: []
  type: TYPE_TB
- en: '| `print.offset` | Set to `true` to display the message offset in addition
    to the value. |'
  prefs: []
  type: TYPE_TB
- en: '| `print.partition` | Set to `true` to display the topic partition a message
    is consumed from. |'
  prefs: []
  type: TYPE_TB
- en: '| `key.separator` | Specify the delimiter character to use between the message
    key and message value when printing. |'
  prefs: []
  type: TYPE_TB
- en: '| `line.separator` | Specify the delimiter character to use between messages.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `key.deserializer` | Provide a class name that is used to deserialize the
    message key before printing. |'
  prefs: []
  type: TYPE_TB
- en: '| `value.deserializer` | Provide a class name that is used to deserialize the
    message value before printing. |'
  prefs: []
  type: TYPE_TB
- en: The deserializer classes must implement `org.apache.kafka.common.​ser⁠ial⁠iza⁠tion.Deserializer`,
    and the console consumer will call the `toString` method on them to get the output
    to display. Typically, you would implement these deserializers as a Java class
    that you would insert into the classpath for the console consumer by setting the
    `CLASSPATH` environment variable before executing `kafka_​con⁠sole_consumer.sh`.
  prefs: []
  type: TYPE_NORMAL
- en: Consuming the offsets topics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is sometimes useful to see what offsets are being committed for the cluster’s
    consumer groups. You may want to see if a particular group is committing offsets
    at all, or how often offsets are being committed. This can be done by using the
    console consumer to consume the special internal topic called `__consumer_offsets`.
    All consumer offsets are written as messages to this topic. In order to decode
    the messages in this topic, you must use the formatter class `kafka.coordinator.group.Group​Met⁠ada⁠taManager$OffsetsMessageFormatter`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Putting all we have learned together, the following is an example of consuming
    the earliest message from the `__consumer_offsets` topic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Partition Management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A default Kafka installation also contains a few scripts for working with the
    management of partitions. One of these tools allows for the reelection of leader
    replicas; another is a low-level utility for assigning partitions to brokers.
    Together these tools can assist in situations where a more manual hands-on approach
    to balance message traffic within a cluster of Kafka brokers is needed.
  prefs: []
  type: TYPE_NORMAL
- en: Preferred Replica Election
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As described in [Chapter 7](ch07.html#reliable_data_delivery), partitions can
    have multiple replicas for reliability. It is important to understand that only
    one of these replicas can be the leader for the partition at any given point in
    time, and all produce and consume operations happen on that broker. Maintaining
    a balance of which partition’s replicas have leadership on which broker is necessary
    to ensure the load is spread out through a full Kafka cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Leadership is defined within Kafka as the first in-sync replica in the replica
    list. However, when a broker is stopped or loses connectivity to the rest of the
    cluster, leadership is transferred to another in-sync replica, and the original
    does not resume leadership of any partitions automatically. This can cause wildly
    inefficient balance after a deployment across a full cluster if automatic leader
    balancing is not enabled. As such it is recommended to ensure that this setting
    is enabled or to use other open source tooling such as Cruise Control to ensure
    that a good balance is maintained at all times.
  prefs: []
  type: TYPE_NORMAL
- en: If you find that your Kafka cluster has a poor balance, a lightweight, generally
    non-impacting procedure can be performed called *preferred leader election*. This
    tells the cluster controller to select the ideal leader for partitions. Clients
    can track leadership changes automatically, so they will be able to move to the
    new broker in the cluster in which leadership is transferred. This operation can
    be manually triggered using the `kafka-leader-election.sh` utility. An older version
    of this tool called `kafka-preferred-replica-election.sh` is also available but
    has been deprecated in favor of the new tool, which allows for more customization,
    such as specifying whether we want a “preferred” or “unclean” election type.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, starting a preferred leader election for all topics in a cluster
    can be executed with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'It is also possible to start elections on specific partitions or topics. This
    can be done by passing in a topic name with the `--topic` option and a partition
    with the `--partition` option directly. It is also possible to pass in a list
    of several partitions to be elected. This is done by configuring a JSON file that
    we will call *partitions.json*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we will start a preferred replica election with a specified
    list of partitions in a file named *partitions.json*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Changing a Partition’s Replicas
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Occasionally it may be necessary to change the replica assignments manually
    for a partition. Some examples of when this might be needed are:'
  prefs: []
  type: TYPE_NORMAL
- en: There is an uneven load on brokers that the automatic leader distribution is
    not correctly handling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a broker is taken offline and the partition is under replicated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a new broker is added and we want to more quickly balance new partitions
    on it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You want to adjust the replication factor of a topic.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `kafka-reassign-partitions.sh` can be used to perform this operation. This
    is a multistep process to generate a move set and then execute on the provided
    move set proposal. First, we want to use a broker list and a topic list to generate
    a proposal for the set of moves. This will require the generation of a JSON file
    with a list of topics to be supplied. The next step executes the moves that were
    generated by the previous proposal. Finally, the tool can be used with the generated
    list to track and verify the progress or completion of the partition reassignments.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s generate a hypothetical scenario in which you have a four-broker Kafka
    cluster. You’ve recently added two new brokers, bringing the total up to six,
    and you want to move two of your topics onto brokers 5 and 6.
  prefs: []
  type: TYPE_NORMAL
- en: 'To generate a set of partition moves, you must first create a file that contains
    a JSON object listing the topics. The JSON object is formatted as follows (the
    version number is currently always 1):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we’ve defined our JSON file, we can use it to generate a set of partition
    moves to move the topics listed in the file *topics.json* to the brokers with
    IDs 5 and 6:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The output proposed here is formatted correctly, to which we can save two new
    JSON files that we will call *revert-reassignment.json* and *expand-cluster-reassignment.json*.
    The first file can be used to move partitions back to where they were originally
    if you need to roll back for some reason. The second file can be used for the
    next step, as this is just a proposal and hasn’t executed anything yet. You’ll
    notice in the output that there isn’t a good balance of leadership, as the proposal
    will result in all leadership moving to broker 5\. We will ignore this for now
    and presume the cluster automatic leadership balancing is enabled, which will
    help distribute it later. It should be noted that the first step can be skipped
    if you know exactly where you want to move your partitions to and you manually
    craft the JSON to move partitions.
  prefs: []
  type: TYPE_NORMAL
- en: 'To execute the proposed partition reassignment from the file *expand-cluster-reassignment.json*,
    run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This will start the reassignment of the specified partition replicas to the
    new brokers. The output is the same as the generated proposal verification. The
    cluster controller performs this reassignment action by adding the new replicas
    to the replica list for each partition, which will temporarily increase the replication
    factor of these topics. The new replicas will then copy all existing messages
    for each partition from the current leader. Depending on the size of the partitions
    on disk, this can take a significant amount of time as the data is copied across
    the network to the new replicas. Once replication is complete, the controller
    removes the old replicas from the replica list by reducing the replication factor
    to the original size with the old replicas removed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few other useful features of the command you could take advantage
    of:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--additional`'
  prefs: []
  type: TYPE_NORMAL
- en: This option will allow you to add to the existing reassignments so they can
    continue to be performed without interruption and without the need to wait until
    the original movements have completed in order to start a new batch.
  prefs: []
  type: TYPE_NORMAL
- en: '`--disable-rack-aware`'
  prefs: []
  type: TYPE_NORMAL
- en: There may be times when, due to rack awareness settings, the end-state of a
    proposal may not be possible. This can be overridden with this command if necessary.
  prefs: []
  type: TYPE_NORMAL
- en: '`--throttle`'
  prefs: []
  type: TYPE_NORMAL
- en: This value is in units of bytes/sec. Partition reassignments have a big impact
    on the performance of your cluster, as they will cause changes in the consistency
    of the memory page cache and use network and disk I/O. Throttling the movement
    of partitions can be useful to prevent this issue. This can be combined with the
    `--additional` tag to throttle an already-started reassignment process that may
    be causing issues.
  prefs: []
  type: TYPE_NORMAL
- en: Improving Network Utilization When Reassigning Replicas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When removing many partitions from a single broker, such as if that broker is
    being removed from the cluster, it may be useful to remove all leadership from
    the broker first. This can be done by manually moving leaderships off the broker;
    however, using the preceding tooling to do this is arduous. Other open source
    tools such as Cruise Control include features like broker “demotion,” which safely
    moves leadership off a broker and is probably the simplest way to do this.
  prefs: []
  type: TYPE_NORMAL
- en: However, if you do not have access to such tools, a simple restart of a broker
    will suffice. As a broker is preparing to shut down, all leadership for the partitions
    on that particular broker will move to other brokers in the clusters. This can
    significantly increase the performance of reassignments and reduce the impact
    on the cluster, as the replication traffic will be distributed to many brokers.
    However, if automatic leader reassignment is enabled after the broker is bounced,
    leadership may return to this broker, so it may be beneficial to temporarily disable
    this feature.
  prefs: []
  type: TYPE_NORMAL
- en: To check on the progress of the partition moves, the tool can be used to verify
    the status of the reassignment. This will show which reassignments are currently
    in progress, which reassignments have completed, and (if there was an error) which
    reassignments have failed. To do this, you must have the file with the JSON object
    that was used in the execute step.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of potential results using the `--verify` option when running
    the preceding partition reassignment from the file *expand-cluster-reassignment.json*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Changing the replication factor
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `kafka-reassign-partitions.sh` tool can also be used to increase or decrease
    the replication factor (RF) for a partition. This may be necessary in situations
    where a partition was created with the wrong RF, you want increased redundancy
    as you expand your cluster, or you want to decrease redundancy for cost savings.
    One clear example is that if a cluster RF default setting is adjusted, existing
    topics will not automatically be increased. The tool can be used to increase RF
    on the existing partitions.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, if we wanted to increase topic “foo1” from the previous example
    from an RF = 2 to RF = 3, then we could craft a JSON similar to the execution
    proposal we used before, except we’d add in an additional broker ID to the replica
    set. For example, we could construct a JSON called *increase-foo1-RF.json* in
    which we add broker 4 to the existing set of 5,6 that we already have:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We’d then use the commands shown earlier to execute on this proposal. When
    it completes, we can verify the RF has been increased by either using the `--verify`
    flag or using the `kafka-topics.sh` script to describe the topic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Canceling replica reassignments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Canceling a replica reassignment in the past was a dangerous process that required
    unsafe manual manipulation of ZooKeeper nodes (or znodes) by deleting the `/admin/reassign_partitions`
    znode. Fortunately, this is no longer the case. The `kafka-reassign-partitions.sh`
    script (as well as the AdminClient it is a wrapper for) now supports the `--cancel`
    option, which will cancel the active reassignments that are ongoing in a cluster.
    When stopping an in-progress partition move, the `--cancel` command is designed
    to restore the replica set to the one it was prior to reassignment being initiated.
    As such, if replicas are being removed from a dead broker or an overloaded broker,
    it may leave the cluster in an undesirable state. There is also no guarantee that
    the reverted replica set will be in the same order as it was previously.
  prefs: []
  type: TYPE_NORMAL
- en: Dumping Log Segments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: On occasion you may have the need to read the specific content of a message,
    perhaps because you ended up with a “poison pill” message in your topic that is
    corrupted and your consumer cannot handle it. The `kafka-dump-log.sh` tool is
    provided to decode the log segments for a partition. This will allow you to view
    individual messages without needing to consume and decode them. The tool takes
    a comma-separated list of log segment files as an argument and can print out either
    message summary information or detailed message data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we will dump the logs from a sample topic, “my-topic,” which
    is a new topic with only four messages in it. First, we will simply decode the
    log segment file named *00000000000000000000.log* and retrieve basic metadata
    info about each message without actually printing the message contents. In our
    example Kafka installation, the Kafka data directory is set up in */tmp/kafka-logs*.
    As such, our directory for finding the log segments will be */tmp/kafka-logs/<topic-name>-<partition>*,
    in this case, */tmp/kafka-logs/my-topic-0/*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'In the next example, we add the `--print-data-log` option, which will provide
    us the actual payload information and more:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The tool also contains a few other useful options, such as validating the index
    file that goes along with a log segment. The index is used for finding messages
    within a log segment, and if corrupted, will cause errors in consumption. Validation
    is performed whenever a broker starts up in an unclean state (i.e., it was not
    stopped normally), but it can be performed manually as well. There are two options
    for checking indices, depending on how much checking you want to do. The option
    `--index-sanity-check` will just check that the index is in a usable state, while
    `--verify-index-only` will check for mismatches in the index without printing
    out all the index entries. Another useful option, `--value-decoder-class`, allows
    serialized messages to be deserialized by passing in a decoder.
  prefs: []
  type: TYPE_NORMAL
- en: Replica Verification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Partition replication works similar to a regular Kafka consumer client: the
    follower broker starts replicating at the oldest offset and checkpoints the current
    offset to disk periodically. When replication stops and restarts, it picks up
    from the last checkpoint. It is possible for previously replicated log segments
    to get deleted from a broker, and the follower will not fill in the gaps in this
    case.'
  prefs: []
  type: TYPE_NORMAL
- en: To validate that the replicas for a topic’s partitions are the same across the
    cluster, you can use the `kafka-replica-verification.sh` tool for verification.
    This tool will fetch messages from all the replicas for a given set of topic partitions,
    check that all messages exist on all replicas, and print out the max lag for given
    partitions. This process will operate continuously in a loop until canceled. To
    do this, you must provide an explicit comma-separated list of brokers to connect
    to. By default, all topics are validated; however, you may also provide the tool
    a regular expression that matches the topics you wish to validate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Caution: Cluster Impact Ahead'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The replica verification tool will have an impact on your cluster similar to
    reassigning partitions, as it must read all messages from the oldest offset in
    order to verify the replica. In addition, it reads from all replicas for a partition
    in parallel, so it should be used with caution.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, verify the replicas for the topics starting with *my* on kafka
    brokers 1 and 2, which contain partition 0 of “my-topic”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Other Tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Several more tools are included in the Kafka distribution that are not covered
    in depth in this book that can be useful in administering your Kafka cluster for
    specific use cases. Further information about them can be found on the [Apache
    Kafka website](https://kafka.apache.org):'
  prefs: []
  type: TYPE_NORMAL
- en: Client ACLs
  prefs: []
  type: TYPE_NORMAL
- en: A command-line tool, `kafka-acls.sh`, is provided for interacting with access
    controls for Kafka clients. This includes full features for authorizer properties,
    set up for deny or allow principles, cluster- or topic-level restrictions, ZooKeeper
    TLS file configuration, and much more.
  prefs: []
  type: TYPE_NORMAL
- en: Lightweight MirrorMaker
  prefs: []
  type: TYPE_NORMAL
- en: A lightweight `kafka-mirror-maker.sh` script is available for mirroring data.
    A more in-depth look at replication can be found in [Chapter 10](ch10.html#cross_cluster_mirroring).
  prefs: []
  type: TYPE_NORMAL
- en: Testing tools
  prefs: []
  type: TYPE_NORMAL
- en: There are several other scripts used for testing Kafka or helping to perform
    upgrades of features. `kafka-broker-api-versions.sh` helps to easily identify
    different versions of usable API elements when upgrading from one Kafka version
    to another and check for compatibility issues. There are producer and consumer
    performance tests scripts. There are several scripts to help administer ZooKeeper
    as well. There is also `trogdor.sh`, which is a test framework designed to run
    benchmarks and other workloads to attempt to stress test the system.
  prefs: []
  type: TYPE_NORMAL
- en: Unsafe Operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are some administrative tasks that are technically possible to do but
    should not be attempted except in the most extreme situations. Often this is when
    you are diagnosing a problem and have run out of options, or you have found a
    specific bug that you need to work around temporarily. These tasks are usually
    undocumented, unsupported, and pose some amount of risk to your application.
  prefs: []
  type: TYPE_NORMAL
- en: Several of the more common of these tasks are documented here so that in an
    emergency situation, there is a potential option for recovery. Their use is not
    recommended under normal cluster operations and should be considered carefully
    before being executed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Danger: Here Be Dragons'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The operations in this section often involve working with the cluster metadata
    stored in ZooKeeper directly. This can be a very dangerous operation, so you must
    be very careful to not modify the information in ZooKeeper directly, except as
    noted.
  prefs: []
  type: TYPE_NORMAL
- en: Moving the Cluster Controller
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every Kafka cluster has a single broker that is designated as a controller.
    The controller has a special thread that is responsible for overseeing cluster
    operations in addition to normal broker work. Normally, controller election is
    done automatically through ephemeral ZooKeeper znode monitoring. When a controller
    turns off or becomes unavailable, other brokers nominate themselves as soon as
    possible, since once the controller shuts down, the znode is removed.
  prefs: []
  type: TYPE_NORMAL
- en: On occasion, when troubleshooting a misbehaving cluster or broker, it may be
    useful to forcibly move the controller to a different broker without shutting
    down the host. One such example is when the controller has suffered an exception
    or other problem that has left it running but not functional. Moving the controller
    in these situations does not normally have a high risk, but as it is not a normal
    task, it should not be performed regularly.
  prefs: []
  type: TYPE_NORMAL
- en: To forcibly move a controller, deleting the ZooKeeper znode at */admin/controller*
    manually will cause the current controller to resign, and the cluster will randomly
    select a new controller. There is currently no way to specify a specific broker
    to be controller in Apache Kafka.
  prefs: []
  type: TYPE_NORMAL
- en: Removing Topics to Be Deleted
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When attempting to delete a topic in Kafka, a ZooKeeper node requests that
    the deletion is created. Once every replica completes deletion of the topic and
    acknowledges deletion is complete, the znode will be removed. Under normal circumstances,
    this is executed by the cluster very quickly. However, sometimes things can go
    wrong with this process. Here are some scenarios in which a deletion request may
    become stuck:'
  prefs: []
  type: TYPE_NORMAL
- en: A requester has no way of knowing whether topic deletion is enabled in the cluster
    and can request deletion of a topic from a cluster in which deletion is disabled.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A very large topic is requested to be deleted, but before the request is handled,
    one or more of the replica sets goes offline due to hardware failures, and the
    deletion cannot complete as the controller cannot ack that the deletion was completed
    successfully.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To “unstick” topic deletion, first delete the */admin/delete_topic/<topic>*
    znode. Deleting the topic ZooKeeper nodes (but not the parent */admin/delete_topic*
    node) will remove the pending requests. If the deletion is re-queued by cached
    requests in the controller, it may be necessary to also forcibly move the controller
    as shown earlier immediately after removing the topic znode to ensure that no
    cached requests are pending in the controller.
  prefs: []
  type: TYPE_NORMAL
- en: Deleting Topics Manually
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you are running a cluster with delete topics disabled, or if you find yourself
    needing to delete some topics outside of the normal flow of operations, it is
    possible to manually delete them from the cluster. This requires a full shutdown
    of all brokers in the cluster, however, and cannot be done while any of the brokers
    in the cluster are running.
  prefs: []
  type: TYPE_NORMAL
- en: Shut Down Brokers First
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Modifying the cluster metadata in ZooKeeper when the cluster is online is a
    very dangerous operation and can put the cluster into an unstable state. Never
    attempt to delete or modify topic metadata in ZooKeeper while the cluster is online.
  prefs: []
  type: TYPE_NORMAL
- en: 'To delete a topic from the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: Shut down all brokers in the cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Remove the ZooKeeper path */brokers/topics/<topic>* from the Kafka cluster path.
    Note that this node has child nodes that must be deleted first.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Remove the partition directories from the log directories on each broker. These
    will be named `<topic>-<int>`, where `<int>` is the partition ID.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Restart all brokers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Running a Kafka cluster can be a daunting endeavor, with numerous configurations
    and maintenance tasks to keep the systems running at peak performance. In this
    chapter, we discussed many of the routine tasks, such as managing topic and client
    configurations, that you will need to handle frequently. We also covered some
    of the more esoteric tasks that you’ll need for debugging problems, like examining
    log segments. Finally, we covered a few of the operations that, while not safe
    or routine, can be used to get you out of a sticky situation. All together, these
    tools will help you to manage your Kafka cluster. As you begin to scale your Kafka
    clusters larger, even the use of these tools may become arduous and difficult
    to manage. It is highly recommended to engage with the open source Kafka community
    and take advantage of the many other open source projects in the ecosystem to
    help automate many of the tasks outlined in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we are confident in the tools needed to administer and manage our cluster,
    it is still impossible without proper monitoring in place. [Chapter 13](ch13.html#monitoring_kafka)
    will discuss ways to monitor broker and cluster health and operations so you can
    be sure Kafka is working well (and know when it isn’t). We will also offer best
    practices for monitoring your clients, including both producers and consumers.
  prefs: []
  type: TYPE_NORMAL

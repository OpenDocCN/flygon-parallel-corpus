- en: Appendix B. Additional Kafka Tools
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录B. 其他Kafka工具
- en: The Apache Kafka community has created a robust ecosystem of tools and platforms
    that make the task of running and using Kafka far easier. While this is by no
    means an exhaustive list, several of the more popular tools are presented here
    to help get you started.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Kafka社区已经创建了一个强大的工具和平台生态系统，使运行和使用Kafka的任务变得更加容易。虽然这并不是一个详尽的列表，但这里介绍了一些较受欢迎的工具，以帮助您入门。
- en: Caveat Emptor
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 买方注意
- en: While the authors are affiliated with some of the companies and projects that
    are included in this list, neither they nor O’Reilly specifically endorse one
    tool over others. Please be sure to do your own research on the suitability of
    these platforms and tools for the work that you need to do.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管作者与列入此列表的一些公司和项目有所关联，但他们和O'Reilly并没有明确支持某个工具。请务必自行研究这些平台和工具是否适合您需要做的工作。
- en: Comprehensive Platforms
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 全面的平台
- en: Several companies offer fully integrated platforms for working with Apache Kafka.
    This includes managed deployments of all components, such that you can focus on
    using Kafka and not on how to run it. This can present an ideal solution for use
    cases where resources are not available (or you do not want to dedicate them)
    for learning how to properly operate Kafka and the infrastructure required around
    it. Several also provide tools, such as schema management, REST interfaces, and
    in some cases client library support, so that you can be assured components interoperate
    correctly.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 一些公司提供了完全集成的平台，用于处理Apache Kafka。这包括所有组件的托管部署，这样您就可以专注于使用Kafka，而不是运行它的方式。这可以为资源不足（或者您不想将资源用于学习如何正确操作Kafka及其所需的基础设施）的用例提供理想的解决方案。一些还提供工具，如模式管理、REST接口，有时还提供客户端库支持，以确保组件正确地进行交互。
- en: '| **Title** | Confluent Cloud |'
  id: totrans-6
  prefs: []
  type: TYPE_TB
  zh: '| **标题** | Confluent Cloud |'
- en: '| **URL** | [*https://www.confluent.io/confluent-cloud*](https://www.confluent.io/confluent-cloud)
    |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| **URL** | [*https://www.confluent.io/confluent-cloud*](https://www.confluent.io/confluent-cloud)
    |'
- en: '| **Description** | It’s only fitting that the company created by some of the
    original developers to develop and support Kafka provides a managed solution.
    Confluent Cloud combines a number of must-have tools—including schema management,
    clients, a RESTful interface, and monitoring—into a single offering. It’s available
    on all three major cloud platforms (AWS, Microsoft Azure, and Google Cloud Platform)
    and is backed with support provided by a sizable portion of the core Apache Kafka
    contributors employed by Confluent. Many of the components that are included in
    the platform, such as the Schema Registry and the REST proxy, are available as
    standalone tools under the [Confluent Community License](https://oreil.ly/lAFga),
    which does restrict some use cases. |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| **描述** | 由一些最初的开发者创建并支持Kafka的公司提供了受管理的解决方案，这是非常合适的。Confluent Cloud将许多必备工具（包括模式管理、客户端、RESTful接口和监控）合并为一个单一的产品。它在所有三个主要的云平台（AWS、Microsoft
    Azure和Google Cloud Platform）上都可用，并得到了Confluent雇佣的核心Apache Kafka贡献者的支持。该平台包括的许多组件，如模式注册表和REST代理，都可以作为独立的工具使用，受[Confluent社区许可证](https://oreil.ly/lAFga)的支持，但限制了一些使用情况。|'
- en: '| **Title** | Aiven |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| **标题** | Aiven |'
- en: '| **URL** | [*https://aiven.io*](https://aiven.io) |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| **URL** | [*https://aiven.io*](https://aiven.io) |'
- en: '| **Description** | Aiven provides managed solutions for many data platforms,
    including Kafka. To support this, it has developed [Karapace](https://karapace.io),
    which is a schema registry and a REST proxy, both API-compatible with Confluent’s
    components but supported under the [Apache 2.0 license](https://oreil.ly/a96F0),
    which does not restrict use cases. In addition to the three major cloud providers,
    Aiven also supports [DigitalOcean](https://www.digitalocean.com) and [UpCloud](https://upcloud.com).
    |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| **描述** | Aiven为许多数据平台提供了受管理的解决方案，包括Kafka。为了支持这一点，它开发了[Karapace](https://karapace.io)，这是一个与Confluent的组件API兼容的模式注册表和REST代理，但在[Apache
    2.0许可证](https://oreil.ly/a96F0)下受支持，不限制使用情况。除了三个主要的云提供商，Aiven还支持[DigitalOcean](https://www.digitalocean.com)和[UpCloud](https://upcloud.com)。|'
- en: '| **Title** | CloudKarafka |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| **标题** | CloudKarafka |'
- en: '| **URL** | [*https://www.cloudkarafka.com*](https://www.cloudkarafka.com)
    |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| **URL** | [*https://www.cloudkarafka.com*](https://www.cloudkarafka.com)
    |'
- en: '| **Description** | CloudKarafka focuses on providing a managed Kafka solution
    with integrations for popular infrastructure services (such as DataDog or Splunk).
    It supports the use of Confluent’s Schema Registry and REST proxy with its platform,
    but only the 5.0 version prior to the license changes by Confluent. CloudKarafka
    provides its services on both AWS and Google Cloud Platform. |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| **描述** | CloudKarafka专注于提供一种受管理的Kafka解决方案，并集成了流行的基础设施服务（如DataDog或Splunk）。它支持使用Confluent的Schema
    Registry和REST代理与其平台，但仅支持Confluent在许可证更改之前的5.0版本。CloudKarafka在AWS和Google Cloud
    Platform上提供其服务。|'
- en: '| **Title** | Amazon Managed Streaming for Apache Kafka (Amazon MSK) |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| **标题** | 亚马逊托管的Apache Kafka流式处理（Amazon MSK） |'
- en: '| **URL** | [*https://aws.amazon.com/msk*](https://aws.amazon.com/msk) |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| **URL** | [*https://aws.amazon.com/msk*](https://aws.amazon.com/msk) |'
- en: '| **Description** | Amazon also provides its own managed Kafka platform, supported
    only on AWS. Schema support is provided through integration with [AWS Glue](https://oreil.ly/hvjoV),
    while a REST proxy is not directly supported. Amazon promotes the use of community
    tools (such as Cruise Control, Burrow, and Confluent’s REST proxy) but does not
    directly support them. As such, MSK is somewhat less integrated than other offers,
    but can still provide a core Kafka cluster. |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| **描述** | 亚马逊还提供了自己的托管Kafka平台，仅在AWS上受支持。通过与[AWS Glue](https://oreil.ly/hvjoV)集成提供模式支持，而REST代理不受直接支持。亚马逊推广使用社区工具（如Cruise
    Control、Burrow和Confluent的REST代理），但不直接支持它们。因此，MSK的集成性比其他提供的要低一些，但仍然可以提供核心Kafka集群。|'
- en: '| **Title** | Azure HDInsight |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| **标题** | Azure HDInsight |'
- en: '| **URL** | [*https://azure.microsoft.com/en-us/services/hdinsight*](https://azure.microsoft.com/en-us/services/hdinsight)
    |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| **URL** | [*https://azure.microsoft.com/en-us/services/hdinsight*](https://azure.microsoft.com/en-us/services/hdinsight)
    |'
- en: '| **Description** | Microsoft also provides a managed platform for Kafka in
    HDInsight, which also supports Hadoop, Spark, and other big data components. Similar
    to MSK, HDInsight focuses on the core Kafka cluster, leaving many of the other
    components (including a schema registry and REST proxy) up to the user to provide.
    Some third parties have provided templates for performing these deployments, but
    they are not supported by Microsoft. |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '- **Description** - Microsoft还为HDInsight中的Kafka提供了托管平台，该平台还支持Hadoop、Spark和其他大数据组件。与MSK类似，HDInsight专注于核心Kafka集群，许多其他组件（包括模式注册表和REST代理）需要用户提供。一些第三方提供了执行这些部署的模板，但它们不受Microsoft支持。'
- en: '| **Title** | Cloudera |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '- **Title** - Cloudera'
- en: '| **URL** | [*https://www.cloudera.com/products/open-source/apache-hadoop/apache-kafka.html*](https://www.cloudera.com/products/open-source/apache-hadoop/apache-kafka.html)
    |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '- **URL** - [*https://www.cloudera.com/products/open-source/apache-hadoop/apache-kafka.html*](https://www.cloudera.com/products/open-source/apache-hadoop/apache-kafka.html)'
- en: '| **Description** | Cloudera has been a fixture in the Kafka community since
    the early days and provides managed Kafka as the stream data component of its
    overall Customer Data Platform (CDP) product. CDP focuses on more than just Kafka,
    however, and it operates in the public cloud environments as well as providing
    private options. |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '- **Description** - Cloudera自早期以来一直是Kafka社区的一部分，并将托管Kafka作为其整体客户数据平台（CDP）产品的流数据组件。CDP不仅专注于Kafka，而且在公共云环境中运行，并提供私有选项。'
- en: Cluster Deployment and Management
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集群部署和管理
- en: When running Kafka outside of a managed platform, you will need several things
    to assist you with running the cluster properly. This includes help with provisioning
    and deployment, balancing data, and visualizing your clusters.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在托管平台之外运行Kafka时，您需要一些辅助工具来正确运行集群。这包括帮助进行供应和部署、平衡数据以及可视化您的集群。
- en: '| **Title** | Strimzi |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '- **Title** - Strimzi'
- en: '| **URL** | [*https://strimzi.io*](https://strimzi.io) |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '- **URL** - [*https://strimzi.io*](https://strimzi.io)'
- en: '| **Description** | Strimzi provides Kubernetes operators for deploying Kafka
    clusters to make it easier to set up Kafka in a Kubernetes environment. It does
    not provide managed services but instead makes it easy for you to get up and running
    in a cloud, whether public or private. It also provides the Strimzi Kafka Bridge,
    which is a REST proxy implementation supported under the [Apache 2.0 license](https://oreil.ly/a96F0).
    At this time, Strimzi does not have support for a schema registry, due to concerns
    about licenses. |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '- **Description** - Strimzi提供了用于在Kubernetes环境中部署Kafka集群的Kubernetes操作员，使您更容易在云中（无论是公共云还是私有云）启动和运行Kafka。它还提供了Strimzi
    Kafka Bridge，这是一个在[Apache 2.0许可证](https://oreil.ly/a96F0)下受支持的REST代理实现。目前，Strimzi不支持模式注册表，因为存在许可证方面的顾虑。'
- en: '| **Title** | AKHQ |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '- **Title** - AKHQ'
- en: '| **URL** | [*https://akhq.io*](https://akhq.io) |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '- **URL** - [*https://akhq.io*](https://akhq.io)'
- en: '| **Description** | AKHQ is a GUI for managing and interacting with Kafka clusters.
    It supports configuration management, including users and ACLs, and provides some
    support for components like the Schema Registry and Kafka Connect as well. It
    also provides tools for working with data in the cluster as an alternative to
    the console tools. |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '- **Description** - AKHQ是用于管理和与Kafka集群交互的图形用户界面。它支持配置管理，包括用户和ACL，并为诸如模式注册表和Kafka
    Connect等组件提供一些支持。它还提供了用于与集群中数据交互的工具，作为控制台工具的替代方案。'
- en: '| **Title** | JulieOps |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '- **Title** - JulieOps'
- en: '| **URL** | [*https://github.com/kafka-ops/julie*](https://github.com/kafka-ops/julie)
    |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '- **URL** - [*https://github.com/kafka-ops/julie*](https://github.com/kafka-ops/julie)'
- en: '| **Description** | JulieOps (formerly Kafka Topology Builder) provides for
    automated management of topics and ACLs using a GitOps model. More than viewing
    the state of the current configuration, JulieOps provides a means for declarative
    configuration and change control of topics, schemas, ACLs, and more over time.
    |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '- **Description** - JulieOps（前身为Kafka拓扑生成器）采用GitOps模型提供自动化管理主题和ACL的功能。JulieOps不仅可以查看当前配置的状态，还可以提供声明性配置和随时间变化的主题、模式、ACL等的变更控制。'
- en: '| **Title** | Cruise Control |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '- **Title** - Cruise Control'
- en: '| **URL** | [*https://github.com/linkedin/cruise-control*](https://github.com/linkedin/cruise-control)
    |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '- **URL** - [*https://github.com/linkedin/cruise-control*](https://github.com/linkedin/cruise-control)'
- en: '| **Description** | Cruise Control is LinkedIn’s answer to how to manage hundreds
    of clusters with thousands of brokers. This tool began as a solution to automated
    rebalancing of data in clusters but has evolved to include anomaly detection and
    administrative operations, such as adding and removing brokers. For anything more
    than a testing cluster, it is a must-have for any Kafka operator. |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '- **Description** - Cruise Control是LinkedIn对如何管理数百个集群和数千个代理的答案。这个工具最初是为了自动重新平衡集群中的数据而诞生的，但已经发展到包括异常检测和管理操作，如添加和删除代理。对于任何不止是测试集群的情况，这对于任何Kafka操作员来说都是必不可少的。'
- en: '| **Title** | Conduktor |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '- **Title** - Conduktor'
- en: '| **URL** | [*https://www.conduktor.io*](https://www.conduktor.io) |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '- **URL** - [*https://www.conduktor.io*](https://www.conduktor.io)'
- en: '| **Description** | While not open source, Conduktor is a popular desktop tool
    for managing and interacting with Kafka clusters. It supports many of the managed
    platforms (including Confluent, Aiven, and MSK) and many different components
    (such as Connect, kSQL, and Streams). It also allows you to interact with data
    in the clusters, as opposed to using the console tools. A free license is provided
    for development use that works with a single cluster. |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '- **Description** - 虽然不是开源的，但Conduktor是一个流行的桌面工具，用于管理和与Kafka集群交互。它支持许多托管平台（包括Confluent、Aiven和MSK）和许多不同的组件（如Connect、kSQL和Streams）。它还允许您与集群中的数据交互，而不是使用控制台工具。提供用于开发使用的免费许可证，可与单个集群一起使用。'
- en: Monitoring and Data Exploration
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控和数据探索
- en: A critical part to running Kafka is to ensure that your cluster and your clients
    are healthy. Like many applications, Kafka exposes numerous metrics and other
    telemetry, but making sense of it can be challenging. Many of the larger monitoring
    platforms (such as [Prometheus](https://prometheus.io)) can easily fetch metrics
    from Kafka brokers and clients. There are also a number of tools available to
    assist with making sense of all the data.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 运行Kafka的关键部分是确保您的集群和客户端健康。与许多应用程序一样，Kafka公开了许多指标和其他遥测数据，但理解它可能是具有挑战性的。许多较大的监控平台（如[Prometheus](https://prometheus.io)）可以轻松地从Kafka代理和客户端获取指标。还有许多可用的工具可帮助理解所有数据。
- en: '| **Title** | Xinfra Monitor |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| **标题** | Xinfra监视器 |'
- en: '| **URL** | [*https://github.com/linkedin/kafka-monitor*](https://github.com/linkedin/kafka-monitor)
    |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| **URL** | [*https://github.com/linkedin/kafka-monitor*](https://github.com/linkedin/kafka-monitor)
    |'
- en: '| **Description** | Xinfra Monitor (formerly Kafka Monitor) was developed by
    LinkedIn to monitor availability of Kafka clusters and brokers. It does this by
    using a set of topics to generate synthetic data through the cluster and measuring
    latency, availability, and completeness. It’s a valuable tool for measuring your
    Kafka deployment’s health without requiring direct interaction with your clients.
    |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| **描述** | Xinfra监视器（前身为Kafka监视器）是LinkedIn开发的，用于监视Kafka集群和代理的可用性。它通过使用一组主题通过集群生成合成数据并测量延迟、可用性和完整性来实现这一点。它是一个有价值的工具，可以测量Kafka部署的健康状况，而无需直接与客户端进行交互。
    |'
- en: '| **Title** | Burrow |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| **标题** | Burrow |'
- en: '| **URL** | [*https://github.com/linkedin/burrow*](https://github.com/linkedin/burrow)
    |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| **URL** | [*https://github.com/linkedin/burrow*](https://github.com/linkedin/burrow)
    |'
- en: '| **Description** | Burrow is another tool originally created by LinkedIn,
    which provides holistic monitoring of consumer lag within Kafka clusters. It provides
    a view into the health of the consumers without needing to directly interact with
    them. Burrow is actively supported by the community and has its own [ecosystem
    of tools](https://oreil.ly/yNPRQ) to connect it with other components. |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| **描述** | Burrow是LinkedIn最初创建的另一个工具，它提供了对Kafka集群中消费者滞后的全面监控。它可以查看消费者的健康状况，而无需直接与它们进行交互。Burrow得到社区的积极支持，并拥有自己的[工具生态系统](https://oreil.ly/yNPRQ)来将其与其他组件连接起来。
    |'
- en: '| **Title** | Kafka Dashboard |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| **标题** | Kafka仪表板 |'
- en: '| **URL** | [*https://www.datadoghq.com/dashboards/kafka-dashboard*](https://www.datadoghq.com/dashboards/kafka-dashboard)
    |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| **URL** | [*https://www.datadoghq.com/dashboards/kafka-dashboard*](https://www.datadoghq.com/dashboards/kafka-dashboard)
    |'
- en: '| **Description** | For those who use DataDog for monitoring, it provides an
    excellent Kafka Dashboard to give you a head start on integrating Kafka clusters
    into your monitoring stack. It is designed to provide a single-pane view of your
    Kafka cluster, simplifying the view of many metrics. |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| **描述** | 对于那些使用DataDog进行监控的人，它提供了一个出色的Kafka仪表板，可以帮助您将Kafka集群整合到您的监控堆栈中。它旨在提供对Kafka集群的单一视图，简化了许多指标的视图。
    |'
- en: '| **Title** | Streams Explorer |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| **标题** | 流资源浏览器 |'
- en: '| **URL** | [*https://github.com/bakdata/streams-explorer*](https://github.com/bakdata/streams-explorer)
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| **URL** | [*https://github.com/bakdata/streams-explorer*](https://github.com/bakdata/streams-explorer)
    |'
- en: '| **Description** | Streams Explorer is a tool for visualizing the flow of
    data through applications and connectors in a Kubernetes deployment. While it
    heavily relies on structuring your deployments using either Kafka Streams or Faust
    through bakdata’s tools, it can then provide an easily comprehensible view of
    those applications and their metrics. |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| **描述** | Streams Explorer是一个用于可视化数据在Kubernetes部署中的应用程序和连接器流动的工具。虽然它在很大程度上依赖于使用bakdata的工具结构化部署，但它可以提供这些应用程序及其指标的易于理解的视图。
    |'
- en: '| **Title** | kcat |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| **标题** | kcat |'
- en: '| **URL** | [*https://github.com/edenhill/kafkacat*](https://github.com/edenhill/kafkacat)
    |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| **URL** | [*https://github.com/edenhill/kafkacat*](https://github.com/edenhill/kafkacat)
    |'
- en: '| **Description** | Kcat (formerly kafkacat) is a much-loved alternative to
    the console producer and consumer that are part of the core Apache Kafka project.
    It is small, fast, and written in C, so it does not have JVM overhead. It also
    supports limited views into cluster status by showing metadata output for the
    cluster. |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| **描述** | Kcat（前身为kafkacat）是Apache Kafka核心项目中的控制台生产者和消费者的备选方案。它体积小，速度快，用C语言编写，因此没有JVM开销。它还通过显示集群的元数据输出来支持对集群状态的有限视图。
    |'
- en: Client Libraries
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 客户端库
- en: The Apache Kafka project provides client libraries for Java applications, but
    one language is never enough. There are many implementations of the Kafka client
    out there, with popular languages such as Python, Go, and Ruby having several
    options. In addition, REST proxies (such as those from Confluent, Strimzi, or
    Karapace) can cover a variety of use cases. Here are a few client implementations
    that have stood the test of time.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Kafka项目为Java应用程序提供了客户端库，但一种语言永远不够。市面上有许多Kafka客户端的实现，流行的语言如Python、Go和Ruby都有几种选择。此外，REST代理（例如Confluent、Strimzi或Karapace）可以涵盖各种用例。以下是一些经得住时间考验的客户端实现。
- en: '| **Title** | librdkafka |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| **标题** | librdkafka |'
- en: '| **URL** | [*https://github.com/edenhill/librdkafka*](https://github.com/edenhill/librdkafka)
    |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| **URL** | [*https://github.com/edenhill/librdkafka*](https://github.com/edenhill/librdkafka)
    |'
- en: '| **Description** | librdkafka is a C library implementation of the Kafka client
    that is regarded as one of the best-performing libraries available. So good, in
    fact, that Confluent supports clients for Go, Python, and .NET that it created
    as wrappers around librdkafka. It is licensed simply under the [two-clause BSD
    license](https://oreil.ly/dLoe8), which makes it easy to use in any application.
    |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| **描述** | librdkafka是Kafka客户端的C库实现，被认为是性能最佳的库之一。事实上，Confluent支持Go、Python和.NET客户端，这些客户端是围绕librdkafka创建的包装器。它仅在[两条款的BSD许可证](https://oreil.ly/dLoe8)下获得许可，这使得它可以轻松用于任何应用程序。
    |'
- en: '| **Title** | Sarama |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| **标题** | Sarama |'
- en: '| **URL** | [*https://github.com/Shopify/sarama*](https://github.com/Shopify/sarama)
    |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| **URL** | [*https://github.com/Shopify/sarama*](https://github.com/Shopify/sarama)
    |'
- en: '| **Description** | Shopify created the Sarama client as a native Golang implementation.
    It’s released under the [MIT license](https://oreil.ly/sajdS). |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: Shopify创建了Sarama客户端作为原生的Golang实现。它是根据[MIT许可证](https://oreil.ly/sajdS)发布的。
- en: '| **Title** | kafka-python |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: kafka-python
- en: '| **URL** | [*https://github.com/dpkp/kafka-python*](https://github.com/dpkp/kafka-python)
    |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '[*https://github.com/dpkp/kafka-python*](https://github.com/dpkp/kafka-python)'
- en: '| **Description** | kafka-python is another native client implementation, this
    time in Python. It’s released under the [Apache 2.0 license](https://oreil.ly/a96F0).
    |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: kafka-python是另一个原生的客户端实现，这次是用Python实现的。它是根据[Apache 2.0许可证](https://oreil.ly/a96F0)发布的。
- en: Stream Processing
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流处理
- en: While the Apache Kafka project includes Kafka Streams for building applications,
    it’s not the only choice out there for stream processing of data from Kafka.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Apache Kafka项目包括Kafka Streams用于构建应用程序，但对于从Kafka处理数据的流处理来说，并不是唯一的选择。
- en: '| **Title** | Samza |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: Samza
- en: '| **URL** | [*https://samza.apache.org*](https://samza.apache.org) |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '[*https://samza.apache.org*](https://samza.apache.org)'
- en: '| **Description** | Apache Samza is a framework for stream processing that
    was specifically designed for Kafka. While it predates Kafka Streams, it was developed
    by many of the same people, and as a result the two share many concepts. However,
    unlike Kafka Streams, Samza runs on Yarn and provides a full framework for applications
    to run in. |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: Apache Samza是一个专为Kafka设计的流处理框架。虽然它早于Kafka Streams，但它是由许多相同的人开发的，因此两者共享许多概念。然而，与Kafka
    Streams不同，Samza在Yarn上运行，并为应用程序提供了一个完整的运行框架。
- en: '| **Title** | Spark |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: Spark
- en: '| **URL** | [*https://spark.apache.org*](https://spark.apache.org) |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '[*https://spark.apache.org*](https://spark.apache.org)'
- en: '| **Description** | Spark is another Apache project oriented toward batch processing
    of data. It handles streams by considering them to be fast microbatches. This
    means the latency is a little higher, but fault tolerance is simply handled through
    reprocessing batches, and Lambda architecture is easy. It also has the benefit
    of wide community support. |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: Spark是另一个面向数据批处理的Apache项目。它通过将流视为快速微批处理来处理流。这意味着延迟略高，但容错性通过重新处理批次来简单处理，并且Lambda架构很容易。它还有广泛的社区支持。
- en: '| **Title** | Flink |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: Flink
- en: '| **URL** | [*https://flink.apache.org*](https://flink.apache.org) |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '[*https://flink.apache.org*](https://flink.apache.org)'
- en: '| **Description** | Apache Flink is specifically oriented toward stream processing
    and operates with very low latency. Like Samza, it supports Yarn but also works
    with Mesos, Kubernetes, or standalone clusters. It also supports Python and R
    with provided high-level APIs. |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: Apache Flink专门面向流处理，并具有非常低的延迟。与Samza一样，它支持Yarn，但也可以与Mesos、Kubernetes或独立集群一起工作。它还支持Python和R，并提供了高级API。
- en: '| **Title** | Beam |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: Beam
- en: '| **URL** | [*https://beam.apache.org*](https://beam.apache.org) |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '[*https://beam.apache.org*](https://beam.apache.org)'
- en: '| **Description** | Apache Beam doesn’t provide stream processing directly
    but instead promotes itself as a unified programming model for both batch and
    stream processing. It utilizes platforms like Samza, Spark, and Flink as runners
    for components in an overall processing pipeline. |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: Apache Beam并不直接提供流处理，而是将自己宣传为批处理和流处理的统一编程模型。它利用像Samza、Spark和Flink这样的平台作为整体处理管道中组件的运行器。

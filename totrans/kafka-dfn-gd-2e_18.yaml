- en: Appendix B. Additional Kafka Tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Apache Kafka community has created a robust ecosystem of tools and platforms
    that make the task of running and using Kafka far easier. While this is by no
    means an exhaustive list, several of the more popular tools are presented here
    to help get you started.
  prefs: []
  type: TYPE_NORMAL
- en: Caveat Emptor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While the authors are affiliated with some of the companies and projects that
    are included in this list, neither they nor O’Reilly specifically endorse one
    tool over others. Please be sure to do your own research on the suitability of
    these platforms and tools for the work that you need to do.
  prefs: []
  type: TYPE_NORMAL
- en: Comprehensive Platforms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Several companies offer fully integrated platforms for working with Apache Kafka.
    This includes managed deployments of all components, such that you can focus on
    using Kafka and not on how to run it. This can present an ideal solution for use
    cases where resources are not available (or you do not want to dedicate them)
    for learning how to properly operate Kafka and the infrastructure required around
    it. Several also provide tools, such as schema management, REST interfaces, and
    in some cases client library support, so that you can be assured components interoperate
    correctly.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Title** | Confluent Cloud |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://www.confluent.io/confluent-cloud*](https://www.confluent.io/confluent-cloud)
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | It’s only fitting that the company created by some of the
    original developers to develop and support Kafka provides a managed solution.
    Confluent Cloud combines a number of must-have tools—including schema management,
    clients, a RESTful interface, and monitoring—into a single offering. It’s available
    on all three major cloud platforms (AWS, Microsoft Azure, and Google Cloud Platform)
    and is backed with support provided by a sizable portion of the core Apache Kafka
    contributors employed by Confluent. Many of the components that are included in
    the platform, such as the Schema Registry and the REST proxy, are available as
    standalone tools under the [Confluent Community License](https://oreil.ly/lAFga),
    which does restrict some use cases. |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | Aiven |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://aiven.io*](https://aiven.io) |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | Aiven provides managed solutions for many data platforms,
    including Kafka. To support this, it has developed [Karapace](https://karapace.io),
    which is a schema registry and a REST proxy, both API-compatible with Confluent’s
    components but supported under the [Apache 2.0 license](https://oreil.ly/a96F0),
    which does not restrict use cases. In addition to the three major cloud providers,
    Aiven also supports [DigitalOcean](https://www.digitalocean.com) and [UpCloud](https://upcloud.com).
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | CloudKarafka |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://www.cloudkarafka.com*](https://www.cloudkarafka.com)
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | CloudKarafka focuses on providing a managed Kafka solution
    with integrations for popular infrastructure services (such as DataDog or Splunk).
    It supports the use of Confluent’s Schema Registry and REST proxy with its platform,
    but only the 5.0 version prior to the license changes by Confluent. CloudKarafka
    provides its services on both AWS and Google Cloud Platform. |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | Amazon Managed Streaming for Apache Kafka (Amazon MSK) |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://aws.amazon.com/msk*](https://aws.amazon.com/msk) |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | Amazon also provides its own managed Kafka platform, supported
    only on AWS. Schema support is provided through integration with [AWS Glue](https://oreil.ly/hvjoV),
    while a REST proxy is not directly supported. Amazon promotes the use of community
    tools (such as Cruise Control, Burrow, and Confluent’s REST proxy) but does not
    directly support them. As such, MSK is somewhat less integrated than other offers,
    but can still provide a core Kafka cluster. |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | Azure HDInsight |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://azure.microsoft.com/en-us/services/hdinsight*](https://azure.microsoft.com/en-us/services/hdinsight)
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | Microsoft also provides a managed platform for Kafka in
    HDInsight, which also supports Hadoop, Spark, and other big data components. Similar
    to MSK, HDInsight focuses on the core Kafka cluster, leaving many of the other
    components (including a schema registry and REST proxy) up to the user to provide.
    Some third parties have provided templates for performing these deployments, but
    they are not supported by Microsoft. |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | Cloudera |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://www.cloudera.com/products/open-source/apache-hadoop/apache-kafka.html*](https://www.cloudera.com/products/open-source/apache-hadoop/apache-kafka.html)
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | Cloudera has been a fixture in the Kafka community since
    the early days and provides managed Kafka as the stream data component of its
    overall Customer Data Platform (CDP) product. CDP focuses on more than just Kafka,
    however, and it operates in the public cloud environments as well as providing
    private options. |'
  prefs: []
  type: TYPE_TB
- en: Cluster Deployment and Management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When running Kafka outside of a managed platform, you will need several things
    to assist you with running the cluster properly. This includes help with provisioning
    and deployment, balancing data, and visualizing your clusters.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Title** | Strimzi |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://strimzi.io*](https://strimzi.io) |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | Strimzi provides Kubernetes operators for deploying Kafka
    clusters to make it easier to set up Kafka in a Kubernetes environment. It does
    not provide managed services but instead makes it easy for you to get up and running
    in a cloud, whether public or private. It also provides the Strimzi Kafka Bridge,
    which is a REST proxy implementation supported under the [Apache 2.0 license](https://oreil.ly/a96F0).
    At this time, Strimzi does not have support for a schema registry, due to concerns
    about licenses. |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | AKHQ |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://akhq.io*](https://akhq.io) |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | AKHQ is a GUI for managing and interacting with Kafka clusters.
    It supports configuration management, including users and ACLs, and provides some
    support for components like the Schema Registry and Kafka Connect as well. It
    also provides tools for working with data in the cluster as an alternative to
    the console tools. |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | JulieOps |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://github.com/kafka-ops/julie*](https://github.com/kafka-ops/julie)
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | JulieOps (formerly Kafka Topology Builder) provides for
    automated management of topics and ACLs using a GitOps model. More than viewing
    the state of the current configuration, JulieOps provides a means for declarative
    configuration and change control of topics, schemas, ACLs, and more over time.
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | Cruise Control |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://github.com/linkedin/cruise-control*](https://github.com/linkedin/cruise-control)
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | Cruise Control is LinkedIn’s answer to how to manage hundreds
    of clusters with thousands of brokers. This tool began as a solution to automated
    rebalancing of data in clusters but has evolved to include anomaly detection and
    administrative operations, such as adding and removing brokers. For anything more
    than a testing cluster, it is a must-have for any Kafka operator. |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | Conduktor |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://www.conduktor.io*](https://www.conduktor.io) |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | While not open source, Conduktor is a popular desktop tool
    for managing and interacting with Kafka clusters. It supports many of the managed
    platforms (including Confluent, Aiven, and MSK) and many different components
    (such as Connect, kSQL, and Streams). It also allows you to interact with data
    in the clusters, as opposed to using the console tools. A free license is provided
    for development use that works with a single cluster. |'
  prefs: []
  type: TYPE_TB
- en: Monitoring and Data Exploration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A critical part to running Kafka is to ensure that your cluster and your clients
    are healthy. Like many applications, Kafka exposes numerous metrics and other
    telemetry, but making sense of it can be challenging. Many of the larger monitoring
    platforms (such as [Prometheus](https://prometheus.io)) can easily fetch metrics
    from Kafka brokers and clients. There are also a number of tools available to
    assist with making sense of all the data.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Title** | Xinfra Monitor |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://github.com/linkedin/kafka-monitor*](https://github.com/linkedin/kafka-monitor)
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | Xinfra Monitor (formerly Kafka Monitor) was developed by
    LinkedIn to monitor availability of Kafka clusters and brokers. It does this by
    using a set of topics to generate synthetic data through the cluster and measuring
    latency, availability, and completeness. It’s a valuable tool for measuring your
    Kafka deployment’s health without requiring direct interaction with your clients.
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | Burrow |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://github.com/linkedin/burrow*](https://github.com/linkedin/burrow)
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | Burrow is another tool originally created by LinkedIn,
    which provides holistic monitoring of consumer lag within Kafka clusters. It provides
    a view into the health of the consumers without needing to directly interact with
    them. Burrow is actively supported by the community and has its own [ecosystem
    of tools](https://oreil.ly/yNPRQ) to connect it with other components. |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | Kafka Dashboard |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://www.datadoghq.com/dashboards/kafka-dashboard*](https://www.datadoghq.com/dashboards/kafka-dashboard)
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | For those who use DataDog for monitoring, it provides an
    excellent Kafka Dashboard to give you a head start on integrating Kafka clusters
    into your monitoring stack. It is designed to provide a single-pane view of your
    Kafka cluster, simplifying the view of many metrics. |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | Streams Explorer |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://github.com/bakdata/streams-explorer*](https://github.com/bakdata/streams-explorer)
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | Streams Explorer is a tool for visualizing the flow of
    data through applications and connectors in a Kubernetes deployment. While it
    heavily relies on structuring your deployments using either Kafka Streams or Faust
    through bakdata’s tools, it can then provide an easily comprehensible view of
    those applications and their metrics. |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | kcat |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://github.com/edenhill/kafkacat*](https://github.com/edenhill/kafkacat)
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | Kcat (formerly kafkacat) is a much-loved alternative to
    the console producer and consumer that are part of the core Apache Kafka project.
    It is small, fast, and written in C, so it does not have JVM overhead. It also
    supports limited views into cluster status by showing metadata output for the
    cluster. |'
  prefs: []
  type: TYPE_TB
- en: Client Libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Apache Kafka project provides client libraries for Java applications, but
    one language is never enough. There are many implementations of the Kafka client
    out there, with popular languages such as Python, Go, and Ruby having several
    options. In addition, REST proxies (such as those from Confluent, Strimzi, or
    Karapace) can cover a variety of use cases. Here are a few client implementations
    that have stood the test of time.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Title** | librdkafka |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://github.com/edenhill/librdkafka*](https://github.com/edenhill/librdkafka)
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | librdkafka is a C library implementation of the Kafka client
    that is regarded as one of the best-performing libraries available. So good, in
    fact, that Confluent supports clients for Go, Python, and .NET that it created
    as wrappers around librdkafka. It is licensed simply under the [two-clause BSD
    license](https://oreil.ly/dLoe8), which makes it easy to use in any application.
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | Sarama |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://github.com/Shopify/sarama*](https://github.com/Shopify/sarama)
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | Shopify created the Sarama client as a native Golang implementation.
    It’s released under the [MIT license](https://oreil.ly/sajdS). |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | kafka-python |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://github.com/dpkp/kafka-python*](https://github.com/dpkp/kafka-python)
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | kafka-python is another native client implementation, this
    time in Python. It’s released under the [Apache 2.0 license](https://oreil.ly/a96F0).
    |'
  prefs: []
  type: TYPE_TB
- en: Stream Processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While the Apache Kafka project includes Kafka Streams for building applications,
    it’s not the only choice out there for stream processing of data from Kafka.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Title** | Samza |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://samza.apache.org*](https://samza.apache.org) |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | Apache Samza is a framework for stream processing that
    was specifically designed for Kafka. While it predates Kafka Streams, it was developed
    by many of the same people, and as a result the two share many concepts. However,
    unlike Kafka Streams, Samza runs on Yarn and provides a full framework for applications
    to run in. |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | Spark |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://spark.apache.org*](https://spark.apache.org) |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | Spark is another Apache project oriented toward batch processing
    of data. It handles streams by considering them to be fast microbatches. This
    means the latency is a little higher, but fault tolerance is simply handled through
    reprocessing batches, and Lambda architecture is easy. It also has the benefit
    of wide community support. |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | Flink |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://flink.apache.org*](https://flink.apache.org) |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | Apache Flink is specifically oriented toward stream processing
    and operates with very low latency. Like Samza, it supports Yarn but also works
    with Mesos, Kubernetes, or standalone clusters. It also supports Python and R
    with provided high-level APIs. |'
  prefs: []
  type: TYPE_TB
- en: '| **Title** | Beam |'
  prefs: []
  type: TYPE_TB
- en: '| **URL** | [*https://beam.apache.org*](https://beam.apache.org) |'
  prefs: []
  type: TYPE_TB
- en: '| **Description** | Apache Beam doesn’t provide stream processing directly
    but instead promotes itself as a unified programming model for both batch and
    stream processing. It utilizes platforms like Samza, Spark, and Flink as runners
    for components in an overall processing pipeline. |'
  prefs: []
  type: TYPE_TB

- en: Using Docker to Supercharge Automation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last chapter, we introduced techniques commonly used to allow a developer
    to evolve, modify, debug, and test their code while running in a container. We
    also learned how to instrument applications so that they generate logging information
    that can help us to do root cause analysis of failures or misbehaviors of applications
    or application services that are running in production.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will show how you can use tools to perform administrative
    tasks without having to install those tools on the host computer. We will also
    illustrate the use of containers that host and run test scripts or code used to
    test and validate application services running in containers. Finally, we will
    guide the reader through the task of building a simple Docker-based CI/CD pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a quick overview of all of the subjects we are going to touch on in
    this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Executing simple admin tasks in a container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using test containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Docker to power a CI/CD pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After finishing this chapter, you will be able to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Run a tool not available on the host in a container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a container to run test scripts or code against an application service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build a simple CI/CD pipeline using Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, if you want to follow along with the code, you need Docker
    for Desktop on your macOS or Windows machine and a code editor, preferably Visual
    Studio Code. The sample will also work on a Linux machine with Docker and VS Code
    installed.
  prefs: []
  type: TYPE_NORMAL
- en: Executing simple admin tasks in a container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s assume you need to strip all leading whitespaces from a file and you
    found the following handy Perl script to do exactly that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'As it turns out, you don''t have Perl installed on your working machine. What
    can you do? Install Perl on the machine? Well, that would certainly be an option,
    and it''s exactly what most developers or system admins do. But wait a second,
    you already have Docker installed on your machine. Can''t we use Docker to circumvent
    the need to install Perl? Yes, we can. This is how we''re going to do it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a folder, `ch07/simple-task`, and navigate to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Open VS Code from within this folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In this folder, create a `sample.txt` file with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Please note the whitespaces at the beginning of each line. Save the file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can run a container with Perl installed in it. Thankfully, there is
    an official Perl image on Docker Hub. We are going to use the slim version of
    the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The preceding command runs a Perl container (`perl:slim`) interactively, maps
    the content of the current folder into the `/usr/src/app` folder of the container,
    and sets the working folder inside the container to `/usr/src/app`. The command
    that is run inside the container is `sh -c "cat sample.txt | perl -lpe 's/^\s*//'"`,
    basically spawning a Bourne shell and executing our desired Perl command.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output generated by the preceding command should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Without needing to install Perl on our machine, we were able to achieve our
    goal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If that doesn''t convince you yet because if you''re on macOS, you already
    have Perl installed, then consider you''re looking into running a Perl script
    named `your-old-perl-script.pl` that is old and not compatible with the newest
    release of Perl that you happen to have installed on your system. Do you try to
    install multiple versions of Perl on your machine and potentially break something?
    No, you just run a container with the (old) version of Perl that is compatible
    with your script, as in this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Here, `<old-version>` corresponds to the tag of the version of Perl that you
    need to run your script. The nice thing is that, after the script has run, the
    container is removed from your system without leaving any traces because we used
    the `--rm` flag in the `docker container run` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'A lot of people use quick and dirty Python scripts or mini apps to automate
    tasks that are not easily coded with, say, Bash. Now if the Python script has
    been written in Python 3.7 and you only happen to have Python 2.7 installed, or
    no version at all on your machine, then the easiest solution is to execute the
    script inside a container. Let''s assume a simple example where the Python script
    counts lines, words, and letters in a given file and outputs the result to the
    console:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Still in the `ch07/simple-task` folder add a `stats.py` file and add the following
    content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'After saving the file, you can run it with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that, in this example, we are reusing the `sample.txt` file from before.
    The output in my case is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The beauty of this approach is that this Python script will now run on any computer
    with any OS installed, as long as the machine is a Docker host and, hence, can
    run containers.
  prefs: []
  type: TYPE_NORMAL
- en: Using test containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For each serious software project out there, it is highly recommended to have
    plenty of tests in place. There are various test categories such as unit tests,
    integration tests, stress and load tests, and end-to-end tests. I have tried to
    visualize the different categories in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/f5d017fc-0214-43d4-9c0a-a701c9731c84.png)'
  prefs: []
  type: TYPE_IMG
- en: Categories of application tests
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests assert the correctness and quality of an individual, isolated piece
    of the overall application or application service. Integration tests make sure
    that pieces that are closely related work together as expected. Stress and load
    tests often take the application or service as a whole and assert a correct behavior
    under various edge cases such as high load through multiple concurrent requests
    handled by the service, or by flooding the service with a huge amount of data.
    Finally, end-to-end tests simulate a real user working with the application or
    application service. The typical tasks that a user would do are automated.
  prefs: []
  type: TYPE_NORMAL
- en: The code or component under test is often called a **System Under Test** (**SUT**).
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests are in their nature tightly coupled to the actual code or SUT. It
    is, hence, necessary that those tests run in the same context as the code under
    test. Hence, the test code lives in the same container as the SUT. All external
    dependencies of the SUT are either mocked or stubbed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Integration tests, stress and load tests, and end-to-end tests, on the other
    hand, act on public interfaces of the system under test and it is, hence, most
    common to run that test code in a separate container:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3e2a02c0-87e7-412b-b912-4060b337280f.png)'
  prefs: []
  type: TYPE_IMG
- en: Integration tests using containers
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding diagram, we can see the **Test Code** running in its own **Test
    Container**. The **Test Code** accesses the public interface of the **API** component
    that also runs in a dedicated container. The **API** component has external dependencies
    such as **Other** **Service** and **Database** that each run in their dedicated
    container. In this case, the whole ensemble of **API**, **Other** **Service**, and
    **Database **is our system under test, or SUT.
  prefs: []
  type: TYPE_NORMAL
- en: 'What exactly would stress and load tests look like? Imagine a situation where
    we have a Kafka Streams application we want to put under test. The following diagram
    gives an idea of what exactly we could test, from a high level:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/7b928ee2-e7df-4a26-9c6c-1504683653ee.png)'
  prefs: []
  type: TYPE_IMG
- en: Stress and load test a Kafka Streams application
  prefs: []
  type: TYPE_NORMAL
- en: 'In a nutshell, a **Kafka Streams application** consumes data from one or more
    topics stored in Apache Kafka(R). The application filters, transforms, or aggregates
    the data. The resulting data is written back to one or several topics in Kafka.
    Typically, when working with Kafka, we deal with real-time data streaming into
    Kafka. Tests could now simulate the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Large topics with a huge amount of records
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data flowing into Kafka with a very high frequency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data being grouped by the application under test, where there is a lot of distinct
    keys, each one with low cardinality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data aggregated by time windows where the size of the window is small, for example, each only
    a few seconds long
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: End-to-end tests automate the users that interact with an application by the
    use of tools such as the Selenium Web Driver, which provides a developer means
    to automate actions on a given web page such as filling out fields in a form or
    clicking buttons.
  prefs: []
  type: TYPE_NORMAL
- en: Integration tests for a Node.js application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s now have a look at a sample integration test implemented in Node.js.
    Here is the setup that we are going to look into:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/b2695574-24aa-48e3-9760-f0ab1e9e8247.png)'
  prefs: []
  type: TYPE_IMG
- en: Integration tests for an Express JS Application
  prefs: []
  type: TYPE_NORMAL
- en: 'Following are the steps to create such an integration test:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s first prepare our project folder structure. We create the project root
    and navigate to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Within this folder, we create three subfolders, `tests`, `api`, and `database`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we open VS Code from the project root:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'To the `database` folder, add an `init-script.sql` file with the following
    content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The preceding script will create a `hobbies` table in our Postgres database
    that we are going to use and fill it with some seed data. Save the file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can start the database. Of course, we are going to use the official
    Docker image for Postgres to run the database in a container. But first, we will
    create a Docker volume where the database will store its files. We will call the
    volume `pg-data`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, it''s time to run the database container. From within the project root
    folder (`integration-test-node`), run the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Note that the folder from which you run the preceding command matters, due to
    the volume mounting we are using for the database initialization script, `init-script.sql`.
    Also note that we are using environment variables to define the name and user
    of the database in Postgres, and we are mapping port `5432` of Postgres to the
    equivalent port on our host machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'After you have started the database container, double-check that it runs as
    expected by retrieving its logs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see something similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Note, we have shortened the output for better readability. The important parts
    of the preceding output are the first few lines, where we can see that the database
    has picked up our initialization script, created the `hobbies` table and seeded
    it with five records. Also important is the last line, telling us that the database
    is ready to work. The container logs are always your first stop when troubleshooting
    problems!
  prefs: []
  type: TYPE_NORMAL
- en: 'With that, our first piece of the SUT is ready. Let''s move on to the next
    one, which is our API implemented in Express JS:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the Terminal window, navigate to the `api` folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, run `npm init` to initialize the API project. Just accept all defaults:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting `package.json` file should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Modify the `scripts` node of the preceding file so that it contains a start
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/6c851736-d5d7-4656-b565-8666cd016cf8.png) Adding a start script
    to the package.json file'
  prefs: []
  type: TYPE_NORMAL
- en: 'We then have to install Express JS and can do so with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This will install the library and all of its dependencies and add a dependencies node to
    our `package.json` file that looks similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/6d01c027-f5be-4de4-be22-57af5ff422e0.png)'
  prefs: []
  type: TYPE_IMG
- en: Adding Express JS as a dependency to the API
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `api` folder, create a `server.js` file and add the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/55518a75-754f-4ef7-98bf-e93eb73332a7.png)'
  prefs: []
  type: TYPE_IMG
- en: Simple Express JS API
  prefs: []
  type: TYPE_NORMAL
- en: This is a simple Express JS API with only the `/` endpoint implemented. It serves
    as a starting point for our exploration into integration testing. Note that the
    API will be listening at port `3000`, on all endpoints inside the container (`0.0.0.0`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can start the API with `npm start` and then test the home endpoint,
    for example, with `curl`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: After all of these steps, we're ready to scaffold the test environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will be using `jasmine` to write our tests. Navigate to the `tests` folder
    and run `npm init` to initialize the test project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Accept all of the defaults.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, add `jasmine` to the project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Then initialize `jasmine` for this project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need to change our `package.json` file so that the scripts block looks
    like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/f06ce569-69d4-47ab-9346-700ec2fa8eaf.png)'
  prefs: []
  type: TYPE_IMG
- en: Adding a test script for our integration tests
  prefs: []
  type: TYPE_NORMAL
- en: 'We cannot run the tests any time by executing `npm test` from within the `tests`
    folder. The first time we run it, we will get an error since we have not yet added
    any tests:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/fa888ef5-069b-4297-a38e-2af3a671686c.png)'
  prefs: []
  type: TYPE_IMG
- en: The first run fails since no tests were found
  prefs: []
  type: TYPE_NORMAL
- en: 'Now in the `spec/support` subfolder of the project, let''s create a `jasmine.json` file.
    This will contain the configuration settings for the `jasmine` test framework.
    Add the following code snippet to this file and save:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we are going to author integration tests we will want to access the SUT
    via its public interface, which, in our case, is a RESTful API. Hence, we need
    a client library that allows us to do so. My choice is the Requests library. Let''s
    add it to our project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Add an `api-spec.js` file to the `spec` subfolder of the project. It will contain
    our test functions. Let''s start with the first one:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/6f2f86bd-53a7-4447-ac3d-171f7955d2de.png)'
  prefs: []
  type: TYPE_IMG
- en: Sample test suite for the API
  prefs: []
  type: TYPE_NORMAL
- en: We are using the `request` library to make RESTful calls to our API (line `1`).
    Then, on line `3`, we're defining the base URL on which the API is listening.
    Note, the code that we use allows us to override the default of `http://localhost:3000`
    with whatever we define in an environment variable called `BASE_URL`. Line `5`
    defines our test suite, which, on line `6`, has a test for `GET /`. We then assert
    two outcomes, namely that the status code of a `GET` call to `/` is `200` (OK)
    and that the text returned in the body of the response is equal to `Sample API`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we run the test now, we get the following outcome:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/11d9290c-3d06-4c15-84ac-ae664f87ad9b.png)'
  prefs: []
  type: TYPE_IMG
- en: Successfully running Jasmine-based integration tests
  prefs: []
  type: TYPE_NORMAL
- en: We have two specifications—another word for tests—running; all of them are successful
    since we have zero failures reported.
  prefs: []
  type: TYPE_NORMAL
- en: Before we continue, please stop the API and remove the Postgres container with
    `docker container rm -f postgres`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'So far so good, but now let''s bring containers to the table. That''s what
    we are most excited about, isn''t it? We''re excited to run everything, including
    test code in containers. If you recall, we are going to deal with three containers,
    the database, the API, and the container with the test code. For the database,
    we are just using the standard Postgres Docker image, but, for the API and tests,
    we will create our own images:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with the API. To the `api` folder, add a `Dockerfile` file with
    this content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This is just a very standard way of creating a container image for a Node.js
    based application. There's nothing special here.
  prefs: []
  type: TYPE_NORMAL
- en: 'To the `tests` folder, also add a Dockerfile with this content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we''re ready to run all three containers, in the right sequence. To simplify
    this task, let''s create a shell script that does exactly that. Add a `test.sh` file to
    the `integration-test-node` folder, our project root folder. Add the following
    content to this file and save:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: On the first two lines of the script, we make sure that the two container images
    for API and tests are built with the newest code. Then, we create a Docker network
    called `test-net` on which we will run all three containers. Don't worry about
    the details of this as we will explain networks in detail in [Chapter 10](f3b1e24a-2ac4-473a-b9c8-270b97df6a8a.xhtml),
    *Single Host Networking*. For the moment, suffice to say that if all containers
    run on the same network, then the applications running inside those containers
    can see each other as if they were running natively on the host, and they can
    call each other by name.
  prefs: []
  type: TYPE_NORMAL
- en: The next command starts the database container, followed by the command that
    starts the API. Then, we pause for a few seconds to give the database and the
    API time to completely start up and initialize, before we start the third and
    final container, the tests container.
  prefs: []
  type: TYPE_NORMAL
- en: 'Make this file an executable with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you can run it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'If everything works as expected, you should see something along these lines
    (shortened for readability):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also create a script that cleans up after testing. For this, add a file
    called `cleanup.sh` and make it an executable the same way as you''ve done with
    the `test.sh` script. Add the following code snippet to this file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Line one removes the `postgres` and `api` containers. Line 2 removes the network
    we used for the third container, and finally, line 3 removes the volume used by
    Postgres. After each test run, execute this file with `./cleanup.sh`.
  prefs: []
  type: TYPE_NORMAL
- en: Now you can start adding more code to your API component and more integration
    tests. Each time you want to test new or modified code, just run the `test.sh`
    script.
  prefs: []
  type: TYPE_NORMAL
- en: 'Challenge: How can you optimize this process further, so that fewer manual
    steps are required?'
  prefs: []
  type: TYPE_NORMAL
- en: Use what we have learned in [Chapter 6](b6647803-2c5c-4b9d-9a4a-a836ac356329.xhtml),
    *Debugging Code Running in Containers*.
  prefs: []
  type: TYPE_NORMAL
- en: The Testcontainers project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you''re a Java developer, then there is a nice project called Testcontainers
    ([https://testcontainers.org](https://testcontainers.org)). In their own words,
    the project can be summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '"Testcontainers is a Java library that supports JUnit tests, providing lightweight,
    throwaway instances of common databases, Selenium web browsers, or anything else
    that can run in  Docker container."To experiment with Testcontainer follow along:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First create a `testcontainer-node` folder and navigate to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Next open VS Code from within that folder with `code .`. Create three subfolders, `database`,
    `api`, and `tests`, within the same folder. To the `api` folder, add a `package.json` file with
    the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/7eb83bfd-88b9-4891-9349-2098351469b2.png)'
  prefs: []
  type: TYPE_IMG
- en: Content of package.json for the API
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a `server.js` file to the `api` folder with this content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/e1dd1426-e8cf-48fb-8cc7-f79f5b4f6c95.png)'
  prefs: []
  type: TYPE_IMG
- en: The sample API using the pg library to access Postgres
  prefs: []
  type: TYPE_NORMAL
- en: Here, we create an Express JS application listening at port `3000`. The application
    uses the `pg` library, which is a client library for Postgres, to access our database.
    On lines `8` through `15`, we are defining a connection pool object that will
    allow us to connect to Postgres and retrieve or write data. On lines `21` through
    `24`, we're defining a `GET` method on the `/hobbies` endpoint, which returns
    the list of hobbies that are retrieved from the database via the SQL query, `SELECT
    hobby FROM hobbies`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now add a Dockerfile to the same folder with this content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/b63beff8-619f-435f-801c-7fe06c7a1333.png)'
  prefs: []
  type: TYPE_IMG
- en: Dockerfile for the API
  prefs: []
  type: TYPE_NORMAL
- en: This is exactly the same definition as we used in the previous example. With
    this, the API is ready to be used. Let's now continue with the tests that will
    use the `testcontainer` library to simplify container-based testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'In your Terminal, navigate to the `tests` folder that we created earlier and
    use `npm init` to initialize it as a Node.js project. Accept all of the defaults.
    Next, use `npm` to install the `request` library and the `testcontainers` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of this is a `package.json` file that should look similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/d2880fcf-f231-45d2-878b-3b4b2289f79f.png)'
  prefs: []
  type: TYPE_IMG
- en: The package.json file for the tests project
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, still in the `tests` folder, create a `tests.js` file and add the following
    code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Note how we're requesting a new object such as the `request` object, which will
    help us to access the RESTful interface of our sample API component. We are also
    requesting the `GenericContainer` object from the `testcontainers` library that
    will allow us to build and run any container.
  prefs: []
  type: TYPE_NORMAL
- en: We then define an async self-invoking function, which will be the wrapper for
    our setup and test code. It has to be an async function since, inside it, we will
    be awaiting other async functions, such as the various methods used from the `testcontainers`
    library.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a very first step, we want to use the `testcontainers` library to create
    a Postgres container with the necessary seed data loaded. Let''s add this code
    snippet after `//TODO`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: The preceding snippet has some similarities with a Docker `run` command. That
    is no accident since we are instructing the `testcontainers` library to do exactly
    that and run an instance of PostgreSQL for us.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we need to find out to which host port the exposed port `5432` is mapped.
    We can do that with the following logic:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: We will need this information since the API component will have to access Postgres
    via this port.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need to know which IP address the host is reachable from within a container—note,
    localhost won''t work from within a container since that would map to the loopback
    adapter of the container''s own network stack. We can get this host IP address
    like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The `lookupPromise` function is a wrapper function to make the normal async
    `dns.lookup` function return a promise so that we can `await` it. Here is its
    definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, with this information, we are ready to instruct the `testcontainer` library
    to first build the container image for the API and then run a container from this
    image. Let''s start with the build:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Note how this command uses the Dockerfile that we defined in the `api` subfolder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have the `apiContainer` variable referencing the new image, we can
    use this to run a container from it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Once again, we need to find out to which host port the exposed port `3000`
    of the API component has been mapped. The `testcontainer` library makes this a
    breeze:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'With this last line, we have finished the test setup code and can now finally
    start implementing some tests. We start by defining the base URL for the API component
    that we want to access. Then, we use the `request` library to make an HTTP GET
    request to the `/hobbies` endpoint:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now implement some assertions right after the `//Test code here...` comment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we log our expectation to the console as a feedback when running tests.
    Then, we assert that the returned status code is `200`, and, if not, we log an
    error. The `logError` helper function just writes the given message in red to
    the console, and prefixes it with `***ERR`. Here is the definition of this function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s add two more assertions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: I leave it up to you, dear reader, to find out what these assertions do exactly.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the end of the assertions, we have to clean up so that we''re ready for
    a next run:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: What we're doing is just stopping the API and the database container. This will
    automatically remove them from memory too.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can run this test suite using the following command from within the
    `tests` subfolder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The output in my case looks like this (note, I have sprinkled a few `console.log`
    statements in the code to more easily follow along what exactly is happening at
    a give time):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ba68b227-ae11-4625-9b29-b37915043c4f.png)'
  prefs: []
  type: TYPE_IMG
- en: Running the testcontainer-based integration tests
  prefs: []
  type: TYPE_NORMAL
- en: The full code is given in the sample code repository that you cloned from GitHub.
    If you have problems running your tests, please compare your implementation to
    the given sample solution.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a good understanding of how to use containers to run our integration
    tests, we'll move on to another very popular use case for container based automation,
    namely, building a Continuous Integration and Continuous Deployment or Delivery
    (CI/CD) pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Using Docker to power a CI/CD pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The goal of this section is to build a CI/CD pipeline that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/6e8eff3d-22ee-4c18-9b2b-30f7745a3e91.png)'
  prefs: []
  type: TYPE_IMG
- en: A simple CI/CD pipeline using Jenkins
  prefs: []
  type: TYPE_NORMAL
- en: We are going to use Jenkins ([https://jenkins.io](https://jenkins.io)) as our
    automation server. Other automation servers such as TeamCity ([https://www.jetbrains.com/teamcity](https://www.jetbrains.com/teamcity))
    work equally well. When using Jenkins, the central document is the `Jenkinsfile`,
    which will contain the definition of the pipeline with its multiple stages.
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple `Jenkinsfile` with the `Build`, `Test`, `Deploy to Staging`, and `Deploy
    to Production` stages could look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Of course, the preceding pipeline just outputs a message during each stage
    and does nothing else. It is useful though as a starting point from which to build
    up our pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a project folder named `jenkins-pipeline` and navigate to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s run Jenkins in a Docker container. Use the following command to
    do so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Note that we are running as the `root` user inside the container and that we
    are mounting the Docker socket into the container (`-v /var/run/docker.sock:/var/run/docker.sock`)
    so that Jenkins can access Docker from within the container. Data produced and
    used by Jenkins will be stored in the Docker volume, `jenkins-data`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can find the initial admin password generated automatically by Jenkins with
    the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: In my case, this outputs `7f449293de5443a2bbcb0918c8558689`. Save this password
    as you will be using it in the next step.
  prefs: []
  type: TYPE_NORMAL
- en: In your browser, navigate to `http://localhost:8080` to access the graphical
    UI of Jenkins.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Unlock Jenkins with the admin password that you retrieved with the previous
    command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, choose Install suggested plugins to have Jenkins automatically install
    the most useful plugins. Plugins include the GitHub integration, an email extension,
    Maven and Gradle integration, and so on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As soon as the plugins are installed, create your first admin account. When
    asked to restart Jenkins, do so.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once you have configured your Jenkins server, start by creating a new project;
    you may need to click **New Item** in the main menu:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/f64e3315-eaf5-43c9-8ffc-d8fd63e0cd4e.png)'
  prefs: []
  type: TYPE_IMG
- en: Add a new project in Jenkins
  prefs: []
  type: TYPE_NORMAL
- en: Give the project the name `sample-pipeline`, select the `Pipeline` type, and
    click OK.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the configuration view, select the Pipeline tab and add the pipeline definition
    from the preceding into the Script textbox:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/b96d4516-0374-453f-b7a2-b419e6815a24.png)'
  prefs: []
  type: TYPE_IMG
- en: Defining the pipeline in our Jenkins project called sample-pipeline
  prefs: []
  type: TYPE_NORMAL
- en: 'Click Save and then, in the main menu of Jenkins, select Build Now. After a
    short moment, you should see this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/009185ff-8c65-4336-82f3-1fb4673adc22.png)'
  prefs: []
  type: TYPE_IMG
- en: Running our sample pipeline in Jenkins
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have prepared Jenkins, we can start to integrate our sample application.
    Let''s start with the build step. First, we initialize the `jenkins-pipeline` project
    folder as a Git project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Add a `package.json` file to this folder with this content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: There is nothing exceptional in this file other the usual list of external dependencies,
    `express` and `jasmine`, in this case. Also, note the two scripts `start` and
    `test` that we define for use with `npm`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a `hobbies.js` file to the project, which implements the logic to retrieve
    hobbies as a JavaScript module called `hobbies`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: This code evidently is simulating a database by serving pre-canned data stored
    in the `hobbies` array. We do this for simplicity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next add a `server.js` file to the folder that defines a RESTful API with the
    three endpoints, `GET /`,  `GET /hobbies`, and `GET /hobbies/:id`. The code uses
    the logic defined in the `hobbies` module to retrieve data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we need to define some unit tests. Create a `spec` subfolder in the project
    and add the `hobbies-spec.js` file to it with the following code that tests the `hobbies` module:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The last step is to add a `support/jasmine.json` file to configure our test
    framework, Jasmine. Add the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: This is all the code that we need for the moment.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now start to build the CI/CD pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Commit the code just created locally with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'To avoid all of the node modules being saved to GitHub, add a `.gitignore` file to
    the project `root` folder with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Now, we need to define a repository on GitHub. Log in to your account on GitHub
    at [https://github.com](https://github.com).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a new repository there and call it `jenkins-pipeline`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/5bd043cb-4a05-4e38-b286-30d4c48a7b40.png)'
  prefs: []
  type: TYPE_IMG
- en: Create a new GitHub repository for the Jenkins pipeline sample applicationNote
    that my GitHub account is `gnschenker`. In your case, it will be your own account.
  prefs: []
  type: TYPE_NORMAL
- en: 'After you have clicked the green button, **Create repository**, go back to
    you project and execute the following two commands from within the project `root`
    folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: Make sure you replace `gnschenker` in the first line with your own GitHub account
    name. After this step, your code will be available on GitHub for further use.
    One of the users will be Jenkins, which will pull the code from this repository
    as we will show shortly.
  prefs: []
  type: TYPE_NORMAL
- en: The next thing is to go back to Jenkins (`localhost:8080`) and modify the configuration
    of the project. Log in to Jenkins if needed and select your project, `sample-pipeline`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, select Configure in the main menu. Select the Pipeline tab and modify
    the settings so that they look similar to this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/c975f0de-984a-4fc0-b092-e4e848fd34dd.png)'
  prefs: []
  type: TYPE_IMG
- en: Configuring Jenkins to pull source from GitHub
  prefs: []
  type: TYPE_NORMAL
- en: 'With this, we configure Jenkins to pull code from GitHub and use a `Jenkinsfile`
    to define the pipeline. `Jenkinsfile` is expected to be found in the `root` of
    the project. Note that for the repository URL path, we need to give the relative
    path to the `/home` directory where our project is located. Remember that, when
    running the Jenkins container, we mapped our own home folder on the host to the
    `/home` folder inside the Jenkins container with this: `-v "$HOME":/home`.'
  prefs: []
  type: TYPE_NORMAL
- en: Hit the green Save button to accept the changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We have defined that `Jenkinsfile` needs to be in the project `root` folder.
    This is the foundation of **Pipeline-as-Code**, since the pipeline definition
    file will be committed to the GitHub repository along with the rest of the code.
    Hence, add a file called `Jenkinsfile` to the `jenkins-pipeline` folder and add
    this code to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'OK, let''s dive into this file one part at a time. At the top, we''re defining
    two environment variables that will be available throughout every stage of the
    pipeline. We will be using those variables in the `Build & Push Docker image` stage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: The first variable, `registry`, just contains the full name of the container
    image we will eventually produce and push to Docker Hub. Replace `gnschenker`
    with your own GitHub username. The second variable, `DOCKER_PWD`, is a bit more
    interesting. It will contain the password to log in to my Docker Hub account.
    Of course, I don't want to have the value hardcoded here in code, hence, I use
    the credentials function of Jenkins that gives me access to a secret stored under
    the name `docker-login-pwd` in Jenkins.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we define the agent we want to use to run the Jenkins pipeline on. In
    our case, it is based on a Docker image. We are using the `gnschenker/node-docker` image for
    this purpose. This is an image based on `node:12.10-alpine`, which has Docker
    and `curl` installed, as we will need these two tools in some of the stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: With the `args` parameter, we are also mapping the Docker socket into the container
    so that we can use Docker from within the agent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Ignore the options part for the moment. We then are defining three stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: The first stage, `Build`, just runs `npm install` to make sure all external
    dependencies of our app can be installed. If this were, for example, a Java application,
    we would probably also compile and package the application in this step.
  prefs: []
  type: TYPE_NORMAL
- en: In the second stage, `Test`, we run `npm test`, which runs our unit tests that
    we have defined for the sample API.
  prefs: []
  type: TYPE_NORMAL
- en: 'The third stage, `Build & Push Docker image`, is a bit more interesting. Now
    that we have successfully built and tested our application, we can create a Docker
    image for it and push it to a registry. We are using Docker Hub as our registry,
    but any private or public registry would work. In this stage, we define four steps:'
  prefs: []
  type: TYPE_NORMAL
- en: We use Docker to build the image. We use the `$registry` environment variable
    we have defined in the first part of the Jenkinsfile. The `$BUILD_NUMBER` variable is
    defined by Jenkins itself.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Before we can push something to the registry, we need to log in. Here, I am
    using the `$DOCKER_PWD` variable that I defined earlier on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once we're successfully logged in to the registry, we can push the image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since the image is now in the registry, we can delete it from the local cache
    to avoid wasting space.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Remember that all of the stages run inside our `gnschenker/node-docker` builder
    container. Hence, we're running Docker inside Docker. But, since we have mapped
    the Docker socket into the builder, the Docker commands act on the host.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s add two more stages to the pipeline. The first one looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: Add it just after the `Build & Push Docker image` stage. This stage just executes
    a `deploy.sh` script located in the `jenkins/scripts` subfolder. We do not yet
    have such a file in our project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hence, add this file to your project with the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: OK, so this code does the following. First, it tries to remove any artifacts
    that might have been left over from an earlier, failed run of the pipeline. Then,
    it creates a Docker network called `test-net`. Next, it runs a container from
    the image we built in the previous step. This container is our Express JS API
    and is called `api` accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: This container and the application within it may take a moment to be ready.
    Hence, we define some logic that uses the `netcat` or `nc` tool to probe port
    `3000`. Once the application is listening at port `3000`, we continue with the
    smoke test. In our case, the smoke test is just making sure it can access the
    `/` endpoint of our API. We are using `curl` for this task. In a more realistic
    setup, you would run some more sophisticated tests here.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a last stage, we are adding a `Cleanup` step:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following snippet as a last stage to your `Jenkinsfile`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: Once again, this `Cleanup` stage uses a script located in the `jenkins/script` subfolder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Please add such a file to your project with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: This script removes the `api` container and the Docker network, `test-net`,
    that we used to run our containers on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we are ready to roll. Use `git` to commit your changes and push them to
    your repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: Once the code is pushed to GitHub, go back to Jenkins.
  prefs: []
  type: TYPE_NORMAL
- en: 'Select your `sample-pipeline` project and click Build now in the main menu.
    Jenkins will start to build the pipeline. If everything goes well, you should
    see something like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/09e00d85-9229-40a2-bad3-1fbf4e92e1bc.png)'
  prefs: []
  type: TYPE_IMG
- en: Running our full code-based pipeline in Jenkins
  prefs: []
  type: TYPE_NORMAL
- en: Our pipeline is executed successfully and now has six steps. The checkout from
    GitHub has been automatically added as a first enabling step. To access the logs
    generated during the pipeline execution, you can click the little ball icon on
    the left side of the run under Build History. In the preceding screenshot, it
    is the bluish icon on the left of **#26**. This is especially helpful if the pipeline
    step fails to quickly find the root cause of the failure.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, we have built a simple CI/CD pipeline where everything, including
    the automation server, Jenkins, is running in containers. We have only scratched
    the surface of what is possible.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to use Docker containers to optimize various
    kinds of automation tasks, from running a simple one-off task to building up a
    containerized CI/CD pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will introduce advanced tips, tricks, and concepts useful
    when containerizing complex distributed applications or when using Docker to automate
    sophisticated tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Name a few pros and cons for running a one-off task in a container instead of
    directly on the host machine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: List two or three advantages of running tests in containers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sketch a high-level diagram of a containerized CI/CD pipeline, starting from
    the user producing code till the code being deployed into production.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Write Maintainable Integration Tests with Docker at [https://www.docker.com/blog/maintainable-integration-tests-with-docker/](https://www.docker.com/blog/maintainable-integration-tests-with-docker/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Docker Workflow for .NET Developer - Part 2 (Integration Tests) at [https://gabrielschenker.com/index.php/2019/10/09/a-docker-workflow-for-net-developers-part-2/](https://gabrielschenker.com/index.php/2019/10/09/a-docker-workflow-for-net-developers-part-2/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jenkins on Docker Hub at [https://hub.docker.com/_/jenkins/](https://hub.docker.com/_/jenkins/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jenkins Tutorial Overview at [https://jenkins.io/doc/tutorials/](https://jenkins.io/doc/tutorials/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL

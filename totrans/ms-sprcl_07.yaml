- en: Advanced Load Balancing and Circuit Breakers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级负载均衡和断路器
- en: In this chapter, we will continue the subject discussed in the previous chapter,
    inter-service communication. We will extend it to more advanced samples of load
    balancing, timeouts, and circuit breaking.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将继续讨论上一章中讨论的主题，即服务间通信。我们将扩展到更高级的负载均衡、超时和断路器示例。
- en: Spring Cloud provides features that make implementation of communication between
    microservices nice and simple. However, we must not forget that the major difficulties
    we would face with such communication concern the processing time of the systems
    involved. If you have many microservices in your system, one of the first issues
    you need to deal with is the problem of latency. In this chapter, I would like
    to discuss a few Spring Cloud features that help us to avoid latency problems
    that are caused by many hops between services when processing a single input request,
    slow responses from several services, or a temporary unavailability of services.
    There are several strategies for dealing with partial failures. These include
    setting network timeouts, limiting the number of waiting requests, implementing
    different load balancing methods, or setting up a circuit breaker pattern and
    fallback implementation.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud提供了使微服务之间的通信实现变得简单和美好的功能。然而，我们不能忘记，我们在这种通信中可能面临的主要困难是系统处理时间。如果您的系统中有许多微服务，您需要处理的第一个问题之一是延迟问题。在本章中，我想讨论一些Spring
    Cloud功能，这些功能可以帮助我们避免由多个服务之间的跳跃引起的延迟问题，包括处理单个输入请求时的慢响应，或服务的临时不可用性。处理部分失败的策略有几种。这些包括设置网络超时、限制等待请求的数量、实现不同的负载均衡方法，或者设置断路器模式和备用实现。
- en: We will also talk about Ribbon and Feign clients once again, this time focusing
    on their more advanced configuration features. An entirely new library that will
    be introduced here is Netflix Hystrix. This library implements the circuit breaker
    pattern.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将再次讨论Ribbon和Feign客户端，这次将重点放在它们更高级的配置功能上。在这里将介绍一个全新的库，即Netflix Hystrix。该库实现了断路器模式。
- en: 'The topics we will cover in this chapter include the following:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Different load balancing algorithms with Ribbon clients
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Ribbon客户端的不同负载均衡算法
- en: Enabling a circuit breaker for the application
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为应用程序启用断路器
- en: Customizing Hystrix with configuration properties
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用配置属性自定义Hystrix
- en: Monitoring interservice communication with the Hystrix dashboard
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Hystrix仪表板监控服务间通信
- en: Using Hystrix together with Feign clients
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Hystrix与Feign客户端一起使用
- en: Load balancing rules
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 负载均衡规则
- en: 'Spring Cloud Netflix provides different load balancing algorithms in order
    to provide different benefits to the user. Your choice of supported method depends
    on your needs. In the Netflix OSS nomenclature, this algorithm is called a **rule**.
    The custom rule class should have implemented an `IRule` base interface. The following
    implementations are available by default inside Spring Cloud:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Netflix提供了不同的负载均衡算法，以满足用户的不同需求。您选择支持的方法取决于您的需求。在Netflix OSS术语中，此算法称为**规则**。自定义规则类应该实现了`IRule`基接口。以下实现默认包含在Spring
    Cloud中：
- en: '`RoundRobinRule`: This rule simply chooses servers using the well-known round
    robin algorithm, where incoming requests are distributed across all instances
    sequentially. It is often used as the default rule or fallbacks for more advanced
    rules, such as `ClientConfigEnabledRoundRobinRule` and `ZoneAvoidanceRule`. `ZoneAvoidanceRule`
    is the default rule for Ribbon clients.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RoundRobinRule`：此规则简单地使用众所周知的轮询算法选择服务器，其中传入请求按顺序分布到所有实例。它通常用作更高级规则的默认规则或回退规则，例如`ClientConfigEnabledRoundRobinRule`和`ZoneAvoidanceRule`。`ZoneAvoidanceRule`是Ribbon客户端的默认规则。'
- en: '`AvailabilityFilteringRule`: This rule will skip servers that are marked as
    circuit tripped or with a high number of concurrent connections. It also uses
    `RoundRobinRule` as a base class. By default, an instance is circuit tripped if
    an HTTP client fails to establish a connection with it three times in a row. This
    approach may be customized with the `niws.loadbalancer.<clientName>.connectionFailureCountThreshold` property.
    Once an instance is circuit tripped, it will remain in this state for the next
    30 seconds before the next retry. This property may also be overridden in the
    configuration settings.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AvailabilityFilteringRule`: 此规则将跳过标记为电路跳闸或具有高并发连接数的服务器。它还使用`RoundRobinRule`作为基类。默认情况下，如果HTTP客户端连续三次未能与实例建立连接，则实例将被视为电路跳闸。此方法可以通过`niws.loadbalancer.<clientName>.connectionFailureCountThreshold`属性进行自定义。一旦实例被视为电路跳闸，它将在下一次重试之前保持在此状态30秒。此属性也可以在配置设置中被覆盖。'
- en: '`WeightedResponseTimeRule`: With this implementation, a traffic volume forwarder
    to the instance is inversely proportional to the instance''s average response
    time. In other words, the longer the response time, the less weight it will get.
    In these circumstances, a load balancing client will record the traffic and response
    time of every instance of the service.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`WeightedResponseTimeRule`：使用此实现，流量量转发到实例与实例的平均响应时间成反比。换句话说，响应时间越长，获得的权重就越小。在这种情况下，负载均衡客户端将记录服务的每个实例的流量和响应时间。'
- en: '`BestAvailableRule`: According to the description from the class documentation,
    this rule skips servers with *tripped* circuit breakers and picks the server with
    the lowest concurrent requests.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BestAvailableRule`：根据类文档中的描述，此规则将跳过具有*跳闸*的服务器，并选择具有最低并发请求的服务器。'
- en: Tripped circuit breaker is a term taken from electrical engineering, and means
    that there's no current flowing through a circuit. In IT terminology, it refers
    to the situation where too many consecutive requests that are sent to a service
    fail, and therefore any further attempts to invoke the remote service will be
    interrupted immediately by the software on the client side in order to relieve
    the server-side application.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 跳闸是从电气工程中借来的一个术语，意思是电路中没有电流流动。在IT术语中，它指的是发送到服务的太多连续请求失败的情况，因此任何进一步尝试调用远程服务都将立即被客户端软件中断，以便解除服务器端应用程序的压力。
- en: The WeightedResponseTime rule
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加权响应时间规则
- en: Until now, we have usually tested our services manually by calling them from
    a web browser or a REST client. The current changes do not allow such an approach
    because we need to set fake delays for the services, as well as generate many
    HTTP requests.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们通常通过从Web浏览器或REST客户端调用服务来手动测试我们的服务。当前的更改不允许这样的方法，因为我们需要为服务设置虚假延迟，并生成许多HTTP请求。
- en: Introducing Hoverfly for testing
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入Hoverfly进行测试
- en: 'At this point, I would like to introduce an interesting framework that may
    be a perfect solution for these kinds of tests. I am talking about Hoverfly, a
    lightweight service virtualization tool that is used to stub or simulate HTTP
    services. It is originally written in Go, but also gives you an expressive API
    for managing Hoverfly in Java. Hoverfly Java, maintained by SpectoLabs, provides
    classes that abstract away the binary and API calls, a DSL for creating simulations,
    and an integration with the JUnit test framework. This framework has a feature
    that I really like. You may easily add a delay to every simulated service by calling
    one method in your DSL definition. To enable Hoverfly for your project, you have
    to include the following dependency in your Maven `pom.xml`:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我想介绍一个有趣的框架，它可能是这类测试的完美解决方案。我在谈论Hoverfly，这是一个轻量级的服务虚拟化工具，用于存根或模拟HTTP服务。它最初是用Go编写的，但也为您提供了一个用于在Java中管理Hoverfly的表达式API。由SpectoLabs维护的Hoverfly
    Java提供了抽象二进制和API调用的类，用于创建模拟的DSL，以及与JUnit测试框架的集成。这个框架有一个我真的很喜欢的功能。您可以通过在DSL定义中调用一个方法轻松地为每个模拟服务添加延迟。要为项目启用Hoverfly，您必须在Maven的`pom.xml`中包含以下依赖项：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Testing the rule
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试规则
- en: The sample we are discussing here is available on GitHub. To access it, you
    have to switch to  `weighted_lb` branch ([https://github.com/piomin/sample-spring-cloud-comm/tree/weighted_lb](https://github.com/piomin/sample-spring-cloud-comm/tree/weighted_lb)).
    Our JUnit test class, called `CustomerControllerTest`, is available under the `src/test/java`
    directory. To enable Hoverfly for the test, we should define the JUnit `@ClassRule`.
    The `HoverflyRule` class provides an API that allows us to simulate many services
    with different addresses, characteristics, and responses. In the following source
    code fragment, you may see that two instances of our sample microservice `account-service`
    have been declared inside `@ClassRule`.  As you probably remember, that service
    has been invoked by `customer-service` and `order-service`.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在讨论的示例可以在GitHub上找到。要访问它，您必须切换到`weighted_lb`分支（[https://github.com/piomin/sample-spring-cloud-comm/tree/weighted_lb](https://github.com/piomin/sample-spring-cloud-comm/tree/weighted_lb)）。我们的JUnit测试类`CustomerControllerTest`位于`src/test/java`目录下。要为测试启用Hoverfly，我们应该定义JUnit的`@ClassRule`。`HoverflyRule`类提供了一个API，允许我们模拟具有不同地址、特征和响应的许多服务。在下面的源代码片段中，您可以看到我们的示例微服务`account-service`的两个实例已经在`@ClassRule`中声明。您可能还记得，该服务已被`customer-service`和`order-service`调用。
- en: 'Let''s take a look at a test class from the `customer-service` module. It simulates
    the `GET /customer/*` method with a predefined response for two instances of `account-service` available
    on ports `8091` and `9091`. The first of them has been delayed by `200` milliseconds,
    while the second is delayed by `50` milliseconds:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下`customer-service`模块中的一个测试类。它模拟了`account-service`的两个实例在端口`8091`和`9091`上的`GET
    /customer/*`方法的预定义响应。其中一个被延迟了`200`毫秒，而另一个被延迟了`50`毫秒：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Before running the test, we should also modify the `ribbon.listOfServers` configuration
    file by changing it to `listOfServers: account-service:8091, account-service:9091`.
    We should only make such a modification when working with Hoverfly.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '在运行测试之前，我们还应该通过将`ribbon.listOfServers`配置文件修改为`listOfServers: account-service:8091,
    account-service:9091`来修改。只有在使用Hoverfly时才应进行此修改。'
- en: 'Here''s a `test` method that invokes the `GET /withAccounts/ {id}` endpoint
    exposed by `customer-service` a thousand times. This, in turn, invokes the `GET
    customer/{customerId}` endpoint from `account-service`, with a list of accounts
    owned by the customer. Every request is load balanced between two instances of
    `account-service` using `WeightedResponseTimeRule`:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个`test`方法，它调用了`customer-service`公开的`GET /withAccounts/ {id}`端点一千次。这反过来又调用了`account-service`的`GET
    customer/{customerId}`端点，其中包含客户拥有的账户列表。每个请求都使用`WeightedResponseTimeRule`在两个`account-service`实例之间进行负载平衡：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The method of working with a weighted response rule implementation is really
    interesting. Just after starting the test, the incoming requests are load balanced
    at a ratio of 50:50 between two instances of `account-service`. But, after some
    time, most of them are forwarded to the instance with the lesser delay.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 使用加权响应规则实现的方法真的很有趣。在测试开始后不久，传入的请求在两个`account-service`实例之间以50:50的比例进行负载平衡。但是，过一段时间后，大部分请求都被转发到延迟较小的实例。
- en: Finally, 731 requests were processed by the instance available on port  `9091` and
    269 by the instance at port `8091` for a JUnit test launched on my local machine. However,
    at the end of the test, the proportion looked a bit different and was weighted
    in favor of the instance with the lesser delay, where incoming traffic is divided
    4:1 between the two instances.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我的本地机器上启动的JUnit测试在`9091`端口上的实例处理了731个请求，而在`8091`端口上的实例处理了269个请求。然而，在测试结束时，比例看起来有点不同，并且更倾向于延迟较小的实例，其中传入流量在两个实例之间以4:1的比例分配。
- en: 'Now, we will change our test case a little by adding a third instance of `account-service`
    with a big delay of around 10 seconds. This modification aims to simulate a timeout
    in HTTP communication. Here''s the fragment from the JUnit `@ClassRule` definition
    with the newest service instance listening on port `10091`:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将通过添加一个延迟约10秒的`account-service`的第三个实例来稍微改变我们的测试用例。这个修改旨在模拟HTTP通信中的超时。以下是JUnit`@ClassRule`定义中的片段，最新的服务实例监听端口`10091`：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We should accordingly perform a change in the Ribbon configuration to enable
    load balancing to the newest instance of `account-service`:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们应该对Ribbon配置进行更改，以便将负载均衡到`account-service`的最新实例：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The last thing that has to be changed, but which is left as it is in the previous
    test case, is the `RestTemplate` bean declaration. In this instance, I have set
    both the read and the connect timeout to one second because the third instance
    of `account-service` launched during the test is delayed by 10 seconds. Every
    request sent there would be terminated by the timeout after one second:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 必须更改的最后一件事，但在以前的测试用例中保持不变的是`RestTemplate` bean声明。在这种情况下，我将读取和连接超时都设置为1秒，因为测试期间启动的`account-service`的第三个实例延迟了10秒。发送到那里的每个请求都将在1秒后超时终止：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If you run the same test as before, the result would not be satisfactory. The
    distribution between all declared instances will be 420, processed by the instance
    listening on port `8091` (with a delay of `200` milliseconds), 468, processed
    by the instance listening on port `9091` (with a delay of `50` milliseconds),
    and 112 sent to the third instance, terminated by the timeout. Why am I quoting
    all these statistics? We may change a default load balancing rule from `WeightedResponseTimeRule`
    to `AvailabilityFilteringRule` and rerun the test. If we do this, 496 requests
    will be sent to both the first and second instance, while only 8 will be sent
    to the third instance, with a one second timeout. Interestingly, if you set `BestAvailableRule`
    as the default rule, all requests would be sent to the first instance.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您运行与之前相同的测试，结果将不尽人意。所有声明的实例之间的分布将是420，由监听端口`8091`的实例处理（延迟`200`毫秒），468，由监听端口`9091`的实例处理（延迟`50`毫秒），以及112发送到第三个实例，由超时终止。为什么我引用所有这些统计数据？我们可以将默认的负载均衡规则从`WeightedResponseTimeRule`更改为`AvailabilityFilteringRule`并重新运行测试。如果我们这样做，将有496个请求发送到第一个和第二个实例，而只有8个请求发送到第三个实例，超时为1秒。有趣的是，如果将`BestAvailableRule`设置为默认规则，则所有请求都将发送到第一个实例。
- en: Now that you have read through this example, you can easily see the differences
    between all available load balancing rules for the Ribbon client.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经阅读了这个例子，您可以很容易地看到Ribbon客户端的所有可用负载均衡规则之间的区别。
- en: Customizing the Ribbon client
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义Ribbon客户端
- en: 'Several configuration settings of the Ribbon client may be overridden with
    Spring bean declarations. As with Feign, it should be declared in the client annotation
    field named configuration, for example,`@RibbonClient(name = "account-service",
    configuration = RibbonConfiguration.class)`. The following features may be customized
    with this approach:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Ribbon客户端的几个配置设置可以通过Spring bean声明进行覆盖。与Feign一样，它应该在名为configuration的客户端注解字段中声明，例如`@RibbonClient(name
    = "account-service", configuration = RibbonConfiguration.class)`。可以使用这种方法自定义以下功能：
- en: '`IClientConfig`: The default implementation of this is `DefaultClientConfigImpl`.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IClientConfig`：这个的默认实现是`DefaultClientConfigImpl`。'
- en: '`IRule`: This component is used to determine which service instance should
    be selected from a list. The `ZoneAvoidanceRule` implementation class is auto-configured.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IRule`：此组件用于确定应从列表中选择哪个服务实例。`ZoneAvoidanceRule`实现类是自动配置的。'
- en: '`IPing`: This is a component that runs in the background. It is responsible
    for ensuring that the instances of service are running.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IPing`：这是在后台运行的组件。它负责确保服务的实例正在运行。'
- en: '`ServerList<Server>`: This can be static or dynamic. If it is dynamic (as used
    by `DynamicServerListLoadBalancer`), a background thread will refresh and filter
    the list at a predefined interval. By default, Ribbon uses a static list of servers
    taken from configuration file. It is implemented by  `ConfigurationBasedServerList`.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ServerList<Server>`：可以是静态的也可以是动态的。如果是动态的（由`DynamicServerListLoadBalancer`使用），后台线程将在预定义的间隔刷新和过滤列表。默认情况下，Ribbon使用从配置文件中获取的服务器的静态列表。它由`ConfigurationBasedServerList`实现。'
- en: '`ServerListFilter<Server>`: `ServerListFilter` is a component used by `DynamicServerListLoadBalancer`
    to filter the servers returned from a `ServerList` implementation. There are two
    implementations of that interface—auto-configured `ZonePreferenceServerListFilter`
    and `ServerListSubsetFilter`.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ServerListFilter<Server>`：`ServerListFilter`是`DynamicServerListLoadBalancer`使用的一个组件，用于过滤从`ServerList`实现返回的服务器。该接口有两个实现——自动配置的`ZonePreferenceServerListFilter`和`ServerListSubsetFilter`。'
- en: '`ILoadBalancer`: This is responsible for performing load balancing between
    available instances of a service on the client side. By default, Ribbon uses `ZoneAwareLoadBalancer`.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ILoadBalancer`：这负责在客户端之间执行服务的可用实例之间的负载均衡。默认情况下，Ribbon使用`ZoneAwareLoadBalancer`。'
- en: '`ServerListUpdater`: This is responsible for updating the list of available
    instances of a given application. By default, Ribbon uses `PollingServerListUpdater`.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ServerListUpdater`：这负责更新给定应用程序的可用实例列表。默认情况下，Ribbon使用`PollingServerListUpdater`。'
- en: 'Let''s look at an example configuration class that defines the default implementation
    of the `IRule` and `IPing` components. Such a configuration may be defined for
    a single Ribbon client, as well as for all Ribbon clients available in the application
    classpath, by providing the `@RibbonClients(defaultConfiguration = RibbonConfiguration.class)` annotation:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个定义了`IRule`和`IPing`组件的默认实现的示例配置类。可以通过提供`@RibbonClients(defaultConfiguration
    = RibbonConfiguration.class)`注解，为单个Ribbon客户端以及应用程序类路径中的所有Ribbon客户端定义这样的配置：
- en: '[PRE6]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Even if you don''t have any experience with Spring, you may probably have guessed
    (based on the previous samples) that the configuration can also be customized
    using the `properties` file. In that case, Spring Cloud Netflix is compatible
    with the properties described in the Ribbon documentation provided by Netflix.
    The following classes are the supported properties, and they should be prefixed
    by `<clientName>.ribbon`, or, if they apply to all clients, by `ribbon`:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您没有使用Spring的经验，您可能已经猜到（基于前面的示例）可以使用`properties`文件来自定义配置。在这种情况下，Spring Cloud
    Netflix与Netflix提供的Ribbon文档中描述的属性兼容。以下类是受支持的属性，并且它们应该以`<clientName>.ribbon`为前缀，或者如果它们适用于所有客户端，则为`ribbon`：
- en: '`NFLoadBalancerClassName`: `ILoadBalancer` default implementation class'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NFLoadBalancerClassName`：`ILoadBalancer`默认实现类'
- en: '`NFLoadBalancerRuleClassName`: `IRule` default implementation class'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NFLoadBalancerRuleClassName`：`IRule`默认实现类'
- en: '`NFLoadBalancerPingClassName`: `IPing` default implementation class'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NFLoadBalancerPingClassName`：`IPing`默认实现类'
- en: '`NIWSServerListClassName`: `ServerList` default implementation class'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NIWSServerListClassName`：`ServerList`默认实现类'
- en: '`NIWSServerListFilterClassName`: `ServerListFilter` default implementation
    class'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NIWSServerListFilterClassName`：`ServerListFilter`默认实现类'
- en: 'Here''s a similar sample to the preceding `@Configuration` class that overrides
    the `IRule` and `IPing` default implementations used by the Spring Cloud application:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个类似于前面的`@Configuration`类的示例，它覆盖了Spring Cloud应用程序使用的`IRule`和`IPing`默认实现：
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The circuit breaker pattern with Hystrix
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Hystrix的断路器模式
- en: We have already discussed the different implementations of load balancer algorithms
    in Spring Cloud Netflix. Some of them are based on monitoring the instance response
    time or the number of failures. In these cases, a load balancer makes decisions
    about which instance should be invoked based on these statistics. The circuit
    breaker pattern should be treated as an extension of that solution. The main idea
    behind a circuit breaker is very simple. A protected function call is wrapped
    in a circuit breaker object, which is responsible for monitoring a number of failure
    calls. If the failures reach a threshold, the circuit is opened, and all further
    calls will be failed automatically. Usually, it is also desirable to have some
    kind of monitor alert if a circuit breaker trips. Some crucial benefits derived
    from the usage of the circuit breaker pattern in your applications are the ability
    to continue operating when a related service fails, the prevention of a cascaded
    failure, and giving a failing service time to recover.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了Spring Cloud Netflix中负载均衡算法的不同实现。其中一些基于监视实例响应时间或失败次数。在这些情况下，负载均衡器根据这些统计数据做出决定，决定调用哪个实例。断路器模式应该被视为该解决方案的扩展。断路器背后的主要思想非常简单。受保护的函数调用被包装在一个断路器对象中，该对象负责监视一定数量的失败调用。如果失败达到阈值，断路器就会打开，并且所有后续调用将自动失败。通常，如果断路器跳闸，也希望有某种监视警报。在您的应用程序中使用断路器模式带来的一些关键好处包括在相关服务失败时继续运行，防止级联故障，并给失败的服务恢复的时间。
- en: Building an application with Hystrix
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Hystrix构建应用程序
- en: 'Netflix provides an implementation of the circuit breaker pattern in their
    library called **Hystrix**. That library has also been included as a default implementation
    of the circuit breaker for Spring Cloud. Hystrix has some other interesting features,
    and should also be treated as a comprehensive tool for dealing with latency and
    fault tolerance for distributed systems. What is important is that if the circuit
    breaker is opened, Hystrix redirects all calls to the specified fallback method.
    The fallback method is designed to provide a generic response without any dependency
    on a network, usually read from an in-memory cache or just implemented as static
    logic. If it becomes necessary to perform a network call, it is recommended that
    you implement it using another `HystrixCommand` or `HystrixObservableCommand`.
    To include Hystrix in your project, you should use the `spring-cloud-starter-netflix-hystrix`
    or `spring-cloud-starter-hystrix` starter for Spring Cloud Netflix versions older
    than 1.4.0:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Netflix在他们的库中提供了断路器模式的实现，称为**Hystrix**。该库也作为Spring Cloud的断路器的默认实现被包含在其中。Hystrix还具有一些其他有趣的特性，并且应该被视为处理分布式系统的延迟和容错的综合工具。重要的是，如果断路器打开，Hystrix会将所有调用重定向到指定的备用方法。备用方法旨在提供一个通用的响应，而不依赖于网络，通常从内存缓存中读取或者只是作为静态逻辑实现。如果需要执行网络调用，建议使用另一个`HystrixCommand`或`HystrixObservableCommand`来实现。要在项目中包含Hystrix，您应该使用`spring-cloud-starter-netflix-hystrix`或`spring-cloud-starter-hystrix`作为Spring
    Cloud Netflix版本1.4.0之前的starter：
- en: '[PRE8]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Implementing Hystrix's commands
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施Hystrix的命令
- en: 'Spring Cloud Netflix Hystrix looks for a method that is annotated with the
    `@HystrixCommand` annotation, and then wraps it in a proxy object connected to
    a circuit breaker. Thanks to this, Hystrix is able to monitor all calls of such
    a method. This annotation currently works only for a class marked with `@Component`
    or `@Service`. That''s important information for us, because we have implemented
    the logic related to other services calling in all the previous samples inside
    the REST controller class, which is marked with the `@RestController` annotation.
    So, in the `customer-service` application, all that logic has been moved to the
    newly created `CustomerService` class, which is then injected into the controller
    bean. The method responsible for communication with `account-service` has been
    annotated with `@HystrixCommand`. I have also implemented a fallback method, the
    name of which passes into the `fallbackMethod` annotation''s field. This method only returns
    an empty list:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Netflix Hystrix寻找一个用`@HystrixCommand`注释的方法，然后将其包装在与断路器连接的代理对象中。由于这样，Hystrix能够监视所有这样的方法的调用。这个注解目前只适用于标有`@Component`或`@Service`的类。这对我们来说是重要的信息，因为我们在所有之前的示例中已经在标有`@RestController`注解的REST控制器类中实现了与其他服务调用相关的逻辑。因此，在`customer-service`应用程序中，所有这些逻辑已经移动到新创建的`CustomerService`类中，然后将其注入到控制器bean中。负责与`account-service`通信的方法已经用`@HystrixCommand`注释。我还实现了一个备用方法，其名称传递到`fallbackMethod`注释字段中。这个方法只返回一个空列表：
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Don''t forget to mark your main class with `@EnableHystrix`, which is needed
    to tell Spring Cloud that it should use circuit breakers for the application.
    We may also optionally annotate a class with `@EnableCircuitBreaker`, which does
    the same. For test purposes, the `account-service.ribbon.listOfServers` property should
    have included the network addresses of two instances of the `localhost:8091, localhost:9091` service.
    Although we have declared two instances of `account-service` for the Ribbon client,
    we will start the only one that is available on the `8091` port. If you call the `customer-service`
    method `GET http://localhost:8092/withAccounts/{id}`, Ribbon will try to load
    balance every incoming request between those two declared instances, that is,
    once you receive the response containing a list of accounts and the second time
    you receive an empty account list, or vice versa. This is illustrated by the following
    fragment of the application logs. This is illustrated by the following fragment
    of application''s logs. To access the sample application''s source code, you should
    switch to the `hystrix_basic` branch ([https://github.com/piomin/sample-spring-cloud-comm/tree/hystrix_basic](https://github.com/piomin/sample-spring-cloud-comm/tree/hystrix_basic))
    in the same GitHub repository as the samples from the previous chapter:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记用`@EnableHystrix`标记你的主类，这是告诉Spring Cloud应用程序应该使用断路器的必要条件。我们还可以选择用`@EnableCircuitBreaker`注释一个类，它也是一样的。为了测试目的，`account-service.ribbon.listOfServers`属性应该包含`localhost:8091,
    localhost:9091`服务的两个实例的网络地址。尽管我们已经为Ribbon客户端声明了两个`account-service`实例，但我们将启动仅在`8091`端口可用的实例。如果您调用`customer-service`方法`GET
    http://localhost:8092/withAccounts/{id}`，Ribbon将尝试在这两个声明的实例之间负载均衡每个传入的请求，也就是说，一次您收到包含账户列表的响应，第二次您收到一个空的账户列表，或者反之亦然。这在应用程序日志的以下片段中有所说明。要访问示例应用程序的源代码，您应该切换到相同GitHub存储库中的`hystrix_basic`分支（[https://github.com/piomin/sample-spring-cloud-comm/tree/hystrix_basic](https://github.com/piomin/sample-spring-cloud-comm/tree/hystrix_basic)）：
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Implementing fallback with cached data
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用缓存数据实现备用
- en: 'The fallback implementation presented in the previous example is very simple.
    Returning an empty list does not make much sense for an application running in
    production. It makes more sense to use the fallback method in your application
    when you read data from a cache in case of a request failure, for example. Such
    a cache may be implemented inside the client application or with the use of third-party
    tools, such as Redis, Hazelcast, or EhCache. The simplest implementation is available
    within the Spring Framework, and can be used after including the `spring-boot-starter-cache` artifact with your
    dependencies. To enable caching for the Spring Boot application, you should annotate
    the main or configuration class with `@EnableCaching` and provide the `CacheManager`
    bean in the following context:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中呈现的备用实现非常简单。返回一个空列表对于在生产中运行的应用程序来说并没有太多意义。当请求失败时，例如在从缓存中读取数据时，更有意义的是在应用程序中使用备用方法。这样的缓存可以在客户端应用程序内部实现，也可以使用第三方工具，如Redis、Hazelcast或EhCache来实现。最简单的实现方式可以在Spring
    Framework中找到，并且可以在包含`spring-boot-starter-cache`依赖项后使用。要为Spring Boot应用程序启用缓存，您应该在主类或配置类上注释`@EnableCaching`，并在以下上下文中提供`CacheManager`
    bean：
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Then you can mark the method wrapped with the circuit breaker using the `@CachePut`
    annotation. This will add the result returning from the calling method to the
    cache map. In that case, our map is named `accounts`. Finally, you may read the
    data inside your fallback method implementation by invoking the `CacheManager`
    bean directly. If you retry the same request a couple of times, you will see that
    the empty list of accounts is no longer returned as a response. Instead, the service
    always returns data that is cached during the first successful call:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以使用`@CachePut`注释标记使用断路器包装的方法。这将把从调用方法返回的结果添加到缓存映射中。在这种情况下，我们的映射名为`accounts`。最后，您可以通过直接调用`CacheManager`
    bean来读取备用方法实现中的数据。如果您多次重试相同的请求，您会发现不再返回空的账户列表作为响应。相反，服务总是返回在第一次成功调用期间缓存的数据：
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The tripping circuit breaker
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跳闸断路器
- en: Let me suggest an exercise for you to do. Until now, you have learned how to
    enable and implement circuit breakers in your application using Hystrix, in conjunction
    with Spring Cloud, and how to use a fallback method to take data from the cache.
    But you still have not used a tripped circuit breaker to prevent the failure instance
    from being invoked by a load balancer. Now, I would like to configure Hystrix
    to open the circuit after three failed call attempts if the failure percentage
    is greater than `30` percent and prevent the API method from being called for
    the next 5 seconds. The measurement time window is around `10` seconds. To meet
    these requirements, we have to override several default Hystrix configuration
    settings. It may be performed using the `@HystrixProperty` annotation inside `@HystrixCommand`.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我建议你做一个练习。到目前为止，您已经学会了如何使用Hystrix和Spring Cloud在应用程序中启用和实现断路器，并且如何使用回退方法从缓存中获取数据。但是，您还没有使用触发的断路器来防止负载均衡器调用失败实例。现在，我想配置Hystrix，在失败调用尝试三次后，如果失败百分比大于`30`％，则打开断路器，并阻止API方法在接下来的5秒内被调用。测量时间窗口大约为`10`秒。为了满足这些要求，我们必须覆盖几个默认的Hystrix配置设置。可以使用`@HystrixCommand`内的`@HystrixProperty`注解来执行此操作。
- en: 'Here''s the current implementation of the method responsible for getting the
    account list from `customer-service`:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这是负责从`customer-service`获取账户列表的方法的当前实现：
- en: '[PRE13]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The full list of Hystrix''s configuration properties is available on Netflix''s
    GitHub site at[ https://github.com/Netflix/Hystrix/wiki/Configuration](https://github.com/Netflix/Hystrix/wiki/Configuration).
    I won''t discuss all of them, only the most important properties for communication
    between microservices. Here''s the list of the properties used in our sample,
    along with their descriptions:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Hystrix的完整配置属性列表可在Netflix的GitHub网站[https://github.com/Netflix/Hystrix/wiki/Configuration](https://github.com/Netflix/Hystrix/wiki/Configuration)上找到。我不会讨论所有这些属性，只会讨论微服务之间通信最重要的属性。以下是我们示例中使用的属性列表及其描述：
- en: '`execution.isolation.thread.timeoutInMilliseconds`: This property sets the
    time in milliseconds, after which a read or connect timeout will occur and the
    client will walk away from the command execution. Hystrix marks such a method
    call as a failure, and performs fallback logic. That timeout may be completely
    turned off by setting the `command.timeout.enabled` property to `false`. The default
    is 1,000 milliseconds.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`execution.isolation.thread.timeoutInMilliseconds`: 此属性设置了以毫秒为单位的时间，在此之后读取或连接超时将发生，客户端将放弃命令执行。Hystrix将这样的方法调用标记为失败，并执行回退逻辑。可以通过将`command.timeout.enabled`属性设置为`false`来完全关闭超时。默认值为1,000毫秒。'
- en: '`circuitBreaker.requestVolumeThreshold`: This property sets the minimum number
    of requests in a rolling window that will trip the circuit. The default value
    is 20\. In our sample, this property is set to `10`, which means that the first
    nine will not trip the circuit, even if all of them fail. I set that value because
    we have assumed that the circuit should be opened if `30` percent of incoming
    requests fail, but the minimum number of incoming requests is three.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`circuitBreaker.requestVolumeThreshold`: 此属性设置在滚动窗口中将触发断路器的最小请求数。默认值为20。在我们的示例中，此属性设置为`10`，这意味着前九个请求即使全部失败也不会触发断路器。我设置了这个值，因为我们假设如果`30`％的传入请求失败，断路器应该打开，但最小的传入请求数量是三个。'
- en: '`circuitBreaker.errorThresholdPercentage`: This property sets the minimum error
    percentage. Exceeding this percentage results in opening the circuit, and the
    system starts short-circuiting requests to fallback logic. The default value is
    50\. I set it to `30` because, in our sample, I want `30` percent of failed requests
    should open the circuit.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`circuitBreaker.errorThresholdPercentage`: 此属性设置了最小错误百分比。超过此百分比会导致断路器打开，并且系统开始将请求短路到回退逻辑。默认值为50。我将其设置为`30`，因为在我们的示例中，我希望`30`％的失败请求会打开断路器。'
- en: '`circuitBreaker.sleepWindowInMilliseconds`: This property sets a period of
    time between tripping the circuit and allowing attempts taken in order to determine
    whether the circuit should be closed again. During this time, all incoming requests
    are rejected. The default value is `5,000`. Because we would like to wait `10`
    seconds before the first call is retired after the circuit has been opened, I
    set it to `10,000`.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`circuitBreaker.sleepWindowInMilliseconds`: 此属性设置了在触发断路器和允许尝试以确定是否应再次关闭断路器之间的时间段。在此期间，所有传入请求都将被拒绝。默认值为`5,000`。因为我们希望在断路器打开后等待`10`秒后第一次调用被撤销，所以我将其设置为`10,000`。'
- en: '`metrics.rollingStats.timeInMilliseconds`: This property sets the duration
    of the statistical rolling window in milliseconds. This is how long Hystrix keeps
    metrics for the circuit breaker to use, and for publishing.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metrics.rollingStats.timeInMilliseconds`: 此属性设置了以毫秒为单位的统计滚动窗口的持续时间。这是Hystrix保留断路器使用和发布的指标的时间。'
- en: 'With these settings, we may run the same JUnit test as for the previous example.
    We launch two stubs of `account-service` using `HoverflyRule`. The first of them
    would be delayed by 200 milliseconds, while a second one that is delayed by 2,000
    milliseconds is greater than the timeout set for `@HystrixCommand` with the `execution.isolation.thread.timeoutInMilliseconds` property.
    After running JUnit `CustomerControllerTest`, take a look at the printed logs.
    I have inserted the logs taken from the test launched on my machine. The first
    request from `customer-service` is load balanced to the first instance, delayed
    by 200 ms `(1)`. Every request sent to the instance available on `9091` finishes
    with a timeout after one second. After sending 10 requests, the first failure
    causes a trip of the circuit `(2)`. Then, for the next 10 seconds, every single
    request is handled by a fallback method, which returns cached data `(3)`, `(4)`.
    After 10 seconds, the client tries to call an instance of `account-service` again
    and succeeds `(5)` because it hits on the instance delayed by 200 ms. That success
    results in the closure of the circuit. Unfortunately, the second instance of `account-service`
    still responds slowly, so the scenario happens all over again until the JUnit
    test finishes `(6)` and `(7)`. This detailed description shows you exactly how
    a circuit breaker with Hystrix works for Spring Cloud:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些设置，我们可以运行与之前示例相同的JUnit测试。我们使用`HoverflyRule`启动了两个`account-service`的存根。其中一个会延迟200毫秒，而另一个延迟2,000毫秒，大于`@HystrixCommand`中设置的`execution.isolation.thread.timeoutInMilliseconds`属性的超时时间。运行完JUnit的`CustomerControllerTest`后，查看打印的日志。我已经插入了从我的机器上运行的测试中获取的日志。来自`customer-service`的第一个请求被负载均衡到第一个实例，延迟了200毫秒`(1)`。发送到`9091`端口的每个请求在一秒后超时。在发送了10个请求后，第一个故障导致断路器跳闸`(2)`。然后，在接下来的10秒内，每个请求都由一个回退方法处理，该方法返回缓存的数据`(3)`，`(4)`。10秒后，客户端再次尝试调用`account-service`的实例，并成功`(5)`，因为它命中了延迟200毫秒的实例。这一成功导致断路器关闭。不幸的是，`account-service`的第二个实例仍然响应缓慢，因此这种情况会一再发生，直到JUnit测试完成`(6)`和`(7)`。这个详细的描述确切地展示了Hystrix断路器在Spring
    Cloud中的工作原理：
- en: '[PRE14]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Monitoring latency and fault tolerance
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控延迟和容错
- en: As I have already mentioned, Hystrix is not only a simple tool implementing
    a circuit breaker pattern. It is a solution that deals with latency and fault
    tolerance in distributed systems. One interesting feature provided by Hystrix
    is the ability to expose the most important metrics related to interservice communication
    and display them using a UI dashboard. This function is available for clients
    wrapped with the Hystrix command.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我已经提到的，Hystrix不仅仅是一个实现断路器模式的简单工具。它是一个处理分布式系统中延迟和容错的解决方案。Hystrix提供的一个有趣的功能是能够公开与服务之间通信相关的最重要的指标，并使用UI仪表板显示它们。这个功能适用于使用Hystrix命令包装的客户端。
- en: In some previous samples, we have analyzed only a part of our system to simulate
    a delay in communication between `customer-service` and `account-service`. That's
    a really good approach when testing advanced load balancing algorithms or different
    circuit breaker configuration settings, but now we will go back to analyzing the
    whole of our sample system setup as a set of standalone Spring Boot applications.
    This allows us to observe how Spring Cloud, in conjunction with Netflix OSS tools,
    helps us to monitor and react to latency issues and failures in communication
    between our microservices. The sample system simulates a failure in a simple way.
    It has a static configuration with the network addresses of two instances, `account-service`,
    and `product-service`, but only one of them for each service is running.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的一些示例中，我们只分析了系统的一部分，以模拟`customer-service`和`account-service`之间通信延迟。这是在测试高级负载平衡算法或不同断路器配置设置时的一个很好的方法，但现在我们将回到将我们的示例系统设置作为一组独立的Spring
    Boot应用程序进行分析。这使我们能够观察Spring Cloud与Netflix OSS工具如何帮助我们监视和应对微服务之间的通信延迟和故障。示例系统以简单的方式模拟了故障。它具有静态配置，其中包含两个实例的网络地址，`account-service`和`product-service`，但每个服务只有一个实例在运行。
- en: 'In order to refresh your memory, the architecture of our sample system, taking
    into consideration assumptions about failure, is shown in the following diagram:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了刷新您的记忆，考虑到关于故障的假设，我们示例系统的架构如下图所示：
- en: '![](img/ce848d7e-8834-48f2-885f-273126e8aa5c.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ce848d7e-8834-48f2-885f-273126e8aa5c.png)'
- en: 'This time, we''ll begin a bit differently, with a test. Here''s the fragment
    of the test method, which is being invoked in a loop. First, it calls the `POST
    http://localhost:8090/` endpoint from `order-service`, sending an `Order` object,
    and it receives a response with the `id`, `status`, and `price` set. Within that
    request, which has been labeled in the preceding diagram as `(1)`, `order-service`
    communicates with `product-service `and `customer-service` and, in addition, `customer-service`
    calls the endpoint from `account-service`. If the order has been accepted, the
    test client calls the `PUT http://localhost:8090/{id}` method with the order''s `id`
    to accept it and withdraw funds from the account. On the server side, there is
    only one interservice communication in that case, which is labeled `(2)` in the
    preceding diagram. Before running this test, you have to launch all microservices
    that are a part of our system:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，我们将以不同的方式开始，进行一项测试。以下是测试方法的片段，它在循环中被调用。首先，它调用`order-service`的`POST http://localhost:8090/`端点，发送一个`Order`对象，并接收设置了`id`、`status`和`price`的响应。在该请求中，被标记为`(1)`的前面图表中，`order-service`与`product-service`和`customer-service`进行通信，此外，`customer-service`调用`account-service`的端点。如果订单已被接受，测试客户端将调用`PUT
    http://localhost:8090/{id}`方法来接受订单并从账户中提取资金。在服务器端，这种情况下只有一个服务之间的通信，被标记为前面图表中的`(2)`。在运行此测试之前，您必须启动我们系统中的所有微服务：
- en: '[PRE15]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Exposing Hystrix's metrics stream
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 暴露Hystrix的指标流
- en: 'Each microservice that uses Hystrix in communication with other microservices
    may expose metrics of every integration wrapped with the Hystrix command. To enable
    such a metrics stream, you should include a dependency on `spring-boot-starter-actuator`.
    This will expose the `/hystrix.stream` object as a management endpoint. It is
    also necessary to include `spring-cloud-starter-hystrix`, which has already been
    added to our sample application:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 每个使用Hystrix与其他微服务通信的微服务都可以公开每个集成的指标，这些指标都包装在Hystrix命令中。要启用这样的指标流，您应该包含`spring-boot-starter-actuator`的依赖项。这将公开`/hystrix.stream`对象作为管理端点。还需要包含`spring-cloud-starter-hystrix`，它已经添加到我们的示例应用程序中：
- en: '[PRE16]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'A generated stream is exposed as further JSON entries containing metrics characterizing
    a single call within a method. Here''s a single entry for a call within the `GET
    /withAccounts/{id}` method from `customer-service`:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的流作为进一步的JSON条目公开，其中包含描述方法内单个调用的指标。以下是来自`customer-service`的`GET /withAccounts/{id}`方法内的调用的单个条目：
- en: '[PRE17]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Hystrix dashboard
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hystrix仪表板
- en: 'Hystrix dashboard visualizes the following information:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Hystrix仪表板可视化以下信息：
- en: Health and traffic volume is displayed as a circle that is changing its color
    and size together with the changes in incoming statistics
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 健康和流量量显示为一个圆，随着传入统计数据的变化而改变其颜色和大小
- en: The error percentage over the last 10 seconds
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过去10秒的错误百分比
- en: The request rate over the last two minutes by number, displaying the results
    on a graph
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过去两分钟的请求数，以数字形式显示在图表上的结果
- en: The circuit breaker status (open/closed)
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 断路器状态（打开/关闭）
- en: The number of service hosts
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务主机的数量
- en: The latency percentiles over the last minute
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过去一分钟的延迟百分位数
- en: The service's thread pools
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务的线程池
- en: Building an application with the dashboard
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用仪表板构建应用程序
- en: 'The Hystrix dashboard is integrated with Spring Cloud. The best approach when
    implementing the dashboard inside a system is to separate out an independent Spring
    Boot application with the dashboard. To include the Hystrix dashboard in your
    project, use the `spring-cloud-starter-hystrix-netflix-dashboard` starter or `spring-cloud-starter-hystrix-dashboard`
    for Spring Cloud Netflix versions older than 1.4.0:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Hystrix仪表板与Spring Cloud集成。在系统内部实现仪表板时，最佳方法是将独立的Spring Boot应用与仪表板分离出来。要在项目中包含Hystrix仪表板，请使用`spring-cloud-starter-hystrix-netflix-dashboard`启动器，或者对于早于1.4.0版本的Spring
    Cloud Netflix，请使用`spring-cloud-starter-hystrix-dashboard`：
- en: '[PRE18]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The application''s main class should be annotated with `@EnableHystrixDashboard`.
    After launching it, the Hystrix dashboard is available under the `/hystrix` context
    path:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序的主类应该用`@EnableHystrixDashboard`进行注释。启动后，Hystrix仪表板将在`/hystrix`上下文路径下可用：
- en: '[PRE19]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'I configured port `9000` as the default for the Hystrix application in our
    sample system, which is implemented in the `hystrix-dashboard` module. So, if
    you call the `http://localhost:9000/hystrix` address in a web browser after launching
    `hystrix-dashboard`, it will display the page as shown in the following screenshot.
    There, you should provide the Hystrix stream endpoint''s address, and, optionally,
    a title. If you would like to display metrics for all the endpoints that are called
    from `order-service`, type the address `http://localhost:8090/hystrix.stream`
    and then click the Monitor Stream button :'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我将端口`9000`配置为示例系统中Hystrix应用的默认端口，该系统在`hystrix-dashboard`模块中实现。因此，如果在启动`hystrix-dashboard`后在Web浏览器中调用`http://localhost:9000/hystrix`地址，它将显示如下屏幕截图所示的页面。在那里，您应该提供Hystrix流端点的地址，以及可选的标题。如果您想要显示从`order-service`调用的所有端点的指标，输入地址`http://localhost:8090/hystrix.stream`，然后单击“监控流”按钮：
- en: '![](img/0aa6b722-29ff-47e5-a8f4-34ea62bc2944.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0aa6b722-29ff-47e5-a8f4-34ea62bc2944.png)'
- en: Monitoring metrics on the dashboard
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控仪表板上的指标
- en: 'In this section, we will look at calling the `GET /withAccounts/{id}` method from
    `customer-service`. It is wrapped with `@HystrixCommand`. It is displayed on the Hystrix
    dashboard under the title `customer-service.findWithAccounts`, taken from a `commandKey` attribute.
    In addition, the UI dashboard also shows information about the thread pools that
    are assigned to every Spring Bean that provides an implementation of methods wrapped
    with Hystrix''s command. In this case, it is `CustomerService`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将查看从`customer-service`调用的`GET /withAccounts/{id}`方法。它被`@HystrixCommand`包装。它显示在Hystrix仪表板上，标题为`customer-service.findWithAccounts`，取自`commandKey`属性。此外，UI仪表板还显示了分配给每个提供方法实现的Spring
    Bean的线程池的信息，这些方法都包装在Hystrix命令中。在这种情况下，它是`CustomerService`：
- en: '[PRE20]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here''s the screen from the Hystrix dashboard just after the start of a JUnit
    test. We monitor the state of all three methods wrapped with `@HystrixCommand`.
    The circuit has been opened for the `findByIds` method from `product-service`,
    as expected. After a few seconds, the circuit has also been opened for the `withdraw`
    method from `account-service`:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Hystrix仪表板在启动JUnit测试后的屏幕。我们监视所有三个使用`@HystrixCommand`包装的方法的状态。预期的是，`product-service`的`findByIds`方法的断路器已打开。几秒钟后，`account-service`的`withdraw`方法的断路器也已打开：
- en: '![](img/fe9084d4-8482-4bd7-aad2-470cd1af41ad.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fe9084d4-8482-4bd7-aad2-470cd1af41ad.png)'
- en: 'After a few moments, the situation will be stabilized. All the circuits remain
    closed because only a small percentage of traffic is sent to the inactive instances
    of applications. This shows the power of Spring Cloud with Hystrix and Ribbon.
    The system was able to automatically reconfigure itself in order to redirect most
    of the incoming requests to the working instances based on the metrics generated
    by the load balancers and circuit breakers:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 几分钟后，情况将稳定下来。所有断路器仍然关闭，因为只有很小一部分流量被发送到不活动的应用实例。这显示了Spring Cloud与Hystrix和Ribbon的强大功能。系统能够根据负载均衡器和断路器生成的指标自动重新配置自己，以将大部分传入请求重定向到工作实例。
- en: '![](img/9a1a4f33-d388-46a9-a060-05d87303eb6c.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9a1a4f33-d388-46a9-a060-05d87303eb6c.png)'
- en: Aggregating Hystrix's streams with Turbine
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Turbine聚合Hystrix的流
- en: You have probably noticed that we were only able to look at an individual instance
    of the service in the Hystrix dashboard. There were no metrics from communication
    between `customer-service` and `account-service` when we were displaying the state
    of commands for `order-service`, and vice versa. We might also imagine that there
    is more than one instance of `order-service` running, which makes it necessary
    to switch regularly between different instances or services in the Hystrix dashboard.
    Fortunately, there is an application called **Turbine** that aggregates all of
    the relevant `/hystrix.stream` endpoints into a combined `/turbine.stream` and
    makes it possible for us to monitor the overall health of the whole system.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到，我们只能查看Hystrix仪表板中服务的单个实例。当我们显示`order-service`的命令状态时，`customer-service`和`account-service`之间的通信没有指标，反之亦然。我们还可以想象，可能有多个`order-service`实例在运行，这使得在Hystrix仪表板中定期在不同实例或服务之间切换成为必要。幸运的是，有一个名为**Turbine**的应用程序，它将所有相关的`/hystrix.stream`端点聚合到一个组合的`/turbine.stream`中，并使我们能够监视整个系统的整体健康状况。
- en: Enabling Turbine
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启用Turbine
- en: 'Before making any changes to enable Turbine for our application, we should
    start by enabling service discovery, which is required here. Switch to the `hystrix_with_turbine` branch to
    access the version of our sample system that supports service discovery with Eureka
    and aggregates Hystrix''s streams using Turbine. To enable Turbine for the project
    exposing the UI dashboard, just include `spring-cloud-starter-turbine` in the
    dependencies and annotate the main application class with `@EnableTurbine`:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在对我们的应用程序启用Turbine进行任何更改之前，我们应该首先启用服务发现，这是必需的。切换到`hystrix_with_turbine`分支以访问支持Eureka服务发现并使用Turbine聚合Hystrix流的示例系统的版本。要为公开UI仪表板的项目启用Turbine，只需在依赖项中包含`spring-cloud-starter-turbine`，并在主应用程序类上加上`@EnableTurbine`注解：
- en: '[PRE21]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The `turbine.appConfig` configuration property is a list of Eureka service
    names that Turbine will use to look up instances. The Turbine stream is then available
    in the Hystrix dashboard under the URL `http://localhost:9000/turbine.stream`.
    The address is also determined by a value of the `turbine.aggregator.clusterConfig`
    property, `http://localhost:9000/turbine.stream?cluster=<clusterName>`. The cluster
    parameter can be omitted if the name is `default`. Here''s the Turbine configuration
    that combines all of Hystrix''s visualization metrics in a single UI dashboard:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`turbine.appConfig`配置属性是Turbine将用于查找实例的Eureka服务名称列表。然后，在Hystrix仪表板下的URL`http://localhost:9000/turbine.stream`中可以找到Turbine流。该地址还由`turbine.aggregator.clusterConfig`属性的值确定，`http://localhost:9000/turbine.stream?cluster=<clusterName>`。如果名称是`default`，则可以省略集群参数。以下是将Hystrix的所有可视化指标组合在单个UI仪表板中的Turbine配置：'
- en: '[PRE22]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now, all of Hystrix''s metrics for the whole sample system are displayed in
    a single dashboard site. All we need to display them is to monitor the statistics
    stream, available under `http://localhost:9000/turbine.stream`:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，整个示例系统的所有Hystrix指标都显示在单个仪表板站点上。我们只需要监视统计流，可在`http://localhost:9000/turbine.stream`下找到：
- en: '![](img/1426d797-14f8-4198-8bc0-0090718a565c.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1426d797-14f8-4198-8bc0-0090718a565c.png)'
- en: 'Alternatively, we can configure a cluster per service by providing a list of
    services with the `turbine.aggregator.clusterConfig` property. In that case, you
    may switch between clusters by providing the service name `cluster` with the `http://localhost:9000/turbine.stream?cluster=ORDER-SERVICE` parameter.
    The cluster name must be provided in uppercase because values returned by the
    Eureka server are in uppercase:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以通过提供带有`turbine.aggregator.clusterConfig`属性的服务列表来为每个服务配置一个集群。在这种情况下，您可以通过在`http://localhost:9000/turbine.stream?cluster=ORDER-SERVICE`参数中提供服务名称`cluster`来在不同集群之间切换。集群名称必须以大写形式提供，因为Eureka服务器返回的值是大写的：
- en: '[PRE23]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'By default, Turbine is looking for the `/hystrix.stream` endpoint on a registered
    instance under its `homePageUrl` address in Eureka. Then it appends `/hystrix.stream`
    to that URL. Our sample application `order-service` is launched under port `8090`,
    so we should also override the default management port to `8090`. The current
    configuration of `order-service` is shown in the following code fragment. Alternatively,
    you may also change that port with the `eureka.instance.metadata-map.management.port`
    property:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Turbine在Eureka注册的实例的`homePageUrl`地址下查找`/hystrix.stream`端点。然后将`/hystrix.stream`附加到该URL。我们的示例应用程序`order-service`在端口`8090`下启动，因此我们还应该将默认管理端口覆盖为`8090`。`order-service`的当前配置如下所示。或者，您也可以使用`eureka.instance.metadata-map.management.port`属性更改该端口：
- en: '[PRE24]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Enabling Turbine with streaming
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启用流式Turbine
- en: 'The classic Turbine model of pulling metrics from all the distributed Hystrix
    commands is not always a good choice. An operation such as collecting metrics
    from HTTP endpoints may also be realized asynchronously with a message broker.
    To enable Turbine with streaming, we should include the following dependencies
    with the project and then annotate the main application with `@EnableTurbineStream`.
    The following sample uses RabbitMQ as a default message broker, but you may use
    Apache Kafka by including `spring-cloud-starter-stream-kafka`:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 从所有分布式Hystrix命令中拉取指标的经典Turbine模型并不总是一个好选择。例如，从HTTP端点收集指标的操作也可以通过消息代理异步实现。要使用流式Turbine，我们应该在项目中包含以下依赖项，然后在主应用程序上加上`@EnableTurbineStream`注解。以下示例使用RabbitMQ作为默认消息代理，但您也可以通过包含`spring-cloud-starter-stream-kafka`来使用Apache
    Kafka：
- en: '[PRE25]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The dependencies visible in the preceding code should be included on the server
    side. For client applications, these are `order-service` and `customer-service`,
    and we need to add the `spring-cloud-netflix-hystrix-stream` library. If you have
    run your message broker locally, it should have worked successfully on auto-configured
    settings. You may also run RabbitMQ using a Docker container, as we did in the
    example of the Spring Cloud Config with AMQP bus described in [Chapter 5](37142825-02d0-48a0-99df-1a1a88a1bbd4.xhtml),
    *Distributed Configuration with Spring Cloud Config*. Then you should override
    the following properties in `application.yml` for both the client-side and server-side
    applications:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中可见的依赖项应该包含在服务器端。对于客户端应用程序，这些是`order-service`和`customer-service`，我们需要添加`spring-cloud-netflix-hystrix-stream`库。如果您在本地运行消息代理，它应该已经成功地在自动配置的设置上运行。您也可以像我们在[第5章](37142825-02d0-48a0-99df-1a1a88a1bbd4.xhtml)中描述的Spring
    Cloud Config与AMQP总线的示例中那样使用Docker容器运行RabbitMQ。然后，您应该在`application.yml`中为客户端和服务器端应用程序覆盖以下属性：
- en: '[PRE26]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: If you log in to the RabbitMQ management console, available under `http://192.168.99.100:15672`, you
    will see that the new exchange with the name `springCloudHystrixStream` has been
    created after our sample application's startup. Now, the only thing left to do
    is to run the same JUnit test as we did for the sample that illustrated the classic
    Turbine approach, described in the previous section. All metrics are sent through
    the message broker and may be observed under the `http://localhost:9000` endpoint.
    If you would like to try it by yourself, switch to the `hystrix_with_turbine_stream` branch (see [https://github.com/piomin/sample-spring-cloud-comm/tree/hystrix_with_turbine_stream](https://github.com/piomin/sample-spring-cloud-comm/tree/hystrix_with_turbine_stream) for
    more information).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您登录到RabbitMQ管理控制台，可在`http://192.168.99.100:15672`下找到新创建的名为`springCloudHystrixStream`的交换。现在，唯一剩下的事情就是运行与我们在上一节中描述的经典Turbine方法示例相同的JUnit测试。所有指标都通过消息代理发送，并可以在`http://localhost:9000`端点下观察到。如果您想自己尝试，请切换到`hystrix_with_turbine_stream`分支（有关更多信息，请参见[https://github.com/piomin/sample-spring-cloud-comm/tree/hystrix_with_turbine_stream](https://github.com/piomin/sample-spring-cloud-comm/tree/hystrix_with_turbine_stream)）。
- en: Failures and the circuit breaker pattern with Feign
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Feign的故障和断路器模式
- en: The Feign client is, by default, integrated with Ribbon and Hystrix. This means
    that, if you wish, you can apply different approaches to deal with latency and
    timeouts in your system when using that library. The first of these approaches
    is a connection retry mechanism provided by the Ribbon client. The second is a
    circuit breaker pattern and a fallback implementation available under the Hystrix
    project, which has already been discussed in the previous sections of this chapter.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Feign客户端默认与Ribbon和Hystrix集成。这意味着，如果您愿意，可以在使用该库时应用不同的方法来处理系统中的延迟和超时。其中之一是由Ribbon客户端提供的连接重试机制。第二个是断路器模式和Hystrix项目下可用的回退实现，这已经在本章的前几节中讨论过。
- en: Retrying the connection with Ribbon
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Ribbon重试连接
- en: 'Hystrix is enabled by default for the application when using a Feign library.
    This means that you should disable it in the configuration settings if you do
    not want to use it. For the purpose of testing a retry mechanism with Ribbon,
    I suggest that you disable Hystrix. In order to enable connection retrying for
    Feign, you only have to set two configuration properties—`MaxAutoRetries` and `MaxAutoRetriesNextServer`.
    The important settings, in this case, are also `ReadTimeout` and `ConnectTimeout`.
    All of them may be overridden in the `application.yml` file. Here''s the list
    of the most important Ribbon settings:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Feign库时，默认情况下启用了Hystrix。这意味着，如果您不想使用它，应该在配置设置中禁用它。为了测试Ribbon的重试机制，建议您禁用Hystrix。为了启用Feign的连接重试，您只需要设置两个配置属性——`MaxAutoRetries`和`MaxAutoRetriesNextServer`。在`application.yml`文件中，这种情况下的重要设置还包括`ReadTimeout`和`ConnectTimeout`。所有这些设置都可以被覆盖。以下是最重要的Ribbon设置列表：
- en: '`MaxAutoRetries`: This is the maximum number of retries on the same server
    or service instances. The first try is excluded from this count.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MaxAutoRetries`：这是在同一服务器或服务实例上重试的最大次数。第一次尝试不计入此计数。'
- en: '`MaxAutoRetriesNextServer`: This is the maximum number of next servers or service
    instances to retry, excluding the first server.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MaxAutoRetriesNextServer`：这是重试的下一个服务器或服务实例的最大次数，不包括第一个服务器。'
- en: '`OkToRetryOnAllOperations`: This states that all operations can be retried
    for this client.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OkToRetryOnAllOperations`：这表示所有操作都可以为此客户端重试。'
- en: '`ConnectTimeout`: This is the maximum time waiting to establish a connection
    to a server or service instance.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ConnectTimeout`：这是等待与服务器或服务实例建立连接的最长时间。'
- en: '`ReadTimeout`: This is the maximum time waiting for a response from the server
    after establishing a connection.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ReadTimeout`：这是在建立连接后等待服务器响应的最长时间。'
- en: 'Let''s assume that we have two instances of a target service. The connection
    to the first has been established, but it responds too slowly and a timeout occurs.
    The client performs one retry to that instance in accordance with the `MaxAutoRetries=1` property.
    If it has still not been successful, it tries to connect with a second available
    instance of that service. This action is repeated twice in the case of a failure,
    according to what has been set in the `MaxAutoRetriesNextServer=2` property. If
    the described mechanism is ultimately *not successful*, the timeout is returned
    to the external client. In that case, it may happen even after more than four
    seconds. Take a look at the following configuration:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有两个目标服务的实例。与第一个的连接已经建立，但它响应太慢，导致超时。客户端根据`MaxAutoRetries=1`属性对该实例进行一次重试。如果仍然不成功，它会尝试连接该服务的第二个可用实例。根据`MaxAutoRetriesNextServer=2`属性，如果失败，这个动作会重复两次。如果所描述的机制最终*不成功*，超时将返回给外部客户端。在这种情况下，甚至可能超过四秒后才发生。看一下以下配置：
- en: '[PRE27]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This solution is a standard retry mechanism implemented for a microservices-based
    environment. We may also look at some other scenarios related to the different
    configuration settings of Ribbon's timeouts and retries. There is no reason why
    we shouldn't use that mechanism together with Hystrix's circuit breaker. However,
    we have to remember that `ribbon.ReadTimeout` should be lower than the value of
    Hystrix's `execution.isolation.thread.timeoutInMilliseconds` property.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这个解决方案是为基于微服务的环境实现的标准重试机制。我们还可以看一些与Ribbon的超时和重试的不同配置设置相关的其他场景。我们没有理由不将这种机制与Hystrix的断路器一起使用。但是，我们必须记住`ribbon.ReadTimeout`应该低于Hystrix的`execution.isolation.thread.timeoutInMilliseconds`属性的值。
- en: I suggest that you test the configuration settings that we just described as
    an exercise. You may use a previously introduced Hoverfly JUnit rule for simulating
    the delays and stubs of a service's instances.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议您测试我们刚刚描述的配置设置作为练习。您可以使用之前介绍的Hoverfly JUnit规则来模拟服务实例的延迟和存根。
- en: Hystrix's support for Feign
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hystrix对Feign的支持
- en: To begin with, I would like to reiterate that Hystrix is enabled by default
    for the application when using a Feign library, but only for the older versions
    of Spring Cloud. According to the documentation for the newest version of Spring
    Cloud, we should set the `feign.hystrix.enabled` property to `true`, which forces
    Feign to wrap all methods with a circuit breaker.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我想重申，当使用Feign库时，默认情况下为应用程序启用Hystrix，但仅适用于较旧版本的Spring Cloud。根据Spring Cloud最新版本的文档，我们应该将`feign.hystrix.enabled`属性设置为`true`，这将强制Feign将所有方法包装成断路器。
- en: Prior to the Spring Cloud Dalston release, if Hystrix was on the classpath,
    Feign would have wrapped all methods in a circuit breaker by default. This default
    behavior was changed in Spring Cloud Dalston in favor of an opt-in approach.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spring Cloud Dalston版本发布之前，如果类路径上有Hystrix，Feign默认会包装所有方法以实现断路器。这种默认行为在Spring
    Cloud Dalston中被更改为支持选择加入。
- en: 'When using Hystrix together with a Feign client, the simplest way to provide
    configuration properties previously set with `@HystrixProperty` inside `@HystrixCommand`
    is through the `application.yml` file. Here''s the equivalent configuration of
    the samples presented before:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 当与Feign客户端一起使用Hystrix时，提供以前在`@HystrixCommand`中设置的配置属性的最简单方法是通过`application.yml`文件。以下是之前介绍的示例的等效配置：
- en: '[PRE28]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Feign supports the notation of a fallback. To enable fallbacks for a given
    `@FeignClient`, we should set the `fallback` attribute with the class name that
    provides a fallback implementation. The implementation class should be defined
    as a Spring Bean:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Feign支持回退的标记。要为给定的`@FeignClient`启用回退，我们应该使用提供回退实现的类名设置`fallback`属性。实现类应该被定义为Spring
    Bean：
- en: '[PRE29]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Fallback implementation is based on a cache, and implements the interface annotated
    with `@FeignClient`:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 回退实现基于缓存，并实现了用`@FeignClient`注释的接口：
- en: '[PRE30]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Optionally, we may implement a `FallbackFactory` class. That approach has one
    big advantage, it gives you access to the cause that made the fallback trigger. To
    declare a `FallbackFactory` class for Feign, just use the `fallbackFactory` attribute
    inside `@FeignClient`:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以实现`FallbackFactory`类。这种方法有一个很大的优势，它让您访问触发回退的原因。要为Feign声明`FallbackFactory`类，只需在`@FeignClient`中使用`fallbackFactory`属性：
- en: '[PRE31]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The custom `FallbackFactory` class needs to implement a `FallbackFactory` interface, which
    declares the one `T create(Throwable cause)` method that has to be overridden:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义的`FallbackFactory`类需要实现`FallbackFactory`接口，该接口声明了一个`T create(Throwable cause)`方法，必须被重写：
- en: '[PRE32]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Summary
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: You may not be aware of the configuration settings or tools described in this
    chapter if you have already been using auto-configured clients for inter-service
    communication. However, I think that it is worth having some knowledge about a
    few of the advanced mechanisms, even if they can run in the background and/or
    out of the box. In this chapter, I have tried to give you a closer view on topics,
    such as load balancers, retries, fallbacks, or circuit breakers by demonstrating
    how they work using simple examples. After reading this chapter, you should be
    able to customize Ribbon, Hystrix, or Feign clients to suit your needs related
    to communication between microservices, both on a small and large scale. You should
    also understand the when and why of using them in your system. With this chapter,
    we are closing the discussion about the core elements inside microservices-based
    architecture. Now, we have got one more important component to look at that is
    outside the system by quite a bit, the gateway. This hides the system complexity
    from an external client.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经在使用自动配置的客户端进行服务间通信，您可能不了解本章中描述的配置设置或工具。然而，我认为了解一些高级机制是值得的，即使它们可以在后台运行或开箱即用。在本章中，我试图通过演示它们的工作原理，如负载均衡器、重试、回退或断路器，让您更近距离地了解这些主题。阅读完本章后，您应该能够定制Ribbon、Hystrix或Feign客户端，以满足您在小规模和大规模微服务之间通信方面的需求。您还应该了解何时以及为什么在系统中使用它们。通过本章，我们结束了关于微服务架构内核要素的讨论。现在，我们还有一个重要的组件需要关注，它离系统相当远，即网关。这将隐藏系统复杂性，使外部客户端无需了解系统内部。

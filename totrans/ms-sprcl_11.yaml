- en: Message-Driven Microservices
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '- 消息驱动的微服务'
- en: We have already discussed many features around microservice-based architecture
    provided by Spring Cloud. However, we have always been considering synchronous,
    RESTful-based inter-service communication. As you probably remember from [Chapter
    1](33ddbb93-e658-4d91-97f5-06d6167ef89e.xhtml), *Introduction to Microservices*,
    there are some other popular communication styles, such as publish/subscribe or
    asynchronous, event-driven point-to-point messaging. In this chapter, I would
    like to introduce a different approach to microservices than that presented in
    previous chapters. We will talk in more detail about how you can work with Spring
    Cloud Stream in order to build message-driven microservices.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了Spring Cloud提供的基于微服务架构的许多特性。然而，我们一直在考虑同步的、基于RESTful的服务间通信。正如你可能还记得的，从[第一章](33ddbb93-e658-4d91-97f5-06d6167ef89e.xhtml)《微服务简介》中，还有一些其他流行的通信方式，比如发布/订阅或异步的、事件驱动的点对点消息传递。在本章中，我想介绍一种与之前章节中介绍的微服务不同的方法。我们将更详细地讨论如何使用Spring
    Cloud Stream来构建消息驱动的微服务。
- en: 'Topics we will cover in this chapter include:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖的主题包括：
- en: The main terms and concepts related to Spring Cloud Stream
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '- 与Spring Cloud Stream相关的主要术语和概念'
- en: Using RabbitMQ and Apache Kafka message brokers as binders
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '- 使用RabbitMQ和Apache Kafka消息代理作为绑定器'
- en: The Spring Cloud Stream programming model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '- Spring Cloud Stream编程模型'
- en: Advanced configurations of binding, producers, and consumers
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '- 绑定、生产者和消费者的高级配置'
- en: Implementation of scaling, grouping, and partitioning mechanisms
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '- 实现扩展、分组和分区机制'
- en: Multiple binder support
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '- 多绑定器支持'
- en: Learning about Spring Cloud Stream
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '- 学习Spring Cloud Stream'
- en: Spring Cloud Stream is built on top of Spring Boot. It allows us to create standalone,
    production-grade Spring applications and uses Spring Integration that helps in
    implementing communication with message brokers. Every application created with
    Spring Cloud Stream integrates with other microservices through input and output
    channels. Those channels are connected to external message brokers via middleware-specific
    binder implementations. There are two built-in binder implementations available—Kafka
    and Rabbit MQ.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream是建立在Spring Boot之上的。它允许我们创建独立的、生产级别的Spring应用程序，并使用Spring Integration来帮助实现与消息代理的通信。每个使用Spring
    Cloud Stream创建的应用程序都通过输入和输出通道与其他微服务集成。这些通道通过特定于中间件的绑定器实现连接到外部消息代理。有两种内置的绑定器实现可用——Kafka和Rabbit
    MQ。
- en: Spring Integration extends the Spring programming model to support the well-known
    **Enterprise Integration Patterns** (**EIP**). EIP defines a number of components
    that are typically used for orchestration in distributed systems. You have probably
    heard about patterns such as message channels, routers, aggregators, or endpoints.
    A primary goal of the Spring Integration framework is to provide a simple model
    for building Spring applications based on EIP. If you are interested in more details
    about EIP, please refer to the website at [http://www.enterpriseintegrationpatterns.com/patterns/messaging/toc.html](http://www.enterpriseintegrationpatterns.com/patterns/messaging/toc.html).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Integration将Spring编程模型扩展到支持众所周知的**企业集成模式**（**EIP**）。EIP定义了一些在分布式系统中通常用于编排的组件。你可能已经听说过诸如消息通道、路由器、聚合器或端点等模式。Spring
    Integration框架的主要目标是提供一个简单的模型，用于基于EIP构建Spring应用程序。如果你对EIP的更多细节感兴趣，请参考网站[http://www.enterpriseintegrationpatterns.com/patterns/messaging/toc.html](http://www.enterpriseintegrationpatterns.com/patterns/messaging/toc.html)。
- en: Building a messaging system
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '- 构建消息系统'
- en: 'I think that the most suitable way to introduce main Spring Cloud Stream features
    is through the sample microservices-based system. We will lightly modify an architecture
    of the system that has been discussed in the previous chapters. Let me provide
    a short recall of that architecture. Our system is responsible for processing
    orders. It consists of four independent microservices. The `order-service` microservice
    first communicates with `product-service` in order to collect the details of the
    selected products, and then with `customer-service` to retrieve information about
    the customer and his accounts. Now, the orders sent to `order-service` will be
    processed asynchronously. There is still an exposed RESTful HTTP API endpoint
    for submitting new orders by the clients, but they are not processed by the application.
    It only saves new orders, sends it to a message broker, and then responds to the
    client that the order has been approved for processing. The main goal of the currently
    discussed example is to show a point-to-point communication, so the messages would
    be received by only one application, `account-service`. Here''s a diagram that
    illustrates the sample system architecture:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为介绍Spring Cloud Stream主要特性的最合适方式是通过示例微服务系统。我们将轻微修改之前章节中讨论过的系统架构。让我简要回顾一下那个架构。我们的系统负责处理订单。它由四个独立的微服务组成。`order-service`微服务首先与`product-service`通信，以收集所选产品的详细信息，然后与`customer-service`通信，以检索有关客户及其账户的信息。现在，发送到`order-service`的订单将被异步处理。仍然有一个暴露的RESTful
    HTTP API端点，供客户端提交新订单，但它们不会被应用程序处理。它只保存新订单，将其发送到消息代理，然后响应客户端订单已被批准处理。当前讨论的示例的主要目标是展示点对点通信，因此消息只会被一个应用程序`account-service`接收。下面是一个说明示例系统架构的图表：
- en: '![](img/6d470d32-4e38-49ef-a0b8-56cc3408ded5.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6d470d32-4e38-49ef-a0b8-56cc3408ded5.png)'
- en: After receiving a new message, `account-service` calls the method exposed by
    `product-service` in order to find out its price. It withdraws money from the
    account and then sends back the response to `order-service` with the current order
    status. That message is also sent through the message broker. The `order-service`
    microservice receives the message and updates the order status. If the external
    client would like to check the current status order, it may call the endpoint
    exposing the `find` method with the order details. The sample application's source
    code is available on GitHub ([https://github.com/piomin/sample-spring-cloud-messaging.git](https://github.com/piomin/sample-spring-cloud-messaging.git)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 收到新消息后，`account-service`调用`product-service`公开的方法以查找其价格。它从帐户中提取资金，然后将响应发送回`order-service`以及当前订单状态。该消息也通过消息代理发送。`order-service`微服务接收消息并更新订单状态。如果外部客户端想要检查当前状态订单，它可以调用公开订单详细信息的`find`方法的端点。示例应用程序的源代码可在GitHub上找到（[https://github.com/piomin/sample-spring-cloud-messaging.git](https://github.com/piomin/sample-spring-cloud-messaging.git)）。
- en: Enabling Spring Cloud Stream
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启用Spring Cloud Stream
- en: 'The recommended way to include Spring Cloud Stream in the project is with a
    dependency management system. Spring Cloud Stream has an independent release trains
    management in relation to the whole Spring Cloud framework. However, if we have
    declared `spring-cloud-dependencies` in the `Edgware.RELEASE` version in the `dependencyManagement`
    section, we wouldn''t have to declare anything else in `pom.xml`. If you prefer
    to use only the Spring Cloud Stream project, you should define the following section:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在项目中包含Spring Cloud Stream的推荐方式是使用依赖管理系统。Spring Cloud Stream与整个Spring Cloud框架相比具有独立的发布管理。但是，如果我们在`dependencyManagement`部分中声明了`Edgware.RELEASE`版本的`spring-cloud-dependencies`，我们就不需要在`pom.xml`中声明其他任何内容。如果您只想使用Spring
    Cloud Stream项目，您应该定义以下部分：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The next step is to add `spring-cloud-stream` to the project dependencies.
    I also recommend you include at least the `spring-cloud-sleuth` library to provide
    sending messaging with the same `traceId` as the source request incoming to `order-service`
    via the Zuul gateway:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将`spring-cloud-stream`添加到项目依赖项中。我还建议您至少包括`spring-cloud-sleuth`库，以便提供与通过Zuul网关传入`order-service`的源请求相同的`traceId`发送消息：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To enable connectivity to a message broker for your application, annotate the
    main class with `@EnableBinding`. The `@EnableBinding` annotation takes one or
    more interfaces as parameters. You may choose between three interfaces provided
    by Spring Cloud Stream:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要为应用程序启用与消息代理的连接，请在主类上注释`@EnableBinding`。`@EnableBinding`注解接受一个或多个接口作为参数。您可以在Spring
    Cloud Stream提供的三个接口之间进行选择：
- en: '`Sink`: This is used for marking a service that receives messages from the
    inbound channel.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`接收器`：这用于标记接收来自入站通道的消息的服务。'
- en: '`Source`: This is used for sending messages to the outbound channel.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`源`：这用于向出站通道发送消息。'
- en: '`Processor`: This can be used in case you need both an inbound channel and
    an outbound channel, as it extends the `Source` and `Sink` interfaces. Because
    `order-service` sends messages, as well as receives them, its main class has been
    annotated with `@EnableBinding(Processor.class)`.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Processor`：如果您需要入站通道和出站通道，可以使用此接口，因为它扩展了`Source`和`Sink`接口。因为`order-service`既发送消息又接收消息，所以它的主类已经用`@EnableBinding(Processor.class)`进行了注释。'
- en: 'Here''s the main class of `order-service` that enables Spring Cloud Stream
    binding:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`order-service`的主要类，它启用了Spring Cloud Stream绑定：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Declaring and binding channels
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 声明和绑定通道
- en: 'Thanks to the use of Spring Integration, the application is independent from
    a message broker implementation included in the project. Spring Cloud Stream automatically
    detects and uses a binder found on the classpath. It means we may choose different
    types of middleware, and use it with the same code. All the middleware-specific
    settings can be overridden through external configuration properties in the form
    supported by Spring Boot, such as application arguments, environment variables,
    or just the `application.yml` file. As I have mentioned before, Spring Cloud Stream
    provides binder implementations for Kafka and Rabbit MQ. To include support for
    Kafka, you add the following dependency to the project:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 由于使用了Spring Integration，应用程序独立于项目中包含的消息代理实现。Spring Cloud Stream会自动检测并使用类路径上找到的绑定器。这意味着我们可以选择不同类型的中间件，并将其与相同的代码一起使用。所有特定于中间件的设置都可以通过外部配置属性进行覆盖，这些属性的形式由Spring
    Boot支持，例如应用程序参数、环境变量或只是`application.yml`文件。如我之前提到的，Spring Cloud Stream为Kafka和Rabbit
    MQ提供了绑定器实现。要包含对Kafka的支持，您需要将以下依赖项添加到项目中：
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Personally, I prefer RabbitMQ, but in this chapter, we will create a sample
    for both RabbitMQ and Kafka. Since we have already discussed RabbitMQ''s features,
    I''ll begin with the samples based on RabbitMQ:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我个人更喜欢RabbitMQ，但在本章中，我们将为RabbitMQ和Kafka创建一个示例。由于我们已经讨论了RabbitMQ的特性，我将从基于RabbitMQ的示例开始：
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'After enabling Spring Cloud Stream and including the binder implementation,
    we may create senders and listeners. Let''s begin with the producer responsible
    for sending new order messages to the broker. This is implemented by `OrderSender`
    in `order-service`, which uses the `Output` bean for sending messages:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在启用Spring Cloud Stream并包含绑定器实现后，我们可以创建发送者和监听器。让我们从负责向代理发送新订单消息的生产者开始。这由`order-service`中的`OrderSender`实现，它使用`Output`
    bean来发送消息：
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'That bean is called by the controller, which exposes the HTTP method that allows
    submitting new orders:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 该bean由控制器调用，该控制器公开允许提交新订单的HTTP方法：
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The message with information about the order has been sent to message broker.
    Now, it should be received by `account-service`. To make this happen, we have
    to declare the receiver, which is listening for messages incoming to the queue
    created on the message broker. To receive the message with the order data, we
    just have to annotate the method that takes the `Order` object as a parameter
    with `@StreamListener`:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 包含有关订单信息的消息已发送到消息代理。现在，它应该被`account-service`接收。为了实现这一点，我们必须声明接收器，它正在监听发送到消息代理上创建的队列的传入消息。要接收带有订单数据的消息，我们只需使用`@StreamListener`注释将接受`Order`对象作为参数的方法：
- en: '[PRE7]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now you may launch the sample applications. But, there is one important detail
    that has not yet been mentioned. Both those applications try to connect with RabbitMQ
    running on localhost, and both of them treat the same exchanges as an input or
    output. It is a problem, since `order-service` sends the message to the output
    exchange, while `account-service` listens for messages incoming to its input exchange.
    These are different exchanges, but first things first. Let's begin with running
    a message broker.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以启动示例应用程序了。但是，还有一个重要的细节尚未提及。这两个应用程序都尝试连接到运行在本地主机上的RabbitMQ，并且它们都将相同的交换视为输入或输出。这是一个问题，因为`order-service`将消息发送到输出交换，而`account-service`则监听发送到其输入交换的消息。这些是不同的交换，但首要问题是首先要解决。让我们从运行消息代理开始。
- en: Customizing connectivity with the RabbitMQ broker
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义与RabbitMQ代理的连接
- en: 'We have already started the RabbitMQ broker using its Docker image in the previous
    chapters, so it is worth reminding ourselves of that command. It starts a standalone
    Docker container with RabbitMQ, available under port `5672`, and its UI web console,
    available under port `15672`:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在前几章中使用其Docker镜像启动了RabbitMQ代理，因此值得提醒一下该命令。它启动一个独立的Docker容器，其中包含RabbitMQ，可在端口`5672`下使用，并且其UI
    Web控制台可在端口`15672`下使用：
- en: '[PRE8]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The default RabbitMQ address should be overridden with the `spring.rabbit.*`
    properties inside the `application.yml` file:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的RabbitMQ地址应该在`application.yml`文件中使用`spring.rabbit.*`属性进行覆盖：
- en: '[PRE9]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'By default, Spring Cloud Stream creates a topic exchange for communication.
    This type of exchange better suits the publish/subscribe interaction model. We
    may override it with the `exchangeType` property, as in the fragment of `application.yml`,
    as shown here:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Spring Cloud Stream创建一个主题交换进行通信。这种类型的交换更适合发布/订阅交互模型。我们可以使用`exchangeType`属性进行覆盖，如下面的`application.yml`片段所示：
- en: '[PRE10]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The same configuration settings should be provided for both `order-service`
    and `account-service`. You don''t have to create any exchange manually. If it
    does not exist, it is automatically created by the application during startup.
    Otherwise, the application just binds to that exchange. By default, it creates
    exchanges with names input for the `@Input` channel, and output for the `@Output`
    channel. These names may be overridden with the `spring.cloud.stream.bindings.output.destination`
    and `spring.cloud.stream.bindings.input.destination` properties, where input and
    output are the names of the channels. This configuration option is not just a
    nice addition to the Spring Cloud Stream features, but the key setting used for
    correlating the input and output destinations in inter-service communication.
    The explanation for why that happens is very simple. In our example, `order-service`
    is the message source application, so it sends messages to the output channel.
    Then, on the other hand, `account-service` listens for incoming messages on the
    input channel. If the `order-service` output channel and `account-service` input
    channel do not refer to the same destination on the broker, the communication
    between them would fail. In conclusion, I decided to use a destination with the
    names `orders-out` and `orders-in`, and I have provided the following configuration
    for `order-service`:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`order-service`和`account-service`都应提供相同的配置设置。您不必手动创建任何交换。如果不存在，应用程序在启动期间会自动创建它。否则，应用程序只是绑定到该交换。默认情况下，它使用`@Input`通道的名称创建交换，并使用`@Output`通道的名称创建输出。这些名称可以使用`spring.cloud.stream.bindings.output.destination`和`spring.cloud.stream.bindings.input.destination`属性进行覆盖，其中input和output是通道的名称。这个配置选项不仅是Spring
    Cloud Stream功能的一个不错的补充，而且是用于在服务间通信中关联输入和输出目的地的关键设置。为什么会发生这种情况的解释非常简单。在我们的例子中，`order-service`是消息源应用程序，因此它将消息发送到输出通道。另一方面，`account-service`在输入通道上监听传入消息。如果`order-service`的输出通道和`account-service`的输入通道不指向代理上的相同目的地，它们之间的通信将失败。总之，我决定使用名称`orders-out`和`orders-in`的目的地，并为`order-service`提供了以下配置：'
- en: '[PRE11]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The similar configuration settings for `account-service` are reversed:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`account-service`的类似配置设置是相反的：'
- en: '[PRE12]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'After both applications start up, you may easily check out the list of exchanges
    declared on the RabbitMQ broker using its web management console, available at `http://192.168.99.100:15672`
    (`quest`/`guest`). The following the implicitly created exchanges, and you may
    see our two destinations created for the test purpose:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 两个应用程序启动后，您可以轻松查看RabbitMQ代理声明的交换列表，使用其Web管理控制台，位于`http://192.168.99.100:15672`（`guest`/`guest`）。以下是隐式创建的交换，您可以看到为测试目的创建的两个目的地：
- en: '![](img/972692ab-4ae9-4f45-ab16-7987f69b003a.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/972692ab-4ae9-4f45-ab16-7987f69b003a.png)'
- en: By default, Spring Cloud Stream provides one input and one output message channel.
    We may imagine a situation where our system would need more than one destination
    for each type of message channel. Let's move back to the sample system architecture
    for a moment, and consider the situation where every order is asynchronously processed
    by two other microservices. Until now, only `account-service` has been listening
    for incoming events from `order-service`. In the current sample, `product-service`
    would be the receiver of incoming orders. Its main goal in that scenario is to
    manage the number of available products and decrease them on the basis of order
    details. It requires us to define two input and output message channels inside
    `order-service`, because we still have point-to-point communication based on a
    direct RabbitMQ exchange, where each message may be processed by exactly one consumer.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Spring Cloud Stream提供一个输入和一个输出消息通道。我们可以想象一个情况，即我们的系统可能需要每种类型的消息通道的多个目的地。让我们暂时回到示例系统架构，并考虑每个订单都由另外两个微服务异步处理的情况。到目前为止，只有`account-service`一直在监听来自`order-service`的传入事件。在当前示例中，`product-service`将成为传入订单的接收者。在这种情况下，其主要目标是管理可用产品的数量，并根据订单详情减少它们。这要求我们在`order-service`内定义两个输入和输出消息通道，因为我们仍然基于直接的RabbitMQ交换进行点对点通信，其中每条消息只能由一个消费者处理。
- en: 'In that case, we should declare two interfaces with `@Input` and `@Output`
    methods. Every method has to return a `channel` object. Spring Cloud Stream provides
    two bindable message components—`MessageChannel` for an outbound communication,
    and its extension, `SubscribableChannel`, for an inbound communication. Here''s
    the interface definition for interaction with `product-service`. The analogous
    interface has been created for messaging with `account-service`:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们应该声明两个带有`@Input`和`@Output`方法的接口。每个方法都必须返回一个`channel`对象。Spring Cloud
    Stream提供了两个可绑定的消息组件——`MessageChannel`用于出站通信，以及其扩展`SubscribableChannel`用于入站通信。这是与`product-service`交互的接口定义。与`account-service`进行消息交互的类似接口也已创建：
- en: '[PRE13]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The next step is to activate the declared components for the application by
    annotating its main class with `@EnableBinding(value={AccountOrder.class, ProductOrder.class}`.
    Now, you may refer to these channels in the configuration properties using their
    names, for example, `spring.cloud.stream.bindings.productOrdersOut.destination=product-orders-in`.
    Each channel name may be customized by specifying a channel name when using the
    `@Input` and `@Output` annotations, as shown in the following example:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是通过在其主类上注释`@EnableBinding(value={AccountOrder.class, ProductOrder.class}`来激活应用程序的声明组件。现在，您可以在配置属性中使用它们的名称引用这些通道，例如，`spring.cloud.stream.bindings.productOrdersOut.destination=product-orders-in`。每个通道名称可以通过在使用`@Input`和`@Output`注解时指定通道名称来自定义，如以下示例所示：
- en: '[PRE14]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Based on the custom interfaces declaration, Spring Cloud Stream will generate
    a bean that implements that interface. However, it still has to be accessed in
    the bean responsible for sending the message. In comparison with the previous
    sample, it would be more comfortable to inject bound channels directly. Here''s
    the current product order sender''s bean implementation. There is also a similar
    implementation of the bean, which sends messages to `account-service`:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 基于自定义接口声明，Spring Cloud Stream将生成一个实现该接口的bean。但是，仍然需要在负责发送消息的bean中访问它。与之前的示例相比，直接注入绑定通道可能更加舒适。这是当前产品订单发送者的bean实现。还有一个类似的bean实现，它发送消息到`account-service`：
- en: '[PRE15]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Every message-channel custom interface should also be provided for the target
    service. The listener should be bound to the right message channel and the destination
    on the message broker:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 每个消息通道自定义接口还应为目标服务提供。监听器应绑定到正确的消息通道和消息代理上的目的地：
- en: '[PRE16]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Integration with other Spring Cloud projects
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与其他Spring Cloud项目集成
- en: 'You have probably noticed that the sample system mixes different styles of
    inter-service communication. There are some microservices that use typical RESTful
    HTTP API, and some others that use the message broker. There are also no objections
    to mixing different styles of communication inside a single application. You may,
    for example, include `spring-cloud-starter-feign` to the project with Spring Cloud
    Stream, and enable it with the `@EnableFeignClients` annotation. In our sample
    system, those two different styles of communication combine `account-service`,
    which integrates with `order-service` via the message broker, and with `product-service`
    through the REST API. Here''s the Feign client''s `product-service` implementation
    inside the `account-service` module:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到，示例系统混合了不同风格的服务间通信。有一些微服务使用典型的RESTful HTTP API，还有一些使用消息代理。在单个应用程序内混合不同风格的通信也没有异议。例如，您可以将`spring-cloud-starter-feign`包含到Spring
    Cloud Stream项目中，并使用`@EnableFeignClients`注解启用它。在我们的示例系统中，这两种不同的通信风格结合了`account-service`，它通过消息代理与`order-service`集成，并通过REST
    API与`product-service`集成。这是`account-service`模块中`product-service`的Feign客户端实现：
- en: '[PRE17]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: There is other good news. Thanks to Spring Cloud Sleuth, all the messages exchanged
    during a single request incoming to the system via a gateway have the same `traceId`.
    Whether it is synchronous REST communication, or asynchronous messaging, you may
    easily track and correlate the logs between microservices using standard log files,
    or log aggregator tools such as Elastic Stack.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 有其他好消息。由于Spring Cloud Sleuth的帮助，通过网关进入系统的单个请求期间交换的所有消息都具有相同的`traceId`。无论是同步的REST通信还是异步消息传递，您都可以轻松地使用标准日志文件或日志聚合工具（如Elastic
    Stack）跟踪和关联微服务之间的日志。
- en: 'I think now is a good time to run and test our sample system. First, we have
    to build the whole project with the `mvn clean install` command. To access the
    code sample with two microservices listening for messages on two different exchanges,
    you should switch to the `advanced` branch ([https://github.com/piomin/sample-spring-cloud-messaging/tree/advanced](https://github.com/piomin/sample-spring-cloud-messaging/tree/advanced)).
    You should launch all the applications available there—gateway, discovery, and
    the three microservices (`account-service`, `order-service`, `product-service`).
    The currently discussed case assumes we have also started RabbitMQ, Logstash,
    Elasticsearch, and Kibana using its Docker container. For detailed instructions
    on how to run Elastic Stack locally using Docker images, refer to [Chapter 9](a84b38a5-4a2f-4e4b-a7fe-6396a2864021.xhtml),
    *Distributed Logging and Tracing*. The following diagram shows the architecture
    of the system in detail:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为现在是运行和测试我们的示例系统的好时机。首先，我们必须使用`mvn clean install`命令构建整个项目。要访问具有两个微服务在两个不同交换上监听消息的代码示例，您应该切换到`advanced`分支（[https://github.com/piomin/sample-spring-cloud-messaging/tree/advanced](https://github.com/piomin/sample-spring-cloud-messaging/tree/advanced)）。您应该启动那里所有可用的应用程序——网关、发现和三个微服务（`account-service`、`order-service`、`product-service`）。当前讨论的情况假设我们还启动了RabbitMQ、Logstash、Elasticsearch和Kibana，使用其Docker容器。有关如何使用Docker映像在本地运行Elastic
    Stack的详细说明，请参阅[第9章](a84b38a5-4a2f-4e4b-a7fe-6396a2864021.xhtml)，*分布式日志和跟踪*。以下图表详细显示了系统的架构：
- en: '![](img/1a3ef3e9-bd8e-45fb-8b75-b8050e1e4560.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1a3ef3e9-bd8e-45fb-8b75-b8050e1e4560.png)'
- en: 'After running all the required applications and tools, we may proceed to the
    tests. Here''s the sample request, which can be sent to the `order-service` via
    the API gateway:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行所有必需的应用程序和工具之后，我们可以进行测试。以下是可以通过API网关发送给`order-service`的示例请求：
- en: '[PRE18]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'When I run the test for the first time with the applications configured following
    the description in the previous sections, it doesn''t work. I can understand that
    some of you may be confused a little, because generally it was tested on the default
    settings. To make it run properly, I also have to add the following property in
    `application.yml`: `spring.cloud.stream.rabbit.bindings.output.producer.routingKeyExpression:
    ''"#"''`. It sets the default producer''s routing key to conform with the exchange''s
    routing key automatically created during the application boot. In the following
    screenshot, you may see one of the output exchange definitions:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '当我第一次使用按照前几节描述配置的应用程序运行测试时，它不起作用。我可以理解有些人可能会有点困惑，因为通常是在默认设置上进行测试的。为了使其正常运行，我还必须在`application.yml`中添加以下属性：`spring.cloud.stream.rabbit.bindings.output.producer.routingKeyExpression:
    ''"#"''`。它将默认生产者的路由键设置为与应用程序启动期间自动创建的交换的路由键相一致。在下面的屏幕截图中，您可以看到一个输出交换定义之一：'
- en: '![](img/d568e23a-9c65-4fb4-beb0-483c8755debb.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d568e23a-9c65-4fb4-beb0-483c8755debb.png)'
- en: 'After the modification described previously, the test should be concluded successfully.
    The logs printed by the microservices are correlated with each other by `traceId`.
    I modified the default Sleuth logging format in `logback-spring.xml` a little,
    and that''s how it is configured now—`%d{HH:mm:ss.SSS} %-5level [%X{X-B3-TraceId:-},%X{X-B3-SpanId:-}]
    %msg%n`. After sending the test request `order-service` test request, log the
    following information:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前描述的修改之后，测试应该能够成功地完成。微服务打印的日志通过`traceId`相互关联。我在`logback-spring.xml`中稍微修改了默认的Sleuth日志格式，现在配置如下：`%d{HH:mm:ss.SSS}
    %-5level [%X{X-B3-TraceId:-},%X{X-B3-SpanId:-}] %msg%n`。发送测试请求`order-service`测试请求后，记录以下信息：
- en: '[PRE19]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'As you can see, `account-service` also uses the same logging format and prints
    the same `traceId` as `order-service`:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`account-service`也使用相同的日志格式，并打印与`order-service`相同的`traceId`：
- en: '[PRE20]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'All the logs generated during the single transaction can be aggregated using
    Elastic Stack. You may filter the entries by the `X-B3-TraceId` field, for example,
    `9da1e5c83094390d`:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 所有在单个事务期间生成的日志可以使用Elastic Stack进行聚合。您可以通过`X-B3-TraceId`字段过滤条目，例如`9da1e5c83094390d`：
- en: '![](img/a2061976-3bb0-4367-ba21-2b8b76e7e2b4.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a2061976-3bb0-4367-ba21-2b8b76e7e2b4.png)'
- en: The publish/subscribe model
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发布/订阅模型
- en: The main motivation for creating a Spring Cloud Stream project is, in fact,
    support for a persistent publish/subscribe model. In the previous sections, we
    have discussed point-to-point communication between microservices, which is just
    an additional feature. However, the programming model is still the same, irrespective
    of whether we decided to use a point-to-point or publish/subscribe model.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 创建Spring Cloud Stream项目的主要动机实际上是支持持久的发布/订阅模型。在前几节中，我们已经讨论了微服务之间的点对点通信，这只是一个附加功能。但是，无论我们决定使用点对点还是发布/订阅模型，编程模型仍然是相同的。
- en: In publish/subscribe communication, the data is broadcast through shared topics.
    It reduces the complexity of both the producer and the consumer, and allows new
    applications to be easily added to the existing topology without any changes in
    flow. This can be clearly seen in the last-presented sample of the system, where
    we decided to add the second application that has consumed events produced by
    the source microservice. In comparison to the initial architecture, we had to
    define custom message channels dedicated for each of the target applications.
    With direct communication through queues, the message can be consumed by only
    one application instance, so as such, the solution was necessary. The uses of
    the publish/subscribe model simplify that architecture.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在发布/订阅通信中，数据通过共享主题进行广播。这减少了生产者和消费者的复杂性，并允许轻松地将新应用程序添加到现有拓扑中，而无需更改流程。这在系统的最后一个示例中可以清楚地看到，我们决定添加第二个应用程序，该应用程序消费了源微服务产生的事件。与初始架构相比，我们必须为每个目标应用程序定义专用的消息通道。通过队列的直接通信，消息只能被一个应用程序实例消费，因此这样的解决方案是必要的。发布/订阅模型的使用简化了该架构。
- en: Running a sample system
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行示例系统
- en: 'The development of the sample application is simpler for the publish/subscribe
    model than for point-to-point communication. We don''t have to override any default
    message channels to enable interaction with more than one receiver. In comparison
    with the initial sample that has illustrated messaging to a single target application
    (`account-service`), we only need to modify configuration settings a little. Because
    Spring Cloud Stream, by default, binds to the topic, we don''t have to override
    `exchangeType` for the input message channel. As you may see in the configuration
    fragment that follows, we still use point-to-point communication when sending
    the response to `order-service`. If we really think about it, that makes sense.
    The  `order-service` microservice sends the message that has to be received by
    both `account-service` and `product-service`, while the response from them is
    addressed only to `order-service`:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 对于发布/订阅模型，示例应用程序的开发比点对点通信更简单。我们不必覆盖任何默认的消息通道以启用与多个接收者的交互。与最初的示例相比，该示例仅需要稍微修改配置设置，最初的示例说明了向单个目标应用程序（`account-service`）发送消息。因为Spring
    Cloud Stream默认绑定到主题，我们不必为输入消息通道覆盖`exchangeType`。正如您在接下来的配置片段中所看到的，当向`order-service`发送响应时，我们仍然使用点对点通信。如果我们真的考虑一下，这是有道理的。`order-service`微服务发送的消息必须被`account-service`和`product-service`都接收到，而它们的响应只针对`order-service`：
- en: '[PRE21]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The logic of the main processing method of `product-service` is really simple.
    It just has to find all the `productIds` from the received order, change the number
    of stored products for every one of them, and then send the response to `order-service`:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`product-service`的主要处理方法的逻辑非常简单。它只需要从接收到的订单中找到所有的`productIds`，为每一个产品改变存储产品的数量，然后发送响应给`order-service`：'
- en: '[PRE22]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: To access the current sample, you just have to switch to the  `publish_subscribe` branch,
    available at [https://github.com/piomin/sample-spring-cloud-messaging/tree/publish_subscribe](https://github.com/piomin/sample-spring-cloud-messaging/tree/publish_subscribe).
    Then, you should build the parent project and run all the services as for the
    previous sample. If you would like to test it all works fine until you have only
    one running instance of `account-service` and `product-service`. Let's discuss
    that problem.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问当前的示例，您只需切换到`publish_subscribe`分支，该分支位于[https://github.com/piomin/sample-spring-cloud-messaging/tree/publish_subscribe](https://github.com/piomin/sample-spring-cloud-messaging/tree/publish_subscribe)。然后，您应该构建父项目并像之前的示例一样运行所有服务。如果您想测试它是否正常工作，直到只有一个运行实例的`account-service`和`product-service`。让我们讨论一下这个问题。
- en: Scaling and grouping
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展和分组
- en: When talking about microservice-based architecture, scalability is always presented
    as one of its main advantages. The ability to scale up the system by creating
    multiple instances of a given application is very important. When doing this,
    different instances of an application are placed in a competing consumer relationship,
    where only one of the instances is expected to handle a given message. For point-to-point
    communication, it is not a problem, but in a publish-subscribe model, where the
    message is consumed by all the receivers, it may be a challenge.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在谈论基于微服务的架构时，可伸缩性总是被提出作为其主要优势之一。通过创建给定应用程序的多个实例来扩展系统的能力非常重要。在这样做时，应用程序的不同实例被放置在竞争消费者关系中，其中只有一个实例预期处理给定的消息。对于点对点通信，这不是问题，但在发布-订阅模型中，消息被所有接收者消费，这可能是一个挑战。
- en: Running multiple instances
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行多个实例
- en: Availability for scaling up the number of microservice's instances is one of
    the main concepts around Spring Cloud Stream. However, there is no magic behind
    this idea. Running multiple instances of an application is very easy with Spring
    Cloud Stream. One of the reasons for this is native support from message brokers,
    which is designed to handle many consumers and huge amounts of traffic.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展微服务实例数量的可用性是Spring Cloud Stream周围的主要概念之一。然而，这个想法背后并没有什么魔法。使用Spring Cloud Stream非常容易运行应用程序的多个实例。其中一个原因是消息代理的本机支持，它被设计用来处理许多消费者和大量的流量。
- en: 'In our case, all the messaging microservices also expose the RESTful HTTP API,
    so first, we have to customize the server port per instance. We have performed
    such operations before. We may also consider setting two Spring Cloud Stream properties,
    `spring.cloud.stream.instanceCount` and `spring.cloud.stream.instanceIndex`. Thanks
    to them, every instance of the microservice is able to receive information about
    how many other examples of the same application are started and what is its own
    instance index. The correct configuration of these properties is required only
    if you would like to enable the partitioning feature. I''ll talk about this mechanism
    more in a moment. Now, let''s take a look at the configuration settings of the
    scaled-up applications. Both `account-service` and `product-service` define two
    profiles for the purpose of running multiple instances of the application. We
    have customized there an HTTP port of the server, number, and an index of the
    instance:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，所有的消息微服务也暴露了RESTful HTTP API，因此，首先，我们必须为每个实例自定义服务器端口。我们以前进行过这样的操作。我们还可以考虑设置两个Spring
    Cloud Stream属性，`spring.cloud.stream.instanceCount`和`spring.cloud.stream.instanceIndex`。由于它们，每个微服务实例都能够接收关于同一应用程序的其他示例启动了多少以及它自己的实例索引的信息。只有在您想要启用分区功能时才需要正确配置这些属性。我稍后会更详细地讨论这个机制。现在，让我们来看一下扩展应用程序的配置设置。`account-service`和`product-service`都为运行应用程序的多个实例定义了两个配置文件。我们在那里自定义了服务器的HTTP端口、实例的数量和索引：
- en: '[PRE23]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: After building the parent project, you may run two instances of the application.
    Each of them is initialized with properties assigned to the right profile passed
    during startup, for example, `java -jar --spring.profiles.active=instance1 target/account-service-1.0-SNAPSHOT.jar`.
    If you send a test request to the `order-service` endpoint `POST /`, the new order
    would be forwarded to the RabbitMQ topic exchange in order to be received by both
    the `account-service` and `product-service`, which are connected to that exchange.
    The problem is that the message is received by all the instances of each service,
    which is not exactly what we wanted to achieve. Here, a grouping mechanism comes
    with help.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Consumer groups
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our purpose is clear. We have many microservices that consume messages from
    the same topic. Different instances of an application are placed in a competing
    consumer relationship, but only one of them should handle a given message. Spring
    Cloud Stream introduces the concept of a consumer group that models this behavior.
    To activate such a behavior, we should set a property called `spring.cloud.stream.bindings.<channelName>.group`,
    with a group name. After setting it, all groups that subscribe to a given destination
    receive a copy of the published data, but only one member of each group receives
    and handles a message from that destination. In our case, there are two groups.
    First, for all the `account-service` instances with a name account, and second,
    for a `product-service` with a name product.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the current binding configuration for `account-service`. The `orders-in`
    destination is a queue created for direct communication with `order-service`,
    so only `orders-out` is grouped by service name. An analogous configuration has
    been prepared for `product-service`:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The first difference is visible in the names of queues automatically created
    for the RabbitMQ exchange. Now, it is not a randomly generated name, such as `orders-in.anonymous.qNxjzDq5Qra-yqHLUv50PQ`,
    but a determined string consisting of the destination and group name. The following
    screenshot shows all the queues currently existing on RabbitMQ:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ea66ddab-9c35-40be-9bb6-9b858aa41305.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
- en: You may perform the retest by yourself to verify if the message is received
    by only one application in the same group. However, you have no confidence which
    instance would handle the incoming message. In order to determine this, you can
    use a partitioning mechanism.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Partitioning
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spring Cloud Stream provides support for partitioning data between multiple
    instances of an application. In the typical use case, the destination is viewed
    as being divided into different partitions. Each producer, when sending messages
    received by multiple consumer instances, ensures that data is identified by configured
    fields to force processing by the same consumer instance.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'To enable the partitioning feature for your application, you have to define
    the `partitionKeyExpression` or `partitionKeyExtractorClass` properties, and `partitionCount`
    in the producer configuration settings. Here''s the sample configuration that
    may be provided for your application:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Partitioning mechanisms also require setting of the `spring.cloud.stream.instanceCount`
    and `spring.cloud.stream.instanceIndex` properties on the consumer side. It also
    has to be explicitly enabled with the `spring.cloud.stream.bindings.input.consumer.partitioned`
    property set to `true`. The instance index is responsible for identifying the
    unique partition from which a particular instance receives data. Generally, `partitionCount`
    on the producer side and `instanceCount` on the consumer side should be equal.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Let me familiarize you with the partitioning mechanism provided by Spring Cloud
    Stream. First, it calculates a partition key based on `partitionKeyExpression`,
    which is evaluated against the outbound message or implementation of the `PartitionKeyExtractorStrategy`
    interface, which defines the algorithm for extracting the key for the message.
    Once the message key is calculated, the target partition is determined as a value
    between zero and `partitionCount - 1`. The default calculation formula is `key.hashCode()
    % partitionCount`. It can be customized with the `partitionSelectorExpression`
    property, or by creating an implementation of the `org.springframework.cloud.stream.binder.PartitionSelectorStrategy`
    interface. The calculated key is matched with `instanceIndex` on the consumer
    side.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我向您介绍Spring Cloud Stream提供的分区机制。首先，它根据`partitionKeyExpression`计算分区键，该键根据出站消息或`PartitionKeyExtractorStrategy`接口的实现进行评估，该接口定义了提取消息键的算法。一旦计算出消息键，目标分区将确定为介于零和`partitionCount
    - 1`之间的值。默认的计算公式是`key.hashCode() % partitionCount`。可以使用`partitionSelectorExpression`属性进行自定义，或者创建`org.springframework.cloud.stream.binder.PartitionSelectorStrategy`接口的实现。计算出的键将与消费者端的`instanceIndex`匹配。
- en: 'I think that the main concept around partitioning has been explained. Let''s
    proceed to the sample. Here''s the current configuration of the input channel
    for `product-service` (the same as with the account group name set for `account-service`):'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为分区的主要概念已经解释完毕。让我们继续进行示例。以下是`product-service`输入通道的当前配置（与为`account-service`设置的帐户组名相同）：
- en: '[PRE26]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We have two running instances of each microservice that consumes data from the
    topic exchange. There are also two partitions set for the producer within `order-service`.
    The message key is calculated based on the `customerId` field from the `Order`
    object. The partition with index `0` is dedicated for orders having an even number
    in the `customerId` field, while the partition with index `1` is for odd numbers
    in the `customerId` field.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有两个运行中的每个微服务实例，它们从主题交换中消费数据。在`order-service`中还为生产者设置了两个分区。消息键是基于`Order`对象中的`customerId`字段计算的。索引为`0`的分区专门用于`customerId`字段中为偶数的订单，而索引为`1`的分区用于`customerId`字段中为奇数的订单。
- en: 'In fact, RabbitMQ does not have native support for partitioning. It is interesting
    how Spring Cloud Stream implements the partitioning process with RabbitMQ. Here''s
    a screenshot that illustrates the list of bindings for exchanges created in RabbitMQ.
    As you may see, there are two routing keys that have been defined for the exchange—`orders-out-0`
    and `orders-out-1`:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，RabbitMQ并不原生支持分区。有趣的是Spring Cloud Stream如何在RabbitMQ中实现分区过程。以下是一个截图，说明了在RabbitMQ中创建的交换的绑定列表。正如您所看到的，为交换定义了两个路由键——`orders-out-0`和`orders-out-1`：
- en: '![](img/e699f2a7-dbb7-46fd-bb9d-3b1952b257c6.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e699f2a7-dbb7-46fd-bb9d-3b1952b257c6.png)'
- en: 'If you send an order with `customerId` equal to 1 in a JSON message, for example,
    `{"customerId": 1,"productIds": [4],"status": "NEW"}`, it would always be processed
    by an instance with `instanceIndex=1`. It may be checked out in the application
    logs or by using the RabbitMQ web console. Here''s a diagram with the message
    rates for each queue, where the message with `customerId=1` has been sent several
    times:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '例如，如果您发送一个`customerId`等于1的订单，JSON消息如下：`{"customerId": 1,"productIds": [4],"status":
    "NEW"}`，它将始终由`instanceIndex=1`的实例处理。可以在应用程序日志中或使用RabbitMQ Web控制台进行检查。以下是每个队列的消息速率的图表，其中具有`customerId=1`的消息已发送多次：'
- en: '![](img/683097cd-7210-4c3b-973c-bea138878ac4.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/683097cd-7210-4c3b-973c-bea138878ac4.png)'
- en: Configuration options
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置选项
- en: Spring Cloud Stream configuration settings may be overridden using any mechanism
    supported by Spring Boot, such as application arguments, environment variables,
    and YAML or property files. It defines a number of generic configuration options that
    may be applied to all binders. However, there are also some additional properties specific
    for a particular message broker used by the application.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream配置设置可以使用Spring Boot支持的任何机制进行覆盖，例如应用程序参数、环境变量和YAML或属性文件。它定义了一些通用的配置选项，可以应用于所有绑定器。但是，还有一些特定于应用程序使用的特定消息代理的附加属性。
- en: Spring Cloud Stream properties
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spring Cloud Stream属性
- en: 'The current group of properties applies to the whole Spring Cloud Stream application.
    All the following properties are prefixed with  `spring.cloud.stream`:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的属性组适用于整个Spring Cloud Stream应用程序。所有以下属性都以`spring.cloud.stream`为前缀：
- en: '| Name | Default value | Description |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 默认值 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `instanceCount` | `1` | The number of running instances of an application.
    For more details, refer to the *Scaling and grouping* section. |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| `instanceCount` | `1` | 应用程序运行实例的数量。有关更多详细信息，请参阅*扩展和分组*部分。 |'
- en: '| `instanceIndex` | `0` | The index of the instance of the application. For
    more details, also refer to the *Scaling and grouping* section. |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| `instanceIndex` | `0` | 应用程序实例的索引。有关更多详细信息，请还参阅*扩展和分组*部分。 |'
- en: '| `dynamicDestinations` | - | A list of destinations that can be bound dynamically.
    |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| `dynamicDestinations` | - | 可以动态绑定的目的地列表。 |'
- en: '| `defaultBinder` | - | The default binder in case there are multiple binders
    defined. For more details, also refer to the *Multiple binders* section. |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| `defaultBinder` | - | 如果定义了多个绑定器，则为默认绑定器。有关更多详细信息，请还参阅*多个绑定器*部分。 |'
- en: '| `overrideCloudConnectors` | `false` | This is used only if the cloud is active
    and Spring Cloud Connectors is found on the classpath. When it is set to `true`, binders
    completely ignore the bound services and rely on the `spring.rabbitmq.*` or `spring.kafka.*` Spring
    Boot properties. |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| `overrideCloudConnectors` | `false` | 仅在云处于活动状态且类路径中找到Spring Cloud Connectors时使用。当设置为`true`时，绑定器完全忽略绑定的服务，并依赖于`spring.rabbitmq.*`或`spring.kafka.*`
    Spring Boot属性。 |'
- en: Binding properties
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绑定属性
- en: 'The next group of properties is related to a message channel. In Spring Cloud
    nomenclature, these are binding properties. They may be assigned only to a consumer,
    a producer, or to both simultaneously. Here is a list of the properties, along
    with their default value and a description:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 下一组属性与消息通道相关。在Spring Cloud术语中，这些是绑定属性。它们只能分配给消费者、生产者或同时分配给两者。以下是属性列表，以及它们的默认值和描述：
- en: '| Name | Default value | Description |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 默认值 | 描述 |'
- en: '| `destination` | - | The target destination name on the broker configured
    for the message channel. It can be specified as a comma-separated list of destinations
    if the channel is used by only one consumer. |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| `destination` | - | 为消息通道配置的代理目标名称。如果通道仅由一个消费者使用，则可以将其指定为逗号分隔的目标列表。 |'
- en: '| `group` | `null` | The consumer group of the channel. See the *Scaling and
    grouping* section for more details. |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| `group` | `null` | 通道的消费者组。有关更多详细信息，请参阅*扩展和分组*部分。 |'
- en: '| `contentType` | `null` | The content type of messages exchanged via a given
    channel. We may set it, for example, to `application/json`. Then all the objects
    sent from that application would be automatically converted to a JSON string.
    |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| `contentType` | `null` | 通过给定通道交换的消息的内容类型。例如，我们可以将其设置为`application/json`。然后，从该应用程序发送的所有对象都将自动转换为JSON字符串。
    |'
- en: '| `binder` | `null` | The default binder used by the channel. See the *Multiple
    binders* section for more details. |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| `binder` | `null` | 通道使用的默认绑定器。有关更多详细信息，请参阅*多绑定器*部分。 |'
- en: The consumer
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消费者
- en: 'The following list of properties is available for input bindings only, and
    must be prefixed with `spring.cloud.stream.bindings.<channelName>.consumer`. I''ll
    indicate just the most important of them:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 以下属性列表仅适用于输入绑定，并且必须以`spring.cloud.stream.bindings.<channelName>.consumer`为前缀。我只会指出其中最重要的：
- en: '| **Name** | **Default value** | **Description** |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| **名称** | **默认值** | **描述** |'
- en: '| --- | --- | --- |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `concurrency` | `1` | Number of consumers per single input channel |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| `concurrency` | `1` | 单个输入通道的消费者数量 |'
- en: '| `partitioned` | `false` | It enables receiving data from a partitioned producer
    |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| `partitioned` | `false` | 它使能够从分区生产者接收数据 |'
- en: '| `headerMode` | `embeddedHeaders` | If it is set to `raw`, header parsing
    on input is disabled |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| `headerMode` | `embeddedHeaders` | 如果设置为`raw`，则禁用输入时的标头解析 |'
- en: '| `maxAttempts` | `3` | Number of retries if message processing fails. Setting
    this option to `1` disables the retry mechanism |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| `maxAttempts` | `3` | 如果消息处理失败，重试次数。将此选项设置为`1`会禁用重试机制 |'
- en: The producer
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生产者
- en: 'The following binding properties are available for output bindings only, and
    must be prefixed with `spring.cloud.stream.bindings.<channelName>.producer`. I''ll
    also indicate only the most important of them:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 以下绑定属性仅适用于输出绑定，并且必须以`spring.cloud.stream.bindings.<channelName>.producer`为前缀。我还将指出其中最重要的：
- en: '| **Name** | **Default value** | **Description** |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| **名称** | **默认值** | **描述** |'
- en: '| `requiredGroups` | - | A comma-separated list of groups that must be created
    on the message broker |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| `requiredGroups` | - | 必须在消息代理上创建的组的逗号分隔列表 |'
- en: '| `headerMode` | `embeddedHeaders` | If it is set to `raw`, header parsing
    on input is disabled |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| `headerMode` | `embeddedHeaders` | 如果设置为`raw`，则禁用输入时的标头解析 |'
- en: '| `useNativeEncoding` | `false` | If it is set to `true`, the outbound message
    is serialized directly by the client library |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| `useNativeEncoding` | `false` | 如果设置为`true`，则出站消息将由客户端库直接序列化 |'
- en: '| `errorChannelEnabled` | `false` | If it is set to `true`, failure messages
    are sent to the error channel for the destination |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| `errorChannelEnabled` | `false` | 如果设置为`true`，则将失败消息发送到目的地的错误通道 |'
- en: The advanced programming model
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级编程模型
- en: The basics around the Spring Cloud Stream programming model have been presented
    together with samples of point-to-point and publish/subscribe communication. Let's
    discuss some more advanced example features.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 已经介绍了Spring Cloud Stream编程模型的基础知识，以及点对点和发布/订阅通信的示例。让我们讨论一些更高级的示例特性。
- en: Producing messages
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生产消息
- en: 'In all the samples presented in this chapter, we have sent orders through RESTful
    API for testing purposes. However, we may easily create some test data by defining
    the message source inside the application. Here''s a bean that generates one message
    per second using `@Poller` and sends it to the output channel:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中介绍的所有示例中，我们已通过RESTful API发送订单进行测试。但是，我们可以通过在应用程序内部定义消息源来轻松创建一些测试数据。以下是使用`@Poller`每秒生成一条消息并将其发送到输出通道的bean：
- en: '[PRE27]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Transformation
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转换
- en: 'As you probably remember, `account-service` and `product-service` have been
    receiving events from `order-service` and then sending back the response message.
    We have created the `OrderSender` bean, which was responsible for preparing the
    response payload and sending it to the output channel. It turns out that the implementation
    may be simpler if we return the response object in method and annotate it with
    `@SentTo`:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还记得，`account-service`和`product-service`一直在接收来自`order-service`的事件，然后发送回响应消息。我们创建了`OrderSender`
    bean，负责准备响应有效载荷并将其发送到输出通道。事实证明，如果我们在方法中返回响应对象并用`@SentTo`注释它，实现可能会更简单：
- en: '[PRE28]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We can even imagine such an implementation, such as the following, without
    using `@StreamListener`. The transformer pattern is responsible for changing the
    object''s form. In that case, it modifies two `order` fields—`status` and `price`:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至可以想象这样的实现，例如下面的实现，而不使用`@StreamListener`。转换器模式负责改变对象的形式。在这种情况下，它修改了两个`order`字段——`status`和`price`：
- en: '[PRE29]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Consuming messages conditionally
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消费消息的条件
- en: 'Assuming we would like to treat messages incoming to the same message channel
    differently, we may use conditional dispatching. Spring Cloud Stream supports
    dispatching messages to multiple `@StreamListener` methods registered on an input
    channel, based on a condition. That condition is a **Spring Expression Language**
    (**SpEL**) expression defined in the `condition` attribute of the `@StreamListener`
    annotation:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要对进入同一消息通道的消息进行不同的处理，我们可以使用条件分发。Spring Cloud Stream支持根据条件将消息分发到注册在输入通道上的多个`@StreamListener`方法，该条件是`@StreamListener`注解的`condition`属性中定义的**Spring
    Expression Language**（**SpEL**）表达式：
- en: '[PRE30]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Here''s the sample implementation that defines two methods annotated with `@StreamListener`
    that listen on the same topic. One of them is dedicated only for messages incoming
    from `account-service`, while the second is dedicated only for `product-service`.
    The incoming message is dispatched, based on its header with the `processor` name:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例实现，定义了两个使用`@StreamListener`注解的方法，它们监听同一个主题。其中一个专门用于来自`account-service`的消息，而另一个专门用于`product-service`。根据消息头中的`processor`名称，传入的消息会被分发：
- en: '[PRE31]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Using Apache Kafka
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Apache Kafka
- en: I have mentioned Apache Kafka a couple of times when discussing Spring Cloud
    integration with message brokers. However, until now, we haven't run any samples
    based on that platform. The fact is that RabbitMQ tends to be the preferred choice
    when working with Spring Cloud projects, but Kafka is also worthy of our attention.
    One of its advantages over RabbitMQ is native support for partitioning, which
    is one of the most important features of Spring Cloud Stream.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论Spring Cloud与消息代理集成时，我已经多次提到了Apache Kafka。但是，直到现在，我们还没有基于该平台运行任何示例。事实是，当与Spring
    Cloud项目一起工作时，RabbitMQ往往是首选，但Kafka也值得我们关注。与RabbitMQ相比，它的一个优势是本地支持分区，这是Spring Cloud
    Stream最重要的功能之一。
- en: Kafka is not a typical message broker. It is rather a distributed streaming
    platform. Its main feature is to allow you to publish and subscribe to streams
    of records. It is especially useful for real-time streaming applications that
    transform or react to streams of data. It is usually run as a cluster consisting
    of one or more servers, and stores streams of records in topics.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka不是典型的消息代理。它更像是一个分布式流平台。其主要特点是允许您发布和订阅记录流。它对于实时流应用程序特别有用，这些应用程序可以转换或对数据流做出反应。通常作为由一个或多个服务器组成的集群运行，并将记录流存储在主题中。
- en: Running Kafka
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行Kafka
- en: 'Unfortunately, there is no official Docker image with Apache Kafka. However,
    we may use one that is unofficial, for example, that shared by Spotify. In comparison
    to other available Kafka docker images, this one runs both Zookeeper and Kafka
    in the same container. Here''s the Docker command that launches Kafka and exposes
    it on port `9092`. Zookeeper is also available outside on port `2181`:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，没有官方的Apache Kafka Docker镜像。但是，我们可以使用一个非官方的镜像，例如Spotify共享的镜像。与其他可用的Kafka
    Docker镜像相比，这个镜像在同一个容器中运行Zookeeper和Kafka。以下是启动Kafka并将其暴露在端口`9092`上的Docker命令。Zookeeper也可以在端口`2181`上外部访问：
- en: '[PRE32]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Customizing application settings
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义应用程序设置
- en: To enable Apache Kafka for the application, include the `spring-cloud-starter-stream-kafka`
    starter to the dependencies. Our current sample is very similar to to the sample
    of publish/subscribe using with RabbitMQ publish/subscribe with grouping and partitioning
    presented in *The publish/subscribe model*, section. The only difference is in
    the dependencies and configuration settings.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要为应用程序启用Apache Kafka，请将`spring-cloud-starter-stream-kafka`启动器包含到依赖项中。我们当前的示例与在*发布/订阅模型*部分中介绍的使用RabbitMQ发布/订阅与分组和分区的示例非常相似。唯一的区别在于依赖项和配置设置。
- en: 'Spring Cloud Stream automatically detects and uses a binder found on the classpath.
    The connection settings may be overridden with `spring.kafka.*` properties. In
    our case, we just need to change the auto-configured Kafka client address to the
    Docker machine address `192.168.99.100`. The same modification should be performed
    for Zookeeper, which is used by the Kafka client:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream会自动检测并使用类路径上找到的绑定器。连接设置可以使用`spring.kafka.*`属性进行覆盖。在我们的情况下，我们只需要将自动配置的Kafka客户端地址更改为Docker机器地址`192.168.99.100`。同样的修改也应该对Kafka客户端使用的Zookeeper进行：
- en: '[PRE33]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'After starting discovery, gateway, and all the required instances of microservices,
    you can perform the same tests as for the previous samples. If everything is configured
    correctly, you should see the following fragment in the logs during your application
    boot. The result of the tests is exactly the same as for the sample based on RabbitMQ:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动发现、网关和所有必需的微服务实例之后，您可以执行与之前示例相同的测试。如果一切配置正确，您应该在应用程序启动期间的日志中看到以下片段。测试的结果与基于RabbitMQ的示例完全相同：
- en: '[PRE34]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Kafka Streams API support
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kafka Streams API支持
- en: 'Spring Cloud Stream Kafka provides a binder specially designed for Kafka Streams
    binding. With this binder, the application can leverage the Kafka Streams API.
    To enable such a feature for your application, include the following dependency
    to your project:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream Kafka提供了专门为Kafka Streams绑定设计的绑定器。借助这个绑定器，应用程序可以利用Kafka Streams
    API。要为应用程序启用这样的功能，请将以下依赖项包含到您的项目中：
- en: '[PRE35]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The Kafka Streams API provides high-level stream DSL. It may be accessed by
    declaring the `@StreamListener` method that takes the `KStream` interface as a
    parameter. KStream provides some useful methods for stream manipulation, well-known
    from other streaming APIs such as `map`, `flatMap`, `join`, or `filter`. There
    are also some other methods specific to Kafka Stream, such as `to(...)` (for sending
    streams to a topic) or `through(...)` (same as `to`, but also creates a new instance
    of `KStream` from the topic):'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka Streams API提供了高级流DSL。可以通过声明将`@StreamListener`方法作为参数的`KStream`接口来访问。KStream提供了一些用于流操作的有用方法，这些方法在其他流API中都很常见，比如`map`、`flatMap`、`join`或`filter`。还有一些特定于Kafka
    Stream的其他方法，比如`to(...)`（用于将流发送到主题）或`through(...)`（与`to`相同，但还从主题创建了一个新的`KStream`实例）：
- en: '[PRE36]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Configuration properties
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置属性
- en: 'Some of the Spring Cloud configuration settings for Kafka have been presented
    before when discussing the implementation of the sample application. Here''s a
    table with the most important properties, which can be set for customizing the
    Apache Kafka binder. All these properties are prefixed by `spring.cloud.stream.kafka.binder`:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论示例应用程序的实现时，已经介绍了一些Kafka的Spring Cloud配置设置。下面是一个包含最重要属性的表格，可用于自定义Apache Kafka绑定器。所有这些属性都以`spring.cloud.stream.kafka.binder`为前缀：
- en: '| Name | Default value | Description |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 默认值 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `brokers` | `localhost` | A comma-separated list of brokers with or without
    port information. |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| `brokers` | `localhost` | 一个逗号分隔的代理列表，带有或不带有端口信息。 |'
- en: '| `defaultBrokerPort` | `9092` | It sets the default port if no port is defined
    using the `brokers` property. |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| `defaultBrokerPort` | `9092` | 如果未使用`brokers`属性定义端口，则设置默认端口。 |'
- en: '| `zkNodes` | `localhost` | A comma-separated list of ZooKeeper nodes with
    or without port information. |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| `zkNodes` | `localhost` | 一个逗号分隔的ZooKeeper节点列表，带有或不带有端口信息。 |'
- en: '| `defaultZkPort` | `2181` | It sets the default ZooKeeper port if no port
    is defined using the `zkNodes` property. |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| `defaultZkPort` | `2181` | 如果未使用`zkNodes`属性定义端口，则设置默认的ZooKeeper端口。 |'
- en: '| `configuration` | - | A Key/Value map of Kafka client properties. It applies
    to all the clients created by the binder. |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| `configuration` | - | Kafka客户端属性的键/值映射。它适用于绑定器创建的所有客户端。 |'
- en: '| `headers` | - | The list of custom headers that will be forwarded by the
    binder. |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| `headers` | - | 将由绑定器转发的自定义标头列表。 |'
- en: '| `autoCreateTopics` | `true` | If set to `true`, the binder creates new topics
    automatically. |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| `autoCreateTopics` | `true` | 如果设置为`true`，绑定器会自动创建新的主题。 |'
- en: '| `autoAddPartitions` | `false` | If set to `true`, the binder creates new
    partitions automatically. |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| `autoAddPartitions` | `false` | 如果设置为`true`，绑定器会自动创建新的分区。 |'
- en: Multiple binders
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多个绑定器
- en: In Spring Cloud Stream nomenclature, the interface that may be implemented to
    provide connection to physical destinations at the external middleware is called
    **binder**. Currently, there are two available built-in binder implementations—Kafka
    and RabbitMQ. In case you would like to provide a custom binder library, the key
    interface that is an abstraction for a strategy for connecting inputs and outputs
    to external middleware is `Binder`, having two methods—`bindConsumer` and `bindProducer`.
    For more details, you may refer to the Spring Cloud Stream specifications.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spring Cloud Stream术语中，可能实现以提供对外部中间件物理目的地的连接的接口称为**绑定器**。目前，有两种可用的内置绑定器实现—Kafka和RabbitMQ。如果您想提供自定义绑定器库，那么作为连接输入和输出到外部中间件的策略的抽象的关键接口是`Binder`，它有两种方法—`bindConsumer`和`bindProducer`。有关更多详细信息，您可以参考Spring
    Cloud Stream规范。
- en: 'The important thing for us is an ability to use multiple binders in a single
    application. You can even mix different implementations, for example, RabbitMQ
    with Kafka. Spring Cloud Stream relies on Spring Boot''s auto-configuration in
    the binding process. The implementation available on the classpath is used automatically.
    In case you would like to use both the default Binders, include the following
    dependencies to the project:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们来说重要的是能够在单个应用程序中使用多个绑定器。甚至可以混合不同的实现，例如RabbitMQ与Kafka。Spring Cloud Stream依赖于Spring
    Boot的自动配置来进行绑定过程。类路径上可用的实现会自动使用。如果您想同时使用默认的绑定器，请将以下依赖项包含到项目中：
- en: '[PRE37]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: If more than one binder has been found in the classpath, the application must
    detect which of them should be used for the particular channel binding. We may
    configure the default binder globally with the `spring.cloud.stream.defaultBinder`
    property, or individually per each channel with the `spring.cloud.stream.bindings.<channelName>.binder`
    property. Now, we go back for a moment to our sample to configure multiple binders
    there. We define RabbitMQ for direct communication between `account-service` and
    `order-service`, and Kafka for the publish/subscribe model between `order-service`
    and other microservices.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在类路径中找到了多个绑定器，应用程序必须检测应该使用哪个绑定器来绑定特定的通道。我们可以使用`spring.cloud.stream.defaultBinder`属性全局配置默认的绑定器，或者使用`spring.cloud.stream.bindings.<channelName>.binder`属性为每个通道单独配置。现在，我们回到我们的示例，为了配置多个绑定器。我们为`account-service`和`order-service`之间的直接通信定义了RabbitMQ，为`order-service`和其他微服务之间的发布/订阅模型定义了Kafka。
- en: 'Here''s the equivalent configuration to that provided for `account-service`
    in the `publish_subscribe` branch ([https://github.com/piomin/sample-spring-cloud-messaging/tree/publish_subscribe](https://github.com/piomin/sample-spring-cloud-messaging/tree/publish_subscribe)),
    but based on two different binders:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这是与`publish_subscribe`分支中为`account-service`提供的等效配置（[https://github.com/piomin/sample-spring-cloud-messaging/tree/publish_subscribe](https://github.com/piomin/sample-spring-cloud-messaging/tree/publish_subscribe)）相当，但基于两个不同的绑定器：
- en: '[PRE38]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Summary
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Spring Cloud Stream can be treated as a separate category in comparison to all
    the other Spring Cloud projects. It is often being associated with other projects,
    and which are currently strongly promoted by Pivotal Spring Cloud Data Flow. That
    is a toolkit for building data integration and real-time data processing pipelines.
    However, it is a huge subject and rather a topic of discussion for a separate
    book.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有其他Spring Cloud项目相比，Spring Cloud Stream可以被视为一个单独的类别。它经常与其他项目相关联，目前由Pivotal
    Spring Cloud Data Flow强烈推广。这是一个用于构建数据集成和实时数据处理管道的工具包。然而，这是一个庞大的主题，更适合作为单独一本书的讨论主题。
- en: More to the point, Spring Cloud Stream provides support for asynchronous messaging,
    which may be easily implemented using a Spring annotation style. I think that
    for some of you, that style of inter-service communication is not as obvious as
    the RESTful API model. Therefore, I have focused on showing you the examples of
    point-to-point and publish/subscribe communication using Spring Cloud Stream.
    I have also described the differences between those two styles of messaging.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，Spring Cloud Stream支持异步消息传递，可以很容易地使用Spring注解风格来实现。我认为，对于一些人来说，这种服务间通信的风格并不像RESTful
    API模型那样显而易见。因此，我专注于向您展示使用Spring Cloud Stream进行点对点和发布/订阅通信的示例。我还描述了这两种消息传递风格之间的区别。
- en: The publish/subscribe model is nothing new, but thanks to Spring Cloud Stream,
    it may be easily included to the microservice-based system. Some of the key concepts,
    such as consumer groups or partitioning, have also been described in this chapter.
    After reading it, you should be able to implement microservices based on the messaging
    model, and integrate them with other Spring Cloud libraries in order to provide
    logging, tracing, or just deploying them as part of the existing, REST-based microservices
    system.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 发布/订阅模型并不新鲜，但由于Spring Cloud Stream的出现，它可以很容易地被包含到基于微服务的系统中。本章还描述了一些关键概念，如消费者组或分区。阅读完本章后，您应该能够基于消息模型实现微服务，并将它们与其他Spring
    Cloud库集成，以提供日志记录、跟踪，或者将它们部署为现有基于REST的微服务系统的一部分。

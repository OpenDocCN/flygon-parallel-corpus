- en: Testing Management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The important thing is not to stop questioning.
  prefs: []
  type: TYPE_NORMAL
- en: '*- Albert Einstein*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the final chapter of the book, and its objective is to guide how to
    understand when and how software testing activities are managed in a living software
    project. To that aim, this chapter is structured into the following sections:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Software development processes**: In this section we study when tests are
    executed in different methodologies: **Behavior-Driven Development** (**BDD**),
    **Test-Driven Development** (**TDD**), **Test-First Development** (**TFD**) and
    **Test-Last Development** (**TLD**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Continuous Integration** (**CI**): In this section, we will discover CI,
    the software development practice, in which the process of build, test, and integration
    is carried out continuously. The common trigger of this process is usually the
    commit of new changes (patches) to a source code repository (for example, GitHub).
    In addition, in this section, we will learn how to extend CI, reviewing the concept
    of Continuous Delivery and Continuous Deployment. Finally, we present two of the
    most important build server nowadays: Jenkins and Travis CI.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test reporting**: In this section, we will first discover the XML format
    in which the xUnit framework usually reports the execution of tests. The problem
    with this format is that it is not human readable. For this reason, there are
    tools which covert this XML into a friendlier format, typically HTML. We review
    two alternatives: Maven Surefire Report and Allure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Defect tracking systems**: In this section, we review several issue trackes:
    JIRA, Bugzilla, Redmine, MantisBT, and GitHub issues.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Static analysis**: In this section, on the one hand we review several automated
    analysis tools (*linters*) such as Checkstyle, FindBugs, PMD, and SonarQube. On
    the other side, we describe several peer review tools, such as Collaborator, Crucible,
    Gerrit, and GitHub pull requests reviews.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Putting all, pieces together**: To conclude the book, in the final section
    we present a complete example application in which different types of tests (unit,
    integration, and end-to-end) are performed using some of the main concepts presented
    along this book.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Software development processes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In software engineering, the software development process (also known as the
    software development life cycle) is the name given to the workflow for the activities,
    actions, and tasks required to create software systems. As introduced in [Chapter
    6](part0148.html#4D4J80-ef8404ed083f459d860f84cc8198f8bb), *From Requirements
    to Test Cases*, the usual phases in any software development process are:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Definition of *what*: Requirements elicitation, analysis and use case modeling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Definition of *how*: The system architecture and modeling of structural and
    behavioral diagrams.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The actual software development (coding).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The set of activities that makes the software available for use (release, installation,
    activation, and so on).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The timing in which tests are designed and implemented in the overall software
    development process results in different test methodologies, namely (see diagram
    after the list):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Behavior-Driven Development** **(BDD)**: At the beginning of the analysis
    phase, conversations between the software consumer (final user or costumer) and
    some of the development team (typically, project leader, manager, or analysts)
    took place. These conversations are used to concretize scenarios (that is, concrete
    examples to build up a common understanding of the system features). These examples
    form the basis to develop acceptance tests using tools such as Cucumber (for more
    details about it, take a look to [Chapter 5](part0122.html#3KB4K0-ef8404ed083f459d860f84cc8198f8bb),
    *Integration of JUnit 5 with external frameworks*.) The description of acceptance
    tests in BDD (for example, using Gherkin in Cucumber) produces both automated
    tests and documentation that accurately describe the application features. The
    BDD approach is naturally aligned with iterative or Agile methodologies, since
    it is very difficult to define requirements upfront, and these evolve as the team
    learns more about the project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The term *agil**e* was popularized with the inception of the Agile manifesto
    in 2001 ([http://agilemanifesto.org/](http://agilemanifesto.org/)). It was written
    by 17 software practitioners (Kent Beck, James Grenning, Robert C. Martin, Mike
    Beedle, Jim Highsmith, Steve Mellor, Arie van Bennekum, Andrew Hunt, Ken Schwaber,
    Alistair Cockburn, Ron Jeffries, Jeff Sutherland, Ward Cunningham, Jon Kern, Dave
    Thomas, Martin Fowler, and Brian Marick), and includes a list of 12 principles
    to guide an iterative and people-centric software development process. Based on
    these principles, several software development frameworks emerged, such as SCRUM,
    Kanban, or extreme programming (XP).
  prefs: []
  type: TYPE_NORMAL
- en: '**Test-Driven Development** (**TDD**): TDD is a methodology in which tests
    are designed and implemented before the actual software design. The idea is to
    convert the requirements obtained in the analysis stage to specific test cases.
    Then, the software is designed and implemented to pass these tests. TDD is part
    of the XP methodology.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test-First Development** (**TFD**): In this methodology, tests are implemented
    after the design stage, but before the actual implementation of the SUT. This
    allows to assure that the software units have been understood correctly before
    its actual implementation. This methodology is followed in the Unified Process,
    which is a popular iterative and incremental software development process. The
    **Rational Unified Process** (**RUP**) is a well-known framework implementation
    of the Unified Process. In addition to TFD, RUP also supports other methodologies
    such as TDD and TLD.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test-Last Development** (**TLD**): In this methodology, the implementation
    of the test is carried out after the implementation of the actual software (SUT).
    This test methodology is followed by classic software development processes, such
    as waterfall (sequential), incremental (multi-waterfall) or spiral (risk-oriented
    multi-waterfall).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/00140.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Test methodologies during the software development processes
  prefs: []
  type: TYPE_NORMAL
- en: There is no universal accepted definitions of the terms presented so far. These
    concepts are subject to continuous evolution and debate, just like the software
    engineering itself. Consider this to be a proposal, which fits into a large number
    of software projects.
  prefs: []
  type: TYPE_NORMAL
- en: Regarding who is responsible for coding the tests, there is a universally accepted
    consensus. It is broadly recommended that unit tests should be written by SUT
    developers. In some cases, especially in small teams, these developers are also
    responsible for other kinds of tests.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, the role of an independent test group (often called testers or
    a QA team) is also a common practice, especially in large teams. One of the objective
    of this role separation is to remove the conflict of interests that may be present
    otherwise. We cannot forget that testing is understood as a destructive activity
    from a physiological point of view (the objective is finding defects). This independent
    test group is usually in charge on the integration, system, and non-functional
    tests. In this case, both groups of engineers should work closely; while tests
    are conducted, developers should be available to correct faults and minimize future
    errors.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, high-level acceptance tests are usually conducted in heterogeneous
    groups involving non-programmers (customers, business analysis, managers, and
    so on) together with software engineers or testers (for example, for implement
    the step definition in Cucumber).
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Integration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The concept of CI was first coined on 1991 by Grady Booch (American software
    engineer, best known for the development of UML together with Ivar Jacobson and
    James Rumbaugh). The **Extreme Programming** (**XP**) methodology adopted this
    term, making it very popular. According to Martin Fowler, CI is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Continuous Integration is a software development practice where members of
    a team integrate their work frequently, usually each person integrates at least
    daily - leading to multiple integrations per day. Each integration is verified
    by an automated build (including test) to detect integration errors as quickly
    as possible.*'
  prefs: []
  type: TYPE_NORMAL
- en: In CI systems, we can identify different parts. First, we need a source code
    repository, which is a file archive to host the source code of our software project,
    typically using a version control system. Nowadays, the preferred version control
    system is Git (originally developed by Linus Torvalds) over older solutions, such
    as CVS or SVN. At the moment of this writing, the leading version control repository
    is GitHub ([https://github.com/](https://github.com/)), which as its name indicates
    it is based on Git. Besides, there are other alternatives, such as GitLab ([https://gitlab.com](https://gitlab.com)),
    BitBucket ([https://bitbucket.org/](https://bitbucket.org/)), or SourceForge ([https://sourceforge.net/](https://sourceforge.net/)).
    The latter was the leading forge in the past, but is nowadays less used.
  prefs: []
  type: TYPE_NORMAL
- en: A copy of the source code repository is synchronized in the local environment
    of developers. The coding work is done against this local copy. Developers are
    supposed to commit new changes (known as *patches*) to the remote repository in
    a daily basis. Frequent commits allow to avoid conflict errors due to the mutual
    modification of the same parts of a given file.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic idea of CI is that every commit should execute the build and test
    the software with the new changes. For that reason, we need a server-side infrastructure
    which automates this process. This infrastructure is known as build server (or
    directly CI server). Two of the most important build servers nowadays are Jenkins
    and Travis CI. Details of both of them are provided in next subsections. As a
    result of the build process, the build server should notify the result of the
    process to the origin developer. If tests were successful, the patch is merged
    in the codebase:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00141.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Continuous Integration process
  prefs: []
  type: TYPE_NORMAL
- en: 'Close to CI, the term DevOps has gained momentum. DevOps comes from *development*
    and *operations*, and it is the name given to a software development process that
    emphasizes the communication and collaboration different teams in a project software:
    development (software engineering), QA (**quality assurance**), and operations
    (infrastructure). The term DevOps is also referred to a job position, typically
    in charge of the setup, monitoring an operation of the build servers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00142.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: DevOps are in between development, operations and QA
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the next figure, the concept of CI can be extended to:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Continuous Delivery**: When the CI pipeline finish correctly, at least a
    release of software will be deployed to a test environment (for instance, deploying
    an SNAPSHOT artifact to a Maven archiver). In this phase, acceptance tests can
    also be executed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Continuous Deployment**: As the final step in the automation toolchain, the
    release of the software can be released to a production environment (for example,
    deploying a web application to the production server for each commit, which achieves
    to pass the complete pipeline).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/00143.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Continuous Integration, Continuous Delivery, and Continuous Deployment chain
  prefs: []
  type: TYPE_NORMAL
- en: Jenkins
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Jenkins ([https://jenkins.io/](https://jenkins.io/)) is an open source build
    server which supports building, deploying, and automating any project. Jenkins
    has been developed in Java, and it can be managed easily using its web interface.
    The global configuration of a Jenkins instance includes information about JDK,
    Git, Maven, Gradle, Ant, and Docker.
  prefs: []
  type: TYPE_NORMAL
- en: Jenkins was originally developed as the Hudson project by Sun Microsystems in
    2004\. After the acquisition of Sun by Oracle, the Hudson project was forked to
    an open source project, renamed to Jenkins. Both names (Hudson and Jenkins) were
    meant to sound like stereotypical English butler names. The idea is they help
    developers carry out tedious tasks, just like a helpful butler.
  prefs: []
  type: TYPE_NORMAL
- en: In Jenkins, builds are typically triggered by new commits in version control
    systems. In addition, builds can be started by other mechanisms, such as scheduled
    cron task or even manually using the Jenkins interface.
  prefs: []
  type: TYPE_NORMAL
- en: Jenkins is highly extensible thanks to its plugin architecture. Thanks to those,
    Jenkins has been extended to a rich plugin ecosystem made by vast number of third-party
    frameworks, libraries, systems, and so on. This is maintained by the open source
    community. The Jenkins plugin portfolio is available on [https://plugins.jenkins.io/](https://plugins.jenkins.io/).
  prefs: []
  type: TYPE_NORMAL
- en: 'At the heart of Jenkins, we find the concept of job. A job is a runnable entity
    monitored by Jenkins. As shown in the screenshot here, a Jenkins job is composed
    of four groups:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Source code management**: This is the URL of the source code repository (Git,
    SVN, and so on)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Build trigger**: This is the mechanism starting the build process, such as
    new changes in the source code repository, external scripts, periodically, and
    so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Build environment**: Optional setup, for example, delete workspace before
    build start, abort the build when stuck, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Collection of steps of the jobs**: These steps can be done with Maven, Gradle,
    Ant, or shell commands. After those, post-build actions can be configured, for
    example, to archive an artifact, to publish JUnit test report (we will describe
    this feature later in this chapter), email notifications, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/00144.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Jenkins job configuration
  prefs: []
  type: TYPE_NORMAL
- en: 'Another interesting way of configuring a job is using a Jenkins *pipeline*,
    which is the description of the build workflow using the Pipeline DSL (a domain-specific
    language based on Groovy). A Jenkins pipeline description is typically stored
    in a file called Jenkinsfile, which can be under the control of the source code
    repository. In short, a Jenkins pipeline is declarative chain of stages composed
    of steps. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Travis CI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Travis CI ([https://travis-ci.org/](https://travis-ci.org/)) is a distributed
    build server used to build and test software projects hosted on GitHub. Travis
    supports open source projects with no charge.
  prefs: []
  type: TYPE_NORMAL
- en: 'The configuration of Travis CI is done using a file named *.travis.yaml*. The
    content of this file is structured using different keywords, including:'
  prefs: []
  type: TYPE_NORMAL
- en: '`language`: Project language, that is, java, node_js, ruby, python, or php
    among others (the complete list is available on [https://docs.travis-ci.com/user/languages/](https://docs.travis-ci.com/user/languages/)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sudo`: Flag value to set if superuser privileges are needed (for example to
    install Ubuntu packages).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dist`: Builds can be executed on Linux environments (Ubuntu Precise 12.04
    or Ubuntu Trusty 14.04).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`addons`: Declarative shortcuts to basic operations of the apt-get commands.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`install`: First part of the Travis build life cycle, in which the installation
    of the required dependencies is done. This part can be optionally initiated using
    `before_install`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`script`: Actual execution of the build. This phase can be optionally surrounded
    by `before_script` and `after_script`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`deploy`: Finally, the deployment of the build can be optionally made in this
    phase. This stage has its own life cycle controlled with `before_deploy` and `after_deploy`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: YAML is lightweight markup language used broadly for configuration files due
    to its minimalist syntax. It was originally defined as Yet Another Markup Language,
    but then it was repurposed to YAML Ain't Markup Language to distinguish its purpose
    as data oriented.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Travis CI provides a web dashboard in which we can check the status of the
    current and past build generated in the projects using Travis CI of our GitHub
    account:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00145.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Travis CI dashboard
  prefs: []
  type: TYPE_NORMAL
- en: Test reporting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From its initial versions, the JUnit testing framework introduced an XML file
    format to report the execution of test suites. Over the years, this XML format
    has become a *de facto* standard for reporting test results, broadly adopted in
    the xUnit family.
  prefs: []
  type: TYPE_NORMAL
- en: These XML can be processed by different programs to display the results in a
    human-friendly format. This is for example what build servers do. For example,
    Jenkins implements a tool called `JUnitResultArchiver`*,* which parses to HTML
    the XML files resulting from the test execution of a job.
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite the fact that this XML format has become pervasive, there is no universal
    formal definition for it. JUnit test executors (for example, Maven, Gradle, and
    so on) usually use its own XSD (XML Schema Definition). For instance, the structure
    of this XML report in Maven ([http://maven.apache.org/surefire/maven-surefire-plugin/](http://maven.apache.org/surefire/maven-surefire-plugin/))
    is as depicted in the following diagram. Note that a test suite is composed by
    a set of properties and a set of test cases. Each test case can be declared as
    a failure (test with some assertion failed), skipped (test ignored), and an error
    (test with an unexpected exception). If none of these states appear in the body
    of the test suite, then the test is interpreted as successful. Finally, for each
    test case the XML also stores the standard output (*system-out*) and the standard
    error output (*system-err*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00146.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Schema representation for Maven Surefire XML reports
  prefs: []
  type: TYPE_NORMAL
- en: The *rerunFailure* is a custom state implemented by Maven Surefire for retrying
    flaky (intermittent) tests ([http://maven.apache.org/surefire/maven-surefire-plugin/examples/rerun-failing-tests.html](http://maven.apache.org/surefire/maven-surefire-plugin/examples/rerun-failing-tests.html)).
  prefs: []
  type: TYPE_NORMAL
- en: With regards to JUnit 5, the Maven and Gradle plugins used to run Jupiter tests
    (`maven-surefire-plugin` and `junit-platform-gradle-plugin` respectively) write
    the results of the test execution following this XML format. In the following
    sections, we are going to see how to transform this XML output to a human readable
    HTML report.
  prefs: []
  type: TYPE_NORMAL
- en: Maven Surefire Report
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'By default, `maven-surefire-plugin` generates the XML resulting from a test
    suite execution as `${basedir}/target/surefire-reports/TEST-*.xml`. This XML output
    can be easily parsed to HTML using the plugin `maven-surefire-report-plugin`.
    To that, we simply need to declare this plugin in the reporting clause of our
    `pom.xml`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This way, when we invoque the Maven lifecycle for documentation (`mvn site`),
    an HTML page with the test result will be included in the general report.
  prefs: []
  type: TYPE_NORMAL
- en: 'See an example of the report, made using the project `junit5-reporting` within
    the GitHub repository examples ([https://github.com/bonigarcia/mastering-junit5](https://github.com/bonigarcia/mastering-junit5)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00147.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: HTML report generated by maven-surefire-report-plugin
  prefs: []
  type: TYPE_NORMAL
- en: Allure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Allure ([http://allure.qatools.ru/](http://allure.qatools.ru/)) is a light-weight
    open source framework for generating test reports for different programming languages,
    including Java, Python, JavaScript, Ruby, Groovy, PHP, .NET, and Scala. Generaliy
    speaking, Allure uses the XML test output and transforms it in an HTML5-rich report.
  prefs: []
  type: TYPE_NORMAL
- en: 'Allure provides support for JUnit 5 projects. This can be done using both Maven
    and Gradle. Regarding Maven, we need to do register a listener in `maven-surefire-plugin`.
    This listener will be the class AllureJunit5 (located in the library `io.qameta.allure:allure-junit5`),
    which is basically a implementation of the JUnit 5’s `TestExecutionListener`.
    As described in [chapter 2](part0051.html#1GKCM0-ef8404ed083f459d860f84cc8198f8bb),
    *What’s New In JUnit 5*, `TestExecutionListener` is part of the Launcher API,
    and it is used to receive events about the test execution. All in all, this listener
    allows to Allure to compile the test information, while it is generated in the
    JUnit platform. This information is stored as JSON files by Allure. After that,
    we can use the plugin `io.qameta.allure:allure-maven` to generate the HTML5 from
    these JSON files. The commands are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The content of our `pom.xml` should contain the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The same process can be done using Gradle, this time using the equivalent plugin,
    `io.qameta.allure:allure-gradle`. All in all, the content of our `build.gradle`
    file should contain:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The following picture shows several screenshots of the Allure report generated
    using the above-mentioned steps (the final result is the same using Maven or Gradle).
    The project of this example is called `junit5-allure`, as usual hosted in GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00148.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Allure reports generated in a JUnit 5 project
  prefs: []
  type: TYPE_NORMAL
- en: Defect-tracking systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A defect-tracking system (also known as bug tracking system, bug tracker, or
    issue tracker) is a software system that keeps track of reported software defects
    in software projects. The main benefits of this kind of systems is to provide
    a centralized overview of development management, bug reporting, and even feature
    request. It is also common to maintain a list of pending items, often called backlog.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a bunch of defect-tracking systems available, both proprietary and
    open source. In this section, we make a brief of several of the most well-known:'
  prefs: []
  type: TYPE_NORMAL
- en: '**JIRA** ([https://www.atlassian.com/software/jira](https://www.atlassian.com/software/jira)):
    It is a proprietary defect-tracking system created by Atlasian. In addition to
    bug and issue tracking, it provides managements capabilities such as SCRUM and
    Kanban boards, a language to query issues (JIRA Query Language), integration with
    external systems (for example, GitHub, Bitbucket), and an add-ons mechanism to
    extend JIRA with plugins from the Atlasian Marketplace ([https://marketplace.atlassian.com/](https://marketplace.atlassian.com/)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bugzilla** ([https://www.bugzilla.org/](https://www.bugzilla.org/)): It is
    an open source web-based, defect-tracking system developed by the Mozilla Foundation.
    Among its features, we can find a database designed to improve performance and
    scalability, query mechanism for searching defects, integrated e-mail capabilities,
    and user roles management.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Redmine** ([http://www.redmine.org/](http://www.redmine.org/)): It is an
    open source, web-based defect-tracking system. It provides wikis, forums, time
    tracking, role-based access control, or Gantt charts for project management.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MantisBT** ([https://www.mantisbt.org/](https://www.mantisbt.org/)): It is
    another open source, web-based defect tracking system designed to be simple but
    effective. Among its features, we can highlight its event-driven plugin system
    to allows extensions both official that third-party, multi-channel notification
    system (e-mail, RSS feed, Twitter plugin, and so on), or role-based access control.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GitHub issues** ([https://guides.github.com/features/issues/](https://guides.github.com/features/issues/)):
    It is the tracking system integrated in each GitHub repository. The approach of
    GitHub issues is to provide a generic tracking system for defects, task scheduling,
    discussions, and even feature request using GitHub issues. Each issue can be categorized
    using a customizable label system, participators management, and notifications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Static analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book, which is finishing soon, has been focused on software testing. No
    surprises, JUnit is about testing. But as we seen in [Chapter 1](part0021.html#K0RQ0-ef8404ed083f459d860f84cc8198f8bb),
    *Retrospective on software quality and Java testing*, although software testing
    is the most commonly performed activities within **Verification & Validation**
    (**V&V**), it is not the only type. The other important group of activities is
    static analysis, in which there is no execution of the software testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are different activities that can be categorized as static analysis.
    Among them, the automated software analysis is an alternative quite inexpensive
    in terms of required effort, and it can help to increase the internal code quality
    significantly. In this chapter, we are going to review several automated software
    analysis tools, known as **linters**, namely:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Checkstyle** ([http://checkstyle.sourceforge.net/](http://checkstyle.sourceforge.net/)):
    It analyzes Java code following different rules, such as missing Javadoc comments,
    the use of magic numbers, naming conventions of variables and methods, method''s
    argument length and line lengths, the use of imports, the spaces between some
    characters, the good practices of class construction, or duplicated code. It can
    be used as Eclipse or IntelliJ plugin, among others.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FindBugs** ([http://findbugs.sourceforge.net/](http://findbugs.sourceforge.net/)):
    It looks for three types of errors within Java code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Correctness bug: Apparent coding mistake (for example, class defines `equal(Object)`
    instead of `equals(Object)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bad practice: Violations of recommended best practices (dropped exceptions,
    misuse of finalize, and so on).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dodgy errors: Confusing code or written in a way that leads to error (for example,
    class `literal` never used, switch fall through, unconfirmed type casts, and redundant
    null check.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**PMD** ([https://pmd.github.io/](https://pmd.github.io/)): It is a cross-language
    static code analyzer, including Java, JavaScript, C++, C#, Go, Groovy, Perl, PHP,
    among others. It has a lot of plugins, including Maven, Gradle, Eclipse, IntelliJ,
    and Jenkins.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SonarQube** ([https://www.sonarqube.org/](https://www.sonarqube.org/)): It
    (formerly just Sonar) is a web-based, open source continuous quality assessment
    dashboard. It supports a wide variety of languages, including Java, C/C++, Objective-C,
    C#, and many others. Offers reports on duplicated code, code smells, code coverage,
    complexity and security vulnerabilities. SonarQube has a distributed flavor called
    **SonarCloud** ([https://sonarcloud.io/](https://sonarcloud.io/)). It can be used
    for free in open source projects, providing a seamless integration with Travis
    CI through a few lines of configuration in `.travis.yml` (see the following snippet),
    including the SonarCloud organization identifier and secure token. These parameters
    can be obtained in the SonarCloud web administration panel, after associating
    out SonarCloud account with GitHub.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, we simply need to call SonarCloud, using Maven or using Gradle:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The following picture shows the SonarCloud dashboard for the example application
    Rate my cat!, described in the last section of this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00149.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: SonarCloud report for the application Rate my cat!
  prefs: []
  type: TYPE_NORMAL
- en: 'Another analysis static technique highly adopted in many software projects
    is **peer review**. This method is quite expensive in terms of time and effort
    required, but when correctly applied, it allows to maintain very good levels of
    internal code quality. Nowadays there is a wide range of tools aimed to ease the
    peer review process of software codebase. Among others, we find the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Collaborator** ([https://smartbear.com/product/collaborator/](https://smartbear.com/product/collaborator/)):
    Peer code (and documentation) review propriety tool created by the company SmartBear.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Crucible** ([https://www.atlassian.com/software/crucible](https://www.atlassian.com/software/crucible)):
    On-premises code review propriety tool for enterprise products, created by Atlassian.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gerrit** ([https://www.gerritcodereview.com/](https://www.gerritcodereview.com/)):
    Web-based code collaboration open source tool. It can be used with GitHub repository
    through GerritHub ([http://gerrithub.io/](http://gerrithub.io/)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GitHub pull request reviews** ([https://help.github.com/articles/about-pull-request-reviews/](https://help.github.com/articles/about-pull-request-reviews/)):
    In GitHub, a pull request is a method for submitting contributions in third-party
    repositories. As part of the collaborative tools provided by GitHub, pull requests
    allows reviews and comments in a easy and integrated fashion.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Putting all pieces together
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this last section of the book, we are going to review some of the major aspects
    covered in this book with a practical example. To that aim, a complete application
    is developed together with different types of tests implemented with JUnit 5.
  prefs: []
  type: TYPE_NORMAL
- en: Features and requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The history of our application begins with a hypothetical person, which loves
    cats. This person owns a clowder, and he/she would like to get feedback about
    them from the external world. For that reason, this person (we can him/her our
    *client* from now on) contacts with us to implement a web application which satisfies
    his/her needs. The name for that application will be *"Rate my cat!"*. In a conversation
    with the client, we elicit a following list of features for the application to
    be developed:'
  prefs: []
  type: TYPE_NORMAL
- en: '**F1**: Each user shall rate a list of cats by watching its name and picture.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**F2**: The rate shall be done once per user using a star mechanism (from `0.5`
    to `5` stars per cat) and optionally comments could be included per cat.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As part of the analysis phase in our development process, those features are
    refined as a list of **functional requirements** (**FR**) as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**FR1**: The application presents a list of cats (composed by name and picture)
    to the end user.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FR2**: Each cat can be rated individually.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FR3**: The range for rating cats is an interval from `0.5` to `5` (stars).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FR4**: Optionally to the numeric rate per cat, users shall include some comments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FR5**: Each end user only shall rate each cat (comments and/or stars) once.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since our application is quite simple, we decide to stop the analysis phase
    here, without modeling our requirements as use cases. Instead, we move on making
    a high-level architectural design of the web application using the classical three-tier
    model: presentation, application (or business) logic, and data tier. Regarding
    the application logic, as the following picture depicts, two components are needed.
    First one, called `CatService` is charge of all the rating actions as described
    in the requirements list. Second one, called `CookiesServices` is needed to handle
    HTTP Cookies, needed to implement FR5*:*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00150.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: High-level architectural design for the application Rate my cat!
  prefs: []
  type: TYPE_NORMAL
- en: 'At this stage, in the development, we are able to decide the major technologies
    implied in the implementation our application:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Spring 5**: This will be the foundation framework for our application. Concretely,
    we use Spring MVC through Spring Boot to simplify the creation of our web application.
    Moreover, we use Spring Data JPA using a simple H2 database to persist the application
    data, and Thymeleaf ([http://www.thymeleaf.org/](http://www.thymeleaf.org/)) as
    template engine (for views in MVC). Finally, we also use the Spring Test module
    to make in-container integration tests in an easy way.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**JUnit 5**: Of course, we cannot use a different testing framework than JUnit
    5 for our tests cases. Moreover, to improve the readability of our assertions
    we use Hamcrest.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mockito**: In order to implement unit test cases, we will use the Mockito
    framework, isolating the SUT from its DOCs in several out-of-container unit tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Selenium WebDriver**: We will also implement different end-to-end tests using
    Selenium WebDriver to exercise our web application from JUnit 5 tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GitHub**: Our source code repository will be hosted in a public GitHub repository.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Travis CI**: Our test suite will be executed each time a new patch is committed
    to our GitHub repository.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Codecov**: To track the code coverage of our test suite we will use Codecov.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SonarCloud**: To provide a complete assessment of the internal quality of
    our source code, we complement our test process with some automatic static analysis
    using SonarCloud.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The screenshot here shows the application GUI in action. It is not the main
    objective of this section to dig deeper in the implementation specifics of the
    application. Visit the GitHub repository of the application on [https://github.com/bonigarcia/rate-my-cat](https://github.com/bonigarcia/rate-my-cat)
    for details about it.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00151.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of the application Rate my cat!
  prefs: []
  type: TYPE_NORMAL
- en: The pictures used to implement this example have been downloaded from the free
    images gallery available on [https://pixabay.com/](https://pixabay.com/).
  prefs: []
  type: TYPE_NORMAL
- en: Tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s focus now on the JUnit 5 tests of this application. We implement three
    types of tests: unit, integration, and end to end. As introduced before, for the
    unit test, we use Mockito to exercise the SUT in isolation. We decide to unit
    test the two major components of our application (`CatService` and `CookiesServices`)
    using Java classes containing different JUnit 5 tests.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the first test (called `RateCatsTest`). As can be seen the code, in
    this class we are defining the class `CatService` as the SUT (using the annotation
    `@InjectMocks`) and the class `CatRepository` (which is used by `CatService` with
    dependency injection) as the DOC (using the annotation `@Mock`). The first test
    of this class (`testCorrectRangeOfStars`) is an example of parameterized JUnit
    5 tests. The objective of this test if to assess the rate method inside `CatService`
    (method `rateCate`). In order to select the test data (input) for this test, we
    follow a black-box strategy and therefore we use the information of the requirements
    definition. Concretely, *FR3* states the range of stars to be used in the rating
    mechanism for cats. Following a boundary analysis approach, we select the edges
    of the input range, that is, 0.5 and 5\. The second test case (`testCorrectRangeOfStars`)
    also tests the same method (`rateCat`), but this time the test evaluates the SUT
    response when out-of-range inputs exercise the SUT (negative test scenario). Then,
    two more tests are implemented in this class, this time aimed to assess *FR4*
    (that is, using also comments to rate cats). Notice that we are using the JUnit
    5 `@Tag` annotation to identify each test with its corresponding requirement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Next, unit test evaluates the cookies service (*FR5*). To that aim, the following
    test use the class `CookiesService` as SUT, and this time we are going to mock
    the standard Java object, which manipulates the HTTP Cookies, that is, `javax.servlet.http.HttpServletResponse`.
    Inspecting the source code of this test class, we can see that the first test
    method (called `testUpdateCookies`) exercise the service method `updateCookies`,
    verifying whether or not the format of the cookies is as expected. Next two tests
    (`testCheckCatInCookies` and `testCheckCatInEmptyCookies`) evaluates the method
    `isCatInCookies` of the service using a positive strategy (that is the input cat
    corresponds with the format of the cookie) and a negative one (the opposite case).
    Finally, the last two tests (`testUpdateOpinionsWithCookies` and `testUpdateOpinionsWithEmptyCookies`)
    exercise the method `updateOpinionsWithCookiesValue` of the SUT following the
    same approach, that is, checking the response of the SUT using a valid and empty
    cookie. All these tests have been implemented following a white-box strategy,
    since its test data and logic relies completely in the specific internal logic
    of the SUT (in this case how the cookies are formatted and managed).
  prefs: []
  type: TYPE_NORMAL
- en: This test does not follow pure white-box approach in the sense of its objective
    is to exercise all the possible paths within the SUT. It can be seen as white-box
    in the sense of it has been designed directly linked to the implementation rather
    than the requirements.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s move on to the next type of tests: integration. For this type of test,
    we are going to use the in-container test capabilities provided by Spring. Concretely,
    we use the Spring test object `MockMvc` to evaluate the HTTP responses of our
    application from the client-side. In each test, different requests are exercised
    verifying if the responses (status code and content type) are as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we also implement several end-to-end tests using Selenium WebDriver.
    Inspecting the implementation of this test, we can see that this test is using
    two JUnit 5 extensions at the same time: `SpringExtension` (to start/stop the
    Spring context within the JUnit 5 tests’ lifecycle) and `SeleniumExtension` (to
    inject WebDriver objects aimed to control web browsers in the test methods). In
    particular, we use three different browsers in one of the tests:'
  prefs: []
  type: TYPE_NORMAL
- en: PhantomJS (headless browser), to assess is the list of cats is properly rendered
    in the web GUI (FR1).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chrome, to rate cats using through the application GUI (FR2).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Firefox, to rate cats using the GUI but getting an error as a result (FR2).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to make easier the traceability of the test executions, in all the
    implemented test, we have selected meaningful test names using `@DisplayName`.
    In addition, for parameterized tests, we use the element name to refine the test
    name of each execution of the test, depending on the test input. The following
    screenshot of the execution of the test suite in Eclipse 4.7 (Oxygen):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00152.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Execution of the test suite for the application Rate my cat! in Eclipse 4.7
  prefs: []
  type: TYPE_NORMAL
- en: As introduced before, we use Travis CI as build server to execute our tests
    during the development process. In the configuration of Travis CI (file `.travis.yml`),
    we setup two additional tools to enhance the development and test process of our
    application. On the one hand, Codecov provides a comprehensive test coverage report.
    On the other hand, SonarCloud provides a complete static analysis. Both tools
    are triggered by Travis CI as part of the continuous integration build process.
    As a result, we can evaluate both the coverage test and the internal code quality
    of our application (such as code smells, duplicated blocks, or technical debt)
    along with our development process.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following picture shows a screenshot of the online report provided by Codecov
    (the report provided by SonarCloud was presented in the previous section of this
    chapter):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00153.jpeg)\'
  prefs: []
  type: TYPE_NORMAL
- en: Codecov report for the application Rate my cat!
  prefs: []
  type: TYPE_NORMAL
- en: 'Last but not least, we are using several *badges* in the `README` of our GitHub
    repository. Concretely, we add badges for Travis CI (status of the last build
    process), SonarCloud (status of the last analysis), and Codecov (percentage of
    the last code coverage analysis):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00154.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: GitHub badges for the application Rate my cat!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we reviewed several concerns about the management side of
    the testing activities. First, we learned that testing can be made in different
    parts of the software development process (software lifecycle) depending on the
    test methodology: BDD (acceptance tests are defined before the requirement analysis),
    TDD (tests are defined before the design of the system), TFD (tests are implemented
    after the system design), and TLD (tests are implemented after the system implementation).'
  prefs: []
  type: TYPE_NORMAL
- en: 'CI is a process more and more used in software development. It consists on
    the automated build and test of a codebase. This process is typically triggered
    with a new commit in a source code repository, such as GitHub, GitLab, or Bitbucket.
    CI is extended to Continuous Delivery (when releases are made to development environment)
    and to Continuous Deployment (when deployment to production environment is made
    continuously). We reviewed two of the most used build servers nowadays: Jenkins
    (*CI as a Service*) and Travis (in-premises).'
  prefs: []
  type: TYPE_NORMAL
- en: There some other tools that can be used to improve the management of tests,
    for example, reporting tools (such as Maven Surefire Report or Allure) or defect
    tracking systems (such as JIRA, Bugzilla, Redmine, MantisBT, and GitHub issues).
    Automated static analysis is a great complement to testing, for example, using
    linters such as Checkstyle, FindBugs, PMD, or SonarQube, and also peer review
    tools such as Collaborator, Crucible, Gerrit, and GitHub pull requests reviews.
  prefs: []
  type: TYPE_NORMAL
- en: To close this book, the final section of this chapter presents a complete web
    application (named *Rate my cat!*) and its corresponding JUnit 5 tests (unit,
    integration, and end-to-end). It consists on a web applications developed and
    assessed using different technologies presented throughout the book, namely, Spring,
    Mockito, Selenium, Hamcrest, Travis CI, Codecov, and SonarCloud.
  prefs: []
  type: TYPE_NORMAL

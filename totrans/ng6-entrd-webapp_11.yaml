- en: Highly-Available Cloud Infrastructure on AWS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The web is a hostile environment. There are good and bad actors. Bad actors
    can try to poke holes in your security or try to bring down your website with
    a **Distributed Denial of Service** (**DDoS**) attack. Good actors, if you're
    lucky, will love your website and won't stop using it. They'll shower you with
    recommendations to improve your site, but also, they may run into bugs and they
    may be so enthusiastic that your site may slow down to a crawl due to high traffic.
    Real-world deployments on the web require a lot of expertise to get it right. As
    a full-stack developer, you can only know about so many nuances of hardware, software,
    and networking. Luckily, with the advent of cloud service providers, a lot of
    this expertise has been translated into software configurations, with the difficult
    hardware and networking concerns taken care of by the provider.
  prefs: []
  type: TYPE_NORMAL
- en: One of the best features of a cloud service provider is cloud scalability, which
    refers to your server automatically scaling out to respond to high volumes of
    unexpected traffic and scaling down to save costs when the traffic returns back
    to normal levels. **Amazon Web Services** (**AWS**) goes beyond basic cloud scalability
    and introduces high-availability and fault tolerant concepts, allowing for resilient
    local and global deployments. I have chosen to introduce you to AWS, because of
    its vast capabilities that go way beyond what I will touch in this book. With
    Route 53, you can get free DDoS protection; with API Gateway, you create API keys,
    with AWS Lambda you can handle millions of transactions for only a few dollars
    a month and with CloudFront you can cache your content at secret edge-locations
    that are scattered around major cities of the world. In addition, Blue-Green deployments
    will allow you to achieve no-downtime deployments of your software.
  prefs: []
  type: TYPE_NORMAL
- en: 'Overall, the tools and techniques you will be learning in this chapter are
    adaptable to any cloud provider and is fast becoming critical knowledge for any
    full-stack developer. We will be going over the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating and protecting AWS accounts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Right-sizing infrastructure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple load testing to optimize instance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring and deploying to AWS ECS Fargate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scripted Blue-Green deployments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Billing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a secure AWS account
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Account access and control is of paramount importance in any cloud service,
    and this includes AWS as well. After initial account creation, you will have your
    root credentials, which is your email and password combination.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by creating an AWS account:'
  prefs: []
  type: TYPE_NORMAL
- en: Start by navigating to `https://console.aws.amazon.com`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you don't have one, create a new account
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you are new to AWS, you can get 12 months of free tier access to various
    services, as shown on the sign-up screen here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/9e286392-91c9-4518-ae4f-7215ac2426db.png)AWS Account Sign Up'
  prefs: []
  type: TYPE_NORMAL
- en: Your AWS billing is tied to your root credentials. If compromised, a lot of
    damage can be done on your account before you can gain back access.
  prefs: []
  type: TYPE_NORMAL
- en: 'Ensure that you enable 2FA on your root credentials:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To add another layer of security, going forward, you need to stop logging in
    to your AWS account using your root credentials. You can create user accounts
    using the AWS **Identity and Access Management** (**IAM**) module. If these accounts
    get compromised, unlike your root account, you can easily and quickly delete or
    replace them.
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the `IAM` module
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new user account with global admin rights
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log in to the AWS console using these credentials
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You should enable 2FA for these credentials as well
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A secure account setup looks as follows, with every status reported as green:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/a42157c6-6389-42d0-be5a-d9295095a7da.png)AWS IAM Module After Secure
    Setup'
  prefs: []
  type: TYPE_NORMAL
- en: The major benefit of working with user accounts is programmatic access. For
    each user account, you can create a public access ID and private access key pair.
    When you're working with third parties, such as hosted continuous integration
    services, your own application code or CLI tools, you use your programmatic access
    keys to connect to your AWS resources. When, inevitably, the access keys leak,
    it is quick and convenient to disable access to the old keys and create new ones.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, user account access can be tightly controlled by very granular
    permissions. You can also create roles with a group of permissions and further
    control communication between AWS services and some external services.
  prefs: []
  type: TYPE_NORMAL
- en: When creating user accounts and roles, always err on the side of minimal permissions.
    This can be an exercise in frustration, when working with clients, contractors,
    or colleagues who are unfamiliar with AWS; however, it is a worthwhile exercise.
  prefs: []
  type: TYPE_NORMAL
- en: You're only as secure and reliable as your weakest link, so you must plan for
    failures and, most importantly, practice recovery plans on a regular basis.
  prefs: []
  type: TYPE_NORMAL
- en: Securing secrets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Password and private key leaks occur more commonly than you may think. Your
    keys may be compromised in unsecured public Wi-Fi networks; you may accidentally
    check them in to your code repository or use the superbly insecure communication
    methods like email. Accidental code check-ins, however, are the biggest issue,
    since most junior developers don't realize that deletion isn't an option in source
    control systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a developer, there are a few noteworthy best practices to follow to safeguard
    your secrets:'
  prefs: []
  type: TYPE_NORMAL
- en: Always use a VPN service on public Wi-Fi, such as [tunnelbear.com](https://www.tunnelbear.com/)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Leverage the `.aws/credentials` file located under your user's `home` folder,
    to create profiles and store access keys
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a `.env` file in the root of your project that is in `.gitignore` to
    store any secrets that your CI server may later inject as a team norm
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Always review commits before pushing them
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Following these conventions every single time will get you in the good habit
    of never checking in your secrets to a code repository. In the next section, we
    will delve into resource considerations for your cloud environment.
  prefs: []
  type: TYPE_NORMAL
- en: Right-sizing infrastructure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The point of optimizing your infrastructure is to protect your companies revenue,
    while minimizing the cost of operating your infrastructure. Your goal should be
    to ensure that users don't encounter high-latency, otherwise known as bad performance
    or worse, unfulfilled or dropped requests, all the while making your venture remains
    a sustainable endeavor.
  prefs: []
  type: TYPE_NORMAL
- en: 'The three pillars of web application performance are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: CPU utilization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Memory usage
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Network bandwidth
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I have intentionally left disk access out of the key consideration metrics,
    since only particular workloads executed on an application server or data store are
    affected by it. Disk access would rarely ever impact the performance of serving
    a web application as long as application assets are delivered by a **Content Delivery
    Network** (**CDN**). That said, still keep an eye on any unexpected runaway disk
    access, such as high frequency creation of temp and log files. Docker, for example,
    can spit out logs that can easily fill up a drive.
  prefs: []
  type: TYPE_NORMAL
- en: In an ideal scenario, CPU, memory, and network bandwidth use should be utilized
    evenly around 60-80% of available capacity. If you encounter performance issues
    due to various other factors such as disk I/O, a slow third-party service, or
    inefficient code, most likely one of your metrics will peek at or near maximum
    capacity, while the other two are idling or severely underutilized. This is an
    opportunity to use more CPU, memory, or bandwidth to compensate for the performance
    issue and also evenly utilize available resources.
  prefs: []
  type: TYPE_NORMAL
- en: The reason behind targeting 60-80% utilization is to allow for some time for
    a new instance (server or container) to be provisioned and ready to serve users.
    After your predefined threshold has been crossed, while a new instance is provisioned,
    you can continue serving the increasing number of users, thus minimizing unfulfilled
    requests.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this book, I have discouraged over-engineering or perfect solutions.
    In today's complicated IT landscape, it is nearly impossible to predict where
    you will encounter performance bottlenecks. Your engineering may, very easily,
    spend $100,000+ worth of engineering hours, where the solution to your problem
    may be a few hundred dollars of new hardware, whether it be a network switch,
    solid state drive, CPU, and more memory.
  prefs: []
  type: TYPE_NORMAL
- en: If your CPU is too busy, you may want to introduce more bookkeeping logic to
    your code, via index, hash tables, or dictionaries, that you can cache in memory
    to speed up subsequent or intermediary steps of your logic. For example, if you
    are constantly running array lookup operations to locate particular properties
    of a record, you can perform an operation on that record, saving the ID and/or
    the property of the record in a hash table that you keep in memory will reduce
    your runtime cost from *O(n)* down to *O(1)*.
  prefs: []
  type: TYPE_NORMAL
- en: Following the preceding example, you may end up using too much memory with hash
    tables. In this case, you may want to more aggressively offload or transfer caches
    to slower, but more plentiful data stores using your spare network bandwidth,
    such as a Redis instance.
  prefs: []
  type: TYPE_NORMAL
- en: If your network utilization is too high, you may want to investigate usage of
    CDNs with expiring links, client-side caching, throttling requests, API access
    limits for customers abusing their quotas, or optimize your instances to have
    disproportionately more network capacity compared to its CPU or Memory capacity.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing instance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In an earlier example, I demonstrated the use of my `duluca/minimal-node-web-server` Docker
    image to host our Angular apps. Even though Node.js is a very lightweight server,
    it is simply not optimized to just be a web server. In addition, Node.js has single-threaded
    execution environment, making it a poor choice for serving static content to many
    concurrent users at once.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can observe the resource that a Docker image is utilizing by executing
    `docker stats`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are comparative results of the system resources that a Node and NGINX-based
    servers utilize at rest:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Server** | **              Image Size** | **             Memory Usage**
    |'
  prefs: []
  type: TYPE_TB
- en: '| `duluca/minimal-nginx-web-server` |                                     16.8
    MB |                                         1.8 MB |'
  prefs: []
  type: TYPE_TB
- en: '| `duluca/minimal-node-web-server` |                                     71.8
    MB |                                       37.0 MB |'
  prefs: []
  type: TYPE_TB
- en: However, at rest values only tell a portion of the story. To get a better understanding,
    we must perform a simple load test to see memory and CPU utilization under load.
  prefs: []
  type: TYPE_NORMAL
- en: Simple load testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To get a better understanding of the performance characteristics of our server,
    let''s put them under some load and stress them:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start your container using `docker run`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'If you''re using `npm Scripts for Docker`, execute the following command to
    start your container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Execute the following bash script to start the load test:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This script will send 100requests/second to the server until you terminate it.
  prefs: []
  type: TYPE_NORMAL
- en: Execute `docker stats` to observe the performance characteristics.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here are high-level observations of CPU and memory utilization:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **CPU Utilization Statistics** | **        Low** | **         Mid** | **          High**
    | **   Max Memory** |'
  prefs: []
  type: TYPE_TB
- en: '| `duluca/minimal-nginx-web-server` |                   2% |                    15%
    |                       60% |                   2.4 MB |'
  prefs: []
  type: TYPE_TB
- en: '| `duluca/minimal-node-web-server` |                 20% |                    45%
    |                     130% |                    75 MB |'
  prefs: []
  type: TYPE_TB
- en: As you can see, there's a significant performance difference between the two
    servers serving the exact same content. Note that this kind of testing based on
    requests/second is good for a comparative analysis and does not necessarily reflect
    real-world usage.
  prefs: []
  type: TYPE_NORMAL
- en: It is clear that our NGINX server will give us the best bang for our buck. Armed
    with an optimal solution, let's deploy the application on AWS.
  prefs: []
  type: TYPE_NORMAL
- en: Deploy to AWS ECS Fargate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AWS **Elastic Container Service** (**ECS**) Fargate is a cost effective and
    an easy-to-configure way to deploy your container in the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: 'ECS consists of four major parts:'
  prefs: []
  type: TYPE_NORMAL
- en: Container Repository, **Elastic Container Registry** (**ECR**), where you publish
    your Docker images
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Services, Tasks and Task Definitions, where you define runtime parameters and
    port mappings for your container as a task definition that a service runs as tasks
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Cluster, a collection of EC2 instances, where tasks can be provisioned and scaled
    out or in
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fargate, a managed cluster service, that abstracts away EC2 instances, load
    balancer, and security group concerns
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At the time of publishing, Fargate is only available in the AWS `us-east-1`
    region.
  prefs: []
  type: TYPE_NORMAL
- en: Our goal is to create a highly-available blue-green deployment, meaning that
    at least one instance of our application will be up and running in the event of
    a server failure or even during a deployment. These concepts are explored in detail
    in [Chapter 12](7e85d2ce-9a69-481e-9945-40e59195414c.xhtml), *Google Analytics
    and Advanced Cloud Ops*, in the *Cost Per User in a Scalable Environment* section.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring ECS Fargate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can access ECS functions under the AWS Services menu, selecting the Elastic
    Container Service link.
  prefs: []
  type: TYPE_NORMAL
- en: If this is your first time logging in, you must go through a tutorial, where
    you will be forced to create a sample app. I would recommend going through the
    tutorial and deleting your sample app afterward. In order to delete a service,
    you'll need to update your service's number of tasks to 0\. In addition, delete
    the default cluster to avoid any unforeseen charges.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Fargate Cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's start by configuring the Fargate Cluster, which act as a point of anchor
    when configuring other AWS services. Our cluster will eventually run a cluster
    service, which we will gradually build up in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: At the time of publishing, AWS Fargate is only available in AWS US East region,
    with support for more regions and Amazon Elastic Container Service for Kubernetes
    (Amazon EKS) coming soon. Kubernetes is a widely preferred open source alternative
    to AWS ECS with richer capabilities for container orchestration with on-premises,
    cloud, and cloud-hybrid deployments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to Elastic Container Service
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Clusters | Create Cluster
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the Networking only... powered by AWS Fargate template
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on the Next step and you see the Create Cluster step, as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/d610cb50-7264-4010-9ba0-abab9bddc018.png)AWS ECS Create Cluster'
  prefs: []
  type: TYPE_NORMAL
- en: Enter Cluster name as `fargate-cluster`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a VPC to isolate your resources from other AWS resources
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Create Cluster to finish the setup
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will see the summary of your actions, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/63465452-62ae-46e0-bd8b-e841b681dcdc.png)AWS ECS Fargate Cluster'
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have created a cluster within it's own **Virtual Private Cloud**
    (**VPC**), you can view it under Elastic Container Service | Clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Creating container repository
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next, we need to set up a repository where we can publish the container images
    we build in our local or CI environment:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to Elastic Container Service
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Repositories | Create Repository
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter repository name as `lemon-mart`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy the Repository URI generated on the screen
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Paste the URI in `package.json` of your application as the new `imageRepo`
    variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Click on Create Repository
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Next step and then on Done to finish setup
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the summary screen, you will get further instructions on how to use your
    repository with Docker. Later in the chapter, we will go over scripts that will
    take care of this for us.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/45094246-8522-48b8-a9b0-84c8bcbfd782.png)AWS ECS Repository'
  prefs: []
  type: TYPE_NORMAL
- en: You can view your new repository under Elastic Container Service | Repositories.
    We will go over how to publish your image in the upcoming `npm Scripts for AWS`
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Creating task definition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With a container target defined in our repository, we can define a task definition,
    which contains the necessary metadata to run our container, such as port mappings,
    reserved CPU, and memory allocations:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to Elastic Container Service
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Task Definitions | Create new Task Definition
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select Fargate launch type compatibility
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter Task Definition Name as `lemon-mart-task`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select Task role `none` (you can add one later to enable access other AWS services)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter Task Size `0.5 GB`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter Task CPU `0.25 CPU`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on Add Container:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter Container name as `lemon-mart`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For Image, paste the image repo URI from earlier, but append the `:latest` tag
    to it so that it always pulls the latest image in the repository, such as `000000000000.dkr.ecr.us-east-1.amazonaws.com/lemon-mart:latest`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set a Soft limit of `128 MB` for NGINX and `256 MB` for Node.js
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under Port mappings, specify Container port as `80` for NGINX and `3000` for
    Node.js
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Accept the remaining defaults
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on Add; this is how your task definition will look before creating it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/19d28a70-feb5-4322-972c-4b458cba7888.jpg)AWS ECS Task Definition'
  prefs: []
  type: TYPE_NORMAL
- en: Click on Create to finish setup
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: View your new Task Definition under Elastic Container Service | Task Definitions.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the default settings will enable AWS CloudWatch logging, which is
    a way you can retroactively access console logs of your container instance. In
    this example, a CloudWatch Log Group named `/ecs/lemon-mart-task` will be created.
  prefs: []
  type: TYPE_NORMAL
- en: View your new Log Group under Cloud Watch | Logs.If you're adding a container
    that needs to persist data, the task definition allows you to define a volume
    and mount a folder to your Docker container. I've published a guide a for configuring
    AWS **Elastic File System** (**EFS**) with your ECS Container at [bit.ly/mount-aws-efs-ecs-container](http://bit.ly/mount-aws-efs-ecs-container).
  prefs: []
  type: TYPE_NORMAL
- en: Creating elastic load balancer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In a highly-available deployment, we will want to be running two instances
    of your container, as defined by the task definition we just created, across two
    different **Availability Zones** (**AZs**). For this kind of dynamically scaling
    out and scaling in, we need to configure an **Application Load Balancer** (**ALB**)
    to handle request routing and draining:'
  prefs: []
  type: TYPE_NORMAL
- en: On a seperate tab, navigate to EC2 | Load Balancers | Create Load Balancer
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an Application Load Balancer
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Enter Name `lemon-mart-alb`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In order to support SSL traffic under listeners, you can add a new listener
    for HTTPS on port `443`. An SSL setup can be achieved conveniently via AWS services
    and wizards. During the ALB configuration process, AWS offers links to these wizards
    to create your certificates. However, it is an involved process and one that can
    vary depending on your existing domain hosting and SSL certification setup. I
    will be skipping over SSL-related configuration in this book. You can find SSL
    related steps, published on the guide I've published at [bit.ly/setupAWSECSCluster](http://bit.ly/setupAWSECSCluster).
  prefs: []
  type: TYPE_NORMAL
- en: Under Availability Zones, select the VPC that was created for your fargate-cluster
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select all AZs listed
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Expand Tags and add a key/value pair to be able to identify the ALB, like ``"App":
    " LemonMart"``'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Next
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select Default ELB security policy
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Next
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new cluster specific security group, `lemon-mart-sg`, only allowing
    port `80` inbound or `443` if using HTTPS
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When creating your Cluster Service in the next section, ensure that the security
    group created here is the one selected during service creation. Otherwise, your
    ALB won't be able to connect to your instances.
  prefs: []
  type: TYPE_NORMAL
- en: Click on Next
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name a new Target group as `lemon-mart-target-group`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change protocol type from `instance` to `ip`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under Health check, keep the default route `/`, if serving a website on HTTP
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Health checks are critical for scaling and deployment operations to work. This
    is the mechanism that AWS can use to check whether an instance has been created
    successfully or not.
  prefs: []
  type: TYPE_NORMAL
- en: If deploying an API and/or redirecting all HTTP calls to HTTPS, ensure that
    your app defines a custom route that is not redirected to HTTPS. On HTTP server
    GET `/healthCheck` return simple 200 message saying `I'm healthy` and verify that
    this does not redirect to HTTPS. Otherwise, you will go through a lot of pain
    and suffering trying to figure out what's wrong, as all health checks fail and
    deployments inexplicably fail. `duluca/minimal-node-web-server` provides HTTPS
    redirection, along with an HTTP-only `/healthCheck` endpoint out of the box. With
    `duluca/minimal-nginx-web-server`, you will need to provide your own configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Click on Next
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do *not* register any Targets or IP Ranges. ECS Fargate will magically manage
    this for you, if you do so yourself, you will provision a semi broken infrastructure
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on Next:Review; your ALB settings should look similar to the one shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/a2c2bb37-74c7-4c43-b071-da94aa7448c2.png)AWS Application Load Balancer
    Settings'
  prefs: []
  type: TYPE_NORMAL
- en: Click on Create to finish setup
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will be using the lemon-mart-alb when creating your Cluster Service in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: Creating cluster service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, we will bring it all together by creating a service in our cluster using
    the task definition and the ALB we created:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to Elastic Container Service
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Clusters | fargate-cluster
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under Services tab, click on Create
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select Launch type `Fargate`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the task definition you created earlier
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that task definitions are versioned, such as `lemon-mart-task:1`. If you
    were to make a change to the task definition, AWS will create `lemon-mart-task:2`.
    You will need to update the service with this new version for your changes to
    take effect.
  prefs: []
  type: TYPE_NORMAL
- en: Enter Service name `lemon-mart-service`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Number of tasks `2`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Minimum healthy percent `50`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Maximum percent `200`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Next
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set minimum health percent to 100 for high-availability even during deployment.
    Fargate pricing is based on usage per second, so while deploying your application,
    you will be charged extra for the additional instances, while the old ones are
    being deprovisioned.
  prefs: []
  type: TYPE_NORMAL
- en: Under Configure network, select the same VPC as your cluster from earlier
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select all subnets that are available; there should be at least two for high-availability
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the security group you created in the previous section—`lemon-mart-sg`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select Load Balancer type as Application Load Balancer
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the lemon-mart-alb option
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add Container port to the ALB, such as `80` or `3000`, by clicking on the Add
    to Load Balancer button
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the Listener port that you had already defined
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the Target group you had already defined
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Uncheck Enable service discovery integration
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Next
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you'd like your instances to scale out and in automatically, when their capacities
    are reach a certain limit, then set Auto Scaling
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I would recommend skipping the set up of auto scaling during the initial setup
    of your service to make it easier to troubleshoot any potential configuration
    issues. You can come back and set it up later. Automatic task scaling policies
    rely on alarms, such as CPU Utilization. In [Chapter 12](7e85d2ce-9a69-481e-9945-40e59195414c.xhtml),
    *Google Analytics and Advanced Cloud Ops,* in the *Cost Per User in Scalable Environment*
    section, you can read about calculating your optimum target server utilization
    and set your alarms based on this number.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on Next and review your changes, as illustrated:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/6ebcff07-5980-4e80-9362-66a39efc8715.png)AWS Fargate cluster service
    settings'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, click on Save to finish setup
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Observe your new service under Elastic Container Service | Clusters | fargate-cluster
    | lemon-mart-service. Until you publish an image to your container repository,
    your AWS service won't be able to provision an instance, since the health check
    will continually fail. After you publish an image, you will want to ensure that
    there are no errors present in the Events tab for your service.
  prefs: []
  type: TYPE_NORMAL
- en: AWS is a complicated beast and with Fargate, you can avoid a lot of complexity.
    However, if you're interested in setting up your own ECS cluster using your own
    Ec2 instances, you can get significant discounts with 1-3 year reserved instances.
    I have a 75+ setup guide available at [bit.ly/setupAWSECSCluster](http://bit.ly/setupAWSECSCluster).
  prefs: []
  type: TYPE_NORMAL
- en: We have executed a lot of steps manually to create our Cluster. AWS CloudFormation
    resolves this issue by offering configuration templates that you can customize
    to your needs or script your own templates from scratch. If you would like to
    get serious about AWS, this kind of code-as-infrastructure setup is definitely
    the way to go.
  prefs: []
  type: TYPE_NORMAL
- en: For production deployments, ensure that your configuration is defined by a CloudFormation
    template, so it can be easily reprovisioned, not if, but when a deployment related
    faux pas occurs.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the DNS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you use AWS Route 53 to manage your domain, it is easy to assign a domain
    or a subdomain to an ALB:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to Route 53 | Hosted Zones
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select your domain, like `thejavascriptpromise.com`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Create record set
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter Name as `lemonmart`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set Alias to `yes`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the lemon-mart-alb from the load balancer list
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Create to finish setup
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/f1b4f3fc-7f27-4687-ab90-4e641b544aa1.png)Route 53 - Create record
    set'
  prefs: []
  type: TYPE_NORMAL
- en: Now, your site will be reachable on the subdomain you just defined, for example `http://lemonmart.thejavascriptpromise.com`.
  prefs: []
  type: TYPE_NORMAL
- en: If don't use Route 53, don't panic. On your domain provider's website, edit
    the `Zone` file to create an `A` record to the ELB's DNS address and you're done.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the DNS Name
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to get your load balancers'' DNS address, perform these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to EC2 | Load Balancers
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the lemon-mart-alb
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the Description tab note the DNS name; consider this example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Prep Angular app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section presumes that you have set up Docker and `npm Scripts for Docker`as
    detailed in [Chapter 3](4e68114e-68b7-4fe6-a853-81347e981667.xhtml)*, Prepare
    Angular App for Production Release*. You can get the latest version of these scripts
    at [bit.ly/npmScriptsForDocker](http://bit.ly/npmScriptsForDocker).
  prefs: []
  type: TYPE_NORMAL
- en: 'Implement an optimized `Dockerfile`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that if you''re using `npm Scripts for Docker`, update the internal image
    port from `3000` to `80`, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Adding npm Scripts for AWS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Just like `npm Scripts for Docker`, I have developed a set of scripts, called `npm
    Scripts for AWS`, that work on Windows 10 and macOS. These scripts will allow
    you to upload and release your Docker images in spectacular, no-downtime, blue-green
    fashion. You can get the latest version of these scripts at [bit.ly/npmScriptsForAWS](http://bit.ly/npmScriptsForAWS):'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that [bit.ly/npmScriptsForDocker](http://bit.ly/npmScriptsForDocker)
    are set up on your project
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a `.env` file and set `AWS_ACCESS_KEY_ID` and  `AWS_SECRET_ACCESS_KEY`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Ensure that your `.env` file is in your `.gitignore` file to protect your secrets
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install or upgrade to latest AWS CLI:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On macOS `brew install awscli`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On Windows ``choco install awscli``
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Log in to AWS CLI with your credentials:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run `aws configure`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You'll need your Access Key ID and Secret Access Key from when you configured
    your IAM account
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set Default region name like `us-east-1`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Update `package.json` to add a new `config` property with the following configuration
    properties:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Ensure that you update `package.json` from when you configured `npm Scripts
    for Docker` so that the `imageRepo` property has the address of your new ECS repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add AWS `scripts` to `package.json`, as illustrated:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '`npm run aws:login` calls platform-specific commands that automate an otherwise
    multi-step action to get a Docker login command from the AWS CLI tool, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'You would first execute `aws ecr get-login` and then copy-paste the resulting `docker
    login` command and execute it so that your local Docker instance is pointed to
    AWS ECR:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '`npm run aws:deploy` pulls a Docker container that itself executes blue-green
    deployment, using the parameters you have provided using the `aws ecr` commands.
    The details of how this works are beyond the scope of this book. To see more examples
    using native `aws ecr` commands, refer to the `aws-samples` repository at [github.com/aws-samples/ecs-blue-green-deployment](https://github.com/aws-samples/ecs-blue-green-deployment).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the `duluca/ecs-deploy-fargate` blue-green deployment script is a
    fork of the original `silintl/ecs-deploy` image modified to support AWS ECS Fargate
    using PR `https://github.com/silinternational/ecs-deploy/pull/129`. Once `silintl/ecs-deploy`
    merges this change, I recommend using `silintl/ecs-deploy` for your blue-green
    deployments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Finally, `npm run aws:release` simply runs `aws:login`, `docker:publish` from
    `npm Scripts for Docker` and `aws:deploy` commands in the right order.
  prefs: []
  type: TYPE_NORMAL
- en: Publish
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Your project is configured to be deployed on AWS. You mostly need to use two
    of the commands we created to build and publish an image:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Execute `docker:debug` to test, build, tag, run, tail, and launch your app
    in a browser to test the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Execute `aws:release` to configure Docker login with AWS, publish your latest
    image build, and release it on ECS:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Verify that your tasks are up and running at the Service level:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/0a2d364f-6765-47de-ae97-71986360135a.png)AWS ECS ServiceEnsure that
    running count and desired count are the same.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Verify that your instances are running at the Task level:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/e562d999-718c-45a3-9e2d-cbf41f192aab.png)AWS ECS task instance'
  prefs: []
  type: TYPE_NORMAL
- en: Note the Public IP address and navigate to it; for example, `http://54.164.92.137` and
    you should see your application or LemonMart running.
  prefs: []
  type: TYPE_NORMAL
- en: Verify that the Load Balancer setup is correct at the DNS level.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Navigate to the ALB DNS address, for example `http://lemon-mart-alb-1871778644.us-east-1.elb.amazonaws.com`,
    and confirm that the app renders, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/490c9bc1-8041-4500-a606-eab6e8ce98fe.png)LemonMart running on AWS
    Fargate'
  prefs: []
  type: TYPE_NORMAL
- en: Et voilà! Your site should be up and running.
  prefs: []
  type: TYPE_NORMAL
- en: 'In subsequent releases, following your first, you will be able to observe blue-green
    deployment in action, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/cf3d456c-09af-4193-94a8-a38efc501f23.png)AWS Service during Blue-Green
    Deployment'
  prefs: []
  type: TYPE_NORMAL
- en: There are two tasks running, with two new ones being provisioned. While the
    new tasks are being verified, running count will rise up to four tasks. After
    the new tasks are verified and the connections from old ones drained, the running
    count will return to two.
  prefs: []
  type: TYPE_NORMAL
- en: You can automate your deployments by configuring CircleCI with your AWS credentials,
    using a container that has the `awscli` tool installed and running `npm Scripts
    for AWS`. With this technique, you can achieve Continuous Deployment to a staging
    environment or Continuous Delivery to a production environment.
  prefs: []
  type: TYPE_NORMAL
- en: This is all great, but how much does a basic highly-available configuration
    cost? Let's examine that in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Billing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'My highly-available deployment of LemonMart on AWS Fargate cost roughly $45
    a month. Here''s the breakdown:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Description** | **     Cost** |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon Simple Storage Service (S3) |          $0.01 |'
  prefs: []
  type: TYPE_TB
- en: '| AWS Data Transfer |          $0.02 |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon CloudWatch |          $0.00 |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon EC2 Container Service (ECS Fargate) |        $27.35 |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon Elastic Compute Cloud(EC2 Load Balancer instances) |        $16.21
    |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon EC2 Container Registry (ECR) |          $0.01 |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon Route 53 |          $0.50 |'
  prefs: []
  type: TYPE_TB
- en: '| **Total** | **       $44.10** |'
  prefs: []
  type: TYPE_TB
- en: Note that the bill is very detailed, but it does accurate all the AWS services
    we end up using. The major costs are running two instances of our web server on
    **EC2 Container Service** (**ECS**) and running load balances on **Elastic Compute
    Cloud** (**EC2**). Objectively speaking, $45/month may seem like a lot of money
    to host one web application. It is possible to get a lot more for your money if
    you're willing to set up your own cluster with dedicated EC2 servers where you
    can pay in 1 or 3-year increments and get cost savings of up to 50%. A similar,
    highly available deployment with two-instances on Heroku starts at $50/month with
    other rich features you can get access to. Similarly, two-instances on Zeit Now
    will cost $30/month. Note that both Heroku and Zeit Now don't give you access
    to physically diverse availability zones. Digital Ocean, on the other hands, allows
    you to provision servers in different data centers; however, you must code your
    own infrastructure. For $15/month, you can set up your own highly-available cluster
    across three servers and be able to host multiple sites on it.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about the nuances and various security considerations
    in properly protecting your AWS account. We went over the concepts of right-sizing
    your infrastructure. You conducted simple load testing in an isolated manner to
    find out relative differences in performance between two web servers. Armed with
    an optimized web server, you configured an AWS ECS Fargate cluster to achieve
    a highly-available cloud infrastructure. Using npm Scripts for AWS, you learned
    how to script repeatable and reliable no-downtime Blue-Green deployments. Finally,
    you became aware of the basic costs of running your infrastructure on AWS and
    other cloud providers such as Heroku, Zeit Now, and Digital Ocean.
  prefs: []
  type: TYPE_NORMAL
- en: In the next and final chapter, we will complete our coverage of the breadth
    of topics that a full-stack web developer should know about when deploying applications
    on the web. We will add Google Analytics to LemonMart to measure user behavior,
    leverage advanced load testing to understand the financial impact of deploying
    a well-configured scalable infrastructure, and measure actual use of important
    application features with custom analytics events.
  prefs: []
  type: TYPE_NORMAL

- en: Building an Audio Recorder
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recording audio is the most performance-intensive operation our app must handle.
    It is also the one feature where having access to native APIs will be the most
    rewarding. We want our users to be able to record with the lowest latency possible
    for the mobile device in order to achieve the highest fidelity of sound. Additionally,
    this recording should optionally happen over the top of an existing mix of pre-recorded
    tracks all playing in sync .
  prefs: []
  type: TYPE_NORMAL
- en: Since this phase of our app development will dive the deepest into platform-specific
    native APIs, we will split our implementations into two phases. We will first
    build out the iOS-specific details of the recording features, followed by Android.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Building a feature rich cross-platform audio recorder for iOS and Android with
    a consistent API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating iOS framework libraries, such as AudioKit ([http://audiokit.io](http://audiokit.io)),
    which was built entirely with Swift
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to convert Swift/Objective C methods to NativeScript
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building custom reusable NativeScript view components based on native APIs,
    as well as how to use them inside Angular
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring a reusable Angular Component that can both be used via routing and opened
    via a popup modal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrate Android Gradle libraries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to convert Java methods to NativeScript
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using multiple item templates with NativeScript's ListView
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Phase 1 – Building an audio recorder for iOS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The audio capabilities of the iOS platform are impressive, to say the least.
    A group of wonderfully talented audiophiles and software engineers have collaborated
    on building an open source framework layer on top of the platform's audio stack. This
    world class engineering effort is the awe inspiring AudioKit ([http://audiokit.io/](http://audiokit.io/)),
    led by the fearless Aurelius Prochazka, a true pioneer in audio technology.
  prefs: []
  type: TYPE_NORMAL
- en: The AudioKit framework is written entirely with Swift, which introduces a couple
    of interesting surface-level challenges when integrating with NativeScript.
  prefs: []
  type: TYPE_NORMAL
- en: Challenge detour – Integrate Swift based library into NativeScript
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: "At the time of this writing, NativeScript can work with Swift if the codebase properly\
    \ exposes the classes and types to Objective-C via what's called a **bridging\
    \ header**, allowing both the languages to be mixed or matched. You can learn\
    \ more about what a bridging header is here: [https://developer.apple.com/library/content/documentation/Swift/Conceptual/BuildingCocoaApps/MixandMatch.html](https://developer.apple.com/library/content/documentation/Swift/Conceptual/BuildingCocoaApps/MixandMatch.html).\
    \ [](https://developer.apple.com/library/content/documentation/Swift/Conceptual/BuildingCocoaApps/MixandMatch.html)\
    \ This bridging header is auto generated when the Swift codebase is compiled into\
    \ a framework. Swift offers rich language features, some of which do not have\
    \ a direct correlation to Objective C. Full featured support for the latest Swift\
    \ language enhancements will likely come to NativeScript eventually however at\
    \ the time of this writing there are a couple considerations to keep in mind.\uFEFF"
  prefs: []
  type: TYPE_NORMAL
- en: 'AudioKit utilizes the best of what the Swift language has to offer, including
    enriched **enum** capabilities. You can learn more about the expanded enum features
    in the Swift language here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://developer.apple.com/library/content/documentation/Swift/Conceptual/Swift_Programming_Language/Enumerations.html](https://developer.apple.com/library/content/documentation/Swift/Conceptual/Swift_Programming_Language/Enumerations.html)'
  prefs: []
  type: TYPE_NORMAL
- en: 'In particular, there is this from the documentation: "t*hey adopt many features
    traditionally supported only by classes, such as computed properties to provide
    additional information about the enumeration’s current value, and instance methods
    to provide functionality related to the values the enumeration represents.*'
  prefs: []
  type: TYPE_NORMAL
- en: Such *enums* are foreign to Objective C and, therefore, cannot be made available
    in the bridging header. Any code that uses Swift's exotic *enums* will be simply
    ignored when the bridging header is generated at compile time, resulting in Objective
    C not being able to interact with those sections of the code. This means you will
    not be able to use a method from a Swift codebase in NativeScript which utilizes
    these enhanced constructs out of the box (*at the time of this writing*).
  prefs: []
  type: TYPE_NORMAL
- en: 'To remedy this, we will fork the AudioKit framework and flatten the exotic
    enums used in the `AKAudioFile` extension files, which provide a powerful and
    convenient export method we will want to use to save our recorded audio files.
    The exotic *enum* we need to modify looks like this ([https://github.com/audiokit/AudioKit/blob/master/AudioKit/Common/Internals/Audio%20File/AKAudioFile%2BProcessingAsynchronously.swift](https://github.com/audiokit/AudioKit/blob/master/AudioKit/Common/Internals/Audio%20File/AKAudioFile%2BProcessingAsynchronously.swift)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This is unlike any *enum* you may be familiar with; as you can see, it includes
    properties in addition to what enums have. When this code is compiled and the
    bridging header is generated to mix or match with Objective-C, the bridging header will
    then exclude any code that uses this construct. We will flatten this out to look
    like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We will then adjust the portions of the `AKAudioFile` extension to use our flattened
    properties. This will allow us to manually build `AudioKit.framework` we can use
    in our app, exposing the method we want to use: `exportAsynchronously`.
  prefs: []
  type: TYPE_NORMAL
- en: We won't go over the details of manually building `AudioKit.framework`, as it
    is well documented here: [https://github.com/audiokit/AudioKit/blob/master/Frameworks/INSTALL.md#building-universal-frameworks-from-scratch](https://github.com/audiokit/AudioKit/blob/master/AudioKit/Common/Internals/Audio%20File/AKAudioFile%2BProcessingAsynchronously.swift).
    With our custom-built framework, we are now ready to integrate it into our app.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating a custom-built iOS framework into NativeScript
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can now create an internal plugin to integrate this iOS framework into our
    app. Take the custom `AudioKit.framework` we have built and create a `nativescript-audiokit` directory
    at the root of our app. We then add a `platforms/ios` folder inside to drop the
    framework into. This will let NativeScript know how to build these iOS-specific
    files into the app. As we want this internal plugin to be treated like any standard
    npm plugin, we will also add `package.json` directly inside the `nativescript-audiokit`
    folder with the following contents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now use the following command to add it to our app (NativeScript will
    look locally first and find the **nativescript-audiokit** plugin):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This will properly add the custom-built iOS framework into our app.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, we need two more very important items:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since AudioKit is a Swift-based framework, we want to ensure our app includes
    the proper supporting Swift libraries. Add a new file, `nativescript-audiokit/platforms/ios/build.xcconfig`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we will be engaging with the user''s microphone, we will want to ensure
    the microphone usage is indicated in our app''s property list. We will also take
    this opportunity to add two additional property settings to enhance our app''s
    abilities. So, in total, we will add three property keys for the following purposes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let the device know our app needs access to the microphone and ensure the user's
    permission is requested on first access.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continue playing audio if the app is placed into the background.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide the ability to see the app's `documents` folder in iTunes when the phone
    is connected to a computer. This will allow you to view recorded files right inside
    of iTunes via the app's Documents. This could be useful for integration into a
    desktop audio editing software.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Add a new file, `nativescript-audiokit/platforms/ios/Info.plist`, with the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a screenshot to better illustrate the internal plugin structure in
    our app:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00036.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, when NativeScript builds the iOS app, it will ensure `AudioKit.framework`
    is included as a library and merge the contents of `build.xcconfig` and `Info.plist`
    into our app''s configuration. Any time we make changes to the files inside this
    internal plugin folder (`nativescript-audiokit`), we want to ensure our app picks
    up those changes. To do so, we can simply remove and add the plugin back, so let''s
    do that now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We are now ready to build our audio recorder using the AudioKit API for iOS.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up native API type checking and generate AudioKit TypeScript definitions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first thing we want to do is install `tns-platform-declarations`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we create a new file in the root of the project called `references.d.ts`
    with the following contents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This provides us with full type checking and intellisense support for iOS and
    Android APIs.
  prefs: []
  type: TYPE_NORMAL
- en: 'We now want to generate typings for the AudioKit framework itself. We can execute
    this command to generate the typings for the included `AudioKit.framework`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We are setting the environment variable `TNS_TYPESCRIPT_DECLARATIONS_PATH` to
    the present working directory (`pwd`) with a folder prefix of `typings`. When
    NativeScript creates the iOS build, it will also generate type definition files
    for all the native APIs available to our app, including third-party libraries.
    We will now see a `typings` folder appear in our project, containing two folders:
    `i386` and `x86_64`. One is for the Simulator architecture and the other the device.
    Both will contain the same output, so we can just focus on one. Open the `i386`
    folder and you will find an `objc!AudioKit.d.ts` file.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to use only that file, so move it to the root of the `typings` folder:
    `typings/objc!AudioKit.d.ts`. We can then remove both the `i386` and `x86_64` folders,
    as we will no longer need them (the other API definition files are provided via
    `tns-platform-declarations`). We just generated these typings to get TypeScript
    definitions for the AudioKit library. This is a one-time thing, done to integrate
    easily with this native library, so you are safe to add this custom `typings`
    folder to source control.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Double-check `tsconfig.json` and ensure you have the `"skipLibCheck": true`
    option enabled. We can now modify our `references.d.ts` file to include the additional
    types for the AudioKit library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Our project structure should now look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00037.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Build recorder with AudioKit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will begin by creating a model around our interaction with AudioKit's recording
    APIs. You could just start writing directly against these APIs right from your
    Angular component or service, but since we want to provide a consistent API across
    iOS and Android, there's a smarter way to architect this. Instead, we will abstract a
    simple API, usable across both platforms, which will tap into the correct native
    implementations under the hood.
  prefs: []
  type: TYPE_NORMAL
- en: 'There will be a lot of interesting details related to AudioKit going on here,
    but create `app/modules/recorder/models/record.model.ts` with the following and
    we will explain some of the bits in a moment:'
  prefs: []
  type: TYPE_NORMAL
- en: Later, we will add the `.ios.ts` suffix to this model, since it will contain
    iOS-specific implementation details. However, here in Phase 1, we will use the
    model directly (omitting the platform suffix) while we develop our iOS recorder.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '`RecordModel` will behave a bit like a state machine, where the only states
    it could be in are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`readyToRecord`: Default starting state. Must be in this state to enter the
    recording state.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`recording`: Quiet in the studio! Recording in process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`readyToPlay`: User has stopped recording and now has a recorded file to play
    back with the mix.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`playing`: User is playing back the recorded file with the mix.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`saved`: User chose to save the recording, that should kick off actions to
    save the new track with the active composition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`finish`: Once the save actions are complete, the recorder should shut down.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We then define the shape of the events the recorder will provide with `IRecordEvents`.
    In this case, we will have a single event, `stateChange`, which will notify any
    listeners when the state changes (*see the state setter*). Our model will extend
    NativeScript's `Observable` class (hence, `RecordModel extends Observable`), which
    will provide us with the notify API to dispatch our events.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then set up several references to the various AudioKit bits we will use.
    Most of what is designed is directly from this AudioKit example on recording:
    [https://github.com/audiokit/AudioKit/blob/master/Examples/iOS/RecorderDemo/RecorderDemo/ViewController.swift](https://github.com/audiokit/AudioKit/blob/master/Examples/iOS/RecorderDemo/RecorderDemo/ViewController.swift).
    We even use the same state enum setup (with a few extras). In their example, AudioKit''s `AKAudioPlayer`
    is used for playback; but, with our design, we will load our recorded files into our
    multitrack player design to play them back with our mix. We could work `AKAudioPlayer`
    into `TrackPlayerModel` for iOS; but, `TNSPlayer` (from the **nativescript-audio**
    plugin) is cross-platform compatible and will work just fine. We''ll cover the
    details of how we load these new recorded files into our design shortly, but notifying
    listeners of the recorder''s state will provide us all the flexibility we need
    to handle all that when we get there.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You may wonder why we type-cast this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Good question. AudioKit provides Extensions to Core Foundation classes such
    as `AVAudioFile`. These were known as `Categories` in Objective C: [https://developer.apple.com/library/content/documentation/General/Conceptual/DevPedia-CocoaCore/Category.html](https://developer.apple.com/library/content/documentation/General/Conceptual/DevPedia-CocoaCore/Category.html);
    however, in Swift, they are referred to as `Extensions`: [https://developer.apple.com/library/content/documentation/Swift/Conceptual/Swift_Programming_Language/Extensions.html](https://developer.apple.com/library/content/documentation/Swift/Conceptual/Swift_Programming_Language/Extensions.html).'
  prefs: []
  type: TYPE_NORMAL
- en: If you recall, we generated TypeScript definitions for AudioKit; but, we only
    kept the `objc!AudioKit.d.ts` file to reference. If we had looked in the foundation
    definitions, we would have seen the extension to `AVAudioFile`. However, since
    we did not keep those definitions around and instead are relying on the default
    `tns-platform-declarations` definitions, this `Extension` is not known to our
    TypeScript compiler, so we simply type-cast it, as we know AudioKit provides this.
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s also critical `RecordModel` sets the audio session to `PlayAndRecord`,
    as this will allow us to record while playing our mix at the same time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You may also be curious why some classes use `init()` and others `init(null)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Some of the initializers for AudioKit's classes take an optional argument, for
    example, `AKMixer` takes an optional `NSArray` of `AVAudioNode` to connect. However,
    our TypeScript definitions have those defined as required, so we are just passing
    `null` to that argument and instead using the `connect` node API directly.
  prefs: []
  type: TYPE_NORMAL
- en: How to convert Swift/ObjC methods to NativeScript
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The last point of interest from `RecordModel` might be the `save` method, which
    will export our recording from the app''s `tmp` directory to the app''s `documents`
    folder while converting it to the smaller filesize `.m4a` audio format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Long method name, right? Yes, indeed; some Swift/ObjC parameterized method
    names collapse to become very long. That particular method in Swift is defined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Since we had the TypeScript definitions generated for AudioKit, they helped
    us out here. However, sometimes, you don't have that luxury. A Swift/ObjC method
    with various parameters for arguments collapse into each other while adding `With` in
    between the start of the method name and the start of the parameter argument names,
    while capitalizing the first character upon collapsing each.
  prefs: []
  type: TYPE_NORMAL
- en: Building custom reusable NativeScript view for native audio Waveform display
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Instead of creating an Angular Component for our Waveform display, we will create
    a custom NativeScript view component, that taps into native APIs, that we can
    then register with Angular to use in our components. The reason for doing this
    is due to NativeScript's powerful `view` base class that we can extend, which
    provides a nice API when using underlying native APIs for the `view`. This Waveform
    display will work in tandem with the `RecordModel` we just created to bring to
    life our real-time Waveform feedback display of the device's microphone. It would
    also be amazing to reuse this Waveform display as a static audio file waveform
    rendering on our track list, as an alternate view for our main composition view.
    AudioKit provides classes and APIs to do all this.
  prefs: []
  type: TYPE_NORMAL
- en: Since we want to be able to use this anywhere in our app, we will create it
    inside the shared module directory; however, keep in mind that it could live anywhere.
    It doesn't matter so much here, since this is not an Angular component that needs
    to be declared in `NgModule`. Additionally, since this will specifically work
    with native APIs, let's create it inside a new `native` folder to potentially
    house other NativeScript-specific view components.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create `app/modules/shared/native/waveform.ts` with the following contents,
    which we will explain in a moment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: We are creating several properties using NativeScript's `Property` class, which
    will add great conveniences when exposing native view properties through the view
    binding properties. One such convenience in defining these properties with the
    `Property` class, these setters will only be called when `nativeView` is defined,
    avoiding double invoked property setters (one via a pure JS property setter, which
    is the alternative, and potentially another for when the underlying `nativeView`
    is ready).
  prefs: []
  type: TYPE_NORMAL
- en: When wanting to expose native view properties that could be bound via your custom
    component, define several `Property` classes for them, referencing the name you'd
    like to use for the view binding.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'By setting up these `Property` instances, we can now do this in our view component
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This will only be invoked once `nativeView` is ready, which is exactly what
    we want. You can read more about this particular syntax and notation in this draft
    written by core team member Alex Vakrilov:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://gist.github.com/vakrilov/ca888a1ea410f4ea7a4c7b2035e06b07#registering-the-property](https://gist.github.com/vakrilov/ca888a1ea410f4ea7a4c7b2035e06b07#registering-the-property).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, at the bottom of our class (after it''s defined), we register the class
    with the `Property` instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Okay, with that explained, let's look at some other elements to this implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are also introducing a helpful interface here, which we will apply to `RecordModel`
    in a moment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This will help define a shape for other models to implement, ensuring they
    conform to an API the Waveform display expects:'
  prefs: []
  type: TYPE_NORMAL
- en: '`target`: Defines the key input to be used with the native class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dispose()`: Each model should provide this method to handle any clean up when
    the view is destroyed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This is the custom NativeScript 3.x View Life cycle call execution order:'
  prefs: []
  type: TYPE_NORMAL
- en: '`createNativeView()`: `AnyNativeView;`  // Create your native view.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`initNativeView()`: `void;`  // Init your native view.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`disposeNativeView()`: `void;`  // Clean up your native view.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `createNativeView` method overridden from NativeScript''s `View` class
    is likely the most interesting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Here, we allow the `type` property to determine which type of Waveform display
    it should render.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of `mic`, we utilize AudioKit's `AKNodeOutputPlot` (which actually
    extends `EZAudioPlot` under the hood) to initialize a waveform (that is, `audioplot`)
    using our model's target, which will end up being our RecordModel's microphone.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of `file`, we utilize AudioKit's `EZAudioPlot` directly to create
    a static waveform representing an audio file.
  prefs: []
  type: TYPE_NORMAL
- en: The `initNativeView` method, also overridden from NativeScript's `View` class,
    is called second in its life cycle and provides a way to initialize your native
    view. You might find it interesting that we call the setters again here. The setters
    are called first when the component bindings are set via the XML and the class
    instantiates, which is *before* `createNativeView` and `initNativeView` are called.
    This why we cache the values in private references. However, we also want these
    setters to modify `nativeView` with Angular's view bindings (when changed dynamically),
    which is why we also have `if (this.nativeView)` inside the setters to change
    `nativeView` dynamically when available.
  prefs: []
  type: TYPE_NORMAL
- en: The `disposeNativeView` method (you guessed it, also overridden from the `{N}`
    of the `View` class) is called when `View` gets destroyed, which is where we call
    the model's `dispose` method if available.
  prefs: []
  type: TYPE_NORMAL
- en: Integrate a custom NativeScript view into our Angular app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To use our NativeScript Waveform view within Angular, we need to first register
    it. You can do this in the root module, root app component, or another place that
    is initialized at boot time (usually, not in a lazy-loaded module). To be tidy,
    we will register it within `SharedModule` in the same directory, so add the following
    in `app/modules/shared/shared.module.ts`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The `registerElement` method allows us to define the name of the Component we
    want to use within Angular components as the first argument, and takes a resolver
    function that should return the NativeScript `View` class to use for it.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now use our new `IWaveformModel` and clean up some of `RecordModel` to
    use it, as well as prepare to create our Android implementation next. Let's refactor
    a couple things out of `RecordModel` into a common file to share code between
    our iOS and Android (coming soon!) models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create `app/modules/recorder/models/record-common.ts`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This contains most of what was at the top of `RecordModel`, with the addition
    of the `IRecordModel` interface, which extends `IWaveformModel`. Since we built
    out our iOS implementation, we now have a model shape we would like our Android
    implementation to adhere to. Abstracting that shape into an interface will provide
    us a clear path to follow when we move to Android momentarily.
  prefs: []
  type: TYPE_NORMAL
- en: 'For convenience, let''s also create an index for our models, which would also
    expose this common file, in `app/modules/recorder/models/index.ts`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now modify `RecordModel` to import these common items, as well as implement
    this new `IRecordModel` interface. Since this new interface also *extends* `IWaveformModel`,
    it will immediately tell us we need to implement the `readonly target`getter and
    the `dispose()`method, as required to be used with our Waveform view:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The `target` of `RecordModel` will be the microphone that the Waveform view
    will use. Our `dispose` method will stop the AudioKit engine while doing reference
    clean up, as well as ensuring to clean out any temporary files created while recording.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Recorder View layout
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When the user taps on Record in the top right corner of the app, it prompts
    the user to authenticate, after which the app routes to the record view. Additionally,
    it would be nice to reuse this record view in a modal popup to show when the composition
    contains tracks, so the user doesn't feel like they are leaving the composition
    while recording. However, when the composition is new, it's fine to navigate to
    the record view via routing. We will show how this can be done, but let's first
    set up our layout using the new fancy Waveform view and our powerful new `RecordModel`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following to `app/modules/recorder/components/record.component.html`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: We are using `FlexboxLayout` because we want our Waveform view to stretch to
    cover the full available vertical space, leaving only the recorder's controls
    positioned at the bottom. `FlexboxLayout` is a very versatile layout container,
    which provides most of the same CSS styling attributes found with the the flexbox
    model on the web.
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, we show a Cancel button inside a `GridLayout` container only
    when displayed as a modal, since we need a way to close the modal. ActionBars
    are ignored and not displayed when the view is opened via a modal.
  prefs: []
  type: TYPE_NORMAL
- en: ActionBars are ignored when the view is opened via a modal, so they are not
    displayed in the modal. `ActionBar` is shown on navigated views only.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, our `ActionBar` setup is rather interesting here and is one of
    the areas of NativeScript view layouts where iOS and Android differ the most.
    On iOS, `NavigationButton` has a default behavior, that automatically pops the
    view from the stack and animates back to the previous view. Additionally, any
    tap events on `NavigationButton` on iOS are completely ignored, whereas on Android,
    the tap event is triggered on `NavigationButton`. Because of this crucial difference,
    we want to completely ignore `NavigationButton` of `ActionBar` by using `visibility="collapsed"`
    to ensure it is never shown. Instead, we use `ActionItem` with an explicit tap
    event to ensure the correct logic is triggered on our component for both platforms.
  prefs: []
  type: TYPE_NORMAL
- en: '`NavigationButton` behavior on iOS and Android is different:'
  prefs: []
  type: TYPE_NORMAL
- en: '**iOS**: `NavigationButton` ignores (tap) events, and this button appears by
    default when navigating to a view.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Android**: `NavigationButton` (tap) events are triggered.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can see our Waveform (the custom NativeScript) view in use here. We use
    Angular's binding syntax when binding the model, since it's an object. For the
    other properties, we specify their values directly, since they are primitive values.
    We could, however, use Angular's binding syntax on those as well if we wanted
    to change those values dynamically via user interaction. For example, we could
    show a fun color picker, which would allow the user to change the color (`plotColor`)
    of the waveform on the fly.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll provide a component-specific stylesheet for our record component, `app/modules/recorder/components/record.component.css`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Some of these CSS properties may look familiar if you''ve used the flexbox
    model on the web. A great and fun resource to learn more about flexbox styling
    is Flexbox Zombies by Dave Geddes: [http://flexboxzombies.com](http://flexboxzombies.com.).'
  prefs: []
  type: TYPE_NORMAL
- en: At this point, our CSS is starting to grow and we could clean things up a lot
    with SASS. We will do exactly that, coming up soon, so hang in there!
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at the Component at `app/modules/recorder/components/record.component.ts`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Starting from the bottom of that file, you'll probably wonder what the heck
    `invokeOnRunLoop` is*.* This is a handy way to ensure thread safety in conditions
    where the thread might rear its ugly head. In this case, AudioKit's engine is
    started from the UI thread in `RecordModel`, since NativeScript marshals native
    calls on the UI thread. However, when our record view closes (whether it be from
    a modal our navigating back), some background threads are invoked. Wrapping our
    handling of closing this view with `invokeOnRunLoop` helps solve this transient
    exception. It's the answer to how to use iOS `dispatch_async(dispatch_get_main_queue(…))`
    with NativeScript.
  prefs: []
  type: TYPE_NORMAL
- en: 'Working our way up the file, we''ll encounter `this.recorderService.state$.subscribe((state:
    number) => …`. In a moment, we''ll be implementing a way to observe the recording
    `state$` as an observable, so our view can simply react to its state changes.'
  prefs: []
  type: TYPE_NORMAL
- en: Also of note, it is a handy way to collapse `RecordState enum` into properties
    we can use as view bindings to compare against the current state (`this.state
    = state;`).
  prefs: []
  type: TYPE_NORMAL
- en: When the component is constructed, `recorderService.setupNewRecording()` will
    prepare our service for a brand new recording each time this view appears.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, take note of the injection of `@Optional()private params: ModalDialogParams`*.*
    Earlier, we mentioned that *it would be nice to reuse this record view in a modal
    popup*. The interesting part is that `ModalDialogParams` is only provided to a
    component when it is opened in a modal. In other words, Angular''s dependency
    injection doesn''t know anything about a `ModalDialogParams` service unless the
    component is explicitly opened via NativeScript''s `ModalService`, so this would
    break our ability to route to this component as we had originally set up, since
    Angular''s DI would fail to recognize such a provider by default. In order to
    allow this component to continue working as a routing component, we will simply
    mark that argument as `@Optional()`, which will just set its value to null when
    not available instead of throwing a dependency injection error.'
  prefs: []
  type: TYPE_NORMAL
- en: This will allow our component to be routed to, as well as be opened in a modal!
    Reuse in full swing!
  prefs: []
  type: TYPE_NORMAL
- en: In order to conditionally navigate to this component via routing, or open it
    in a modal, we can make a few small adjustments, bearing in mind that `RecorderModule`
    is lazy loaded, so we'll want to lazily load the module before opening it as a
    modal.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open `app/modules/mixer/components/action-bar/action-bar.component.ts` and
    make the following modifications:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we conditionally emit an event using `EventEmitter` with a Component
    `Output` decorator if the composition contains tracks; otherwise we navigate to
    the record view. We then adjust `Button` in the view template to use the method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now modify `app/modules/mixer/components/mixer.component.html` to use
    `Output` by its name as a normal event:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Now for the fun part. Since we'd love to be able to open any component in a
    modal, whether it's part of a lazy loaded module or not, let's add a new method
    to `DialogService` that can be used anywhere.
  prefs: []
  type: TYPE_NORMAL
- en: 'Make the following changes to `app/modules/core/services/dialog.service.ts`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Here, we inject `ModalDialogService` and `NgModuleFactoryLoader` (which is actually `NSModuleFactoryLoader`,
    since, if you recall, we provided for in [Chapter 5](part0064.html#1T1400-289fe2426d594f99a90e4363b2c9c34d),
    *Routing and Lazy Loading*) to load any module on demand to open a Component (declared
    in that lazy loaded module) in a modal. *It also works for components that do
    not need to be lazy loaded*. In other words, it will optionally lazily load any
    module by its path, if provided, and then use its `NgModuleFactory` to get a module
    reference, which we can pass along as an option (via the `moduleRef` key) to `this.modalService.showModal`
    to open a Component declared in that lazily-loaded module.
  prefs: []
  type: TYPE_NORMAL
- en: 'This will come in handy again later; however, let''s put it to use now by making
    the following changes to `app/modules/mixer/components/mixer.component.ts`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: This will lazily load `RecorderModule` and then open `RecordComponent` in a
    popup modal. Cool!
  prefs: []
  type: TYPE_NORMAL
- en: Finishing implementation with RecorderService
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s finish this implementation with `RecorderService` in `app/modules/recorder/services/recorder.service.ts`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The pinnacle of our recording service is its ability to react to the model''s
    state changes. This, in turn, emits an Observable stream notifying observers (our
    `RecordComponent`) when the state changes, as well as internally doing the work
    necessary to control `RecordModel` along with `PlayerService`. The critical key
    to our design is we want our active composition''s tracks to play in the background
    while we record, so we can play along with the mix. This case is important:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'When `RecordModel` is `readyToPlay`, we know that a recording has been created
    and is now ready to play. We stop the playing mix, get a reference to the recorded
    file''s path. Then, we update `PlayerService` to queue up this new track to be
    played back. We will show the updated `PlayerService` in a moment, which handles
    adding the new file to the mix, but it adds a new `TrackPlayer` like everything
    else in our mix. However, the file points to a temporary recorded file at the
    moment, as we don''t want to save the composition until the user decides to officially
    commit and save the recording. The recording session will allow the user to re-record
    again if they are not happy with the recording. This is why we hold a reference
    to `_trackId`. If a recording had already been added to the mix, we use that `_trackId`
    to exclude it when re-recording, since we would not want to hear back the recording
    we are re-recording over:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We also use it to clean up after ourselves if the user chose to cancel instead
    of saving:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s take a look at the modifications to `PlayerService` we need to make
    in order to support our recording:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: These changes will support our recorder's ability to interact with the active
    composition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Considerations when reusing a Component to lazy load in a modal as well
    as allow lazy loading via routing.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Angular services must be provided *only* at the *root* level *if they are intended
    to be singletons* shared across all lazy loaded modules, as well as the root module.
    `RecorderService` is lazy loaded with `RecordModule` when it is navigated to,
    as well as being opened in a modal. Since we are now injecting `PlayerService`
    into our `RecorderService` (which is lazily loaded) and `PlayerService` now injects
    `MixerService` (which is also lazily loaded as the root route in our app), we
    will have to create a problem where our services are no longer singletons. In
    fact, you may even see an error like this if you were to try and navigate to `RecordComponent`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'JS: ERROR Error: Uncaught (in promise): Error: No provider for PlayerService!'
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve this, we will drop the providers from `PlayerModule` and `MixerModule`
    (since those modules are both lazily loaded) and instead provide those services
    only in our `CoreModule`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The modified `app/modules/player/player.module.ts` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The modified `app/modules/mixer/mixer.module.ts` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Updated to provide these services as true singletons from `CoreModule` only,
    the code for `app/modules/core/core.module.ts` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: This is how you can solve these types of issues; but, this is exactly the reason
    why we recommend using Ngrx in  [Chapter 10](https://cdp.packtpub.com/mastering_nativescript_mobile_development/wp-admin/post.php?post=104&action=edit#post_361), *@ngrx/store
    + @ngrx/effects for State Management*, coming up soon, as it can help alleviate
    these dependency injection issues.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, our setup works nicely; but, it can be greatly improved and even
    simplified when we start integrating ngrx for a more Redux-style architecture.
    We have done a few reactive things here, such as our `RecordComponent` reacting
    to our service's `state$` observable; but, we needed to inject `MixerService`
    into `PlayerService`, which feels slightly wrong architecturally, since `PlayerModule`
    should not really have a dependency on anything `MixerModule` provides. Again,
    *this technically works just fine,* but when we start working with ngrx in [Chapter
    10](part0121.html#3JCK20-289fe2426d594f99a90e4363b2c9c34d), *@ngrx/store + @ngrx/effects
    for State Management*, you'll see how we can reduce our dependency mixing throughout
    the whole codebase.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a moment though, relax, and pat ourselves on the back, as this
    has been an impressive amount of work. Take a look at what the fruits of our labor
    are producing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00038.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Phase 2 – Building an audio recorder for Android
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Believe it or not we''ve actually done most of the heavy lifting to make this
    work on Android already! That''s the beauty of NativeScript. Designing an API
    that makes sense, as well as an architecture that can plug/play underlying native
    APIs, is key to NativeScript development. At this point, we just need to plug
    in the Android pieces into the shape we have designed. So, to summarize, we now
    have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`RecorderService` that works in tandem with `PlayerService` to coordinate our
    multitrack handling abilities'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Waveform view that is flexible and ready to provide an Android implementation
    under the hood
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RecordModel` that should tap into the appropriate underlying target platform
    APIs and be ready for Android details to be plugged into'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Built interfaces defining the shape of the model, for Android models to simply
    implement to know which API they should define
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get to work.
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to rename `record.model.ts` to `record.model.ios.ts`, since it''s specific
    to iOS, but before doing so, we will want a TypeScript definition file (`.d.ts`)
    for it, so our codebase can continue importing as `''record.model''`. There are
    several ways this could be done, including just manually writing one out. However,
    the tsc compiler has a handy `-d` flag, which will generate definition files for
    us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: This will spit out a ton of TypeScript warnings and errors; but, it doesn't
    matter in this case, since our definition file will be generated correctly. We
    don't need to generate JavaScript, just the definition, so you can ignore the
    wall of issues that results.
  prefs: []
  type: TYPE_NORMAL
- en: 'We now have two new files:'
  prefs: []
  type: TYPE_NORMAL
- en: '`record-common.model.d.ts` (*you can delete this as we won''t need it*)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`record.model.d.ts`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `record-common.model` file is imported by `RecordModel`, which is why a
    definition was generated for it as well; but, you can *delete* that. Now, we have
    the definition file, but we want to modify it slightly. We don''t need any of
    the `private` declarations and/or any native types it included; you would notice
    it contained the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Since those are iOS-specific, we''ll want to type those as *any*, so it''s
    applicable to both iOS and Android. This is what things look like with our modifications:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Perfect, now rename `record.model.ts` to `record.model.ios.ts`. We have now
    finalized our iOS implementation, as well as ensured maximum code reuse to turn
    our focus to Android. NativeScript will use the target platform suffix files at
    build time, so you don't ever need to worry that iOS-only code would end up on
    Android and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: The `.d.ts` definition file we generated previously will be used at JavaScript
    transpilation time by the TypeScript compiler, whereas the runtime will use the
    platform-specific JS files (without the extension).
  prefs: []
  type: TYPE_NORMAL
- en: 'Okay, now create `app/modules/recorder/models/record.model.android.ts`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: This may look a whole lot like the iOS side, and that's because it will be nearly
    the same! In fact, this setup works great, so now we just want to fill in the
    Android specifics.
  prefs: []
  type: TYPE_NORMAL
- en: Using nativescript-audio's TNSRecorder for Android in our RecordModel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We could use some fancy Android APIs and/or libraries for our recorder, but
    in this case, the **nativescript-audio** plugin we''re using for our cross-platform
    multitrack player also provides a cross-platform recorder. We could have even
    used it with iOS, but we wanted to specifically work with AudioKit''s powerful
    APIs there. However, here on Android, let''s use the recorder from the plugin
    and make the following modifications to `record.model.android.ts`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Wow! Okay, a lot of interesting things going on here. Let''s get one necessary
    thing out of the way for Android and ensure for API level 23+ that permissions
    are properly handled. For this, you can install the permissions plugin:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: We also want to ensure our manifest file contains the proper permission key.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open `app/App_Resources/Android/AndroidManifest.xml` and add the following
    in the correct place:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: We use the nativescript-audio plugin's `TNSRecorder` as our implementation and
    wire things up accordingly to its API. `AudioRecorderOptions` provides a `metering`
    option, allowing the ability to monitor the microphone's meters via an interval.
  prefs: []
  type: TYPE_NORMAL
- en: What is most versatile about our overall design is that our model's target can
    literally be anything. In this case, we create a RxJS Subject observable as `_target$`,
    which is then returned as our target getter. This allows us to emit the microphone's
    meter value through the `Subject` observable for consumption by our Waveform.
    You will see in a moment how we will take advantage of this.
  prefs: []
  type: TYPE_NORMAL
- en: We are now ready to move on to our Waveform implementation for Android.
  prefs: []
  type: TYPE_NORMAL
- en: Just like we did for the model, we will want to refactor the common bits into
    a shared file and handle the suffix.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create `app/modules/shared/native/waveform-common.ts`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, just adjust `app/modules/shared/native/waveform.ts` to use it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Before renaming our waveform to contain an `.ios` suffix, let''s generate a
    TypeScript definition file for it first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'You may again see TypeScript errors or warnings, but we don''t need to worry
    about those, as it should have still generated a `waveform.d.ts` file. Let''s
    simplify it slightly to contain only the parts that are applicable to both iOS
    and Android:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Okay, now, rename `waveform.ts` to `waveform.ios.ts` and create `app/modules/shared/native/waveform.android.ts`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Okay, excellent! This is the barebones setup we will need, *but what native
    Android view should we use?*
  prefs: []
  type: TYPE_NORMAL
- en: 'If you''re looking around for open source Android libs, you may come across
    a group of very talented developers with **Yalantis**, a fantastic mobile development
    company based out of Ukraine. Roman Kozlov and his team created an open source
    project, **Horizon**, which provides beautiful audio visualizations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/Yalantis/Horizon](https://github.com/Yalantis/Horizon)'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://yalantis.com/blog/horizon-open-source-library-for-sound-visualization/](https://yalantis.com/blog/horizon-open-source-library-for-sound-visualization/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Just like for iOS, we also want to prepare for a multifaceted Waveform view
    that can also render a static waveform for just a file. Looking further through
    the open source options, we may come across another wonderfully talented team
    with **Semantive**, based in Warsaw, the sprawling capital of Poland. They created
    an incredibly powerful Waveform view for Android:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/Semantive/waveform-android](https://github.com/Semantive/waveform-android)'
  prefs: []
  type: TYPE_NORMAL
- en: Let's integrate both of these libraries for our Android Waveform integration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to how we integrated AudioKit for iOS, let''s create a folder in the
    root called `android-waveform-libs` with the following setup, that provides `include.gradle`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00039.jpeg)Why deviate from the `nativescript-` prefix when including
    native libs?'
  prefs: []
  type: TYPE_NORMAL
- en: The prefix is a good way to go if you plan to refactor the internal plugin into
    an open source plugin published via npm for the community down the road, using
    [https://github.com/NathanWalker/nativescript-plugin-seed](https://github.com/NathanWalker/nativescript-plugin-seed)
    for instance.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, you just need to integrate several native libs for a specific platform,
    as we are in this case, so we don't really need the `nativescript-` prefix on
    our folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'We make sure to add `package.json`, so we can add these native libs like we
    would any other plugin:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we simply add them as a plugin to our project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: We are now ready to integrate these libs into our Waveform view.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s make the following modifications to the `app/modules/shared/native/waveform.android.ts` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: We begin our Android implementation by defining the `const` references to the
    various packaged classes we need to access, to alleviate having to reference the
    fully qualified package location each time in our Waveform. Just like on the iOS
    side, we design a dual-purpose Waveform by allowing the type (`'mic'` or `'file'`)
    to drive which rendering to use. This allows us to reuse this with our record
    view for real-time microphone visualization and the other to statically render
    our tracks as Waveforms (more on that soon!).
  prefs: []
  type: TYPE_NORMAL
- en: 'The Horizon lib utilizes Android''s `GLSurfaceView` as the primary rendering,
    hence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: During development, we found that `GLSurfaceView` requires at least a height
    to constrain it, otherwise it would render at full screen height. Therefore, we
    explicitly set a reasonable `height` of `200` to the custom NativeScript view,
    which will automatically handle measuring the native view for us. Interestingly,
    we also found that sometimes our model setter would fire *before* `initNativeView`
    and other times *after*. Because the model is a critical binding for initializing
    our Horizon view, we designed a custom internal `_initView` method with the appropriate
    conditional, which could be called from `initNativeView`, as well as after our
    model setter fired. The condition (`!this._initialized && this.nativeView && this.model`)
    ensures it's only ever initialized once though. This is the way to handle any
    potential race conditions around the sequence of these method calls.
  prefs: []
  type: TYPE_NORMAL
- en: 'The native `Horizon.java` class provides an `update` method that expects a
    Java byte array with a signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'What we do in NativeScript for this is retain a reference to a construct that
    will represent this native Java byte array with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Utilizing Android's `android.media.AudioRecord` class, in conjunction with the
    various recorder settings that we set up, we are able to gather an initial `bufferSize`,
    that we use to initialize our byte array size.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then take advantage of our overall versatile design, wherein our model''s
    target in this implementation is an rxjs Subject Observable, allowing us to subscribe
    to its event stream. For the `''mic''` type, this stream will be the metering
    value changes from the recorder, which we use to fill our byte array and in turn
    update the `Horizon` view:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'This provides our recorder a nice visualization, which will animate as the
    input level changes. Here''s a preview; however, the style is still a little ugly,
    since we have not applied any CSS polish just yet:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00040.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: For our static audio file waveform rendering, we initialize `WaveformView` with
    the Android context. We then use its API to configure it for our use during construction
    in `createNativeView`.
  prefs: []
  type: TYPE_NORMAL
- en: 'During initialization, we create an instance of `CheapSoundFile` as required
    by `WaveformView`, and interestingly, we use `setSoundFile` inside `setTimeout`,
    alongside a call to `this.nativeView.invalidate()`, which is calling invalidate
    on `WaveformView`. This causes the native view to update with the processed file,
    as follows (again, we will address the styling polish later):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/00041.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has introduced a wealth of powerful concepts and techniques on
    how to work with native APIs on iOS and Android. Knowing how to work with open
    source native libraries is fundamental to getting the most out of your app development
    and achieving the feature set you are after. Direct access to these APIs right
    from TypeScript gives you the luxury of never leaving your preferred development
    environment, as well as engaging with the languages you love in a fun and accessible
    way.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, learning solid practices around how/when to create custom NativeScript
    views and interworking them throughout your Angular app are among the key elements
    to leverage the most of this tech stack.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will provide some extra goodies by empowering our track
    list view with more bells and whistles, leveraging some of what you've learned
    here.
  prefs: []
  type: TYPE_NORMAL

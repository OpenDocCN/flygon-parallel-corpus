["```scala\n[cloudera@quickstart ~]$ mkdir cyrus \n[cloudera@quickstart ~]$ vi getCyrusFiles.sh \n[cloudera@quickstart ~]$ cat getCyrusFiles.sh  \nfor i in `seq 10` \ndo \ncurl www.artamene.org/documents/cyrus$i.txt -o cyrus$i.txt \ndone \n```", "```scala\n[cloudera@quickstart ~]$ vi processCyrusFiles.sh \n[cloudera@quickstart ~]$ cat processCyrusFiles.sh  \ncd ~/cyrus; \nfor i in `ls cyrus*.txt` do cat $i >> cyrusorig.txt; done \ncat cyrusorig.txt | tr -dc '[:print:]' | tr A-Z a-z > cyrusprint.txt  \n```", "```scala\n[cloudera@quickstart ~]$ chmod 755 getCyrusFiles.sh  \n[cloudera@quickstart ~]$ chmod 755 processCyrusFiles.sh  \n```", "```scala\n[cloudera@quickstart cyrus]$ ./getCyrusFiles.sh  \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \n                                 Dload  Upload   Total   Spent    Left  Speed \n100  908k  100  908k    0     0   372k      0  0:00:02  0:00:02 --:--:--  421k \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \n                                 Dload  Upload   Total   Spent    Left  Speed \n100 1125k  100 1125k    0     0   414k      0  0:00:02  0:00:02 --:--:--  471k \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \n                                 Dload  Upload   Total   Spent    Left  Speed \n100 1084k  100 1084k    0     0   186k      0  0:00:05  0:00:05 --:--:--  236k \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \n                                 Dload  Upload   Total   Spent    Left  Speed \n100 1048k  100 1048k    0     0   267k      0  0:00:03  0:00:03 --:--:--  291k \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \n                                 Dload  Upload   Total   Spent    Left  Speed \n100 1116k  100 1116k    0     0   351k      0  0:00:03  0:00:03 --:--:--  489k \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \n                                 Dload  Upload   Total   Spent    Left  Speed \n100 1213k  100 1213k    0     0   440k      0  0:00:02  0:00:02 --:--:--  488k \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \n                                 Dload  Upload   Total   Spent    Left  Speed \n100 1119k  100 1119k    0     0   370k      0  0:00:03  0:00:03 --:--:--  407k \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \n                                 Dload  Upload   Total   Spent    Left  Speed \n100 1132k  100 1132k    0     0   190k      0  0:00:05  0:00:05 --:--:--  249k \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \n                                 Dload  Upload   Total   Spent    Left  Speed \n100 1084k  100 1084k    0     0   325k      0  0:00:03  0:00:03 --:--:--  365k \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \n                                 Dload  Upload   Total   Spent    Left  Speed \n100 1259k  100 1259k    0     0   445k      0  0:00:02  0:00:02 --:--:--  486k \n\n[cloudera@quickstart cyrus]$ ls \ncyrus10.txt  cyrus3.txt  cyrus6.txt  cyrus9.txt \ncyrus1.txt   cyrus4.txt  cyrus7.txt  getCyrusFiles.sh \ncyrus2.txt   cyrus5.txt  cyrus8.txt  processCyrusFiles.sh \n\n```", "```scala\n\n[cloudera@quickstart cyrus]$ ./processCyrusFiles.sh  \n\n[cloudera@quickstart cyrus]$ ls \ncyrus10.txt  cyrus3.txt  cyrus6.txt  cyrus9.txt      getCyrusFiles.sh \ncyrus1.txt   cyrus4.txt  cyrus7.txt  cyrusorig.txt   processCyrusFiles.sh \ncyrus2.txt   cyrus5.txt  cyrus8.txt  cyrusprint.txt \n\n[cloudera@quickstart cyrus]$ ls -altrh cyrusprint.txt  \n-rw-rw-r-- 1 cloudera cloudera 11M Jun 28 20:02 cyrusprint.txt \n\n[cloudera@quickstart cyrus]$ wc -w cyrusprint.txt  \n1953931 cyrusprint.txt \n```", "```scala\n[cloudera@quickstart cyrus]$ hdfs dfs -ls /user/cloudera \n\n[cloudera@quickstart cyrus]$ hdfs dfs -mkdir /user/cloudera/input \n\n[cloudera@quickstart cyrus]$ hdfs dfs -put cyrusprint.txt /user/cloudera/input/ \n\n[cloudera@quickstart cyrus]$ vi mapper.py \n\n[cloudera@quickstart cyrus]$ cat mapper.py  \n#!/usr/bin/env python \n#the above just indicates to use python to intepret this file \n#This mapper code will input a line of text and output <word, 1> # \n\nimport sys \nsys.path.append('.') \n\nfor line in sys.stdin: \n   line = line.strip() \n   keys = line.split() \n   for key in keys: \n          value = 1 \n          print (\"%s\\t%d\" % (key,value)) \n\n[cloudera@quickstart cyrus]$ vi reducer.py # Copy-Paste the content of reducer.py as shown below using the vi or nano Unix editor.\n\n[cloudera@quickstart cyrus]$ cat reducer.py  \n#!/usr/bin/env python \n\nimport sys \nsys.path.append('.') \n\nlast_key = None \nrunning_total = 0 \n\nfor input_line in sys.stdin: \n   input_line = input_line.strip() \n   this_key, value = input_line.split(\"\\t\", 1) \n   value = int(value) \n\n   if last_key == this_key: \n       running_total += value \n   else: \n       if last_key: \n           print(\"%s\\t%d\" % (last_key, running_total)) \n       running_total = value \n       last_key = this_key \n\nif last_key == this_key: \n   print( \"%s\\t%d\" % (last_key, running_total) ) \n\n[cloudera@quickstart cyrus]$ chmod 755 *.py\n```", "```scala\n[cloudera@quickstart cyrus]$ hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -input /user/cloudera/input -output /user/cloudera/output -mapper /home/cloudera/cyrus/mapper.py -reducer /home/cloudera/cyrus/reducer.py \n\npackageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.10.0.jar] /tmp/streamjob1786353270976133464.jar tmpDir=null \n17/06/28 20:11:21 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032 \n17/06/28 20:11:21 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032 \n17/06/28 20:11:22 INFO mapred.FileInputFormat: Total input paths to process : 1 \n17/06/28 20:11:22 INFO mapreduce.JobSubmitter: number of splits:2 \n17/06/28 20:11:23 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1498704103152_0002 \n17/06/28 20:11:23 INFO impl.YarnClientImpl: Submitted application application_1498704103152_0002 \n17/06/28 20:11:23 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1498704103152_0002/ \n17/06/28 20:11:23 INFO mapreduce.Job: Running job: job_1498704103152_0002 \n17/06/28 20:11:30 INFO mapreduce.Job: Job job_1498704103152_0002 running in uber mode : false \n17/06/28 20:11:30 INFO mapreduce.Job:  map 0% reduce 0% \n17/06/28 20:11:41 INFO mapreduce.Job:  map 50% reduce 0% \n17/06/28 20:11:54 INFO mapreduce.Job:  map 83% reduce 0% \n17/06/28 20:11:57 INFO mapreduce.Job:  map 100% reduce 0% \n17/06/28 20:12:04 INFO mapreduce.Job:  map 100% reduce 100% \n17/06/28 20:12:04 INFO mapreduce.Job: Job job_1498704103152_0002 completed successfully \n17/06/28 20:12:04 INFO mapreduce.Job: Counters: 50 \n   File System Counters \n          FILE: Number of bytes read=18869506 \n          FILE: Number of bytes written=38108830 \n          FILE: Number of read operations=0 \n          FILE: Number of large read operations=0 \n          FILE: Number of write operations=0 \n          HDFS: Number of bytes read=16633042 \n          HDFS: Number of bytes written=547815 \n          HDFS: Number of read operations=9 \n          HDFS: Number of large read operations=0 \n          HDFS: Number of write operations=2 \n   Job Counters  \n          Killed map tasks=1 \n          Launched map tasks=3 \n          Launched reduce tasks=1 \n          Data-local map tasks=3 \n          Total time spent by all maps in occupied slots (ms)=39591 \n          Total time spent by all reduces in occupied slots (ms)=18844 \n          Total time spent by all map tasks (ms)=39591 \n          Total time spent by all reduce tasks (ms)=18844 \n          Total vcore-seconds taken by all map tasks=39591 \n          Total vcore-seconds taken by all reduce tasks=18844 \n          Total megabyte-seconds taken by all map tasks=40541184 \n          Total megabyte-seconds taken by all reduce tasks=19296256 \n   Map-Reduce Framework \n          Map input records=1 \n          Map output records=1953931 \n          Map output bytes=14961638 \n          Map output materialized bytes=18869512 \n          Input split bytes=236 \n          Combine input records=0 \n          Combine output records=0 \n          Reduce input groups=45962 \n          Reduce shuffle bytes=18869512 \n          Reduce input records=1953931 \n          Reduce output records=45962 \n          Spilled Records=3907862 \n          Shuffled Maps =2 \n          Failed Shuffles=0 \n          Merged Map outputs=2 \n          GC time elapsed (ms)=352 \n          CPU time spent (ms)=8400 \n          Physical memory (bytes) snapshot=602038272 \n          Virtual memory (bytes) snapshot=4512694272 \n          Total committed heap usage (bytes)=391979008 \n   Shuffle Errors \n          BAD_ID=0 \n          CONNECTION=0 \n          IO_ERROR=0 \n          WRONG_LENGTH=0 \n          WRONG_MAP=0 \n          WRONG_REDUCE=0 \n   File Input Format Counters  \n          Bytes Read=16632806 \n   File Output Format Counters  \n          Bytes Written=547815 \n17/06/28 20:12:04 INFO streaming.StreamJob: Output directory: /user/cloudera/output\n```", "```scala\n[cloudera@quickstart cyrus]$ hdfs dfs -ls /user/cloudera/output \nFound 2 items \n-rw-r--r--   1 cloudera cloudera          0 2017-06-28 20:12 /user/cloudera/output/_SUCCESS \n-rw-r--r--   1 cloudera cloudera     547815 2017-06-28 20:12 /user/cloudera/output/part-00000  \n```", "```scala\n[cloudera@quickstart cyrus]$ hdfs dfs -cat /user/cloudera/output/part-00000 | head -10 \n!  1206 \n!) 1 \n!quoy,    1 \n'  3 \n'' 1 \n'. 1 \n'a 32 \n'appelloit 1 \n'auoit    1 \n'auroit   10  \n```", "```scala\n# Download the csv file \ncd /home/cloudera; \nwget -O oil.csv \"https://stats.oecd.org/sdmx-json/data/DP_LIVE/.OILIMPPRICE.../OECD?contentType=csv&amp;detail=code&amp;separator=comma&amp;csv-lang=en\" \n```", "```scala\n[cloudera@quickstart ~]$ sed -i 's/\\\"//g' oil.csv \n```", "```scala\n[cloudera@quickstart ~]$ tr -cd '\\11\\12\\15\\40-\\176' oil_.csv > oil_clean.csv\n```", "```scala\n[cloudera@quickstart ~]$ mv oil_clean.csv oil.csv \nmv: overwrite `oil.csv'? yes \n```", "```scala\nCREATE TABLE IF NOT EXISTS OIL \n   (location String, indicator String, subject String, measure String,  \n   frequency String, time String, value Float, flagCode String) \n   ROW FORMAT DELIMITED \n   FIELDS TERMINATED BY ',' \n   LINES TERMINATED BY '\\n' \n   STORED AS TEXTFILE \n   tblproperties(\"skip.header.line.count\"=\"1\"); \n\nLOAD DATA LOCAL INPATH '/home/cloudera/oil.csv' INTO TABLE OIL; \nSELECT * FROM OIL; \n```", "```scala\nSELECT LOCATION, MIN(value) as MINPRICE, AVG(value) as AVGPRICE,  \nMAX(value) as MAXPRICE \nFROM OIL \nWHERE FREQUENCY LIKE \"A\" \nGROUP BY LOCATION; \n```", "```scala\n# ENTER THE FOLLOWING IN THE UNIX TERMINAL \n# DOWNLOAD LATLONG CSV FILE \n\ncd /home/cloudera; \nwget -O latlong.csv \"https://gist.githubusercontent.com/tadast/8827699/raw/7255fdfbf292c592b75cf5f7a19c16ea59735f74/countries_codes_and_coordinates.csv\" \n\n# REMOVE QUOTATION MARKS \nsed -i 's/\\\"//g' latlong.csv \n```", "```scala\nCREATE TABLE IF NOT EXISTS LATLONG \n   (country String, alpha2 String, alpha3 String, numCode Int, latitude Float, longitude Float) \n   ROW FORMAT DELIMITED \n   FIELDS TERMINATED BY ',' \n   LINES TERMINATED BY '\\n' \n   STORED AS TEXTFILE \n   TBLPROPERTIES(\"skip.header.line.count\"=\"1\"); \n\nLOAD DATA LOCAL INPATH '/home/cloudera/latlong.csv' INTO TABLE LATLONG; \n\n```", "```scala\nSELECT DISTINCT * FROM \n(SELECT location, avg(value) as AVGPRICE from oil GROUP BY location) x \nLEFT JOIN \n(SELECT TRIM(ALPHA3) AS alpha3, latitude, longitude from LATLONG) y \nON (x.location = y.alpha3); \n```"]
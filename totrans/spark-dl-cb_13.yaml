- en: Image Classification with TensorFlow on Spark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following recipes will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Downloading 30 images each of Messi and Ronaldo
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring PySpark installation with deep learning packages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading images onto PySpark dataframes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding transfer learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a pipeline for image classification training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating model performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-tuning model parameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Over the last couple of years, image recognition software has become increasingly
    in demand. It is not a coincidence that this demand has coincided with the advancements
    of big data storage. Google Photos, Facebook, and Apple all utilize image classification
    software to tag photos for their users. Much of the image recognition software
    used by these companies are powered by deep learning models built on top of popular
    libraries such as TensorFlow. This chapter extends the technique of deep learning
    by leveraging the training of one set of images to the learning or recognition
    of another set of images. This concept is referred to as transfer learning. In
    this chapter, we will focus on leveraging transfer learning to recognize the top
    two football players in the world:'
  prefs: []
  type: TYPE_NORMAL
- en: Lionel Messi
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Cristiano Ronaldo
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Take a look at this photo:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00377.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Downloading 30 images each of Messi and Ronaldo
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before any classification of images can take place, we must first download images
    of our footballers from the web.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are several add-ons to browsers that download images in bulk. Since Ubuntu
    comes pre-installed with Mozilla Firefox as a browser, we will use it as our browser
    of choice to install a bulk image downloader extension.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following section explains how to download images in bulk. Take a look
    at these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Visit the following website for downloading and installing Firefox add-ons:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://addons.mozilla.org/en-US/firefox/](https://addons.mozilla.org/en-US/firefox/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Search for and select the Download all Images add-on, as seen in the following
    screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00378.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'This will take us to the installation page. At which point, select Add to Firefox,
    as seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00379.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Confirm your installation, as this add-on will require permission to access
    your browser's download history, access your data for all websites, and send you
    notifications.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once that is complete, you should see a small picture icon for Download all
    Images on the upper right-hand side of your browser, as seen in the following
    screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00380.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We are now ready to begin downloading images of our footballers, using the
    newly added extension for Firefox. We can visit many different websites to download
    images from, such as [https://www.google.com](https://www.google.com). For the
    purposes of this chapter, search for Cristiano Ronaldo and download his images
    using [https://www.pexels.com](https://www.pexels.com), as seen in the following
    screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00381.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, click on the Download all Images icon and specify the following download
    settings for the images as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00382.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on Save, as you will then have the option to download all of the pictures
    as a `.zip` file to a local directory. You can then unzip the file into a folder
    and peruse through all of the images. In our example, the images have all been
    extracted to `/Home/sparkNotebooks/Ch13/football/ronaldo/`, as seen in the following
    screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00383.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Of all the images that are available in the folder, choose 30 images of Ronaldo
    and name them `ronaldo1.jpg`, `ronaldo2.jpg`....`ronaldo30.jpg`, as shown in the
    following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00384.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Repeat the steps again, this time for Messi to obtain 30 images of each. The
    final folder structure should look like the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00385.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section explains the process of how the add-on downloads the images in
    bulk to our desired location:'
  prefs: []
  type: TYPE_NORMAL
- en: Bulk image downloading software is readily available these days and integrated
    within browsers. We will use Download all Images as an add-on with Firefox to
    quickly download images for Messi and Ronaldo.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We want to specify settings in the app to download lower-quality images, so
    we set a minimum threshold of 0 bytes, a maximum threshold of 500 bytes, and an
    image type of `jpg` or `jpeg`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we want to handpick only the 30 images that best represent each player,
    as 20 of them will serve as our training dataset, and the remaining 10 will serve
    as our test dataset. All other images can be deleted.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All of the images will be tagged or labeled for training purposes by their last
    name and a number between 1 and 30\. For example, `Messi1.jpg`, `Messi2.jpg`,
    `Ronaldo1.jpg`, `Ronaldo2.jpg`, and so on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While you can use your own images that you have downloaded using Download all
    Images, you can download the same images for Ronaldo and Messi that will be used
    for training purposes in this chapter by visiting the following websites:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For Messi:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/asherif844/ApacheSparkDeepLearningCookbook/tree/master/CH13/football/messi](https://github.com/asherif844/ApacheSparkDeepLearningCookbook/tree/master/CH13/football/messi)'
  prefs: []
  type: TYPE_NORMAL
- en: 'For Ronaldo:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/asherif844/ApacheSparkDeepLearningCookbook/tree/master/CH13/football/ronaldo](https://github.com/asherif844/ApacheSparkDeepLearningCookbook/tree/master/CH13/football/ronaldo)'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are similar add-ons and extensions for other browsers. If you are working
    with Google Chrome, there is a similar add-on called *D*ownload''em All that can
    be downloaded from the following website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://chrome.google.com/webstore/detail/downloadem-all/ccdfjnniglfbpaplecpifdiglfmcebce?hl=en-US](https://chrome.google.com/webstore/detail/downloadem-all/ccdfjnniglfbpaplecpifdiglfmcebce?hl=en-US)'
  prefs: []
  type: TYPE_NORMAL
- en: Configuring PySpark installation with deep learning packages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are some additional configurations that need to be done within PySpark
    to implement deep learning packages from Databricks called `spark-deep-learning`.
    These are configurations that were made all the way back in [chapter 1](part0026.html#OPEK0-3be7262ff9a54db3b2ea862fdce1797b),
    *Setting up your Spark Environment for Deep Learning*.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This configuration requires making changes in the terminal, using **bash**.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following section walks through the steps to configure PySpark with deep
    learning packages:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the terminal application and type in the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Scroll all the way to the bottom of the document and look for the `sparknotebook()` function
    we created back in [chapter 1](part0026.html#OPEK0-3be7262ff9a54db3b2ea862fdce1797b),
    *Setting up your Spark Environment for Deep Learning*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Update the last row of the function. It should currently look like the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Change it to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the configuration change is made, exit the document and execute the following
    script to confirm that all necessary changes were saved:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following section explains how PySpark is modified to incorporate deep
    learning packages take a look at these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Accessing bash allows us to make configurations at the command line, as seen
    in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00386.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: At the end of our document, we can see our original function, `sparknotebook()`,
    still intact; however, we need to modify it to incorporate the `spark-deep-learning`
    package.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Since this modification is to PySpark directly, and not to a Python library,
    we cannot incorporate it into our framework using a typical `pip` installation.
    Instead, we will modify our PySpark configuration to appear as shown in the following
    screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00387.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We have now configured our PySpark installation to incorporate deep learning
    libraries that incorporate APIs that help build models for all types of solutions,
    such as image classification.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This package, `spark-deep-learning`, is managed by `Databricks`. Databricks
    was founded by one of the co-creators of Spark, Ali Ghodsi, and is used to deliver
    managed Spark offerings through a unified platform.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more about other third-party packages developed for Spark, visit the
    following website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://spark-packages.org/](https://spark-packages.org/).'
  prefs: []
  type: TYPE_NORMAL
- en: Loading images on to PySpark dataframes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are now ready to begin importing our images into our notebook for classification.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will be using several libraries and their dependencies in this section,
    which will require us to install the following packages through `pip install`
    on the terminal within Ubuntu Desktop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following steps will demonstrate how to decode images into a Spark dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Initiate a `spark` session, using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Import the following libraries from PySpark to create dataframes, using the
    following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Execute the following script to create two dataframes for Messi and Ronaldo,
    using the main folder location for each player:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Split each dataframe into a train-and-test set at a `66.7/33.3` ratio, and
    set a random seed set to `12`, using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, merge both the training dataframes and the testing dataframes into
    one new dataframe each, `trainDF` and `testDF`, using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following section explains how the images are loaded and read into a Jupyter
    notebook. Take a look at these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: We always begin a Spark project by initiating a Spark session to set the application
    name as well as to set the Spark executor memory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We import both `pyspark.sql.functions` and `sparkdl` to help build dataframes
    based on encoded images. When `sparkdl` is imported, we see that it is using TensorFlow
    in the backend, as seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00388.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The dataframes are created using `sparkdl` with three columns: filepath, image,
    and label. Sparkdl is used to import each image and encode it by color and shape.
    Additionally, a function, `lit`, is used to tag a literal value (0 or 1) to each
    of the two dataframes under the label column for training purposes, as seen in
    the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00389.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Since there are 30 images for each footballer, a split of 66.7/33.3 is used
    to create 18 training images and 12 testing images, as seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Please note that the more images used in the training process the better when
    using deep learning. However, the point we will try and prove in this chapter
    is that with transfer learning being implemented as an extension of deep learning,
    we can classify images using fewer training samples, as is the case in this chapter
    with only 30 images for Ronaldo and Messi each.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00390.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'To build out our model, we are only interested in creating a single training
    dataframe with the 36 images, as well as a single testing dataframe with the remaining
    24 images. Once we merge the dataframes we can confirm that they are the correct
    size, as seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00391.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It may be lost in the process but it is important to note that loading the images
    into a dataframe was easy, and only took a few lines of code using `sparkdl.readImages`.
    This showcases the power of the machine learning pipelines that are available
    with Spark.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more about the `sparkdl` package, visit the following repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://databricks.github.io/spark-deep-learning/site/api/python/sparkdl.html](https://databricks.github.io/spark-deep-learning/site/api/python/sparkdl.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding transfer learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The rest of this chapter will involve transfer learning techniques; therefore,
    we will spend this section explaining how transfer learning works within our architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are no dependencies required for this section.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section walks through the steps for how transfer learning works:'
  prefs: []
  type: TYPE_NORMAL
- en: Identify a pre-trained model that will be used as the training methodology that
    will be transferred to our chosen task. In our case, the task will be in identifying
    images of Messi and Ronaldo.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'There are several available pre-trained models that can be used. The most popular
    ones are the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Xception
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: InceptionV3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ResNet50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: VGG16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: VGG19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The features from the pre-trained convolutional neural network are extracted
    and saved for a certain set of images over several layers of filtering and pooling.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The final layer for the pre-trained convolutional neural network is substituted
    with the specific features that we are looking to classify based on our dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section explains the methodology of transfer learning:'
  prefs: []
  type: TYPE_NORMAL
- en: In early chapters, we discuss how machine learning models, and more importantly
    deep learning models, work best with larger samples for training purposes. In
    fact, the general motto with deep learning is the more the merrier.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'However, there are situations when a high volume of data or images is just
    not available to train a model. It is in these circumstances where we wish to
    transfer the learning of one field to predict the outcome of a different field.
    The heavy lifting of extracting features and filtering through layers and layers
    within a convolutional neural network have already been performed by institutions
    that have developed many pre-trained models such as InceptionV3 and ResNet50:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: InceptionV3 was developed over at Google and has smaller weights than ResNet50
    and VGG
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ResNet50 uses 50 weight layers
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: VGG16 and VGG19 have 16 and 19 weight layers respectively
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Several higher level deep learning libraries such as Keras now come pre-built
    with these pre-trained networks for a more simplified application by specifying
    the model name.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Determining which pre-trained model works best for the data or image set in
    question will depend on the image types used. It is always best to try different
    pre-trained sets and determine which one delivers the best accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more about the Inception V3 pre-trained model, read the following
    paper:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://arxiv.org/abs/1409.4842](https://arxiv.org/abs/1409.4842)'
  prefs: []
  type: TYPE_NORMAL
- en: 'To learn more about the VGG pre-trained models, read the following paper:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556)'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a pipeline for image classification training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are now ready to build the deep learning pipeline for training our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following libraries will be imported to assist with the pipeline development:'
  prefs: []
  type: TYPE_NORMAL
- en: '`LogisticRegression`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Pipeline`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following section walks through the following steps for creating a pipeline
    for image classification:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Execute the following script to begin the deep learning pipeline as well as
    to configure the classification parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a new dataframe, `predictDF`, that houses the original testing labels
    as well as the new prediction scores, using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following section explains how the pipeline for image classification is
    configured for optimal performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '`LogisticRegression` is imported, as it will be the main classification algorithm
    used to distinguish between Messi and Ronaldo images. `DeepImageFeaturizer` is
    imported from `sparkdl` to create features based off of the images that will be
    used as the final input to the logistic regression algorithm.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is important to note that the features created from `DeepImageFeaturizer`
    will be using a pre-trained model based on `InceptionV3`, and assigned a variable
    of `vectorizer`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The logistic regression model is tuned to run for a maximum of 30 iterations.
    Finally, the pipeline ingests both `vectorizer` and `LogisticRegression` variables
    and fits it into the training dataframe, `trainDF`. `vectorizer` is used to create
    numeric values out of the images. The output of the `DeepImageFeaturizer` can
    be seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00392.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The test dataframe, `testDF`, is transformed into a new dataframe, `predictDF`,
    by applying the fitted pipeline model, `pipeline_model`, which creates a new column
    called prediction. We can then compare our label column with our prediction column,
    as seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00393.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`InceptionV3` is the image classifier model that we used for classifying our
    images; however, we could have very easily chosen other pre-trained models and
    compared accuracy within our pipeline.'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more about transfer learning, read the following article from the
    University of Wisconsin:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://ftp.cs.wisc.edu/machine-learning/shavlik-group/torrey.handbook09.pdf](http://ftp.cs.wisc.edu/machine-learning/shavlik-group/torrey.handbook09.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating model performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are ready to evaluate our model and see how well we can distinguish between
    Messi and Ronaldo.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since we will be doing some model evaluation, we will need to import the following
    library:'
  prefs: []
  type: TYPE_NORMAL
- en: '`MulticlassClassificationEvaluator`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following section walks through the following steps to evaluate model performance:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Execute the following script to create a confusion matrix from the `predictDF`
    dataframe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculate an accuracy score based on our 24 test images of Ronaldo and Messi
    by executing the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following section explains how we evaluate the model performance. Take
    a look at these images:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can convert our dataframe, predictDF, into a crosstab to create a confusion
    matrix. This allows us to understand how many true positives, false positives,
    true negatives, and false negatives are in our model, as seen in the following
    screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00394.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'At this point, we are ready to calculate how well we did with our model in
    using the 36 training images to accurately classify the 24 remaining test images
    of Ronaldo and Messi. From the previous screenshot, it shows that we had 21 accurate
    classifications out of 24\. We had 2 images of Messi misclassified as Ronaldo
    and only one image of Ronaldo misclassified as Messi. This should come out to
    an accuracy score of 88%. We can see that the accuracy score from the MulticlassClassificationEvaluator
    also scores our accuracy at 87.5%, as seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00395.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While we did end up using accuracy as our benchmark indicator for how well
    our model performed, we could have just as easily used precision or recall. Additionally,
    we used the `MulticlassClassificationEvaluator` for evaluating the accuracy of
    the model. Since we are dealing with a binary outcome in this specific case for
    only two types of images for Ronaldo or Messi, we could have also just used a `BinaryClassificationEvaluator`
    as seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00396.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We still end up with the same accuracy rate of 87.5%.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more about `MulticlassClassificationEvaluator` from the logistic regression
    function in PySpark, visit the following website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://spark.apache.org/docs/2.2.0/ml-classification-regression.html](https://spark.apache.org/docs/2.2.0/ml-classification-regression.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning model parameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is always room for improvement in the accuracy of any model. In this section,
    we will talk about some of the parameters that can be tweaked to improve our model
    accuracy score of 87.5% obtained from the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section does not require any new prerequisites.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section walks through the steps to fine-tune the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Define a new logistic regression model with additional parameters for `regParam`
    and `elasticNetParam` as seen in the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a new pipeline configured for the newly created model using the following
    script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Fit the pipeline to the trained dataset, `trainDF`, using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the model transformation to the test dataset, `testDF`, to be able to
    compare actual versus predicted scores using the following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, evaluate the new model accuracy rate, `binary_rate_FT`, using the
    following script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section explains how the model is fine-tuned:'
  prefs: []
  type: TYPE_NORMAL
- en: The logistic regression model, `logregFT`, is fine-tuned using both the `regParam`
    and the `elasticNetParam` parameters. Both parameters correspond to the γ and
    the α parameters of a logistic regression model. The regularization parameter
    or `regParam` is used to find a balance between minimizing the loss function and
    minimizing overfitting the model. The more complex we make the model, the more
    likely it will overfit and not be generalized, but we will also likely get a lower
    training error. Additionally, the less complex we make the model, the less likely
    it will overfit, but the more likely it will have a higher training error.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The elastic net parameter or `elasticNetParam` is another regularization technique
    that is used to combine multiple regularizers, L1 and L2, to minimize overfitting
    in a model. Additionally, we have decreased our iteration run from 20 to 15 to
    see if we can achieve a better accuracy score by including regularization and
    decreasing runs at the same time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once again, as we did previously in this chapter, we create a pipeline that
    incorporates our numerical features generated from our images, `vectorizer`, as
    well our logistic regression model, `logregFT`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The model is then fit on the training data, `trainDF`, and the transformation
    of the model is applied to the testing data, `testDF`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can once again compare our actual versus predicted results from the outcome
    of the model in a crosstab as seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00397.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We have now only 1 miss-classified image compared to 3 from the previous section.
    We accomplished this by lowering our maxIter to `15` runs and setting `regParam`
    to `0.05` and the `elasticNetParam` to `0.3`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Our new accuracy rate is now at `95.83%` as seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/00398.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Certainly, we have improved our rate from 87.5% from 95.83% simply by incorporating
    specific parameters into our model. Additional fine-tuning and tweaking of our
    parameters could take place to determine if an accuracy of 100% could be reached
    for our image classification model.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more about the regularization and elastic net parameters within a
    logistic regression, visit the following website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://spark.apache.org/docs/2.2.0/mllib-linear-methods.html#logistic-regression](https://spark.apache.org/docs/2.2.0/mllib-linear-methods.html#logistic-regression)'
  prefs: []
  type: TYPE_NORMAL

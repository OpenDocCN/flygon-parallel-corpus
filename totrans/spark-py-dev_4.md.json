["```py\n        import numpy as np\n        import scipy.sparse as sps\n        from pyspark.mllib.linalg import Vectors\n\n        # NumPy array for dense vector.\n        dvect1 = np.array([5.0, 0.0, 1.0, 7.0])\n        # Python list for dense vector.\n        dvect2 = [5.0, 0.0, 1.0, 7.0]\n        # SparseVector creation\n        svect1 = Vectors.sparse(4, [0, 2, 3], [5.0, 1.0, 7.0])\n        # Sparse vector using a single-column SciPy csc_matrix\n        svect2 = sps.csc_matrix((np.array([5.0, 1.0, 7.0]), np.array([0, 2, 3])), shape = (4, 1))\n        ```", "```py\n        from pyspark.mllib.linalg import SparseVector\n        from pyspark.mllib.regression import LabeledPoint\n\n        # Labeled point with a positive label and a dense feature vector.\n        lp_pos = LabeledPoint(1.0, [5.0, 0.0, 1.0, 7.0])\n\n        # Labeled point with a negative label and a sparse feature vector.\n        lp_neg = LabeledPoint(0.0, SparseVector(4, [0, 2, 3], [5.0, 1.0, 7.0]))\n        ```", "```py\n        from pyspark.mllib.linalg import Matrix, Matrices\n\n        # Dense matrix ((1.0, 2.0, 3.0), (4.0, 5.0, 6.0))\n        dMatrix = Matrices.dense(2, 3, [1, 2, 3, 4, 5, 6])\n\n        # Sparse matrix ((9.0, 0.0), (0.0, 8.0), (0.0, 6.0))\n        sMatrix = Matrices.sparse(3, 2, [0, 1, 3], [0, 2, 1], [9, 6, 8])\n        ```", "```py\nimport pandas as pd\n\ncsv_in = 'C:\\\\Users\\\\Amit\\\\Documents\\\\IPython Notebooks\\\\AN00_Data\\\\unq_tweetstxt.csv'\ntwts_df01 = pd.read_csv(csv_in, sep =';', encoding='utf-8')\n\nIn [24]:\n\ntwts_df01.count()\nOut[24]:\nUnnamed: 0    7540\nid            7540\ncreated_at    7540\nuser_id       7540\nuser_name     7538\ntweet_text    7540\ndtype: int64\n\n#\n# Introspecting the tweets text\n#\nIn [82]:\n\ntwtstxt_ls01[6910:6920]\nOut[82]:\n['RT @deroach_Ismoke: I am NOT voting for #hilaryclinton http://t.co/jaZZpcHkkJ',\n 'RT @AnimalRightsJen: #HilaryClinton What do Bernie Sanders and Donald Trump Have in Common?: He has so far been th... http://t.co/t2YRcGCh6\u2026',\n 'I understand why Bill was out banging other chicks........I mean look at what he is married to.....\\n@HilaryClinton',\n '#HilaryClinton What do Bernie Sanders and Donald Trump Have in Common?: He has so far been th... http://t.co/t2YRcGCh67 #Tcot #UniteBlue']\n```", "```py\nIn [37]:\n\nprint(\"Extracting features from the training dataset using a sparse vectorizer\")\nt0 = time()\nExtracting features from the training dataset using a sparse vectorizer\nIn [38]:\n\nvectorizer = TfidfVectorizer(max_df=0.5, max_features=10000,\n                                 min_df=2, stop_words='english',\n                                 use_idf=True)\nX = vectorizer.fit_transform(twtstxt_ls01)\n#\n# Output of the TFIDF Feature vectorizer\n#\nprint(\"done in %fs\" % (time() - t0))\nprint(\"n_samples: %d, n_features: %d\" % X.shape)\nprint()\ndone in 5.232165s\nn_samples: 7540, n_features: 6638\n```", "```py\nIn [47]:\n\nkm = KMeans(n_clusters=7, init='k-means++', max_iter=100, n_init=1,\n            verbose=1)\n\nprint(\"Clustering sparse data with %s\" % km)\nt0 = time()\nkm.fit(X)\nprint(\"done in %0.3fs\" % (time() - t0))\n\nClustering sparse data with KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=7, n_init=1,\n    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n    verbose=1)\nInitialization complete\nIteration  0, inertia 13635.141\nIteration  1, inertia 6943.485\nIteration  2, inertia 6924.093\nIteration  3, inertia 6915.004\nIteration  4, inertia 6909.212\nIteration  5, inertia 6903.848\nIteration  6, inertia 6888.606\nIteration  7, inertia 6863.226\nIteration  8, inertia 6860.026\nIteration  9, inertia 6859.338\nIteration 10, inertia 6859.213\nIteration 11, inertia 6859.102\nIteration 12, inertia 6859.080\nIteration 13, inertia 6859.060\nIteration 14, inertia 6859.047\nIteration 15, inertia 6859.039\nIteration 16, inertia 6859.032\nIteration 17, inertia 6859.031\nIteration 18, inertia 6859.029\nConverged at iteration 18\ndone in 1.701s\n```", "```py\n#\n# Introspect top terms per cluster\n#\n\nIn [49]:\n\nprint(\"Top terms per cluster:\")\norder_centroids = km.cluster_centers_.argsort()[:, ::-1]\nterms = vectorizer.get_feature_names()\nfor i in range(7):\n    print(\"Cluster %d:\" % i, end='')\n    for ind in order_centroids[i, :20]:\n        print(' %s' % terms[ind], end='')\n    print()\nTop terms per cluster:\nCluster 0: justinbieber love mean rt follow thank hi https whatdoyoumean video wanna hear whatdoyoumeanviral rorykramer happy lol making person dream justin\nCluster 1: donaldtrump hilaryclinton rt https trump2016 realdonaldtrump trump gop amp justinbieber president clinton emails oy8ltkstze tcot like berniesanders hilary people email\nCluster 2: bigdata apachespark hadoop analytics rt spark training chennai ibm datascience apache processing cloudera mapreduce data sap https vora transforming development\nCluster 3: apachespark python https rt spark data amp databricks using new learn hadoop ibm big apache continuumio bluemix learning join open\nCluster 4: ernestsgantt simbata3 jdhm2015 elsahel12 phuketdailynews dreamintentions beyhiveinfrance almtorta18 civipartnership 9_a_6 25whu72ep0 k7erhvu7wn fdmxxxcm3h osxuh2fxnt 5o5rmb0xhp jnbgkqn0dj ovap57ujdh dtzsz3lb6x sunnysai12345 sdcvulih6g\nCluster 5: trump donald donaldtrump starbucks trumpquote trumpforpresident oy8ltkstze https zfns7pxysx silly goy stump trump2016 news jeremy coffee corbyn ok7vc8aetz rt tonight\nCluster 6: ladygaga gaga lady rt https love follow horror cd story ahshotel american japan hotel human trafficking music fashion diet queen ahs\n```", "```py\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom sklearn.manifold import MDS\n\nMDS()\n\n#\n# Bring down the MDS to two dimensions (components) as we will plot \n# the clusters\n#\nmds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n\npos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n\nxs, ys = pos[:, 0], pos[:, 1]\n\nIn [67]:\n\n#\n# Set up colors per clusters using a dict\n#\ncluster_colors = {0: '#1b9e77', 1: '#d95f02', 2: '#7570b3', 3: '#e7298a', 4: '#66a61e', 5: '#9990b3', 6: '#e8888a'}\n\n#\n#set up cluster names using a dict\n#\ncluster_names = {0: 'Music, Pop', \n                 1: 'USA Politics, Election', \n                 2: 'BigData, Spark', \n                 3: 'Spark, Python',\n                 4: 'Thailand', \n                 5: 'USA Politics, Election', \n                 6: 'Music, Pop'}\nIn [115]:\n#\n# ipython magic to show the matplotlib plots inline\n#\n%matplotlib inline \n\n#\n# Create data frame which includes MDS results, cluster numbers and tweet texts to be displayed\n#\ndf = pd.DataFrame(dict(x=xs, y=ys, label=clusters, txt=twtstxt_ls02_utf8))\nix_start = 2000\nix_stop  = 2050\ndf01 = df[ix_start:ix_stop]\n\nprint(df01[['label','txt']])\nprint(len(df01))\nprint()\n\n# Group by cluster\n\ngroups = df.groupby('label')\ngroups01 = df01.groupby('label')\n\n# Set up the plot\n\nfig, ax = plt.subplots(figsize=(17, 10)) \nax.margins(0.05) \n\n#\n# Build the plot object\n#\nfor name, group in groups01:\n    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, \n            label=cluster_names[name], color=cluster_colors[name], \n            mec='none')\n    ax.set_aspect('auto')\n    ax.tick_params(\\\n        axis= 'x',         # settings for x-axis\n        which='both',      # \n        bottom='off',      # \n        top='off',         # \n        labelbottom='off')\n    ax.tick_params(\\\n        axis= 'y',         # settings for y-axis\n        which='both',      # \n        left='off',        # \n        top='off',         # \n        labelleft='off')\n\nax.legend(numpoints=1)     #\n#\n# Add label in x,y position with tweet text\n#\nfor i in range(ix_start, ix_stop):\n    ax.text(df01.ix[i]['x'], df01.ix[i]['y'], df01.ix[i]['txt'], size=10)  \n\nplt.show()                 # Display the plot\n\n      label       text\n2000      2       b'RT @BigDataTechCon: '\n2001      3       b\"@4Quant 's presentat\"\n2002      2       b'Cassandra Summit 201'\n```", "```py\nIn [3]:\n#\n# Read csv in a Panda DF\n#\n#\nimport pandas as pd\ncsv_in = '/home/an/spark/spark-1.5.0-bin-hadoop2.6/examples/AN_Spark/data/unq_tweetstxt.csv'\npddf_in = pd.read_csv(csv_in, index_col=None, header=0, sep=';', encoding='utf-8')\n\nIn [4]:\n\nsqlContext = SQLContext(sc)\n\nIn [5]:\n\n#\n# Convert a Panda DF to a Spark DF\n#\n#\n\nspdf_02 = sqlContext.createDataFrame(pddf_in[['id', 'user_id', 'user_name', 'tweet_text']])\n\nIn [8]:\n\nspdf_02.show()\n\nIn [7]:\n\nspdf_02.take(3)\n\nOut[7]:\n\n[Row(id=638830426971181057, user_id=3276255125, user_name=u'True Equality', tweet_text=u'ernestsgantt: BeyHiveInFrance: 9_A_6: dreamintentions: elsahel12: simbata3: JDHM2015: almtorta18: dreamintentions:\\u2026 http://t.co/VpD7FoqMr0'),\n Row(id=638830426727911424, user_id=3276255125, user_name=u'True Equality', tweet_text=u'ernestsgantt: BeyHiveInFrance: PhuketDailyNews: dreamintentions: elsahel12: simbata3: JDHM2015: almtorta18: CiviPa\\u2026 http://t.co/VpD7FoqMr0'),\n Row(id=638830425402556417, user_id=3276255125, user_name=u'True Equality', tweet_text=u'ernestsgantt: BeyHiveInFrance: 9_A_6: ernestsgantt: elsahel12: simbata3: JDHM2015: almtorta18: CiviPartnership: dr\\u2026 http://t.co/EMDOn8chPK')]\n\nIn [9]:\n\nfrom pyspark.ml.feature import HashingTF, IDF, Tokenizer\n\nIn [10]:\n\n#\n# Tokenize the tweet_text \n#\ntokenizer = Tokenizer(inputCol=\"tweet_text\", outputCol=\"tokens\")\ntokensData = tokenizer.transform(spdf_02)\n\nIn [11]:\n\ntokensData.take(1)\n\nOut[11]:\n\n[Row(id=638830426971181057, user_id=3276255125, user_name=u'True Equality', tweet_text=u'ernestsgantt: BeyHiveInFrance: 9_A_6: dreamintentions: elsahel12: simbata3: JDHM2015: almtorta18: dreamintentions:\\u2026 http://t.co/VpD7FoqMr0', tokens=[u'ernestsgantt:', u'beyhiveinfrance:', u'9_a_6:', u'dreamintentions:', u'elsahel12:', u'simbata3:', u'jdhm2015:', u'almtorta18:', u'dreamintentions:\\u2026', u'http://t.co/vpd7foqmr0'])]\n\nIn [14]:\n\n#\n# Apply Hashing TF to the tokens\n#\nhashingTF = HashingTF(inputCol=\"tokens\", outputCol=\"rawFeatures\", numFeatures=2000)\nfeaturesData = hashingTF.transform(tokensData)\n\nIn [15]:\n\nfeaturesData.take(1)\n\nOut[15]:\n\n[Row(id=638830426971181057, user_id=3276255125, user_name=u'True Equality', tweet_text=u'ernestsgantt: BeyHiveInFrance: 9_A_6: dreamintentions: elsahel12: simbata3: JDHM2015: almtorta18: dreamintentions:\\u2026 http://t.co/VpD7FoqMr0', tokens=[u'ernestsgantt:', u'beyhiveinfrance:', u'9_a_6:', u'dreamintentions:', u'elsahel12:', u'simbata3:', u'jdhm2015:', u'almtorta18:', u'dreamintentions:\\u2026', u'http://t.co/vpd7foqmr0'], rawFeatures=SparseVector(2000, {74: 1.0, 97: 1.0, 100: 1.0, 160: 1.0, 185: 1.0, 742: 1.0, 856: 1.0, 991: 1.0, 1383: 1.0, 1620: 1.0}))]\n\nIn [16]:\n\n#\n# Apply IDF to the raw features and rescale the data\n#\nidf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\nidfModel = idf.fit(featuresData)\nrescaledData = idfModel.transform(featuresData)\n\nfor features in rescaledData.select(\"features\").take(3):\n  print(features)\n\nIn [17]:\n\nrescaledData.take(2)\n\nOut[17]:\n\n[Row(id=638830426971181057, user_id=3276255125, user_name=u'True Equality', tweet_text=u'ernestsgantt: BeyHiveInFrance: 9_A_6: dreamintentions: elsahel12: simbata3: JDHM2015: almtorta18: dreamintentions:\\u2026 http://t.co/VpD7FoqMr0', tokens=[u'ernestsgantt:', u'beyhiveinfrance:', u'9_a_6:', u'dreamintentions:', u'elsahel12:', u'simbata3:', u'jdhm2015:', u'almtorta18:', u'dreamintentions:\\u2026', u'http://t.co/vpd7foqmr0'], rawFeatures=SparseVector(2000, {74: 1.0, 97: 1.0, 100: 1.0, 160: 1.0, 185: 1.0, 742: 1.0, 856: 1.0, 991: 1.0, 1383: 1.0, 1620: 1.0}), features=SparseVector(2000, {74: 2.6762, 97: 1.8625, 100: 2.6384, 160: 2.9985, 185: 2.7481, 742: 5.5269, 856: 4.1406, 991: 2.9518, 1383: 4.694, 1620: 3.073})),\n Row(id=638830426727911424, user_id=3276255125, user_name=u'True Equality', tweet_text=u'ernestsgantt: BeyHiveInFrance: PhuketDailyNews: dreamintentions: elsahel12: simbata3: JDHM2015: almtorta18: CiviPa\\u2026 http://t.co/VpD7FoqMr0', tokens=[u'ernestsgantt:', u'beyhiveinfrance:', u'phuketdailynews:', u'dreamintentions:', u'elsahel12:', u'simbata3:', u'jdhm2015:', u'almtorta18:', u'civipa\\u2026', u'http://t.co/vpd7foqmr0'], rawFeatures=SparseVector(2000, {74: 1.0, 97: 1.0, 100: 1.0, 160: 1.0, 185: 1.0, 460: 1.0, 987: 1.0, 991: 1.0, 1383: 1.0, 1620: 1.0}), features=SparseVector(2000, {74: 2.6762, 97: 1.8625, 100: 2.6384, 160: 2.9985, 185: 2.7481, 460: 6.4432, 987: 2.9959, 991: 2.9518, 1383: 4.694, 1620: 3.073}))]\n\nIn [21]:\n\nrs_pddf = rescaledData.toPandas()\n\nIn [22]:\n\nrs_pddf.count()\n\nOut[22]:\n\nid             7540\nuser_id        7540\nuser_name      7540\ntweet_text     7540\ntokens         7540\nrawFeatures    7540\nfeatures       7540\ndtype: int64\n\nIn [27]:\n\nfeat_lst = rs_pddf.features.tolist()\n\nIn [28]:\n\nfeat_lst[:2]\n\nOut[28]:\n\n[SparseVector(2000, {74: 2.6762, 97: 1.8625, 100: 2.6384, 160: 2.9985, 185: 2.7481, 742: 5.5269, 856: 4.1406, 991: 2.9518, 1383: 4.694, 1620: 3.073}),\n SparseVector(2000, {74: 2.6762, 97: 1.8625, 100: 2.6384, 160: 2.9985, 185: 2.7481, 460: 6.4432, 987: 2.9959, 991: 2.9518, 1383: 4.694, 1620: 3.073})]\n```", "```py\nIn [32]:\n\nfrom pyspark.mllib.clustering import KMeans, KMeansModel\nfrom numpy import array\nfrom math import sqrt\n\nIn [34]:\n\n# Load and parse the data\n\nin_Data = sc.parallelize(feat_lst)\n\nIn [35]:\n\nin_Data.take(3)\n\nOut[35]:\n\n[SparseVector(2000, {74: 2.6762, 97: 1.8625, 100: 2.6384, 160: 2.9985, 185: 2.7481, 742: 5.5269, 856: 4.1406, 991: 2.9518, 1383: 4.694, 1620: 3.073}),\n SparseVector(2000, {74: 2.6762, 97: 1.8625, 100: 2.6384, 160: 2.9985, 185: 2.7481, 460: 6.4432, 987: 2.9959, 991: 2.9518, 1383: 4.694, 1620: 3.073}),\n SparseVector(2000, {20: 4.3534, 74: 2.6762, 97: 1.8625, 100: 5.2768, 185: 2.7481, 856: 4.1406, 991: 2.9518, 1039: 3.073, 1620: 3.073, 1864: 4.6377})]\n\nIn [37]:\n\nin_Data.count()\n\nOut[37]:\n\n7540\n\nIn [38]:\n\n# Build the model (cluster the data)\n\nclusters = KMeans.train(in_Data, 5, maxIterations=10,\n        runs=10, initializationMode=\"random\")\n\nIn [53]:\n\n# Evaluate clustering by computing Within Set Sum of Squared Errors\n\ndef error(point):\n    center = clusters.centers[clusters.predict(point)]\n    return sqrt(sum([x**2 for x in (point - center)]))\n\nWSSSE = in_Data.map(lambda point: error(point)).reduce(lambda x, y: x + y)\nprint(\"Within Set Sum of Squared Error = \" + str(WSSSE))\n```", "```py\nIn [43]:\n\ncluster_membership = in_Data.map(lambda x: clusters.predict(x))\n\nIn [54]:\n\ncluster_idx = cluster_membership.zipWithIndex()\n\nIn [55]:\n\ntype(cluster_idx)\n\nOut[55]:\n\npyspark.rdd.PipelinedRDD\n\nIn [58]:\n\ncluster_idx.take(20)\n\nOut[58]:\n\n[(3, 0),\n (3, 1),\n (3, 2),\n (3, 3),\n (3, 4),\n (3, 5),\n (1, 6),\n (3, 7),\n (3, 8),\n (3, 9),\n (3, 10),\n (3, 11),\n (3, 12),\n (3, 13),\n (3, 14),\n (1, 15),\n (3, 16),\n (3, 17),\n (1, 18),\n (1, 19)]\n\nIn [59]:\n\ncluster_df = cluster_idx.toDF()\n\nIn [65]:\n\npddf_with_cluster = pd.concat([pddf_in, cluster_pddf],axis=1)\n\nIn [76]:\n\npddf_with_cluster._1.unique()\n\nOut[76]:\n\narray([3, 1, 4, 0, 2])\n\nIn [79]:\n\npddf_with_cluster[pddf_with_cluster['_1'] == 0].head(10)\n\nOut[79]:\n  Unnamed: 0   id   created_at   user_id   user_name   tweet_text   _1   _2\n6227   3   642418116819988480   Fri Sep 11 19:23:09 +0000 2015   49693598   Ajinkya Kale   RT @bigdata: Distributed Matrix Computations i...   0   6227\n6257   45   642391207205859328   Fri Sep 11 17:36:13 +0000 2015   937467860   Angela Bassa   [Auto] I'm reading \"\"Distributed Matrix Comput...   0   6257\n6297   119   642348577147064320   Fri Sep 11 14:46:49 +0000 2015   18318677   Ben Lorica   Distributed Matrix Computations in @ApacheSpar...   0   6297\nIn [80]:\n\npddf_with_cluster[pddf_with_cluster['_1'] == 1].head(10)\n\nOut[80]:\n  Unnamed: 0   id   created_at   user_id   user_name   tweet_text   _1   _2\n6   6   638830419090079746   Tue Sep 01 21:46:55 +0000 2015   2241040634   Massimo Carrisi   Python:Python: Removing \\xa0 from string? - I ...   1   6\n15   17   638830380578045953   Tue Sep 01 21:46:46 +0000 2015   57699376   Rafael Monnerat   RT @ramalhoorg: Noite de aut\u00f3grafos do Fluent ...   1   15\n18   41   638830280988426250   Tue Sep 01 21:46:22 +0000 2015   951081582   Jack Baldwin   RT @cloudaus: We are 3/4 full! 2-day @swcarpen...   1   18\n19   42   638830276626399232   Tue Sep 01 21:46:21 +0000 2015   6525302   Masayoshi Nakamura   PynamoDB #AWS #DynamoDB #Python http://...   1   19\n20   43   638830213288235008   Tue Sep 01 21:46:06 +0000 2015   3153874869   Baltimore Python   Flexx: Python UI tookit based on web technolog...   1   20\n21   44   638830117645516800   Tue Sep 01 21:45:43 +0000 2015   48474625   Radio Free Denali   Hmm, emerge --depclean wants to remove somethi...   1   21\n22   46   638829977014636544   Tue Sep 01 21:45:10 +0000 2015   154915461   Luciano Ramalho   Noite de aut\u00f3grafos do Fluent Python no Garoa ...   1   22\n23   47   638829882928070656   Tue Sep 01 21:44:47 +0000 2015   917320920   bsbafflesbrains   @DanSWright Harper channeling Monty Python. \"...   1   23\n24   48   638829868679954432   Tue Sep 01 21:44:44 +0000 2015   134280898   Lannick Technology   RT @SergeyKalnish: I am #hiring: Senior Back e...   1   24\n25   49   638829707484508161   Tue Sep 01 21:44:05 +0000 2015   2839203454   Joshua Jones   RT @LindseyPelas: Surviving Monty Python in Fl...   1   25\nIn [81]:\n\npddf_with_cluster[pddf_with_cluster['_1'] == 2].head(10)\n\nOut[81]:\n  Unnamed: 0   id   created_at   user_id   user_name   tweet_text   _1   _2\n7280   688   639056941592014848   Wed Sep 02 12:47:02 +0000 2015   2735137484   Chris   A true gay icon when will @ladygaga @Madonna @...   2   7280\nIn [82]:\n\npddf_with_cluster[pddf_with_cluster['_1'] == 3].head(10)\n\nOut[82]:\n  Unnamed: 0   id   created_at   user_id   user_name   tweet_text   _1   _2\n0   0   638830426971181057   Tue Sep 01 21:46:57 +0000 2015   3276255125   True Equality   ernestsgantt: BeyHiveInFrance: 9_A_6: dreamint...   3   0\n1   1   638830426727911424   Tue Sep 01 21:46:57 +0000 2015   3276255125   True Equality   ernestsgantt: BeyHiveInFrance: PhuketDailyNews...   3   1\n2   2   638830425402556417   Tue Sep 01 21:46:56 +0000 2015   3276255125   True Equality   ernestsgantt: BeyHiveInFrance: 9_A_6: ernestsg...   3   2\n3   3   638830424563716097   Tue Sep 01 21:46:56 +0000 2015   3276255125   True Equality   ernestsgantt: BeyHiveInFrance: PhuketDailyNews...   3   3\n4   4   638830422256816132   Tue Sep 01 21:46:56 +0000 2015   3276255125   True Equality   ernestsgantt: elsahel12: 9_A_6: dreamintention...   3   4\n5   5   638830420159655936   Tue Sep 01 21:46:55 +0000 2015   3276255125   True Equality   ernestsgantt: BeyHiveInFrance: PhuketDailyNews...   3   5\n7   7   638830418330980352   Tue Sep 01 21:46:55 +0000 2015   3276255125   True Equality   ernestsgantt: elsahel12: 9_A_6: dreamintention...   3   7\n8   8   638830397648822272   Tue Sep 01 21:46:50 +0000 2015   3276255125   True Equality   ernestsgantt: BeyHiveInFrance: PhuketDailyNews...   3   8\n9   9   638830395375529984   Tue Sep 01 21:46:49 +0000 2015   3276255125   True Equality   ernestsgantt: elsahel12: 9_A_6: dreamintention...   3   9\n10   10   638830392389177344   Tue Sep 01 21:46:49 +0000 2015   3276255125   True Equality   ernestsgantt: BeyHiveInFrance: PhuketDailyNews...   3   10\nIn [83]:\n\npddf_with_cluster[pddf_with_cluster['_1'] == 4].head(10)\n\nOut[83]:\n  Unnamed: 0   id   created_at   user_id   user_name   tweet_text   _1   _2\n1361   882   642648214454317056   Sat Sep 12 10:37:28 +0000 2015   27415756   Raymond Enisuoh   LA Chosen For US 2024 Olympic Bid - LA2016 See...   4   1361\n1363   885   642647848744583168   Sat Sep 12 10:36:01 +0000 2015   27415756   Raymond Enisuoh   Prison See: https://t.co/x3EKAExeFi \u2026 \u2026 \u2026 \u2026 \u2026 ...   4   1363\n5412   11   640480770369286144   Sun Sep 06 11:04:49 +0000 2015   3242403023   Donald Trump 2016   \" igiboooy! @ Starbucks https://t.co/97wdL...   4   5412\n5428   27   640477140660518912   Sun Sep 06 10:50:24 +0000 2015   3242403023   Donald Trump 2016   \"  @ Starbucks https://t.co/wsEYFIefk7 \" - D...   4   5428\n5455   61   640469542272110592   Sun Sep 06 10:20:12 +0000 2015   3242403023   Donald Trump 2016   \" starbucks @ Starbucks Mam Plaza https://t.co...   4   5455\n5456   62   640469541370372096   Sun Sep 06 10:20:12 +0000 2015   3242403023   Donald Trump 2016   \" Aaahhh the pumpkin spice latte is back, fall...   4   5456\n5457   63   640469539524898817   Sun Sep 06 10:20:12 +0000 2015   3242403023   Donald Trump 2016   \" RT kayyleighferry: Oh my goddd Harry Potter ...   4   5457\n5458   64   640469537176031232   Sun Sep 06 10:20:11 +0000 2015   3242403023   Donald Trump 2016   \" Starbucks https://t.co/3xYYXlwNkf \" - Donald...   4   5458\n5459   65   640469536119070720   Sun Sep 06 10:20:11 +0000 2015   3242403023   Donald Trump 2016   \" A Starbucks is under construction in my neig...   4   5459\n5460   66   640469530435813376   Sun Sep 06 10:20:10 +0000 2015   3242403023   Donald Trump 2016   \" Babam starbucks'tan fotogtaf at\u0131yor bende du...   4   5460\n```"]
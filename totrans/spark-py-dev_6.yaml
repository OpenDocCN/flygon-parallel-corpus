- en: Chapter 6. Visualizing Insights and Trends
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have focused on the collection, analysis, and processing of data
    from Twitter. We have set the stage to use our data for visual rendering and extracting
    insights and trends. We will give a quick lay of the land about visualization
    tools in the Python ecosystem. We will highlight Bokeh as a powerful tool for
    rendering and viewing large datasets. Bokeh is part of the Python Anaconda Distribution
    ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following points:'
  prefs: []
  type: TYPE_NORMAL
- en: Gauging the key words and memes within a social network community using charts
    and wordcloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mapping the most active location where communities are growing around certain
    themes or topics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Revisiting the data-intensive apps architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have reached the final layer of the data-intensive apps architecture: the
    engagement layer. This layer focuses on how to synthesize, emphasize, and visualize
    the key context relevant information for the data consumers. A bunch of numbers
    in a console will not suffice to engage with end-users. It is critical to present
    the mass of information in a rapid, digestible, and attractive fashion.'
  prefs: []
  type: TYPE_NORMAL
- en: The following diagram sets the context of the chapter's focus highlighting the
    engagement layer.
  prefs: []
  type: TYPE_NORMAL
- en: '![Revisiting the data-intensive apps architecture](img/B03968_06_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'For Python plotting and visualizations, we have quite a few tools and libraries.
    The most interesting and relevant ones for our purpose are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Matplotlib** is the grandfather of the Python plotting libraries. Matplotlib
    was originally the brainchild of *John Hunter* who was an open source software
    proponent and established Matplotlib as one of the most prevalent plotting libraries
    both in the academic and the data scientific communities. Matplotlib allows the
    generation of plots, histograms, power spectra, bar charts, error charts, scatterplots,
    and so on. Examples can be found on the Matplotlib dedicated website at [http://matplotlib.org/examples/index.html](http://matplotlib.org/examples/index.html).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Seaborn**, developed by *Michael Waskom*, is a great library to quickly visualize
    statistical information. It is built on top of Matplotlib and integrates seamlessly
    with Pandas and the Python data stack, including Numpy. A gallery of graphs from
    Seaborn at [http://stanford.edu/~mwaskom/software/seaborn/examples/index.html](http://stanford.edu/~mwaskom/software/seaborn/examples/index.html)
    shows the potential of the library.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ggplot** is relatively new and aims to offer the equivalent of the famous
    ggplot2 from the R ecosystem for the Python data wranglers. It has the same look
    and feel of ggplot2 and uses the same grammar of graphics as expounded by Hadley
    Wickham. The ggplot the Python port is developed by the team at `yhat`. More information
    can be found at [http://ggplot.yhathq.com](http://ggplot.yhathq.com).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**D3.js** is a very popular, JavaScript library developed by *Mike Bostock*.
    **D3** stands for **Data Driven Documents** and brings data to life on any modern
    browser leveraging HTML, SVG, and CSS. It delivers dynamic, powerful, interactive
    visualizations by manipulating the DOM, the Document Object Model. The Python
    community could not wait to integrate D3 with Matplotlib. Under the impulse of
    Jake Vanderplas, mpld3 was created with the aim of bringing `matplotlib` to the
    browser. Examples graphics are hosted at the following address: [http://mpld3.github.io/index.html](http://mpld3.github.io/index.html).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bokeh** aims to deliver high-performance interactivity over very large or
    streaming datasets whilst leveraging lot of the concepts of `D3.js` without the
    burden of writing some intimidating `javascript` and `css` code. Bokeh delivers
    dynamic visualizations on the browser with or without a server. It integrates
    seamlessly with Matplotlib, Seaborn and ggplot and renders beautifully in IPython
    notebooks or Jupyter notebooks. Bokeh is actively developed by the team at Continuum.io
    and is an integral part of the Anaconda Python data stack.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bokeh server provides a full-fledged, dynamic plotting engine that materializes
    a reactive scene graph from JSON. It uses web sockets to keep state and update
    the HTML5 canvas using Backbone.js and Coffee-script under the hoods. Bokeh, as
    it is fueled by data in JSON, creates easy bindings for other languages such as
    R, Scala, and Julia.
  prefs: []
  type: TYPE_NORMAL
- en: This gives a high-level overview of the main plotting and visualization library.
    It is not exhaustive. Let's move to concrete examples of visualizations.
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing the data for visualization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before jumping into the visualizations, we will do some preparatory work on
    the data harvested:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'For the purpose of our visualization activity, we will use a dataset of 7,540
    tweets. The key information is stored in the `tweet_text` column. We preview the
    data stored in the dataframe calling the `head()` function on the dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now create some utility functions to clean up the tweet text and parse
    the twitter date. First, we import the Python regular expression regex library
    `re` and the time library to parse dates and time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We create a dictionary of regex that will be compiled and then passed as function:'
  prefs: []
  type: TYPE_NORMAL
- en: '**RT**: The first regex with key `RT` looks for the keyword `RT` at the beginning
    of the tweet text:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**ALNUM**: The second regex with key `ALNUM` looks for words including alphanumeric
    characters and underscore sign preceded by the `@` symbol in the tweet text:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '**HASHTAG**: The third regex with key `HASHTAG` looks for words including alphanumeric
    characters preceded by the `#` symbol in the tweet text:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '**SPACES**: The fourth regex with key `SPACES` looks for blank or line space
    characters in the tweet text:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '**URL**: The fifth regex with key `URL` looks for `url` addresses including
    alphanumeric characters preceded with `https://` or `http://` markers in the tweet
    text:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We create a utility function to identify whether a tweet is a retweet or an
    original tweet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we extract all user handles in a tweet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We also extract all hashtags in a tweet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract all URL links in a tweet as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We strip all URL links and user handles preceded by `@` sign in a tweet text.
    This function will be the basis of the wordcloud we will build soon:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We label the data so we can create groups of datasets for the wordcloud:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We parse the twitter date in the `yyyy-mm-dd hh:mm:ss` format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We preview the data prior to processing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We create new dataframe columns by applying the utility functions described.
    We create a new column for `htag`, user handles, URLs, the text terms stripped
    from URLs, and unwanted characters and the labels. We finally parse the date:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code gives a quick snapshot of the newly generated dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We save the processed information in a CSV format. We have 7,540 records and
    13 columns. In your case, the output will vary according to the dataset you chose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Gauging words, moods, and memes at a glance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are now ready to proceed with building the wordclouds which will give us
    a sense of the important words carried in those tweets. We will create wordclouds
    for the datasets harvested. Wordclouds extract the top words in a list of words
    and create a scatterplot of the words where the size of the word is correlated
    to its frequency. The more frequent the word in the dataset, the bigger will be
    the font size in the wordcloud rendering. They include three very different themes
    and two competing or analogous entities. Our first theme is obviously data processing
    and analytics, with Apache Spark and Python as our entities. Our second theme
    is the 2016 presidential election campaign, with the two contenders: Hilary Clinton
    and Donald Trump. Our last theme is the world of pop music with Justin Bieber
    and Lady Gaga as the two exponents.'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up wordcloud
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will illustrate the programming steps by analyzing the spark related tweets.
    We load the data and preview the dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The wordcloud library we will use is the one developed by Andreas Mueller and
    hosted on his GitHub account at [https://github.com/amueller/word_cloud](https://github.com/amueller/word_cloud).
  prefs: []
  type: TYPE_NORMAL
- en: 'The library requires **PIL** (short for **Python Imaging Library**). PIL is
    easily installable by invoking `conda install pil`. PIL is a complex library to
    install and is not yet ported on Python 3.4, so we need to run a Python 2.7+ environment
    to be able to see our wordcloud:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The following packages will be downloaded:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The following packages will be UPDATED:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we install the wordcloud library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Creating wordclouds
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this stage, we are ready to invoke the wordcloud program with the generated
    list of terms from the tweet text.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s get started with the wordcloud program by first calling `%matplotlib`
    inline to display the wordcloud in our notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We convert the dataframe `txt_terms` column into a list of words. We make sure
    it is all converted into the `str` type to avoid any bad surprises and check the
    list''s first four records:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We first call the Matplotlib and the wordcloud libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'From the input list of terms, we create a unified string of terms separated
    by a whitespace as the input to the wordcloud program. The wordcloud program removes
    stopwords:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can visualize the wordclouds for Apache Spark and Python. Clearly,
    in the case of Spark, *Hadoop*, *big data*, and *analytics* are the memes, while
    Python recalls the root of its name Monty Python with a strong focus on *developer*,
    *apache spark*, and programming with some hints to java and ruby.
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating wordclouds](img/B03968_06_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can also get a glimpse in the following wordclouds of the words preoccupying
    the North American 2016 presidential election candidates: Hilary Clinton and Donald
    Trump. Seemingly Hilary Clinton is overshadowed by the presence of her opponents
    Donald Trump and Bernie Sanders, while Trump is heavily centered only on himself:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating wordclouds](img/B03968_06_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Interestingly, in the case of Justin Bieber and Lady Gaga, the word *love* appears.
    In the case of Bieber, *follow* and *belieber* are key words, while *diet*, *weight
    loss*, and *fashion* are the preoccupations for the Lady Gaga crowd.
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating wordclouds](img/B03968_06_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Geo-locating tweets and mapping meetups
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we will dive into the creation of interactive maps with Bokeh. First, we
    create a world map where we geo-locate sample tweets and, on moving our mouse
    over these locations, we can see the users and their respective tweets in a hover
    box.
  prefs: []
  type: TYPE_NORMAL
- en: The second map is focused on mapping upcoming meetups in London. It could be
    an interactive map that would act as a reminder of date, time, and location for
    upcoming meetups in a specific city.
  prefs: []
  type: TYPE_NORMAL
- en: Geo-locating tweets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The objective is to create a world map scatter plot of the locations of important
    tweets on the map, and the tweets and authors are revealed on hovering over these
    points. We will go through three steps to build this interactive visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: Create the background world map by first loading a dictionary of all the world
    country boundaries defined by their respective longitude and latitudes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Load the important tweets we wish to geo-locate with their respective coordinates
    and authors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, scatter plot on the world map the tweets coordinates and activate the
    hover tool to visualize interactively the tweets and author on the highlighted
    dots on the map.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In step one, we create a Python list called data that will contain all the
    world countries boundaries with their respective latitude and longitude:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'In step two, we load a sample set of important tweets that we wish to visualize
    with their respective geo-location information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: In step three, we first imported all the necessary Bokeh libraries. We will
    instantiate the output in the Jupyter Notebook. We get the world countries boundary
    information loaded. We get the geo-located tweet data. We instantiate the Bokeh
    interactive tools such as wheel and box zoom as well as the hover tool.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We are now ready to layer the various elements gathered into an object figure
    called **p**. Define the title, width, and height of **p**. Attach the tools.
    Create the world map background by patches with a light background color and borders.
    Scatter plot the tweets according to their respective geo-coordinates. Then, activate
    the hover tool with the users and their respective tweet. Finally, render the
    picture on the browser. The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code gives an overview of the world map with the red dots representing
    the locations of the tweets'' origins:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Geo-locating tweets](img/B03968_06_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can hover on a specific dot to reveal the tweets in that location:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Geo-locating tweets](img/B03968_06_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can zoom into a specific location:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Geo-locating tweets](img/B03968_06_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, we can reveal the tweets in the given zoomed-in location:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Geo-locating tweets](img/B03968_06_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Displaying upcoming meetups on Google Maps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, our objective is to focus on upcoming meetups in London. We are mapping
    three meetups **Data Science London**, **Apache Spark**, and **Machine Learning**.
    We embed a Google Map within a Bokeh visualization and geo-locate the three meetups
    according to their coordinates and get information such as the name of the upcoming
    event for each meetup with a hover tool.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import all the necessary Bokeh libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'We will instantiate the Google Map that will act as the substrate upon which
    our Bokeh visualization will be layered:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Instantiate the Bokeh object plot from the class `GMapPlot` with the dimensions
    and map options from the previous step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Bring in the information from our three meetups we wish to plot and get the
    information by hovering above the respective coordinates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the dots to be drawn on the Google Map:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the stings for the Bokeh tools to be used in this visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Activate the `hover` tool with the information that will be carried:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Render the plot that gives a pretty good view of London:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Displaying upcoming meetups on Google Maps](img/B03968_06_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once we hover on a highlighted dot, we can get the information of the given
    meetup:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Displaying upcoming meetups on Google Maps](img/B03968_06_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Full smooth zooming capability is preserved, as the following screenshot shows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Displaying upcoming meetups on Google Maps](img/B03968_06_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we focused on few visualization techniques. We saw how to build
    wordclouds and their intuitive power to reveal, at a glance, lots of the key words,
    moods, and memes carried through thousands of tweets.
  prefs: []
  type: TYPE_NORMAL
- en: We then discussed interactive mapping visualizations using Bokeh. We built a
    world map from the ground up and created a scatter plot of critical tweets. Once
    the map was rendered on the browser, we could interactively hover from dot to
    dot and reveal the tweets originating from different parts of the world.
  prefs: []
  type: TYPE_NORMAL
- en: Our final visualization was focused on mapping upcoming meetups in London on
    Spark, data science, and machine learning and their respective topics, making
    a beautiful interactive visualization with an actual Google Map.
  prefs: []
  type: TYPE_NORMAL

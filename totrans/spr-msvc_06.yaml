- en: Chapter 6. Autoscaling Microservices
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章 自动缩放微服务
- en: Spring Cloud provides the support essential for the deployment of microservices
    at scale. In order to get the full power of a cloud-like environment, the microservices
    instances should also be capable of scaling out and shrinking automatically based
    on traffic patterns.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud提供了必要的支持，以便在规模上部署微服务。为了充分发挥类似云的环境的全部功能，微服务实例还应能够根据流量模式自动扩展和收缩。
- en: This chapter will detail out how to make microservices elastically grow and
    shrink by effectively using the actuator data collected from Spring Boot microservices
    to control the deployment topology by implementing a simple life cycle manager.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将详细介绍如何通过有效使用从Spring Boot微服务收集的执行器数据来控制部署拓扑，从而使微服务能够弹性增长和收缩，并实现一个简单的生命周期管理器。
- en: 'By the end of this chapter, you will learn about the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您将学习以下主题：
- en: The basic concept of autoscaling and different approaches for autoscaling
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动缩放的基本概念和不同的自动缩放方法
- en: The importance and capabilities of a life cycle manager in the context of microservices
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在微服务的上下文中，生命周期管理器的重要性和能力
- en: Examining the custom life cycle manager to achieve autoscaling
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查自定义生命周期管理器以实现自动缩放
- en: Programmatically collecting statistics from the Spring Boot actuator and using
    it to control and shape incoming traffic
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从Spring Boot执行器中以编程方式收集统计信息，并将其用于控制和塑造传入流量
- en: Reviewing the microservice capability model
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 审查微服务能力模型
- en: 'This chapter will cover the **Application Lifecycle Management** capability
    in the microservices capability model discussed in [Chapter 3](ch03.html "Chapter 3. Applying
    Microservices Concepts"), *Applying Microservices Concepts*, highlighted in the
    following diagram:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖微服务能力模型中讨论的**应用生命周期管理**能力，该能力在[第3章](ch03.html "第3章 应用微服务概念")中讨论，*应用微服务概念*，如下图所示：
- en: '![Reviewing the microservice capability model](img/B05447_6_1.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![审查微服务能力模型](img/B05447_6_1.jpg)'
- en: We will see a basic version of the life cycle manager in this chapter, which
    will be enhanced in later chapters.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将看到生命周期管理器的基本版本，这将在后续章节中得到增强。
- en: Scaling microservices with Spring Cloud
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spring Cloud扩展微服务
- en: In [Chapter 5](ch05.html "Chapter 5. Scaling Microservices with Spring Cloud"),
    *Scaling Microservices with Spring Cloud*, you learned how to scale Spring Boot
    microservices using Spring Cloud components. The two key concepts of Spring Cloud
    that we implemented are self-registration and self-discovery. These two capabilities
    enable automated microservices deployments. With self-registration, microservices
    can automatically advertise the service availability by registering service metadata
    to a central service registry as soon as the instances are ready to accept traffic.
    Once the microservices are registered, consumers can consume the newly registered
    services from the very next moment by discovering service instances using the
    registry service. Registry is at the heart of this automation.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第5章](ch05.html "第5章 使用Spring Cloud扩展微服务")中，*使用Spring Cloud扩展微服务*，您学习了如何使用Spring
    Cloud组件扩展Spring Boot微服务。我们实现的Spring Cloud的两个关键概念是自注册和自发现。这两个能力使得微服务部署自动化。通过自注册，微服务可以在实例准备好接受流量时，通过向中央服务注册表注册服务元数据来自动宣传服务的可用性。一旦微服务注册，消费者就可以通过发现注册表服务实例来从下一刻开始消费新注册的服务。注册表是这种自动化的核心。
- en: This is quite different from the traditional clustering approach employed by
    the traditional JEE application servers. In the case of JEE application servers,
    the server instances' IP addresses are more or less statically configured in a
    load balancer. Therefore, the cluster approach is not the best solution for automatic
    scaling in Internet-scale deployments. Also, clusters impose other challenges,
    such as they have to have exactly the same version of binaries on all cluster
    nodes. It is also possible that the failure of one cluster node can poison other
    nodes due to the tight dependency between nodes.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这与传统JEE应用服务器采用的传统集群方法有很大不同。在JEE应用服务器的情况下，服务器实例的IP地址在负载均衡器中更多地是静态配置的。因此，在互联网规模的部署中，集群方法并不是自动缩放的最佳解决方案。此外，集群还带来其他挑战，例如它们必须在所有集群节点上具有完全相同的二进制版本。还有可能一个集群节点的故障会因节点之间的紧密依赖关系而影响其他节点。
- en: 'The registry approach decouples the service instances. It also eliminates the
    need to manually maintain service addresses in the load balancer or configure
    virtual IPs:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 注册表方法将服务实例解耦。它还消除了在负载均衡器中手动维护服务地址或配置虚拟IP的需要：
- en: '![Scaling microservices with Spring Cloud](img/B05447_6_2.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![使用Spring Cloud扩展微服务](img/B05447_6_2.jpg)'
- en: 'As shown in the diagram, there are three key components in our automated microservices
    deployment topology:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，在我们的自动化微服务部署拓扑中有三个关键组件：
- en: '**Eureka** is the central registry component for microservice registration
    and discovery. REST APIs are used by both consumers as well as providers to access
    the registry. The registry also holds the service metadata such as the service
    identity, host, port, health status, and so on.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Eureka**是微服务注册和发现的中央注册组件。消费者和提供者都使用REST API来访问注册表。注册表还保存服务元数据，如服务标识、主机、端口、健康状态等。'
- en: The **Eureka** client, together with the **Ribbon** client, provide client-side
    dynamic load balancing. Consumers use the Eureka client to look up the Eureka
    server to identify the available instances of a target service. The Ribbon client
    uses this server list to load-balance between the available microservice instances.
    In a similar way, if the service instance goes out of service, these instances
    will be taken out of the Eureka registry. The load balancer automatically reacts
    to these dynamic topology changes.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The third component is the **microservices** instances developed using Spring
    Boot with the actuator endpoints enabled.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, there is one gap in this approach. When there is need for an additional
    microservice instance, a manual task is required to kick off a new instance. In
    an ideal scenario, the starting and stopping of microservice instances also require
    automation.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: For example, when there is a requirement to add another Search microservice
    instance to handle the increase in traffic volumes or a load burst scenario, the
    administrator has to manually bring up a new instance. Also, when the Search instance
    is idle for some time, it needs to be manually taken out of service to have optimal
    infrastructure usage. This is especially relevant when services run on a pay-as-per-usage
    cloud environment.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the concept of autoscaling
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Autoscaling is an approach to automatically scaling out instances based on the
    resource usage to meet the SLAs by replicating the services to be scaled.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: 'The system automatically detects an increase in traffic, spins up additional
    instances, and makes them available for traffic handling. Similarly, when the
    traffic volumes go down, the system automatically detects and reduces the number
    of instances by taking active instances back from the service:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding the concept of autoscaling](img/B05447_6_3.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
- en: As shown in the preceding diagram, autoscaling is done, generally, using a set
    of reserve machines.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: As many of the cloud subscriptions are based on a pay-as-you-go model, this
    is an essential capability when targeting cloud deployments. This approach is
    often called **elasticity**. It is also called **dynamic resource provisioning
    and deprovisioning**. Autoscaling is an effective approach specifically for microservices
    with varying traffic patterns. For example, an Accounting service would have high
    traffic during month ends and year ends. There is no point in permanently provisioning
    instances to handle these seasonal loads.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: In the autoscaling approach, there is often a resource pool with a number of
    spare instances. Based on the demand, instances will be moved from the resource
    pool to the active state to meet the surplus demand. These instances are not pretagged
    for any particular microservices or prepackaged with any of the microservice binaries.
    In advanced deployments, the Spring Boot binaries are downloaded on demand from
    an artifact repository such as Nexus or Artifactory.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: The benefits of autoscaling
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many benefits in implementing the autoscaling mechanism. In traditional
    deployments, administrators reserve a set of servers against each application.
    With autoscaling, this preallocation is no longer required. This prefixed server
    allocation may result in underutilized servers. In this case, idle servers cannot
    be utilized even when neighboring services struggle for additional resources.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: 'With hundreds of microservice instances, preallocating a fixed number of servers
    to each of the microservices is not cost effective. A better approach is to reserve
    a number of server instances for a group of microservices without preallocating
    or tagging them against a microservice. Instead, based on the demand, a group
    of services can share a set of available resources. By doing so, microservices
    can be dynamically moved across the available server instances by optimally using
    the resources:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '![The benefits of autoscaling](img/B05447_6_4.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
- en: 'As shown in the preceding diagram, there are three instances of the **M1**
    microservice, one instance of **M2**, and one instance of **M3** up and running.
    There is another server kept unallocated. Based on the demand, the unallocated
    server can be used for any of the microservices: **M1**, **M2**, or **M3**. If
    **M1** has more service requests, then the unallocated instance will be used for
    **M1**. When the service usage goes down, the server instance will be freed up
    and moved back to the pool. Later, if the **M2** demand increases, the same server
    instance can be activated using **M2**.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，**M1**微服务有三个实例，**M2**有一个实例，**M3**有一个实例正在运行。还有另一台服务器保持未分配。根据需求，未分配的服务器可以用于任何微服务：**M1**、**M2**或**M3**。如果**M1**有更多的服务请求，那么未分配的实例将用于**M1**。当服务使用量下降时，服务器实例将被释放并移回池中。稍后，如果**M2**的需求增加，同一服务器实例可以使用**M2**激活。
- en: 'Some of the key benefits of autoscaling are:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 自动扩展的一些关键好处包括：
- en: '**It has high availability and is fault tolerant**: As there are multiple service
    instances, even if one fails, another instance can take over and continue serving
    clients. This failover will be transparent to the consumers. If no other instance
    of this service is available, the autoscaling service will recognize this situation
    and bring up another server with the service instance. As the whole process of
    bringing up or bringing down instances is automatic, the overall availability
    of the services will be higher than the systems implemented without autoscaling.
    The systems without autoscaling require manual intervention to add or remove service
    instances, which will be hard to manage in large deployments.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**它具有高可用性和容错性**：由于存在多个服务实例，即使一个失败，另一个实例也可以接管并继续为客户提供服务。这种故障转移对消费者来说是透明的。如果此服务没有其他实例可用，自动扩展服务将识别此情况并启动另一台带有服务实例的服务器。由于启动或关闭实例的整个过程是自动的，因此服务的整体可用性将高于没有自动扩展的系统。没有自动扩展的系统需要手动干预以添加或删除服务实例，在大规模部署中将很难管理。'
- en: For example, assume that two of instances of the Booking service are running.
    If there is an increase in the traffic flow, in a normal scenario, the existing
    instance might become overloaded. In most of the scenarios, the entire set of
    services will be jammed, resulting in service unavailability. In the case of autoscaling,
    a new Booking service instance can be brought up quickly. This will balance the
    load and ensure service availability.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设有两个**预订**服务实例正在运行。如果流量增加，通常情况下，现有实例可能会过载。在大多数情况下，整套服务将被堵塞，导致服务不可用。在自动扩展的情况下，可以快速启动新的**预订**服务实例。这将平衡负载并确保服务可用性。
- en: '**It increases scalability**: One of the key benefits of autoscaling is horizontal
    scalability. Autoscaling allows us to selectively scale up or scale down services
    automatically based on traffic patterns.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**它增加了可伸缩性**：自动扩展的关键好处之一是水平可伸缩性。自动扩展允许我们根据流量模式自动选择性地扩展或缩减服务。'
- en: '**It has optimal usage and is cost saving**: In a pay-as-you-go subscription
    model, billing is based on actual resource utilization. With the autoscaling approach,
    instances will be started and shut down based on the demand. Hence, resources
    are optimally utilized, thereby saving cost.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**它具有最佳的使用和节省成本**：在按使用量付费的订阅模型中，计费是基于实际资源利用率的。采用自动扩展方法，实例将根据需求启动和关闭。因此，资源得到了最佳利用，从而节省成本。'
- en: '**It gives priority to certain services or group of services**: With autoscaling,
    it is possible to give priority to certain critical transactions over low-value
    transactions. This will be done by removing an instance from a low-value service
    and reallocating it to a high-value service. This will also eliminate situations
    where a low-priority transaction heavily utilizes resources when high-value transactions
    are cramped up for resources.![The benefits of autoscaling](img/B05447_6_5.jpg)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**它优先考虑某些服务或服务组**：通过自动扩展，可以优先考虑某些关键交易而不是低价值交易。这将通过从低价值服务中移除实例并重新分配给高价值服务来实现。这也将消除低优先级交易在高价值交易因资源不足而受阻时大量利用资源的情况。![自动扩展的好处](img/B05447_6_5.jpg)'
- en: For instance, the **Booking** and **Reports** services run with two instances,
    as shown in the preceding diagram. Let's assume that the **Booking** service is
    a revenue generation service and therefore has a higher value than the **Reports**
    service. If there are more demands for the **Booking** service, then one can set
    policies to take one **Reports** service out of the service and release this server
    for the **Booking** service.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，**预订**和**报告**服务以两个实例运行，如前图所示。假设**预订**服务是一个收入生成服务，因此价值高于**报告**服务。如果对**预订**服务的需求更大，那么可以设置策略将一个**报告**服务从服务中移除，并释放此服务器供**预订**服务使用。
- en: Different autoscaling models
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不同的自动扩展模型
- en: Autoscaling can be applied at the application level or at the infrastructure
    level. In a nutshell, application scaling is scaling by replicating application
    binaries only, whereas infrastructure scaling is replicating the entire virtual
    machine, including application binaries.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 自动扩展可以应用于应用程序级别或基础设施级别。简而言之，应用程序扩展是通过仅复制应用程序二进制文件进行扩展，而基础设施扩展是复制整个虚拟机，包括应用程序二进制文件。
- en: Autoscaling an application
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 应用程序的自动扩展
- en: 'In this scenario, scaling is done by replicating the microservices, not the
    underlying infrastructure, such as virtual machines. The assumption is that there
    is a pool of VMs or physical infrastructures available to scale up microservices.
    These VMs have the basic image fused with any dependencies, such as JRE. It is
    also assumed that microservices are homogeneous in nature. This gives flexibility
    in reusing the same virtual or physical machines for different services:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，扩展是通过复制微服务而不是底层基础设施（如虚拟机）来完成的。假设有一组可用于扩展微服务的VM或物理基础设施。这些VM具有基本镜像，以及诸如JRE之类的任何依赖项。还假设微服务在性质上是同质的。这样可以灵活地重用相同的虚拟或物理机器来运行不同的服务：
- en: '![Autoscaling an application](img/B05447_6_6.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![自动扩展应用程序](img/B05447_6_6.jpg)'
- en: As shown in the preceding diagram, in scenario **A**, **VM3** is used for **Service
    1**, whereas in scenario **B**, the same **VM3** is used for **Service 2**. In
    this case, we only swapped the application library and not the underlying infrastructure.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，在**场景A**中，**VM3**用于**Service 1**，而在**场景B**中，相同的**VM3**用于**Service 2**。在这种情况下，我们只交换了应用程序库，而没有交换底层基础设施。
- en: This approach gives faster instantiation as we are only handling the application
    binaries and not the underlying VMs. The switching is easier and faster as the
    binaries are smaller in size and there is no OS boot required either. However,
    the downside of this approach is that if certain microservices require OS-level
    tuning or use polyglot technologies, then dynamically swapping microservices will
    not be effective.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法可以更快地实例化，因为我们只处理应用程序二进制文件，而不是底层的虚拟机。切换更容易更快，因为二进制文件体积较小，也不需要操作系统启动。然而，这种方法的缺点是，如果某些微服务需要操作系统级调整或使用多语言技术，那么动态交换微服务将不会有效。
- en: Autoscaling the infrastructure
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 云中的自动扩展
- en: 'In contrast to the previous approach, in this case, the infrastructure is also
    provisioned automatically. In most cases, this will create a new VM on the fly
    or destroy the VMs based on the demand:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 与前一种方法相比，在这种情况下，基础设施也是自动配置的。在大多数情况下，这将根据需求创建新的VM或销毁VM：
- en: '![Autoscaling the infrastructure](img/B05447_6_7.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![自动扩展基础设施](img/B05447_6_7.jpg)'
- en: As shown in the preceding diagram, the reserve instances are created as VM images
    with predefined service instances. When there is demand for **Service 1**, **VM3**
    is moved to an active state. When there is a demand for **Service 2**, **VM4**
    is moved to the active state.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，保留实例是作为具有预定义服务实例的VM映像创建的。当对**Service 1**有需求时，**VM3**被移动到活动状态。当对**Service
    2**有需求时，**VM4**被移动到活动状态。
- en: This approach is efficient if the applications depend upon the parameters and
    libraries at the infrastructure level, such as the operating system. Also, this
    approach is better for polyglot microservices. The downside is the heavy nature
    of VM images and the time required to spin up a new VM. Lightweight containers
    such as Dockers are preferred in such cases instead of traditional heavyweight
    virtual machines.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果应用程序依赖于基础设施级别的参数和库，例如操作系统，这种方法是有效的。此外，这种方法对于多语言微服务更好。缺点是VM镜像的重量级和启动新VM所需的时间。在这种情况下，与传统的重量级虚拟机相比，轻量级容器（如Docker）更受青睐。
- en: Autoscaling in the cloud
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 云中的自动扩展
- en: Elasticity or autoscaling is one of the fundamental features of most cloud providers.
    Cloud providers use infrastructure scaling patterns, as discussed in the previous
    section. These are typically based on a set of pooled machines.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 弹性或自动扩展是大多数云提供商的基本功能之一。云提供商使用基础设施扩展模式，如前一节所讨论的。这些通常基于一组池化的机器。
- en: For example, in AWS, these are based on introducing new EC2 instances with a
    predefined AMI. AWS supports autoscaling with the help of autoscaling groups.
    Each group is set with a minimum and maximum number of instances. AWS ensures
    that the instances are scaled on demand within these bounds. In case of predictable
    traffic patterns, provisioning can be configured based on timelines. AWS also
    provides ability for applications to customize autoscaling policies.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在AWS中，这是基于引入具有预定义AMI的新EC2实例。AWS支持使用自动扩展组来进行自动扩展。每个组都设置了最小和最大数量的实例。AWS确保在这些范围内根据需求进行实例扩展。在可预测的流量模式下，可以根据时间表配置预配。AWS还提供了应用程序自定义自动扩展策略的能力。
- en: Microsoft Azure also supports autoscaling based on the utilization of resources
    such as the CPU, message queue length, and so on. IBM Bluemix supports autoscaling
    based on resources such as CPU usage.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft Azure还支持根据CPU、消息队列长度等资源利用率进行自动扩展。IBM Bluemix支持根据CPU使用率进行自动扩展。
- en: Other PaaS platforms, such as CloudBees and OpenShift, also support autoscaling
    for Java applications. Pivotal Cloud Foundry supports autoscaling with the help
    of Pivotal Autoscale. Scaling policies are generally based on resource utilization,
    such as the CPU and memory thresholds.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 其他PaaS平台，如CloudBees和OpenShift，也支持Java应用程序的自动扩展。Pivotal Cloud Foundry通过Pivotal
    Autoscale支持自动扩展。扩展策略通常基于资源利用率，如CPU和内存阈值。
- en: There are components that run on top of the cloud and provide fine-grained controls
    to handle autoscaling. Netflix Fenzo, Eucalyptus, Boxfuse, and Mesosphere are
    some of the components in this category.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些组件在云顶部运行，并提供细粒度的控制来处理自动扩展。Netflix Fenzo、Eucalyptus、Boxfuse和Mesosphere是这一类组件中的一些。
- en: Autoscaling approaches
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动扩展方法
- en: Autoscaling is handled by considering different parameters and thresholds. In
    this section, we will discuss the different approaches and policies that are typically
    applied to take decisions on when to scale up or down.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 自动扩展是通过考虑不同的参数和阈值来处理的。在本节中，我们将讨论通常应用于决定何时扩展或缩小的不同方法和策略。
- en: Scaling with resource constraints
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 根据资源约束进行扩展
- en: This approach is based on real-time service metrics collected through monitoring
    mechanisms. Generally, the resource-scaling approach takes decisions based on
    the CPU, memory, or the disk of machines. This can also be done by looking at
    the statistics collected on the service instances themselves, such as heap memory
    usage.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法是基于通过监控机制收集的实时服务指标。通常，资源扩展方法是基于机器的CPU、内存或磁盘做出决策。也可以通过查看服务实例本身收集的统计数据来实现，比如堆内存使用情况。
- en: 'A typical policy may be spinning up another instance when the CPU utilization
    of the machine goes beyond 60%. Similarly, if the heap size goes beyond a certain
    threshold, we can add a new instance. The same applies to downsizing the compute
    capacity when the resource utilization goes below a set threshold. This is done
    by gradually shutting down servers:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的策略可能是当机器的CPU利用率超过60%时，启动另一个实例。同样，如果堆大小超过一定阈值，我们可以添加一个新实例。资源利用率低于设定阈值时，也可以缩减计算能力。这是通过逐渐关闭服务器来实现的：
- en: '![Scaling with resource constraints](img/B05447_6_8.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![受资源约束的扩展](img/B05447_6_8.jpg)'
- en: In typical production scenarios, the creation of additional services is not
    done on the first occurrence of a threshold breach. The most appropriate approach
    is to define a sliding window or a waiting period.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在典型的生产场景中，不会在第一次阈值违规时创建额外的服务。最合适的方法是定义一个滑动窗口或等待期。
- en: 'The following are some of the examples:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些例子：
- en: An example of a **response sliding window** is if 60% of the response time of
    a particular transaction is consistently more than the set threshold value in
    a 60-second sampling window, increase service instances
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**响应滑动窗口**的一个例子是，如果特定交易的60%响应时间在60秒的采样窗口中一直超过设定的阈值，就增加服务实例'
- en: In a **CPU sliding window**, if the CPU utilization is consistently beyond 70%
    in a 5 minutes sliding window, then a new instance is created
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在**CPU滑动窗口**中，如果CPU利用率在5分钟的滑动窗口中一直超过70%，那么会创建一个新实例
- en: An example of the **exception sliding window** is if 80% of the transactions
    in a sliding window of 60 seconds or 10 consecutive executions result in a particular
    system exception, such as a connection timeout due to exhausting the thread pool,
    then a new service instance is created
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常滑动窗口**的一个例子是，如果在60秒的滑动窗口中有80%的交易或连续10次执行导致特定系统异常，比如由于线程池耗尽而导致连接超时，那么会创建一个新的服务实例'
- en: In many cases, we will set a lower threshold than the actual expected thresholds.
    For example, instead of setting the CPU utilization threshold at 80%, set it at
    60% so that the system gets enough time to spin up an instance before it stops
    responding. Similarly, when scaling down, we use a lower threshold than the actual.
    For example, we will use 40% CPU utilization to scale down instead of 60%. This
    allows us to have a cool-down period so that there will not be any resource struggle
    when shutting down instances.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，我们会将实际预期的阈值设定为较低的阈值。例如，不是将CPU利用率阈值设定为80%，而是设定为60%，这样系统有足够的时间来启动一个实例，而不会停止响应。同样，在缩减规模时，我们会使用比实际阈值更低的阈值。例如，我们将使用40%的CPU利用率来缩减规模，而不是60%。这样可以让我们有一个冷却期，以便在关闭实例时不会出现资源竞争。
- en: Resource-based scaling is also applicable to service-level parameters such as
    the throughput of the service, latency, applications thread pool, connection pool,
    and so on. These can also be at the application level, such as the number of **sales
    orders** processing in a service instance, based on internal benchmarking.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 基于资源的扩展也适用于服务级参数，如服务的吞吐量、延迟、应用程序线程池、连接池等。这些也可以是在应用程序级别，比如基于内部基准测试的服务实例中处理的**销售订单**数量。
- en: Scaling during specific time periods
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特定时间段的扩展
- en: 'Time-based scaling is an approach to scaling services based on certain periods
    of the day, month, or year to handle seasonal or business peaks. For example,
    some services may experience a higher number of transactions during office hours
    and a considerably low number of transactions outside office hours. In this case,
    during the day, services autoscale to meet the demand and automatically downsize
    during the non-office hours:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 基于时间的扩展是一种根据一天、一个月或一年的某些时段来扩展服务的方法，以处理季节性或业务高峰。例如，一些服务可能在办公时间内经历更多的交易，而在非办公时间内交易数量明显较少。在这种情况下，白天，服务会自动扩展以满足需求，并在非办公时间自动缩减：
- en: '![Scaling during specific time periods](img/B05447_6_9.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![特定时间段的扩展](img/B05447_6_9.jpg)'
- en: Many airports worldwide impose restrictions on night-time landing. As a result,
    the number of passengers checking in at the airports during the night time is
    less compared to the day time. Hence, it is cost effective to reduce the number
    of instances during the night time.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 全球许多机场对夜间着陆施加限制。因此，与白天相比，夜间在机场办理登机手续的乘客数量较少。因此，在夜间减少实例数量是成本有效的。
- en: Scaling based on the message queue length
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于消息队列长度的扩展
- en: 'This is particularly useful when the microservices are based on asynchronous
    messaging. In this approach, new consumers are automatically added when the messages
    in the queue go beyond certain limits:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 当微服务基于异步消息传递时，这种方法特别有用。在这种方法中，当队列中的消息超过一定限制时，会自动添加新的消费者：
- en: '![Scaling based on the message queue length](img/B05447_6_10.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![基于消息队列长度的扩展](img/B05447_6_10.jpg)'
- en: This approach is based on the competing consumer pattern. In this case, a pool
    of instances is used to consume messages. Based on the message threshold, new
    instances are added to consume additional messages.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法是基于竞争消费者模式。在这种情况下，一组实例用于消费消息。根据消息阈值，会添加新实例来消费额外的消息。
- en: Scaling based on business parameters
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于业务参数的扩展
- en: 'In this case, adding instances is based on certain business parameters—for
    example, spinning up a new instance just before handling **sales closing** transactions.
    As soon as the monitoring service receives a preconfigured business event (such
    as **sales closing minus 1 hour**), a new instance will be brought up in anticipation
    of large volumes of transactions. This will provide fine-grained control on scaling
    based on business rules:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，增加实例是基于某些业务参数的，例如，在处理**销售结束**交易之前立即启动一个新实例。一旦监控服务接收到预先配置的业务事件（例如**销售结束前1小时**），将会预先启动一个新实例，以预期大量交易。这将根据业务规则提供基于细粒度控制的扩展：
- en: '![Scaling based on business parameters](img/B05447_6_11.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![基于业务参数的扩展](img/B05447_6_11.jpg)'
- en: Predictive autoscaling
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测自动扩展
- en: Predictive scaling is a new paradigm of autoscaling that is different from the
    traditional real-time metrics-based autoscaling. A prediction engine will take
    multiple inputs, such as historical information, current trends, and so on, to
    predict possible traffic patterns. Autoscaling is done based on these predictions.
    Predictive autoscaling helps avoid hardcoded rules and time windows. Instead,
    the system can automatically predict such time windows. In more sophisticated
    deployments, predictive analysis may use cognitive computing mechanisms to predict
    autoscaling.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 预测扩展是一种新的自动扩展范式，不同于传统的基于实时指标的自动扩展。预测引擎将采用多个输入，例如历史信息，当前趋势等，来预测可能的流量模式。根据这些预测进行自动扩展。预测自动扩展有助于避免硬编码规则和时间窗口。相反，系统可以自动预测这些时间窗口。在更复杂的部署中，预测分析可能使用认知计算机制来预测自动扩展。
- en: In the cases of sudden traffic spikes, traditional autoscaling may not help.
    Before the autoscaling component can react to the situation, the spike would have
    hit and damaged the system. The predictive system can understand these scenarios
    and predict them before their actual occurrence. An example will be handling a
    flood of requests immediately after a planned outage.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在突发流量激增的情况下，传统的自动扩展可能无法帮助。在自动扩展组件能够对情况做出反应之前，激增已经发生并损害了系统。预测系统可以理解这些情况并在它们实际发生之前进行预测。一个例子是在计划的停机后立即处理一大堆请求。
- en: Netflix Scryer is an example of such a system that can predict resource requirements
    in advance.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Netflix Scryer是这样一个系统的例子，它可以提前预测资源需求。
- en: Autoscaling BrownField PSS microservices
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动扩展BrownField PSS微服务
- en: In this section, we will examine how to enhance microservices developed in [Chapter
    5](ch05.html "Chapter 5. Scaling Microservices with Spring Cloud"), *Scaling Microservices
    with Spring Cloud*, for autoscaling. We need a component to monitor certain performance
    metrics and trigger autoscaling. We will call this component the **life cycle
    manager**.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将研究如何增强[第5章](ch05.html "第5章。使用Spring Cloud扩展微服务")中开发的微服务，*使用Spring Cloud扩展微服务*，以实现自动扩展。我们需要一个组件来监视某些性能指标并触发自动扩展。我们将称这个组件为**生命周期管理器**。
- en: The service life cycle manager, or the application life cycle manager, is responsible
    for detecting scaling requirements and adjusting the number of instances accordingly.
    It is responsible for starting and shutting down instances dynamically.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 服务生命周期管理器或应用程序生命周期管理器负责检测扩展需求并相应地调整实例数量。它负责动态启动和关闭实例。
- en: In this section, we will take a look at a primitive autoscaling system to understand
    the basic concepts, which will be enhanced in later chapters.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将研究一个原始的自动扩展系统，以了解基本概念，这将在后面的章节中得到增强。
- en: The capabilities required for an autoscaling system
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动扩展系统所需的功能
- en: 'A typical autoscaling system has capabilities as shown in the following diagram:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的自动扩展系统具有以下图表中显示的功能：
- en: '![The capabilities required for an autoscaling system](img/B05447_6_12.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![自动扩展系统所需的功能](img/B05447_6_12.jpg)'
- en: 'The components involved in the autoscaling ecosystem in the context of microservices
    are explained as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在微服务的自动扩展生态系统中涉及的组件如下所述：
- en: '**Microservices**: These are sets of the up-and-running microservice instances
    that keep sending health and metrics information. Alternately, these services
    expose actuator endpoints for metrics collection. In the preceding diagram, these
    are represented as **Microservice 1** through **Microservice 4**.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微服务**：这些是一组正在运行的微服务实例，它们不断发送健康和指标信息。或者，这些服务公开执行器端点以进行指标收集。在前面的图表中，这些被表示为**微服务1**到**微服务4**。'
- en: '**Service Registry**: A service registry keeps track of all the services, their
    health states, their metadata, and their endpoint URI.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务注册表**：服务注册表跟踪所有服务、它们的健康状态、它们的元数据和它们的端点URI。'
- en: '**Load Balancer**: This is a client-side load balancer that looks up the service
    registry to get up-to-date information about the available service instances.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负载均衡器**：这是一个客户端负载均衡器，它查找服务注册表以获取有关可用服务实例的最新信息。'
- en: '**Lifecycle Manager**: The life cycle manger is responsible for autoscaling,
    which has the following subcomponents:'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生命周期管理器**：生命周期管理器负责自动扩展，具有以下子组件：'
- en: '**Metrics Collector**: A metrics collection unit is responsible for collecting
    metrics from all service instances. The life cycle manager will aggregate the
    metrics. It may also keep a sliding time window. The metrics could be infrastructure-level
    metrics, such as CPU usage, or application-level metrics, such as transactions
    per minute.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指标收集器**：指标收集单元负责从所有服务实例收集指标。生命周期管理器将汇总这些指标。它还可以保持一个滑动时间窗口。这些指标可以是基础设施级别的指标，例如CPU使用率，也可以是应用程序级别的指标，例如每分钟的交易数。'
- en: '**Scaling policies**: Scaling policies are nothing but sets of rules indicating
    when to scale up and scale down microservices—for example, 90% of CPU usage above
    60% in a sliding window of 5 minutes.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扩展策略**：扩展策略只是指示何时扩展和缩小微服务的一组规则，例如，在5分钟的滑动时间窗口内，CPU使用率超过60%的90%。'
- en: '**Decision Engine**: A decision engine is responsible for making decisions
    to scale up and scale down based on the aggregated metrics and scaling policies.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策引擎**：决策引擎负责根据汇总的指标和扩展策略做出扩展或缩减的决策。'
- en: '**Deployment Rules**: The deployment engine uses deployment rules to decide
    which parameters to consider when deploying services. For example, a service deployment
    constraint may say that the instance must be distributed across multiple availability
    regions or a 4 GB minimum of memory required for the service.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署规则**：部署引擎使用部署规则来决定部署服务时要考虑哪些参数。例如，服务部署约束可能要求实例必须分布在多个可用区域，或者服务需要至少4GB的内存。'
- en: '**Deployment Engine**: The deployment engine, based on the decisions of the
    decision engine, can start or stop microservice instances or update the registry
    by altering the health states of services. For example, it sets the health status
    as "out of service" to take out a service temporarily.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署引擎**：基于决策引擎的决策，部署引擎可以启动或停止微服务实例，或通过改变服务的健康状态来更新注册表。例如，它将健康状态设置为“暂时停用”以暂时移除服务。'
- en: Implementing a custom life cycle manager using Spring Boot
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Spring Boot实现自定义生命周期管理器
- en: The life cycle manager introduced in this section is a minimal implementation
    to understand autoscaling capabilities. In later chapters, we will enhance this
    implementation with containers and cluster management solutions. Ansible, Marathon,
    and Kubernetes are some of the tools useful in building this capability.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍的生命周期管理器是一个最小实现，用于理解自动扩展的能力。在后面的章节中，我们将使用容器和集群管理解决方案来增强这个实现。Ansible、Marathon和Kubernetes是一些有用的工具，用于构建这种能力。
- en: In this section, we will implement an application-level autoscaling component
    using Spring Boot for the services developed in [Chapter 5](ch05.html "Chapter 5. Scaling
    Microservices with Spring Cloud"), *Scaling Microservices with Spring Cloud*.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用Spring Boot为[第5章](ch05.html "第5章。使用Spring Cloud扩展微服务")中开发的服务实现一个应用级自动扩展组件，*使用Spring
    Cloud扩展微服务*。
- en: Understanding the deployment topology
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解部署拓扑
- en: 'The following diagram shows a sample deployment topology of BrownField PSS
    microservices:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了BrownField PSS微服务的示例部署拓扑：
- en: '![Understanding the deployment topology](img/B05447_6_13.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![理解部署拓扑](img/B05447_6_13.jpg)'
- en: As shown in the diagram, there are four physical machines. Eight VMs are created
    from four physical machines. Each physical machine is capable of hosting two VMs,
    and each VM is capable of running two Spring Boot instances, assuming that all
    services have the same resource requirements.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，有四台物理机器。从四台物理机器创建了八个虚拟机。每台物理机器能够承载两个虚拟机，每个虚拟机能够运行两个Spring Boot实例，假设所有服务具有相同的资源需求。
- en: Four VMs, **VM1** through **VM4**, are active and are used to handle traffic.
    **VM5** to **VM8** are kept as reserve VMs to handle scalability. **VM5** and
    **VM6** can be used for any of the microservices and can also be switched between
    microservices based on scaling demands. Redundant services use VMs created from
    different physical machines to improve fault tolerance.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 四台虚拟机**VM1**到**VM4**是活动的，用于处理流量。**VM5**到**VM8**被保留用于处理可扩展性。**VM5**和**VM6**可以用于任何微服务，并且也可以根据扩展需求在微服务之间切换。冗余服务使用来自不同物理机器创建的虚拟机，以提高容错性。
- en: Our objective is to scale out any services when there is increase in traffic
    flow using four VMs, **VM5** through **VM8**, and scale down when there is not
    enough load. The architecture of our solution is as follows.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是在流量增加时使用四个虚拟机**VM5**到**VM8**扩展任何服务，并在负载不足时缩减。我们解决方案的架构如下。
- en: Understanding the execution flow
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解执行流程
- en: 'Have a look at the following flowchart:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看以下流程图：
- en: '![Understanding the execution flow](img/B05447_6_14.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![理解执行流程](img/B05447_6_14.jpg)'
- en: 'As shown in the preceding diagram, the following activities are important for
    us:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，以下活动对我们很重要：
- en: The Spring Boot service represents microservices such as Search, Book, Fares,
    and Check-in. Services at startup automatically register endpoint details to the
    Eureka registry. These services are actuator-enabled, so the life cycle manager
    can collect metrics from the actuator endpoints.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spring Boot服务代表了诸如搜索、预订、票价和办理登机等微服务。这些服务在启动时会自动将端点详细信息注册到Eureka注册表。这些服务启用了执行器，因此生命周期管理器可以从执行器端点收集指标。
- en: The life cycle manager service is nothing but another Spring Boot application.
    The life cycle manager has a metrics collector that runs a background job, periodically
    polls the Eureka server, and gets details of all the service instances. The metrics
    collector then invokes the actuator endpoints of each microservice registered
    in the Eureka registry to get the health and metrics information. In a real production
    scenario, a subscription approach for data collection is better.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生命周期管理器服务实际上就是另一个Spring Boot应用程序。生命周期管理器具有一个指标收集器，它运行一个后台作业，定期轮询Eureka服务器，并获取所有服务实例的详细信息。然后，指标收集器调用Eureka注册表中注册的每个微服务的执行器端点，以获取健康和指标信息。在真实的生产场景中，采用订阅方法进行数据收集更好。
- en: With the collected metrics information, the life cycle manager executes a list
    of policies and derives decisions on whether to scale up or scale down instances.
    These decisions are either to start a new service instance of a particular type
    on a particular VM or to shut down a particular instance.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过收集的指标信息，生命周期管理器执行一系列策略，并根据这些策略决定是否扩展或缩减实例。这些决策要么是在特定虚拟机上启动特定类型的新服务实例，要么是关闭特定实例。
- en: In the case of shutdown, it connects to the server using an actuator endpoint
    and calls the shutdown service to gracefully shut down an instance.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在关闭的情况下，它使用执行器端点连接到服务器，并调用关闭服务来优雅地关闭一个实例。
- en: In the case of starting a new instance, the deployment engine of the life cycle
    manager uses the scaling rules and decides where to start the new instance and
    what parameters are to be used when starting the instance. Then, it connects to
    the respective VMs using SSH. Once connected, it executes a preinstalled script
    (or passes this script as a part of the execution) by passing the required constraints
    as a parameter. This script fetches the application library from a central Nexus
    repository in which the production binaries are kept and initiates it as a Spring
    Boot application. The port number is parameterized by the life cycle manager.
    SSH needs to be enabled on the target machines.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在启动新实例的情况下，生命周期管理器的部署引擎使用扩展规则并决定在哪里启动新实例以及启动实例时要使用的参数。然后，它使用SSH连接到相应的VM。一旦连接，它通过传递所需的约束作为参数来执行预安装的脚本（或将此脚本作为执行的一部分）。此脚本从中央Nexus存储库中获取应用程序库，其中保存了生产二进制文件，并将其初始化为Spring
    Boot应用程序。端口号由生命周期管理器参数化。目标机器上需要启用SSH。
- en: In this example, we will use **TPM** (**Transactions Per Minute**) or **RPM**
    (**Requests Per Minute**) as sampler metrics for decision making. If the Search
    service has more than 10 TPM, then it will spin up a new Search service instance.
    Similarly, if the TPM is below 2, one of the instances will be shut down and released
    back to the pool.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们将使用**TPM**（**每分钟事务数**）或**RPM**（**每分钟请求数**）作为决策的采样指标。如果搜索服务的TPM超过10，那么它将启动一个新的搜索服务实例。同样，如果TPM低于2，其中一个实例将被关闭并释放回池中。
- en: 'When starting a new instance, the following policies will be applied:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动新实例时，将应用以下策略：
- en: The number of service instances at any point should be a minimum of 1 and a
    maximum of 4\. This also means that at least one service instance will always
    be up and running.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何时候的服务实例数应该至少为1，最多为4。这也意味着至少一个服务实例将始终处于运行状态。
- en: A scaling group is defined in such a way that a new instance is created on a
    VM that is on a different physical machine. This will ensure that the services
    run across different physical machines.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义了一个扩展组，以便在不同物理机器上创建一个新实例的VM上。这将确保服务在不同的物理机器上运行。
- en: These policies could be further enhanced. The life cycle manager ideally provides
    options to customize these rules through REST APIs or Groovy scripts.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这些策略可以进一步增强。生命周期管理器理想情况下提供通过REST API或Groovy脚本自定义这些规则的选项。
- en: A walkthrough of the life cycle manager code
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生命周期管理器代码演示
- en: We will take a look at how a simple life cycle manager is implemented. This
    section will be a walkthrough of the code to understand the different components
    of the life cycle manager.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看一下如何实现一个简单的生命周期管理器。本节将演示代码，以了解生命周期管理器的不同组件。
- en: Tip
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: The full source code is available under the `Chapter 6` project in the code
    files. The `chapter5.configserver`, `chapter5.eurekaserver`, `chapter5.search`,
    and `chapter5.search-apigateway` are copied and renamed as `chapter6.*`, respectively.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的源代码在代码文件中的`第6章`项目中可用。`chapter5.configserver`，`chapter5.eurekaserver`，`chapter5.search`和`chapter5.search-apigateway`分别复制并重命名为`chapter6.*`。
- en: 'Perform the following steps to implement the custom life cycle manager:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤来实现自定义生命周期管理器：
- en: Create a new Spring Boot application and name it `chapter6.lifecyclemanager`.
    The project structure is shown in the following diagram:![A walkthrough of the
    life cycle manager code](img/B05447_6_15.jpg)
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Spring Boot应用程序，并将其命名为`chapter6.lifecyclemanager`。项目结构如下图所示：![生命周期管理器代码演示](img/B05447_6_15.jpg)
- en: 'The flowchart for this example is as shown in the following diagram:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例的流程图如下图所示：
- en: '![A walkthrough of the life cycle manager code](img/B05447_6_16.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![生命周期管理器代码演示](img/B05447_6_16.jpg)'
- en: The components of this diagram are explained in details here.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 此图的组件在此处详细解释。
- en: 'Create a `MetricsCollector` class with the following method. At the startup
    of the Spring Boot application, this method will be invoked using `CommandLineRunner`,
    as follows:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`MetricsCollector`类，其中包含以下方法。在Spring Boot应用程序启动时，将使用`CommandLineRunner`调用此方法，如下所示：
- en: '[PRE0]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The preceding method looks for the services registered in the Eureka server
    and gets all the instances. In the real world, rather than polling, the instances
    should publish metrics to a common place, where metrics aggregation will happen.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的方法查找在Eureka服务器中注册的服务并获取所有实例。在现实世界中，实例应该发布指标到一个共同的地方，指标聚合将在那里发生，而不是轮询。
- en: 'The following `DecisionEngine` code accepts the metric and applies certain
    scaling policies to determine whether the service requires scaling up or not:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下的`DecisionEngine`代码接受指标并应用特定的扩展策略来确定服务是否需要扩展：
- en: '[PRE1]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Based on the service ID, the policies that are related to the services will
    be picked up and applied. In this case, a minimal TPM scaling policy is implemented
    in `TpmScalingPolicy`, as follows:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据服务ID，将挑选并应用与服务相关的策略。在这种情况下，`TpmScalingPolicy`中实现了最小TPM扩展策略，如下所示：
- en: '[PRE2]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If the policy returns `true`, `DecisionEngine` then invokes `DeploymentEngine`
    to spin up another instance. `DeploymentEngine` makes use of `DeploymentRules`
    to decide how to execute scaling. The rules can enforce the number of min and
    max instances, in which region or machine the new instance has to be started,
    the resources required for the new instance, and so on. `DummyDeploymentRule`
    simply makes sure the max instance is not more than 2.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果策略返回`true`，`DecisionEngine`将调用`DeploymentEngine`来启动另一个实例。`DeploymentEngine`使用`DeploymentRules`来决定如何执行扩展。规则可以强制执行最小和最大实例数，在哪个区域或机器上启动新实例，新实例所需的资源等。`DummyDeploymentRule`只需确保最大实例数不超过2。
- en: '`DeploymentEngine`, in this case, uses the **JSch** (**Java Secure Channel**)
    library from JCraft to SSH to the destination server and start the service. This
    requires the following additional Maven dependency:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这种情况下，`DeploymentEngine`使用JCraft的**JSch**（**Java Secure Channel**）库来SSH到目标服务器并启动服务。这需要以下额外的Maven依赖项：
- en: '[PRE3]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The current SSH implementation is kept simple enough as we will change this
    in future chapters. In this example, `DeploymentEngine` sends the following command
    over the SSH library on the target machine:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当前的SSH实现足够简单，因为我们将在未来的章节中更改它。在这个例子中，`DeploymentEngine`通过SSH库向目标机器发送以下命令：
- en: '[PRE4]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Integration with Nexus happens from the target machine using Linux scripts with
    Nexus CLI or using `curl`. In this example, we will not explore Nexus.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 与Nexus的集成是通过目标机器使用带有Nexus CLI的Linux脚本或使用`curl`来完成的。在这个例子中，我们不会探索Nexus。
- en: The next step is to change the Search microservice to expose a new gauge for
    TPM. We have to change all the microservices developed earlier to submit this
    additional metric.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是更改搜索微服务以公开一个新的TPM量规。我们必须更改之前开发的所有微服务以提交这个额外的指标。
- en: We will only examine Search in this chapter, but in order to complete it, all
    the services have to be updated. In order to get the `gauge.servo.tpm` metrics,
    we have to add `TPMCounter` to all the microservices.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们只会检查搜索，但为了完成它，所有服务都必须更新。为了获得 `gauge.servo.tpm` 指标，我们必须在所有微服务中添加 `TPMCounter`。
- en: 'The following code counts the transactions over a sliding window of 1 minute:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码计算了一个滑动窗口内的交易次数：
- en: '[PRE5]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following code needs to be added to `SearchController` to set the `tpm`
    value:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码需要添加到`SearchController`中以设置`tpm`值：
- en: '[PRE6]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The following code is from the get REST endpoint (the search method) of `SearchRestController`,
    which submits the `tpm` value as a gauge to the actuator endpoint:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码来自`SearchRestController`的get REST端点（搜索方法），它将`tpm`值作为量规提交给执行器端点：
- en: '[PRE7]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Running the life cycle manager
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行生命周期管理器
- en: 'Perform the following steps to run the life cycle manager developed in the
    previous section:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤来运行前一节中开发的生命周期管理器：
- en: 'Edit `DeploymentEngine.java` and update the password to reflect the machine''s
    password, as follows. This is required for the SSH connection:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑`DeploymentEngine.java`并更新密码以反映机器的密码，如下所示。这是SSH连接所需的：
- en: '[PRE8]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Build all the projects by running Maven from the root folder (`Chapter 6`)
    via the following command:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过从根文件夹（`第6章`）运行Maven来构建所有项目，使用以下命令：
- en: '[PRE9]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then, run RabbitMQ, as follows:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，按以下方式运行RabbitMQ：
- en: '[PRE10]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Ensure that the Config server is pointing to the right configuration repository.
    We need to add a property file for the life cycle manager.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保配置服务器指向正确的配置存储库。我们需要为生命周期管理器添加一个属性文件。
- en: 'Run the following commands from the respective project folders:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从各自的项目文件夹运行以下命令：
- en: '[PRE11]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Once all the services are started, open a browser window and load `http://localhost:8001`.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦所有服务都启动了，打开浏览器窗口并加载 `http://localhost:8001`。
- en: Execute the flight search 11 times, one after the other, within a minute. This
    will trigger the decision engine to instantiate another instance of the Search
    microservice.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连续执行11次航班搜索，在一分钟内依次执行。这将触发决策引擎实例化搜索微服务的另一个实例。
- en: Open the Eureka console (`http://localhost:8761`) and watch for a second **SEARCH-SERVICE**.
    Once the server is started, the instances will appear as shown here:![Running
    the life cycle manager](img/B05447_6_17.jpg)
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Eureka控制台（`http://localhost:8761`）并观察第二个**SEARCH-SERVICE**。一旦服务器启动，实例将如下所示出现：![运行生命周期管理器](img/B05447_6_17.jpg)
- en: Summary
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned the importance of autoscaling when deploying large-scale
    microservices.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您了解了在部署大规模微服务时自动缩放的重要性。
- en: We also explored the concept of autoscaling and the different models of and
    approaches to autoscaling, such as the time-based, resource-based, queue length-based,
    and predictive ones. We then reviewed the role of a life cycle manager in the
    context of microservices and reviewed its capabilities. Finally, we ended this
    chapter by reviewing a sample implementation of a simple custom life cycle manager
    in the context of BrownField PSS microservices.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还探讨了自动缩放的概念以及自动缩放的不同模型和方法，例如基于时间、基于资源、基于队列长度和预测性的方法。然后我们审查了生命周期管理器在微服务环境中的作用并审查了它的能力。最后，我们通过审查一个简单的自定义生命周期管理器的示例实现来结束本章，该示例是在BrownField
    PSS微服务环境中。
- en: Autoscaling is an important supporting capability required when dealing with
    large-scale microservices. We will discuss a more mature implementation of the
    life cycle manager in [Chapter 9](ch09.html "Chapter 9. Managing Dockerized Microservices
    with Mesos and Marathon"), *Managing Dockerized Microservices with Mesos and Marathon*.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 自动缩放是处理大规模微服务时所需的重要支持能力。我们将在[第9章](ch09.html "第9章。使用Mesos和Marathon管理Docker化的微服务")中讨论生命周期管理器的更成熟的实现，*使用Mesos和Marathon管理Docker化的微服务*。
- en: The next chapter will explore the logging and monitoring capabilities that are
    indispensable for successful microservice deployments.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将探讨对于成功的微服务部署至关重要的日志记录和监控能力。

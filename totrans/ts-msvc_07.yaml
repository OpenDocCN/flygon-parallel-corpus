- en: Service State and Interservice Communication
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务状态和服务间通信
- en: Now that we have developed some microservices, seen API Gateway, and understood
    service registry and discovery, it's time to dive deeper into microservices and
    understand the system from an individual microservice point of view. To gain the
    most benefits out of microservices architecture, every component in the system
    has to collaborate in just the right way—a way that ensures that there is most
    likely no coupling between microservices, which will enable us to be Agile.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经开发了一些微服务，看到了API网关，并了解了服务注册表和发现，现在是时候深入了解微服务，并从单个微服务的角度了解系统。为了从微服务架构中获得最大的好处，系统中的每个组件都必须以恰当的方式进行协作，这种方式可以确保微服务之间几乎没有耦合，这将使我们能够灵活应对。
- en: 'In this chapter, we will understand various communication styles between microservices
    and see how services exchange data among themselves. Then we will move on to the
    service bus, an enterprise way of how system components communicate with each
    other. Many services would need to persist some state in one form or another.
    We will see how to make our service stateless. We will see the current database
    landscape and understand service state. We will understand pub-sub pattern and
    look at tools such as Kafka, and RabbitMQ, to understand event-driven architecture.
    This chapter covers the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将了解微服务之间的各种通信方式，以及服务之间如何交换数据。然后我们将转向服务总线，这是系统组件之间如何通信的企业方式。许多服务需要以一种形式或另一种形式持久化一些状态。我们将看到如何使我们的服务无状态。我们将了解当前的数据库格局并理解服务状态。我们将了解发布-订阅模式，并了解诸如Kafka和RabbitMQ之类的工具，以了解事件驱动架构。本章涵盖以下主题：
- en: Core concepts—state, communication, and dependencies
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心概念-状态、通信和依赖关系
- en: Communication styles
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通信方式
- en: Synchronous versus asynchronous way of data sharing
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同步与异步的数据共享方式
- en: Microservice versioning and failure handling
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务版本控制和故障处理
- en: Service bus
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务总线
- en: Data sharing between microservices
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务之间的数据共享
- en: Cache via Redis
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过Redis进行缓存
- en: Publish-subscribe pattern
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布-订阅模式
- en: Core concepts – state, communication, and dependencies
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 核心概念-状态、通信和依赖关系
- en: Each microservice implements a single capability such as shipping, and deducting
    from the inventory. However, to deliver an end user, a service request such as
    business capability, user need, or user-specific requests; it may or may not be
    a set of business capabilities. For example, a person who wants to buy the product
    is a single service request from the user's point of view. However, multiple requests
    are involved here, such as add to cart microservice, payment microservice, shipping
    microservice.  Hence, to deliver, microservices need to collaborate among each
    other. In this section, we will look at core concepts of microservice collaboration
    such as service state, communication styles, and more. Choosing the correct communication
    style helps us to design a loosely coupled architecture that ensures that each
    microservice has clear boundaries and it stays inside its bounded context. In
    this section, we will look at some core concepts that will affect our microservice
    design and architecture. So, let's get started.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 每个微服务实现一个单一的能力，比如发货和从库存中扣除。然而，为了向最终用户交付一个服务请求，比如业务能力、用户需求或用户特定请求；可能是一组业务能力，也可能不是。例如，从用户的角度来看，想要购买产品的人是一个单一的服务请求。然而，这里涉及到多个请求，比如加入购物车微服务、支付微服务、发货微服务。因此，为了交付，微服务需要相互协作。在本节中，我们将看到微服务协作的核心概念，如服务状态、通信方式等。选择正确的通信方式有助于设计一个松散耦合的架构，确保每个微服务都有清晰的边界，并且它保持在其有界上下文内。在本节中，我们将看一些核心概念，这些概念将影响我们的微服务设计和架构。所以，让我们开始吧。
- en: Microservice state
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微服务状态
- en: While we should indeed thrive on making services as stateless as possible, there
    are some instances where we do need stateful services. A state is simply any condition
    or quality at any specific point in time. A stateful service is one that is dependent
    on the state of the system. Being stateful means to rely on these moments in time,
    whereas statelessness means to be independent of any sort of state.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们确实应该努力使服务尽可能无状态，但有些情况下我们确实需要有状态的服务。状态只是在任何特定时间点的任何条件或质量。有状态的服务是依赖于系统状态的服务。有状态意味着依赖于这些时间点，而无状态意味着独立于任何状态。
- en: Stateful service is essential in instances where we have a workflow that calls
    some REST services, we need to support retries on failures, we need to track progress,
    store intermediate results, and so on. We need to keep state somewhere outside
    of our service instances boundaries. This is where databases come into the picture.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在需要调用一些REST服务的工作流中，有状态的服务是必不可少的，我们需要在失败时支持重试，需要跟踪进度，存储中间结果等。我们需要在我们的服务实例边界之外的某个地方保持状态。这就是数据库出现的地方。
- en: Databases are an important and interesting part to think on. Introducing database
    in a microservice should be done in such a way that no other team can directly
    talk to our database. They, in fact, shouldn't even know the type of our database.
    The current database landscape has various options available to us, both in the
    SQL and NoSQL category. There are even graph databases, in-memory databases, and
    databases with either high read and write capabilities.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库是一个重要且有趣的思考部分。在微服务中引入数据库应该以这样一种方式进行，即其他团队不能直接与我们的数据库交谈。事实上，他们甚至不应该知道我们的数据库类型。当前的数据库格局对我们来说有各种可用的选项，包括SQL和NoSQL类别。甚至还有图数据库、内存数据库以及具有高读写能力的数据库。
- en: Our microservices can have both stateless and stateful microservices. If a service
    relies on the state it should be separated out in a dedicated container that is
    easily accessible and not shared with anyone. Microservices have the ability to
    scale better when stateless. We scale the container rather than scaling the VM.
    Hence each state store should be in a container that can be scaled at any point
    in time. We use Docker to scale the database store, which creates a separate persistence
    layer that is host-independent. The new cloud data stores such as Redis, Cassandra,
    and DynamoDB maximize availability with a minimum delay in consistency. Designing
    a stateful microservice with asynchronous and scalable nature needs some thinking
    on the problem—to find some means of communication state between any sequential
    messages and to ensure that messages don't mix up with any context where they
    don't belong. We will see various synchronous patterns such as CQRS and Saga for
    achieving this in this chapter.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的微服务可以既有无状态的微服务，也有有状态的微服务。如果一个服务依赖于状态，它应该被分离到一个专用容器中，这个容器易于访问，不与任何人共享。无状态的微服务具有更好的扩展性。我们扩展容器而不是扩展虚拟机。因此，每个状态存储应该在一个容器中，可以随时进行扩展。我们使用Docker来扩展数据库存储，它创建一个独立的持久化层，与主机无关。新的云数据存储，如Redis、Cassandra和DynamoDB，最大程度地提高了可用性，同时最小化了一致性的延迟。设计具有异步和可扩展性特性的有状态微服务需要在问题上进行一些思考——找到一些通信状态的方法，以确保任何连续消息之间的通信状态，并确保消息不会混淆到任何不属于它们的上下文中。在本章中，我们将看到各种同步模式，如CQRS和Saga，以实现这一点。
- en: 'Maintaining state is not something that can be done on the service level only.
    Actually, there are three places wherein state can be maintained in the network:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 维护状态不仅仅是在服务层面上可以完成的事情。实际上，在网络中有三个地方可以维护状态：
- en: '**HTTP**: This is actually the application layer from where the state is maintained
    mostly session-based or persisting in the database. Generally speaking by maintaining
    a communication layer between a client and an application or a service.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HTTP**：这实际上是应用层，大部分维护状态都是基于会话或持久化在数据库中。一般来说，通过在客户端和应用程序或服务之间维护通信层来维护状态。'
- en: '**TCP**: This is actually the transportation layer. The objective of maintaining
    state here is to ensure a reliable delivery channel between the client and an
    application or a service.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TCP**：这实际上是传输层。在这里维护状态的目的是确保客户端和应用程序或服务之间有一个可靠的传递通道。'
- en: '**SSL**: This is the layer without any home between the TCP and HTTP layer.
    It provides confidentiality and privacy in data. State here is maintained, as
    encryption and decryption rely solely on information that is unique to the connection
    between client and application or a service.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SSL**：这是在TCP和HTTP层之间没有家的层。它提供数据的机密性和隐私性。在这里维护状态，因为加密和解密完全依赖于客户端和应用程序或服务之间的连接的唯一信息。'
- en: So even if our services are stateless, the TCP and SSL layer do need to maintain
    state. So you are never pure stateless. Anyway, we will just stick to the application
    layer for the scope of the book.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，即使我们的服务是无状态的，TCP和SSL层也需要维护状态。所以你永远不是纯粹的无状态。无论如何，我们将仅限于本书的范围内的应用层。
- en: Interservice communication
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务间通信
- en: 'Being finely grained and closely bound to a scope, microservices need to collaborate
    in some way or another to deliver functionality to end users. They either need
    to share state or dependencies or talk to other services. Let''s take a look at
    a practical example. Consider the frequent buyers rewards program microservice.
    This microservice is responsible for rewards for frequent buyers business capability.
    The program is simple—whenever customers purchase something, some points are accumulated
    in their account. Now, when a customer buys something, he can use those rewards
    points for a discount on the selling price. The rewards microservice depends on
    the customer purchase microservice and other business capabilities. Other business
    capabilities depend on the rewards program. As shown in the following diagram,
    microservices need to collaborate with other microservices:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务因为粒度细和与范围紧密相关，需要以某种方式相互协作，以向最终用户提供功能。它们需要共享状态或依赖关系，或者与其他服务进行通信。让我们看一个实际的例子。考虑频繁购买者奖励计划微服务。这个微服务负责频繁购买者业务能力的奖励。该计划很简单——每当客户购买东西时，他们的账户中就会积累一些积分。现在，当客户购买东西时，他可以使用这些奖励积分来获得销售价格的折扣。奖励微服务依赖于客户购买微服务和其他业务能力。其他业务能力依赖于奖励计划。如下图所示，微服务需要与其他微服务协作：
- en: '![](img/35077dd7-21de-47d6-a900-73df46b1d16f.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/35077dd7-21de-47d6-a900-73df46b1d16f.png)'
- en: Need of microservices
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务的需求
- en: As seen in the preceding diagram, microservices are finely divided into business
    capabilities. However, end user functionality needs several business capabilities
    for which microservices must need to collaborate with each other to deliver use
    cases to end users. When any microservices collaborate, the collaboration style
    follows in majorly three categories—**commands**, **queries**, and **events**.
    Let's understand all the three categories with some examples.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，微服务被细分为业务能力。然而，最终用户功能需要多个业务能力，因此微服务必须需要相互协作，以向最终用户提供用例。当任何微服务协作时，协作方式主要分为三类——**命令**、**查询**和**事件**。让我们通过一些例子来了解这三类。
- en: Commands
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 命令
- en: '**Commands** are used whenever any microservice wants another microservice
    to perform an action. They are synchronous in nature and are generally implemented
    using HTTP POST or PUT requests. For example, in the preceding figure, the rewards
    program microservice sends a command to user profile microservice or invoice microservice
    regarding promotional offers based on rewards. When sending a command fails, the
    sender won''t know if the receiver processed the command or not. This can result
    in errors or some degraded functionalities if a set of rules is not followed by
    the sender as well as receiver side.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 命令在任何微服务想要另一个微服务执行操作时使用。它们是同步的，通常使用HTTP POST或PUT请求来实现。例如，在前面的图中，奖励计划微服务向用户配置文件微服务或发票微服务发送命令，关于基于奖励的促销优惠。当发送命令失败时，发送者将不知道接收者是否处理了命令。如果发送方和接收方没有遵循一组规则，这可能导致错误或一些功能降级。
- en: Queries
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查询
- en: Similar to commands, queries are used when one microservice needs some information
    from another microservice. For example, during invoice in our shopping cart microservice,
    we need information on the total number of reward points so as to give a promotional
    discount, so the invoice microservice queries the rewards points microservice.
    This is a synchronous mode of communication and is generally implemented using
    HTTP GET requests. Whenever a query fails, the caller does not get the data it
    needs. If the caller handles exceptions well enough then there is a minimal impact
    with some degraded functionality. If it does not handle errors well enough, the
    error propagates throughout the system.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 与命令类似，查询在一个微服务需要从另一个微服务获取一些信息时使用。例如，在我们的购物车微服务中的发票过程中，我们需要有关奖励积分总数的信息，以便提供促销折扣，因此发票微服务查询奖励积分微服务。这是一种同步的通信模式，通常使用HTTP
    GET请求。每当查询失败时，调用者将无法获取所需的数据。如果调用者能够很好地处理异常，那么影响将很小，但功能可能会有所降级。如果处理错误不够好，错误将在整个系统中传播。
- en: Events
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 事件
- en: While deviating from the standard approaches, the third approach is more of
    a reactive approach. Events are generally preferred whenever a microservice needs
    to react to something that has occurred in another microservice. The custom logging
    microservice listens to all other services for log entries so that it can push
    logs to Elasticsearch. Similarly, the rewards microservices listens to shopping
    tracker microservices in order to update user rewards accordingly based on user
    shopping. When a subscriber polls any event feed and if the call fails the impact
    is very limited. The subscriber can still poll the event feed later until the
    event feed is up and start receiving events at any time. Some of the events will
    be delayed, but this should not be a problem as everything is done asynchronously.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在偏离标准方法的同时，第三种方法更多地是一种反应性方法。事件通常在一个微服务需要对另一个微服务中发生的事情做出反应时使用。自定义日志微服务监听所有其他服务的日志条目，以便它可以将日志推送到Elasticsearch。类似地，奖励微服务监听购物追踪微服务，以便根据用户购物相应地更新用户奖励。当订阅者轮询任何事件源，如果调用失败，影响非常有限。订阅者仍然可以稍后轮询事件源，直到事件源恢复，并随时开始接收事件。一些事件将被延迟，但这不应该是一个问题，因为一切都是异步完成。
- en: Exchanging data formats
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交换数据格式
- en: The essence or fundamental of interservice communication is the exchange of
    messages in any formats. Messages usually contain data and so a very important
    design aspect is the format of data. This can greatly impact the efficiency of
    communication, the usability and changes, and evolving the service in time. It
    is very necessary to select cross-message format. There are two types of message
    formats—**text** and **binary**. In this section, we will look at both.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务之间通信的本质或基本是以任何格式交换消息。消息通常包含数据，因此数据格式是非常重要的设计方面。这可以极大地影响通信的效率、可用性和变化，以及随时间演变的服务。选择跨消息格式非常必要。有两种消息格式——文本和二进制。在本节中，我们将看看两者。
- en: Text-based message formats
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于文本的消息格式
- en: Commonly used message formats such as JSON and XML are human-readable and self-describing.
    These formats enable a user to pick out the values that the consumer is interested
    in and discard the rest. Any changes to the schema format can easily be backward-compatible.
    The downsides to using text-based formats include being too verbose in nature
    and overhead of parsing the entire text. For stronger efficiency, binary formats
    are recommended to be used.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 常用的消息格式，如JSON和XML，是人类可读的并且是自描述的。这些格式使用户能够挑选出消费者感兴趣的值并丢弃其余部分。对模式格式的任何更改都可以很容易地向后兼容。使用基于文本的格式的缺点包括其本质上过于冗长以及解析整个文本的开销。为了更高效，建议使用二进制格式。
- en: Binary message formats
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二进制消息格式
- en: These formats provide a typed identity language for defining a structure for
    the messages. A compiler then generates the code that serializes and deserializes
    the messages for us (we will be seeing Apache Thrift later in the chapter). If
    the client has a statically typed language then the compiler checks if the API
    is used correctly or not. Avro, Thrift, and Google's protobuf are prominent binary
    message formats.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这些格式为消息定义了一个结构的类型标识语言。然后编译器为我们生成序列化和反序列化消息的代码（我们将在本章后面看到Apache Thrift）。如果客户端使用的是静态类型的语言，那么编译器会检查API是否被正确使用。Avro、Thrift和Google的protobuf是著名的二进制消息格式。
- en: Now that we have a clear idea about communication essentials, we can move on
    to the next section on dependencies. Let's summarize the points before moving
    on.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对通信要点有了清晰的了解，我们可以继续下一节的依赖性。在继续之前，让我们总结一下要点。
- en: 'You can opt for using commands and queries if the following use cases are met:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果满足以下用例，可以选择使用命令和查询：
- en: In order to process the service request, the service client needs a response
    to move further along its process. For example, for the payment microservice,
    we need customer information.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了处理服务请求，服务客户端需要响应以进一步推进其流程。例如，对于支付微服务，我们需要客户信息。
- en: The situation demands asynchronous operation. For example, inventory should
    only be deducted if payment has been made and product processed for customer delivery.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 情况需要异步操作。例如，只有在付款已经完成并且产品已经处理好准备交付给客户时，才应扣减库存。
- en: Request to other services is a simple query or command, that is, something that
    can be processed via HTTP `GET`, `PUT`, `POST`, and `DELETE` methods.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对其他服务的请求是一个简单的查询或命令，即可以通过HTTP `GET`、`PUT`、`POST`和`DELETE`方法处理的内容。
- en: 'You can opt for using events if the following use cases are met:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果满足以下用例，可以选择使用事件：
- en: When you need to scale the application as pure commands and queries do not scale
    over a larger problem set.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当您需要扩展应用程序时，纯命令和查询无法扩展到更大的问题集。
- en: Producer or sender does not care how much extra processing is done on the receiver
    or consumer's end and it has no such effect on the producers end.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产者或发送方不关心接收方或消费者端进行了多少额外的处理，这对生产者端没有影响。
- en: When multiple clients read a single message. For example, an order has been
    invoiced, then multiple processes need to be done such as getting it ready to
    be dispatched, updating inventory, sending client notifications, and so on.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当多个客户端读取单个消息时。例如，订单已开具发票，然后需要执行多个流程，如准备发货、更新库存、发送客户通知等。
- en: Dependencies
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 依赖关系
- en: Now that we are aware of communication styles in microservices, we will learn
    about the next obvious thing in development—dependencies and avoiding dependency
    hell. With developing more and more microservices, you will spot code duplication
    across multiple microservices. To resolve these, we need to understand dependencies
    and how to separate supporting code. Node.js has the package manager NPM that
    grabs application dependencies (as well as dependencies of your dependencies).
    NPM has support for private repositories, directly downloaded from GitHub, setting
    up your own repository (such as JFrog, Artifactory), which not only helps to avoid
    code but also in deployment processes.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经意识到微服务中的通信风格，我们将学习开发中的下一个显而易见的事情——依赖关系和避免依赖地狱。随着越来越多的微服务的开发，你会发现多个微服务之间存在代码重复。为了解决这些问题，我们需要理解依赖关系以及如何分离支持代码。Node.js拥有包管理器NPM，可以获取应用程序的依赖项（以及依赖项的依赖项）。NPM支持私有存储库，可以直接从GitHub下载，设置自己的存储库（如JFrog、Artifactory），这不仅有助于避免代码重复，还有助于部署过程。
- en: 'However, we must not forget **Microservices 101**. We make microservices to
    ensure that each service can release and deploy independently, for which we must
    avoid dependency hell. To understand dependency hell, let''s consider the following
    example, shopping cart microservice has API listing products that have now upgraded
    to API listing products with specific brands. Now all dependencies on the shopping
    cart microservice may send a message to listing products with specific brands,
    which are originally meant for listing products. If backward-compatibility is
    not handled, then this evolves into dependency hell. To avoid dependency hell,
    strategies that can be used are—APIs must be forward and backward-compatible,
    they must have accurate documentation, contract testing must be done (we will
    see this in [Chapter 8](a7273aa2-2981-4013-8d5f-dbee87462d35.xhtml), *Testing,
    Debugging, and Documenting*, under *PACT*), and using an appropriate tooling library
    that has a clear objective to throw out errors if there is an unknown field encountered.
    To make sure that we want to avoid dependency hell we must simply follow these
    rules:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们不应忘记**微服务101**。我们创建微服务是为了确保每个服务都可以独立发布和部署，因此我们必须避免依赖地狱。要理解依赖地狱，让我们考虑以下示例，购物车微服务具有列出产品的API，现在已升级为具有特定品牌产品列表的API。现在购物车微服务的所有依赖关系可能会发送消息到最初用于列出产品的特定品牌产品列表。如果不处理向后兼容性，那么这将演变成依赖地狱。为了避免依赖地狱，可以使用的策略包括——API必须是前向和后向兼容的，它们必须有准确的文档，必须进行合同测试（我们将在[第8章](a7273aa2-2981-4013-8d5f-dbee87462d35.xhtml)中看到，*测试、调试和文档*，在*PACT*下），并使用一个具有明确目标的适当工具库，如果遇到未知字段，则会抛出错误。为了确保我们要避免依赖地狱，我们必须简单地遵循这些规则：
- en: A microservice cannot call another microservice nor access its data source directly
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务不能调用另一个微服务，也不能直接访问其数据源
- en: A microservice can only call another microservice only through either event-based
    mechanism or some microservice script (a script can be anything such as API Gateway,
    UI, service registry, and so on)
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务只能通过基于事件的机制或某些微服务脚本（脚本可以是任何东西，如API网关、UI、服务注册表等）调用另一个微服务
- en: In the next section, we will look at microservice communication styles and see
    how they collaborate with each other. We will look at the widely used patterns
    based on different classification factors and understand the scenarios for using
    which pattern at what moment.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将研究微服务通信风格，看看它们如何相互协作。我们将研究基于不同分类因素的广泛使用的模式，并了解在什么时候使用哪种模式的场景。
- en: Communication styles
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通信风格
- en: A microservice ecosystem is essentially a distributed system that is running
    on multiple machines. Each service instance is just another process. We saw in
    the earlier diagram different process communications. In this section, we will
    learn about communication styles in much more detail.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务生态系统本质上是在多台机器上运行的分布式系统。每个服务实例只是另一个进程。我们在之前的图表中看到了不同的进程通信。在本节中，我们将更详细地了解通信风格。
- en: A service consumer and service responder may communicate through many different
    types of communication styles, each one targeting some scenario and outcome in
    mind. The communication types can be categorized into two different aspects.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 服务消费者和服务响应者可以通过许多不同类型的通信风格进行通信，每种通信风格都针对某些场景和预期结果。通信类型可以分为两个不同的方面。
- en: 'The first aspect deals with the type of protocol, whether it is synchronous
    or asynchronous:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个方面涉及协议类型，即同步或异步：
- en: Communication invoked via commands and queries such as HTTP are synchronous
    in nature. The client sends a request to wait for a response from the service.
    This waiting is language-dependent, that is, it can be synchronous (languages
    such as Java) and it can be asynchronous (response can be processed via callbacks,
    promises, and so on, in our case, Node.js). The important point is that a service
    request can only be served once the client receives a proper HTTP server response.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过命令和查询（如HTTP）调用的通信是同步的。客户端发送请求等待服务端响应。这种等待是与语言相关的，即可以是同步的（例如Java等语言），也可以是异步的（响应可以通过回调、承诺等方式处理，在我们的例子中是Node.js）。重要的是，只有客户端收到正确的HTTP服务器响应后，服务请求才能得到服务。
- en: Other protocols such as AMQP, sockets, and so on are asynchronous in nature
    (the log and shopping tracker microservice). The client code or message sender
    does not wait for a response, it simply sends the message to any queue or message
    broker and simply.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他协议，如AMQP、sockets等，都是异步的（日志和购物跟踪微服务）。客户端代码或消息发送者不会等待响应，只需将消息发送到任何队列或消息代理即可。
- en: 'The second aspect deals with the number of receivers, whether there is just
    a single receiver or there are multiple receivers:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个方面涉及接收者的数量，无论是只有一个接收者还是有多个接收者：
- en: For a single receiver, each request has to be processed by only one receiver
    or service. Command and query pattern are examples of this kind of communication.
    One-to-one interaction includes models such as request/response, one-way requests
    such as notifications, and request/async responses.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于单个接收者，每个请求只能由一个接收者或服务处理。命令和查询模式就是这种通信的例子。一对一的交互包括请求/响应模型，单向请求（如通知）以及请求/异步响应。
- en: For multiple receivers, each request can be processed by zero or multiple services
    or receivers. This is an asynchronous mode of communication with an example of
    the publisher-subscriber mechanism promoting event-driven architecture. Data updates
    between multiple microservices are propagated through events that are implemented
    through some service bus (Azure service bus) or any message brokers (AMQP, Kafka,
    RabbitMQ, and so on).
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于多个接收者，每个请求可以由零个或多个服务或接收者处理。这是一种异步的通信模式，以发布-订阅机制为例，促进事件驱动架构。多个微服务之间的数据更新通过通过某些服务总线（Azure服务总线）或任何消息代理（AMQP、Kafka、RabbitMQ等）实现的事件进行传播。
- en: NextGen communication styles
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下一代通信风格
- en: While we saw some common communication styles, the world is constantly changing.
    With evolution everywhere, even the fundamental HTTP protocol has evolved and
    we now have the HTTP 2.X protocol with some added advantages. In this section,
    we are going to look at next-gen communication styles and see the advantages they
    have to offer.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们看到了一些常见的通信风格，但世界在不断变化。随着各处的进化，甚至基本的HTTP协议也发生了变化，现在我们有了HTTP 2.X协议，带来了一些额外的优势。在本节中，我们将看看下一代通信风格，并了解它们所提供的优势。
- en: HTTP/2
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HTTP/2
- en: 'HTTP/2 gives significant enhancements and focuses more on improving the usage
    of TCP connections. The following are some major enhancements as compared to HTTP/1.1:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP/2提供了显著的增强，并更加关注改进TCP连接的使用。与HTTP/1.1相比，以下是一些主要的增强：
- en: '**Compression and binary framing**: HTTP/2 has header compression inbuilt in
    order to reduce the footprint of HTTP headers that can grow in kilobytes (say,
    for example, cookies). It also controls headers that are repeated across multiple
    requests and responses. Also, the client and the server maintain a list of frequently
    visible fields along with their compressed values, so when these fields are repeated,
    the individual simply includes the reference to the compressed value. Besides
    this, HTTP/2 uses binary encoding for frames.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**压缩和二进制帧**：HTTP/2内置了头部压缩，以减少HTTP头部的占用空间（例如，cookies可能增长到几千字节）。它还控制了在多个请求和响应中重复的头部。此外，客户端和服务器维护一个频繁可见字段的列表，以及它们的压缩值，因此当这些字段重复时，个体只需包含对压缩值的引用。除此之外，HTTP/2使用二进制编码进行帧。'
- en: '**Multiplexing**: As compared to a single request and response flow (client
    has to wait for a response before issuing next request), HTTP/2 introduces fully
    asynchronous multiplexing of a request by implementing streams (behold reactive
    programming!). Clients and servers can both start multiple requests on a single
    TCP connection. For example, when a client requests a web page, the server can
    start a separate stream to transfer images and videos that are needed for that
    web page.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多路复用**：与单一请求和响应流（客户端必须在发出下一个请求之前等待响应）相比，HTTP/2通过实现流（哇，响应式编程！）引入了完全异步的请求多路复用。客户端和服务器都可以在单个TCP连接上启动多个请求。例如，当客户端请求网页时，服务器可以启动一个单独的流来传输该网页所需的图像和视频。'
- en: '**Flow Control**: With multiplexing introduced, there is a need for a flow
    control in place to avoid destructive behavior across any of the streams. HTTP/2
    provides building blocks for client and server to have proper flow controls suitable
    for any specific situations. Flow control can allow the browser to get only a
    part of the particular resource, put that operation on hold by reducing window
    down to zero, and resuming at any point in time. Also, priorities can be set.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流量控制**：随着多路复用的引入，需要有流量控制来避免在任何流中出现破坏性行为。HTTP/2为客户端和服务器提供了适用于任何特定情况的适当流量控制的构建模块。流量控制可以让浏览器只获取特定资源的一部分，通过将窗口减小到零来暂停该操作，并在任何时间点恢复。此外，还可以设置优先级。'
- en: 'In this section, we are going to look at how to implement HTTP/2 in our microservice
    system. You can check `example http2` under `chapter 7`, source code to follow
    the implementation:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看看如何在我们的微服务系统中实现HTTP/2。您可以查看`第7章`下的`示例http2`，并跟随实现的源代码。
- en: 'HTTP/2 is supported on Node.js 10.XX, but there are other ways to achieve support
    without upgrading to the latest version, which was introduced just two weeks ago
    (Node.js 10.XX was introduced just two weeks ago at the time of writing). We will
    use node module `spdy`, which provides HTTP/2 support to our `Express` application.
    Copy our `first-microservice` skeleton from [Chapter 2](c1987454-3c62-4e25-abf5-28a9abf833e8.xhtml),
    *Gearing up for the Journey*, and install `spdy` as a node module by using the
    following command:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Node.js 10.XX支持HTTP/2，但也有其他方法可以实现支持，而无需升级到最新版本，该版本是在写作时刚刚推出的（Node.js 10.XX在写作时刚刚推出了两周）。我们将使用`spdy`节点模块，为我们的`Express`应用程序提供HTTP/2支持。从[第2章](c1987454-3c62-4e25-abf5-28a9abf833e8.xhtml)中复制我们的`first-microservice`骨架，*为旅程做准备*，并使用以下命令将`spdy`安装为节点模块：
- en: '[PRE0]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For HTTP/2 to work, the SSL/TLS has to be enabled. For our development environment
    to work properly we will self-generate the CSR and certificates that can easily
    be replaced by procuring certificates in production environments. To generate
    the certificates, follow along with these commands:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使HTTP/2正常工作，必须启用SSL/TLS。为了使我们的开发环境正常工作，我们将自动生成CSR和证书，这些证书可以在生产环境中轻松替换。要生成证书，请按照以下命令进行操作：
- en: '[PRE1]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The outcome of all these steps will result in three files: `server.crt`, `server.csr`,
    and `server.key`.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些步骤的结果将产生三个文件：`server.crt`、`server.csr`和`server.key`。
- en: 'Next, we need to change the way we start our express server. Instead of using
    default methods, we need to use one provided by `spdy`. Make the following changes
    in `Application.ts`. Replace  `this.express.app.listen` with the following code:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要更改启动express服务器的方式。我们需要使用`spdy`提供的方法，而不是使用默认方法。在`Application.ts`中进行以下更改。用以下代码替换`this.express.app.listen`：
- en: '[PRE2]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We are ready to start dishing out HTTP/2 requests. Start the server and open
    up `https://localhost:3000/hello-world`. Open up the Developer console and you
    should be able to see HTTP/2 just like in the following screenshot:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已经准备好开始处理HTTP/2请求了。启动服务器并打开`https://localhost:3000/hello-world`。打开开发者控制台，您应该能够看到HTTP/2，就像以下截图中一样：
- en: '![](img/cf4057f7-f62e-4842-ab95-c2ed89c68b71.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cf4057f7-f62e-4842-ab95-c2ed89c68b71.png)'
- en: HTTP support
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP支持
- en: These are HTTP calls. In the next section, we will look at the RPC mechanism,
    which is another way to do collaboration among microservices.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是HTTP调用。在下一节中，我们将看一下RPC机制，这是微服务之间协作的另一种方式。
- en: gRPC with Apache Thrift
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Apache Thrift的gRPC
- en: '**gRPC** is a framework designed for writing cross-language RPC (remote procedure
    calls) clients and servers. It works on binary formats and focuses on an API First
    approach for designing any services. It provides fixed IDL (interactive data language
    fixed formats) to later generate client-side stubs and server-side skeletons adhering
    to that fixed IDL format. The compiler can generate code for most of the languages
    and they exchange data using HTTP/2, which is beneficial in the long run. Apache
    Thrift is a great alternative for writing cross-language RPC clients and servers.
    It has a C-style IDL Definition language. The compiler generates code for a variety
    of languages, which includes C++, Java, and even TypeScript. A Thrift definition
    is very analogous to the TypeScript interface. Thrift methods can give out any
    value or they can be just one-way communication. Methods that have a return type
    implement the request/response model, whereas methods that do not have a return
    type are defined to implement the notification model. Thrift has support for JSON
    as well as binary. Let''s get started with an example. You can follow along with
    the `thrift-rpc` folder in [Chapter 7](162a0f25-2890-4a58-aa41-e9c9b5fc6c2d.xhtml), *Service
    State and Interservice Communication*, in the extracted source code.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**gRPC**是一个专为编写跨语言RPC（远程过程调用）客户端和服务器而设计的框架。它使用二进制格式，并专注于以API优先的方式设计任何服务。它提供固定的IDL（交互式数据语言固定格式），以后可以生成符合该固定IDL格式的客户端存根和服务器端骨架。编译器可以为大多数语言生成代码，并且它们使用HTTP/2进行数据交换，这在长期内是有益的。Apache
    Thrift是编写跨语言RPC客户端和服务器的一个很好的替代方案。它具有C风格的IDL定义语言。编译器可以为各种语言生成代码，包括C++、Java，甚至TypeScript。Thrift定义与TypeScript接口非常类似。Thrift方法可以输出任何值，或者它们可以只是单向通信。具有返回类型的方法实现请求/响应模型，而没有返回类型的方法被定义为实现通知模型。Thrift还支持JSON和二进制。让我们从一个示例开始。您可以在提取的源代码中的[第7章](162a0f25-2890-4a58-aa41-e9c9b5fc6c2d.xhtml)中的`thrift-rpc`文件夹中跟随。'
- en: 'The overall process that we are going to do is as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要做的整个过程如下：
- en: Write ourselves a `.thrift` file that will describe our product microservice
    and popularity microservice
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写一个`.thrift`文件，描述我们的产品微服务和受欢迎度微服务
- en: Generate source code for TypeScript, the language in which we are going to write
    our service communication
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为我们将要编写的服务通信生成TypeScript的源代码
- en: Import the generated code and start writing our service
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导入生成的代码并开始编写我们的服务
- en: Include the generated source of popularity in product and write our service
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将受欢迎度的生成源包含在产品中并编写我们的服务
- en: Create API Gateway as a single entry point
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建API网关作为单一入口点
- en: Though Thrift provides Node.js and TypeScript libraries, we are going to use
    `npm` modules of **CreditKarma** ([https://github.com/creditkarma](https://github.com/creditkarma)),
    as original modules lack in generating strict types. So let's get started.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Thrift提供了Node.js和TypeScript库，但我们将使用**CreditKarma**（[https://github.com/creditkarma](https://github.com/creditkarma)）的`npm`模块，因为原始模块在生成严格类型方面存在不足。所以让我们开始吧。
- en: 'Now, let''s perform the following steps:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们执行以下步骤：
- en: 'Initialize a Node.js project. Instead of downloading Thrift, I am going to
    use `npm` modules. Hence, install the following modules as dependencies:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一个Node.js项目。我将使用`npm`模块而不是下载Thrift。因此，将以下模块安装为依赖项：
- en: '[PRE3]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Create one folder called `thrift` and inside it create two Thrift files—`PopularityService.thrift`
    (`thrift/popularity/PopularityService.thrift`) and `ProductService.thrift` (`thrift/product/ProductService.thrift`).
    A Thrift file is like a TypeScript interface:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`thrift`的文件夹，在其中创建两个Thrift文件——`PopularityService.thrift`（`thrift/popularity/PopularityService.thrift`）和`ProductService.thrift`（`thrift/product/ProductService.thrift`）。Thrift文件就像TypeScript接口：
- en: '[PRE4]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Since we need popularity inside the product, we will import that in `ProductService.thrift`,
    and you can check other default syntax here [https://thrift.apache.org/docs/idl](https://thrift.apache.org/docs/idl).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们需要在产品中使用流行度，我们将在`ProductService.thrift`中导入它，您可以在此处检查其他默认语法[https://thrift.apache.org/docs/idl](https://thrift.apache.org/docs/idl)。
- en: 'Now we will generate our code using IDL files defined in the preceding step.
    Open up `package.json` and add the following scripts inside the `scripts` tag:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将使用在前一步中定义的IDL文件生成我们的代码。打开`package.json`并在`scripts`标签内添加以下脚本：
- en: '[PRE5]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This script will generate the code for us, as we simply will have to type `npm
    run codegen`.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这个脚本将为我们生成代码，我们只需要输入`npm run codegen`。
- en: The next part involves writing `findByProductId` and `findPopularityOfProduct`
    methods. Check out `src/popularity/data.ts` and `src/product/data.ts` for dummy
    data and dummy find methods in the extracted source code.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一部分涉及编写`findByProductId`和`findPopularityOfProduct`方法。在提取的源代码中查看`src/popularity/data.ts`和`src/product/data.ts`以获取虚拟数据和虚拟查找方法。
- en: 'We will now write code for starting `PopluarityThriftService` and `ProductThriftService`.
    Create one `serviceHandler` inside `src/popularity/server.ts` as follows:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将编写代码来启动`PopluarityThriftService`和`ProductThriftService`。在`src/popularity/server.ts`内创建一个`serviceHandler`如下：
- en: '[PRE6]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Start this `server.ts` as `express` by adding `ThriftServerExpress` as middleware:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将`ThriftServerExpress`添加为中间件，将此`server.ts`作为`express`启动：
- en: '[PRE7]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, inside `src/product/server.ts`, add the following code that will make
    an RPC call to the `PopularityService` to get popularity by `productId`:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在`src/product/server.ts`内，添加以下代码，将对`PopularityService`进行RPC调用以获取`productId`的流行度：
- en: '[PRE8]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Similarly, `create gateway/server.ts`. Define a route for `/product/: productId`
    and it will make an RPC call to `ProductMicroservice` to fetch the data of `productId`
    passed.'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '同样，`create gateway/server.ts`。为`/product/: productId`定义一个路由，并将其作为RPC调用`ProductMicroservice`来获取传递的`productId`的数据。'
- en: Run the program and make a request to `localhost:9000/product/1` and you will
    be able to see combined communicated response via RPC calls.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行程序并向`localhost:9000/product/1`发出请求，您将能够通过RPC调用看到组合通信响应。
- en: In this section, we had hands-on experience with some microservice communication
    styles along with some practicals. In the next section, we are going to see how
    to version microservices and make our microservices have a fail-safe mechanism.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们亲身体验了一些微服务通信风格以及一些实践。在下一节中，我们将看到如何对微服务进行版本控制，并使我们的微服务具有故障安全机制。
- en: Versioning microservices and failure handling
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微服务版本控制和故障处理
- en: Evolution is necessary and we can't prevent it. Whenever we allow one of the
    services to evolve, one of the most considerable aspects of maintaining is service
    versioning. In this section, we are going to see various aspects related to handling
    changes in the system and overcoming failures if any are introduced in the system.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 进化是必要的，我们无法阻止它。每当我们允许其中一个服务进化时，服务版本控制就是维护的一个最重要的方面。在本节中，我们将看到与系统变化处理和克服系统中引入的任何故障相关的各种方面。
- en: Versioning 101
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 版本控制 101
- en: Service versioning should be thought of firstly and not be taken up as an after-development
    exercise. An API is a published contract between a server and consumer. Maintaining
    versions helps us to release new services without breaking anything for existing
    customers (not everyone accepts change in the first attempt). Both the old version
    and the new version should coexist side by side.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 首先应该考虑服务版本控制，而不是将其作为开发后的练习。API是服务器和消费者之间的公开合同。维护版本帮助我们发布新服务而不会破坏现有客户的任何内容（并非每个人都在第一次尝试中接受变化）。新版本和旧版本应该并存。
- en: 'Prevalent styles of versioning are using the semantic versions. Any semantic
    version will have three major components—**major** (whenever there is a groundbreaking
    change), **minor** (whenever there is a backward-compatible behavior), and **patch**
    (backward-compatible with any bug fix). Versioning is extremely problematic whenever
    there is more than a single service inside a microservice. A recommended way is
    to version any services at the service level rather than doing it at the operations
    level. If there is a single change in any of the operations the service is upgraded
    and deployed to **Version2** (**V2**), which is applicable to all operations in
    the service. There are three ways in which we can version any service:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 流行的版本控制风格是使用语义版本。任何语义版本都有三个主要组成部分——**major**（每当有重大变化时），**minor**（每当有向后兼容的行为时），和**patch**（向后兼容的任何错误修复）。当微服务中有多个服务时，版本控制是极其棘手的。推荐的方法是在服务级别而不是在操作级别对任何服务进行版本控制。如果在任何操作中有单个更改，服务将升级并部署到**Version2**（**V2**），这适用于服务中的所有操作。我们可以以三种方式对任何服务进行版本控制：
- en: '**URI versioning**: The version number of the service is included in the URL
    itself. We just need to worry about major versions of this approach, as that would
    change the URL route. If there is a minor version or any patch available the consumer
    does not need to worry about the change. Keeping an alias for the latest version
    to non-versioned URI is one of the good practices that needs to be followed. For
    example, the URL `/api/v5/product/1234` should be aliased to `/api/product/1234`—aliased
    to `v5`. Moreover, passing version number can also be done as follows:'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**URI版本控制**：服务的版本号包含在URL本身中。我们只需要担心这种方法的主要版本，因为那会改变URL路由。如果有次要版本或任何可用的补丁，消费者无需担心变化。保持最新版本的别名为非版本化的URI是需要遵循的良好实践之一。例如，URL
    `/api/v5/product/1234`应该被别名为`/api/product/1234`—别名为`v5`。此外，传递版本号也可以这样做：'
- en: '[PRE9]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**Media type versioning**: The media type versioning follows a slightly different
    approach. Here the version is set by the client on the HTTP Accept header. Its
    structure is something similar to, `Accept: application/vnd.api+json`. The Accept
    header gives us a way to specify generic and less generic content types as well
    as giving fallbacks. A command such as `Accept: application/vnd.api.v5+json` specifically
    asks for `v5` of the API. If the Accept header is omitted, the consumer interacts
    with the latest version, which may not be production-grade. GitHub uses such kinds
    of versioning.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**媒体类型版本控制**：媒体类型版本控制采用略有不同的方法。这里，版本由客户端在HTTP Accept标头上设置。其结构与`Accept: application/vnd.api+json`类似。Accept标头为我们提供了一种指定通用和不太通用的内容类型以及提供回退的方法。例如，`Accept:
    application/vnd.api.v5+json`命令明确要求API的`v5`版本。如果省略了Accept标头，消费者将与最新版本交互，这可能不是生产级别的。GitHub使用这种版本控制。'
- en: '**Custom header**: The last approach is to maintain our own custom header.
    Consumers would still use an Accept header and add a new one on top of that. It
    would be something like this: `X-my-api-version:1`.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自定义标头**：最后一种方法是维护我们自己的自定义标头。消费者仍然会使用Accept标头，并在其上添加一个新的标头。它可能是这样的：`X-my-api-version:1`。'
- en: When comparing the preceding three approaches, it is simple for clients to consume
    services in a URI approach, but also managing nested URI resources can be complex
    in a URI approach. Migrating clients is complex when it comes to a URI-based approach
    as compared to media type versioning, as we need to maintain caching of multiple
    versions. However, most of the big players, such as Google, Salesforce, and so
    on, go with the URI approach.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 当比较前面三种方法时，客户端在URI方法中消费服务很简单，但在URI方法中管理嵌套的URI资源可能会很复杂。与媒体类型版本控制相比，基于URI的方法在迁移客户端时更复杂，因为我们需要维护多个版本的缓存。然而，大多数大公司，如谷歌、Salesforce等，都采用URI方法。
- en: When a developer's nightmare comes true
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当开发人员的噩梦成真
- en: 'All systems will experience failures. Microservices being distributed, the
    probability increases very high. How we handle failures and respond to failures
    is what defines a developer. While making the overall product ecosystem resilient
    is spectacular (activities involve clustering servers, setting up application
    load balancers, distributing infrastructure between multiple locations, and setting
    up disaster recovery), our work does not stop there. This part only addresses
    the complete loss of a system. However, whenever a service is running slow or
    there is memory leak, it is extremely difficult to detect the problem for the
    following reasons:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 所有系统都会经历故障。微服务是分布式的，故障的概率非常高。我们如何处理故障和应对故障是定义开发人员的关键。虽然使整体产品生态系统具有弹性是令人惊叹的（活动包括集群服务器、设置应用程序负载均衡器、在多个位置之间分配基础设施以及设置灾难恢复），但我们的工作并不止于此。这部分只涉及系统的完全丢失。然而，每当服务运行缓慢或存在内存泄漏时，由于以下原因，极其难以检测问题：
- en: A service degradation starts slow, but rapidly gains momentum and spreads just
    like an infection. The application container exhausts its thread pool resources
    completely and the system goes down.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务降级开始缓慢，但迅速获得动力并像感染一样传播。应用程序容器完全耗尽其线程池资源，系统崩溃。
- en: Too many synchronous calls where a caller has to wait endlessly for the service
    to return a response.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 太多的同步调用，调用者必须无休止地等待服务返回响应。
- en: Applications don't deal with partial degradations. As long as any service is
    completely down, the application continues to make calls to that service that
    soon exists in resource exhaustion.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序无法处理部分降级。只要任何服务完全停机，应用程序就会继续调用该服务，很快就会出现资源耗尽。
- en: The worst thing about such situations is that such failures cascade up and adversely
    affect the system just like a contagion. A single poorly performing system can
    soon take out multiple dependent systems. It becomes necessary to protect a service's
    resources from getting exhausted because of some other poorly performing service.
    In the next section, we will look at some of these patterns to avoid failure cascading
    in the system and causing the ripple effect.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况最糟糕的是，这种故障会像传染病一样级联并对系统产生不利影响。一个性能不佳的系统很快就会影响多个依赖系统。有必要保护服务的资源，以免因其他性能不佳的服务而耗尽。在下一节中，我们将看一些模式，以避免系统中的故障级联并引起连锁效应。
- en: Client resiliency patterns
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 客户端弹性模式
- en: 'Client resiliency patterns allow the client to fail fast and not block database
    connections or thread pools. These patterns are implemented in the client layer,
    which calls any remote resource. There are the following four common client resiliency
    patterns:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端弹性模式允许客户端快速失败，不会阻塞数据库连接或线程池。这些模式在调用任何远程资源的客户端层中实现。有以下四种常见的客户端弹性模式：
- en: Bulkhead and retry
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 舱壁和重试
- en: Client-side load balancing or queue-based load leveling
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户端负载均衡或基于队列的负载平衡
- en: Circuit breaker
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 断路器
- en: Fallback and compensating transaction
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回退和补偿交易
- en: 'The four patterns can be seen in the diagram as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这四种模式可以在下图中看到：
- en: '![](img/236387ce-c92c-4ff1-a1e8-04fadc93b610.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/236387ce-c92c-4ff1-a1e8-04fadc93b610.png)
- en: Client resiliency patterns
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端弹性模式
- en: Bulkhead and retry pattern
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 舱壁和重试模式
- en: The bulkhead pattern is similar to the pattern of building a ship, where a ship
    is divided into completely isolated and watertight compartments called bulkheads.
    Even if the ship's hull is punctured, the ship is not affected as it is divided
    into watertight compartments. The bulkheads keep the water confined to the specific
    region of the ship where the puncture occurred and prevent the ship from sinking.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 舱壁模式类似于建造船舶的模式，其中船被分成完全隔离和防水的舱壁。即使船体被刺穿，船也不会受到影响，因为它被分成防水的舱壁。舱壁将水限制在发生刺穿的船体特定区域，并防止船沉没。
- en: A similar concept is applied in the bulkhead pattern for a service interacting
    with many remote resources. By using this pattern we break the calls to remote
    resources into their own bulkheads (their own thread pools) and reduce the risk
    and prevent the application from going down because of a slow remote resource.
    If one service is slow, then the thread pool for that type of service will become
    saturated to stop processing further requests. Service calls to another service
    won't be hampered as each one has its own thread pool. The retry pattern helps
    an application to handle any anticipated, temporary failure whenever it tries
    to connect to a service or any network resource by transparently retrying an operation
    that has previously failed due to some criteria. Instead of waiting, it rather
    does a fixed number of retries.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 类似的概念也适用于与许多远程资源交互的隔离模式。通过使用这种模式，我们将对远程资源的调用分解为它们自己的隔离区（自己的线程池），减少风险并防止应用因远程资源缓慢而崩溃。如果一个服务缓慢，那么该类型服务的线程池将变得饱和，以阻止进一步处理请求。对另一个服务的调用不会受到影响，因为每个服务都有自己的线程池。重试模式帮助应用程序处理任何预期的临时故障，每当它尝试连接到服务或任何网络资源时，通过透明地重试先前由于某些条件而失败的操作。它不是等待，而是进行固定次数的重试。
- en: Client-side load balancing or queue-based load leveling pattern
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 客户端负载均衡或基于队列的负载均衡模式
- en: We saw client-side load balancing in [Chapter 6](0c5e001e-6dca-4805-866c-7be793a91c70.xhtml), *Service
    Registry and Discovery*. It involves having the client look up all of a service's
    individual instances from any service discovery agent (Eureka/Consul) and then
    caching the location of available service instances. Whenever any further request
    comes, the client-side load balancer will return a location from the pool of service
    locations it is maintained at the client-side. Locations are periodically refreshed
    based on some interval. If the client-side load balancer detects a problem in
    any service location, it removes it from the pool and prevents any further requests
    from hitting that service. For example, Netflix Ribbon. Another resiliency approach
    includes adding a queue that acts as a buffer between any task and/or service
    that it invokes so as to smoothly handle any intermittent loads and prevent loss
    of data.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第6章](0c5e001e-6dca-4805-866c-7be793a91c70.xhtml)中看到了客户端负载均衡，*服务注册和发现*。它涉及客户端从任何服务发现代理（Eureka/Consul）查找所有服务的各个实例，然后缓存可用服务实例的位置。每当有进一步的请求时，客户端负载均衡器将从维护在客户端的服务位置池中返回一个位置。位置会根据一定的间隔定期刷新。如果客户端负载均衡器检测到任何服务位置存在问题，它将从池中移除它，并阻止任何进一步的请求命中该服务。例如，Netflix
    Ribbon。另一种弹性方法包括添加一个队列，作为任何任务和/或服务调用之间的缓冲，以便平稳处理任何间歇性负载，并防止数据丢失。
- en: Circuit breaker pattern
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 断路器模式
- en: We already saw this pattern in [Chapter 1](2eeeb09d-ecd0-403b-8a64-ac754090cebe.xhtml), *Debunking
    Microservices*. Let's quickly recall that. Whenever we have a circuit breaker
    installed and a remote service is being called, the circuit breaker monitors the
    call. If calls are taking too long, the circuit breaker will kill the call and
    make the circuit open, making it impossible to allow any further calls. This is
    the concept of fail fast, recover fast.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在[第1章](2eeeb09d-ecd0-403b-8a64-ac754090cebe.xhtml)中看到了这种模式，*揭秘微服务*。让我们快速回顾一下。每当我们安装了断路器并调用远程服务时，断路器会监视调用。如果调用时间过长，断路器将终止调用并打开断路，使进一步的调用变得不可能。这就是快速失败，快速恢复的概念。
- en: The fallback and compensating transaction pattern
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 备用和补偿事务模式
- en: 'In this pattern, whenever a remote service call fails, rather than generating
    an exception, the consumer will try to carry out an alternative way to do that
    action. Ways to achieve this usually include looking for data from an alternate
    data source (let''s say cache) or queuing user''s input for future processing.
    Users will be notified that their requests will be addressed later on and if all
    routes fail the system tries to compensate whatever actions that have been processed.
    Some common approaches to fallback that we use are (as highlighted by Netflix):'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种模式中，每当远程服务调用失败时，消费者会尝试以替代方式执行该操作，而不是生成异常。通常实现这一点的方法包括从备用数据源（比如缓存）获取数据，或将用户的输入排队以供将来处理。用户将被通知他们的请求将在以后处理，如果所有路由失败，系统会尝试补偿已经处理的任何操作。我们使用的一些常见的备用方法（由Netflix强调）包括：
- en: '**Cache**: Get data from local or remote cache if the real-time dependency
    is missing, periodically refresh cache data to avoid stale data'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缓存**：如果实时依赖项丢失，则从本地或远程缓存获取数据，定期刷新缓存数据以避免旧数据'
- en: '**Eventual Consistency**: Persist data in queues to be processed further when
    service is available'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最终一致性**：在服务可用时将数据持久化到队列中以进一步处理'
- en: '**Stubbed Data**: Keep default values and use those when personalized or service
    responses are not available'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存根数据**：保留默认值，并在个性化或服务响应不可用时使用'
- en: '**Empty Response**: Return null or empty list'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**空响应**：返回空值或空列表'
- en: Now, let's look at some practical case studies to handle failures and prevent
    them from cascading or causing a ripple effect.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看一些实际案例研究，以处理故障并防止它们级联或造成连锁反应。
- en: Case Study – The NetFlix Stack
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 案例研究 - NetFlix技术栈
- en: 'In this case study we are going to embrace the Netflix stack and adopt it in
    our microservices. Since the beginning in time we heard : polyglot development
    environment. We are going to do the same here. In this section we will set up
    API Gateway using ZUUL, add auto discovery using Java and Typescript. The user
    will not know which request actually hit, as he is only going to access the Gateway.
    The first part of the case study deals with Introducing Zuul, Eureka and registering
    some services in it and how communication occurs via central Gateway. The next
    part will deal with more significant things such as how to deal with load balancing,
    security, etc. So let''s get started. You can follow along with the example in
    `Chapter 7/netflix` cloud folder. We don''t reinvent the wheel until and unless
    it is very much necessary. Lets leverage things the most we can. The following
    case study supports and encourages polyglot architecture. So let''s get moving.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例研究中，我们将拥抱Netflix堆栈并将其应用于我们的微服务。自时间开始以来，我们听说过：多语言开发环境。我们将在这里做同样的事情。在本节中，我们将使用ZUUL设置API网关，使用Java和Typescript添加自动发现。用户将不知道实际请求命中了哪里，因为他只会访问网关。案例研究的第一部分涉及介绍Zuul、Eureka并在其中注册一些服务，以及通过中央网关进行通信。下一部分将涉及更重要的事情，比如如何处理负载平衡、安全等。所以让我们开始吧。您可以在`Chapter
    7/netflix`云文件夹中跟随示例。除非非常必要，否则我们不会重新发明轮子。让我们尽可能地利用这些资源。以下案例研究支持并鼓励多语言架构。所以让我们开始吧。
- en: Part A – Zuul and Polyglot Environment
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一部分 - Zuul和多语言环境
- en: 'Let''s have a look at the following steps:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下步骤：
- en: First off we need is a gateway ([Chapter 5](720d1d4e-1795-457c-903e-65c5a5fb5433.xhtml),
    *Understanding API Gateway*) and service registry and discovery ([Chapter 6](0c5e001e-6dca-4805-866c-7be793a91c70.xhtml),
    *Service Registry and Discovery*) solution. We will leverage Zuul and Eureka from
    the Netflix OSS.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先我们需要的是一个网关（[第5章](720d1d4e-1795-457c-903e-65c5a5fb5433.xhtml)，*理解API网关*）和服务注册和发现（[第6章](0c5e001e-6dca-4805-866c-7be793a91c70.xhtml)，*服务注册和发现*）解决方案。我们将利用Netflix
    OSS的Zuul和Eureka。
- en: First off we need a Eureka server, copy the source from `Chapter-6/ eureka/eureka-server`
    to a new folder or follow the steps from [Chapter 6](0c5e001e-6dca-4805-866c-7be793a91c70.xhtml), *Service
    Registry and Discovery*, in the Eureka section to create a new server which would
    run on JVM.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先我们需要一个Eureka服务器，将源代码从`Chapter-6/ eureka/eureka-server`复制到一个新文件夹，或者按照[第6章](0c5e001e-6dca-4805-866c-7be793a91c70.xhtml)中的步骤，在Eureka部分创建一个新的服务器，该服务器将在JVM上运行。
- en: Doing nothing fancy, just add annotations `@EnableEurekaServer` and `@SpringBootApplication`
    at relevant places—`DemoServiceDiscoveryApplication.java.`
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 没有什么花哨的，只需在相关位置添加注释`@EnableEurekaServer`和`@SpringBootApplication`—`DemoServiceDiscoveryApplication.java`。
- en: 'Configure properties like port number, health check in the `application.properties`
    file by adding the following:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过添加以下内容在`application.properties`文件中配置属性，如端口号、健康检查：
- en: '[PRE10]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Run the Eureka server by the following command:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过以下命令运行Eureka服务器：
- en: '[PRE11]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: You should be able to see Eureka server up and running in port `8761`.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该能够在端口`8761`上看到Eureka服务器正在运行。
- en: Next up is Zuul or our API Gateway. Zuul will act as routing point for any service
    requests as well as it will be in constant touch with Eureka Server. We will enable
    auto registration of service with Zuul, that is, if any service registers or deregisters
    we won't have to restart Zuul. Having our Gateway in JVM rather than Node.js will
    also give a significant durable boost.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来是Zuul或我们的API网关。Zuul将作为任何服务请求的路由点，同时它将与Eureka服务器保持不断联系。我们将启用服务与Zuul的自动注册，也就是说，如果任何服务注册或注销，我们不必重新启动Zuul。将我们的网关放在JVM中而不是Node.js中也将显著提高耐用性。
- en: Open [https://start.spring.io/](https://start.spring.io/) and generate project
    by adding Zuul and Eureka discovery as dependency. (You can find `zuuul-server`
    under `Chapter 7/netflix cloud`).
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开[https://start.spring.io/](https://start.spring.io/)并通过添加Zuul和Eureka发现作为依赖项来生成项目。（您可以在`Chapter
    7/netflix cloud`下找到`zuuul-server`）。
- en: Open `NetflixOsssApplication` and add the following annotations on top of it.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开`NetflixOsssApplication`并在顶部添加以下注释。
- en: '[PRE12]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Next up we will configure our Zuul server with application level properties:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用应用程序级属性配置我们的Zuul服务器：
- en: '[PRE13]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Run the application by `mvn clean install && java -jar target\netflix-osss-0.0.1-SNAPSHOT.jar`
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过`mvn clean install && java -jar target\netflix-osss-0.0.1-SNAPSHOT.jar`运行应用程序
- en: You should be able to see your Zuul server registered in Eureka dashboard meaning
    that Zuul has run up and successfully.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您应该能够在Eureka仪表板中看到您的Zuul服务器已注册，这意味着Zuul已经成功运行起来。
- en: Next up is we create a service in Node.js and Java and register it in Eureka,
    as Zuul has Auto registration enabled, our services will be directly routed without
    any other configurations. Wow!
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将在Node.js和Java中创建一个服务，并在Eureka中注册它，因为Zuul已启用自动注册，我们的服务将直接路由，无需其他配置。哇！
- en: 'So first let''s create a Node.js microservice. Register your microservice with
    Eureka by adding following code in `Application.ts` (place where Express is initialized):'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所以首先让我们创建一个Node.js微服务。通过在`Application.ts`（初始化Express的地方）中添加以下代码将您的微服务注册到Eureka：
- en: '[PRE14]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We did nothing new, this is same code we had in [Chapter 6](0c5e001e-6dca-4805-866c-7be793a91c70.xhtml),
    *Service Registry and Discovery*. Just remember that `instanceId`, `vipAddress`
    should be same.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有做任何新的事情，这是我们在[第6章](0c5e001e-6dca-4805-866c-7be793a91c70.xhtml)中的相同代码。只需记住`instanceId`，`vipAddress`应该相同。
- en: Now run the service by `npm start`. It will open in port `3001`, but our Zuul
    server is listening at port `8762`. So hit the URL `http://localhost:8762/hello-world-chapter-6`
    where `hello-world-chapter-6` is the `vipAddress` or the application name. You
    will be able to see the same output. This confirms our working of Zuul server.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在通过`npm start`运行服务。它将在端口`3001`上打开，但我们的Zuul服务器正在端口`8762`上监听。因此，访问URL `http://localhost:8762/hello-world-chapter-6`，其中`hello-world-chapter-6`是`vipAddress`或应用程序名称。您将能够看到相同的输出。这证实了我们Zuul服务器的工作。
- en: To further understand microservices, I have added a microservice (`http://localhost:8080/product`)
    in Java (nothing fancy, just a GET call, check folder `java-microservice`). After
    registering microservice which runs at port `8080`, when i check via my gateway
    (`http://localhost:8762/java-microservice-producer/product`) it works like a charm.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了进一步了解微服务，我在Java中添加了一个微服务(`http://localhost:8080/product`)（没有花哨的东西，只是一个GET调用，请检查文件夹`java-microservice`）。在注册运行在端口`8080`的微服务之后，当我通过我的网关(`http://localhost:8762/java-microservice-producer/product`)进行检查时，它就像魅力一样运行。
- en: Another feasible option for us includes using Netflix Sidecar. 14\. Let's take
    a break and pat yourself. We have achieved auto registration/deregistration which
    can handle service in any language. We have created a polyglot environment.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的另一个可行选项包括使用Netflix Sidecar。14.让我们休息一下，给自己鼓掌。我们已经实现了可以处理任何语言服务的自动注册/注销。我们已经创建了一个多语言环境。
- en: Part B – Zuul, Load balancing and failure resiliency
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: B部分- Zuul，负载平衡和故障恢复
- en: Whoa!! *Part A* was awesome. We will go on the same track. The next part which
    comes in our plate is, what will happen when there is heavy traffic. In this part
    we will see how to leverage Zuul which has in built Netflix Ribbon support to
    load balance the requests without much huss or fuss. Whenever a request come to
    Zuul, it pick up one of the available locations it finds and forwards the service
    request to the actual service instance present there. The whole process of caching
    the location of instances and periodically refreshing it and
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！！*A部分*太棒了。我们将继续同样的轨道。我们盘子里的下一部分是，当交通繁忙时会发生什么。在这一部分中，我们将看到如何利用Zuul，它具有内置的Netflix
    Ribbon支持，以在没有太多麻烦的情况下负载平衡请求。每当请求到达Zuul时，它会选择其中一个可用的位置，并将服务请求转发到那里的实际服务实例。整个过程都是缓存实例的位置并定期刷新它和
- en: 'forwarding the request to actual location is given out of the box without any
    configurations needed. Behind the scenes Zuul uses Eureka to administer the routing.
    Furthermore we will be seeing circuit breaker in this example and configure it
    in Hystrix dashboard to see real time analytics. In this section we will configure
    circuit breaker and send those streams to Hystrix. So let us get started. You
    can follow along the example at `Chapter 7/ hystrix`:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 将请求转发到实际位置是无需任何配置即可获得的。在幕后，Zuul使用Eureka来管理路由。此外，我们将在此示例中看到断路器，并在Hystrix仪表板中配置它以查看实时分析。在本节中，我们将配置断路器并将这些流发送到Hystrix。所以让我们开始吧。您可以在`第7章/
    hystrix`中跟随示例：
- en: 'In extracted source grab the `standalone-hystrix-dashboard-all.jar` and hit
    the `java -jar standalone-hystrix-dashboard-all.jar` command. This will open up
    Hystrix dashboard in port `7979`. Verify URL `http://localhost:7979/hystrix-dashboard`
    to check:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在提取的源代码中抓取`standalone-hystrix-dashboard-all.jar`并输入`java -jar standalone-hystrix-dashboard-all.jar`命令。这将在端口`7979`上打开Hystrix仪表板。验证URL`http://localhost:7979/hystrix-dashboard`以检查：
- en: '![](img/00fa516c-e477-4428-90f8-2055fba54958.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00fa516c-e477-4428-90f8-2055fba54958.png)'
- en: Time to write a simple program which will trip open a circuit at some time.
    We will be leveraging `opossum` module ([https://www.npmjs.com/package/opossum](https://www.npmjs.com/package/opossum))
    to trip open a circuit. Install the opossum module by the `npm install opossum
    --save` command and write down its custom types as they are not available yet.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是时候编写一个简单的程序，在某个时间点打开一个电路。我们将利用`opossum`模块([https://www.npmjs.com/package/opossum](https://www.npmjs.com/package/opossum))来打开一个电路。通过`npm
    install opossum --save`命令安装opossum模块，并写下其自定义类型，因为它们尚不可用。
- en: We would write a simple logic. We will initialize a number, if it reaches threshold,
    then the circuit would be broken—open state and our fallback function will hit.
    Let's do the needful.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将编写一个简单的逻辑。我们将初始化一个数字，如果达到阈值，那么电路将被打开-打开状态，我们的回退函数将触发。让我们做必要的事情。
- en: 'Let''s define our variables:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义我们的变量：
- en: '[PRE15]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We start with count 20 and use two variables to compare in time:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从计数20开始，并使用两个变量在时间上进行比较：
- en: '[PRE16]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We define `circuitBreaker` and instruct our express app to use it:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义`circuitBreaker`并指示我们的express应用程序使用它：
- en: '[PRE17]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We define a function which increases over time, until it trips open. And we
    define a fall back function like Oops! Service down:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义一个随时间增加的函数，直到它打开。并且我们定义一个类似的回退函数，比如糟糕！服务中断：
- en: '[PRE18]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'That''s it! Open up Hystrix, enter URL `http://localhost:3000/hystrix.stream`
    in Hystrix streams, and you will be able to see live monitoring of the circuit:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就是这样！打开Hystrix，输入URL`http://localhost:3000/hystrix.stream`到Hystrix流中，您将能够看到电路的实时监控：
- en: '![](img/efa92def-d38f-4d51-8656-8cbf38b0fd0e.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/efa92def-d38f-4d51-8656-8cbf38b0fd0e.png)'
- en: 'Once it reaches the peak stage, it will trip open:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦达到峰值阶段，它将自动打开：
- en: '![](img/4992df36-cc89-4678-bbeb-0f219ea4b1c8.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4992df36-cc89-4678-bbeb-0f219ea4b1c8.png)'
- en: After preconfigured time, it will again be closed state and ready to serve requests.
    A full detailed API can be found here [https://www.npmjs.com/package/opossum](https://www.npmjs.com/package/opossum).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在预先配置的时间之后，它将再次处于关闭状态，并准备好为请求提供服务。可以在这里找到完整的详细API[https://www.npmjs.com/package/opossum](https://www.npmjs.com/package/opossum)。
- en: Message queues and brokers
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消息队列和代理
- en: A message queue is an answer for problem of application to application communication.
    This communication occurs regardless of where my application or my data is, whether
    I am on same server, separate server, server with different OS or anything similar.
    Message queuing is build for scenarios such as a task list or work queue. A message
    queue solves the problem by passing and sending data via queues. Application then
    make use of information in the messages to interact further. The platform provided
    is secured and reliable. Whereas a Message broker is build to extend the functionality
    of message queue and it is able to understand the content of each message which
    moves through out the broker. A set of operations defined on each message are
    processed. Message processing nodes which are packaged along with message broker
    are able to understand messages from various sources such as JMS, HTTP, and files.
    In this section we will explore message bus and message brokers in detail. Popular
    message brokers include Kakfa, RabbitMQ, Redis, and NSQ. We will see Apache Kakfa
    in much detail in the next section which is a advanced version of messaging queues.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 消息队列是应用程序间通信问题的解决方案。无论我的应用程序或数据在哪里，无论我是在同一台服务器上，独立的服务器上，带有不同操作系统的服务器上或类似的地方，这种通信都会发生。消息队列是为诸如任务列表或工作队列之类的场景而构建的。消息队列通过队列传递和发送数据来解决问题。然后应用程序利用消息中的信息进行进一步交互。所提供的平台是安全可靠的。而消息代理是为了扩展消息队列的功能而构建的，它能够理解通过代理传递的每条消息的内容。对每条消息定义的一组操作被处理。与消息代理一起打包的消息处理节点能够理解来自各种来源的消息，如JMS、HTTP和文件。在本节中，我们将详细探讨消息总线和消息代理。流行的消息代理包括Kakfa、RabbitMQ、Redis和NSQ。我们将在下一节中更详细地了解Apache
    Kakfa，这是消息队列的高级版本。
- en: Introduction to pub/sub pattern
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发布/订阅模式介绍
- en: Just as message queuing, pub-sub (publish-subscribe) pattern moves information
    from producer to a consumer. However the major difference here is this pattern
    allows multiple consumers to receive each message in a topic. It ensures that
    the consumer receives messages in a topic in exact same order in which it was
    received in the messaging system. This pattern can be better understood by taking
    a real life scenario. Consider a stock market. It is used by large number of people
    and applications, all of whom should be send messages real time and just the exact
    sequence of prices. There is a huge difference between a stock going up to down
    and stock going down to up. Lets see an example Apache Kafka is one of the shining
    solution when it comes to pub sub pattern. As per docs of Apache Kafka—Kafka is
    a distributed, partitioned, replicated commit log service. It provides the functionality
    of a messaging system, but with a unique design.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 与消息队列一样，发布/订阅（发布-订阅）模式将信息从生产者传递给消费者。然而，这里的主要区别在于这种模式允许多个消费者在一个主题中接收每条消息。它确保消费者按照消息系统中接收消息的确切顺序接收主题中的消息。通过采用一个真实的场景，可以更好地理解这种模式。考虑股票市场。它被大量的人和应用程序使用，所有这些人和应用程序都应该实时发送消息，并且只有确切的价格顺序。股票上涨和下跌之间存在巨大的差异。让我们看一个例子，Apache
    Kafka是在发布/订阅模式下的一个出色解决方案。根据Apache Kafka的文档，Kafka是一个分布式、分区、复制的提交日志服务。它提供了消息系统的功能，但具有独特的设计。
- en: 'Kafka is a streaming platform that allows applications to get and take messages.
    It is used for making real time data pipeline streaming apps. Let''s get acquainted
    with Kafka terminology:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka是一个允许应用程序获取和接收消息的流平台。它用于制作实时数据管道流应用程序。让我们熟悉一下Kafka的术语：
- en: Producers are someone who send data to Kafka.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产者是向Kafka发送数据的人。
- en: Consumers are someone who read data from Kafka.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消费者是从Kafka读取数据的人。
- en: Data is send in the form of record. Each record is associated with a topic.
    A topic has a category and it consists of a key, a value and a timestamp.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据以记录的形式发送。每个记录都与一个主题相关联。主题有一个类别，它由一个键、一个值和一个时间戳组成。
- en: Consumers usually subscribe to given topics and get a stream of records and
    they are alerted whenever a new record comes.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消费者通常订阅特定的主题，并获得一系列记录，并在新记录到达时收到通知。
- en: If a consumer goes down, they can restart streaming by tracking the last offset.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果消费者宕机，他们可以通过跟踪最后的偏移量重新启动流。
- en: Order of messages is guaranteed.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 消息的顺序是有保证的。
- en: 'We will commence this case study with three phases:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将分三个阶段开始这个案例研究：
- en: 'Install Kakfa Locally:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本地安装Kakfa：
- en: To setup Kakfa locally, download the bundle and extract it to a location of
    choice. Once extracted we need to setup Zookeeper. To do so start `zookeeper`
    by the following command—`bin\windows\zookeeper-server-start.bat config\zookeeper.properties`.
    Java 8 is essential for this case study. Since I am working on windows for this
    example, my commands has `Windows` folder in it. Be sure to be aware about the
    `.sh` and the `.bat` difference.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要在本地设置Kakfa，下载捆绑包并将其提取到所选位置。提取后，我们需要设置Zookeeper。为此，请使用以下命令启动`zookeeper` - `bin\windows\zookeeper-server-start.bat
    config\zookeeper.properties`。对于这个案例研究，Java 8是必不可少的。由于我在Windows上进行这个例子，我的命令中有`Windows`文件夹。一定要注意`.sh`和`.bat`之间的区别。
- en: 2\. Next we will start the Kakfa server. Hit the the following command—
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 接下来我们将启动Kakfa服务器。输入以下命令-
- en: '`bin\windows\kafka-server-start.bat config\server.properties`.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '`bin\windows\kafka-server-start.bat config\server.properties`。'
- en: 3\. We will create a topic named offers with a single partition and only one
    replica—`bin\windows\kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor
    1 --partitions 1 --topic offers`. You will get a prompt Created topic offers.
    To see the topic we can hit `bin\windows\kafka-topics.bat --list --zookeeper localhost:2181`.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 我们将创建一个名为offers的主题，只有一个分区和一个副本 - `bin\windows\kafka-topics.bat --create --zookeeper
    localhost:2181 --replication-factor 1 --partitions 1 --topic offers`。您将收到提示Created
    topic offers。要查看主题，我们可以输入`bin\windows\kafka-topics.bat --list --zookeeper localhost:2181`。
- en: 4\. Kakfa is up and running on `localhost:2181`. We can even create topics via
    our broker or Node.js client.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 4. Kakfa在`localhost:2181`上运行。我们甚至可以通过我们的代理或Node.js客户端创建主题。
- en: Creating a Kafka producer
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建Kafka生产者
- en: We will leverage `kakfa-node` module ([https://www.npmjs.com/package/kafka-node](https://www.npmjs.com/package/kafka-node)).
    As per need we can either setup a separate service or integrate in existing application
    service.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将利用`kakfa-node`模块（[https://www.npmjs.com/package/kafka-node](https://www.npmjs.com/package/kafka-node)）。根据需要，我们可以设置一个单独的服务或集成到现有的应用服务中。
- en: Right now we will just write two seperate files in two different projects to
    test out our application.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将在两个不同的项目中编写两个单独的文件来测试我们的应用程序。
- en: 'You can check `Chapter-8/kakfka/node-producer` to check the source:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以检查`Chapter-8/kakfka/node-producer`以查看源代码：
- en: '[PRE19]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'You can bind the on message event like this. Through the same module we can
    create client who is going to listen on message of offers and process event accordingly:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以像这样绑定消息事件。通过相同的模块，我们可以创建一个客户端，他将监听报价消息并相应地处理事件：
- en: '[PRE20]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Kafka is a powerful player which can be used in variety of things where we actually
    need real time data processing. The pub/sub pattern is a great way to achieve
    event driven communication.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka是一个强大的工具，可以用于各种需要实时数据处理的场景。发布/订阅模式是实现事件驱动通信的一种很好的方式。
- en: Sharing dependencies
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 共享依赖
- en: Microservices are great when it comes to building scalable code bases with independent
    deployments, separating concerns, better resilience, polyglot technologies and
    better modularity, reusability, and development life cycle. However, modularity
    and reusability come at a cost. More modularity and reusability may often result
    in high coupling or code duplications. Having many different services attached
    to the same shared library will soon lead us back to square one and we will end
    up with monolithic hell.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 当构建可独立部署的可扩展代码库时，微服务非常出色，分离关注点，具有更好的弹性，多语言技术和更好的模块化，可重用性和开发生命周期。然而，模块化和可重用性是有代价的。更多的模块化和可重用性往往会导致高耦合或代码重复。将许多不同的服务连接到相同的共享库将很快使我们回到原点，最终我们将陷入单块地狱。
- en: In this section, we are going to see how to overcome this hell. We will see
    some options with practical implementations and understand the sharing code and
    common code process. So let's get started.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到如何摆脱这种困境。我们将看到一些具有实际实现的选项，并了解共享代码和通用代码的过程。所以让我们开始吧。
- en: The problem and solution
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题和解决方案
- en: 'Sharing code between microservices is always tricky. We need to make sure that
    a common dependency does not break our microservices freedom. The major goals
    that we want to achieve while sharing code are:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在微服务之间共享代码总是棘手的。我们需要确保共同的依赖不会限制我们微服务的自由。我们在共享代码时要实现的主要目标是：
- en: Share common code among our microservices, while making sure that our code is
    **Don't Repeat Yourself** (**DRY**)—it is a coding principle with the main aim
    to reduce any repetition of code
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在我们的微服务之间共享通用代码，同时确保我们的代码是**不重复自己**（**DRY**）——这是一个编码原则，其主要目标是减少代码的重复
- en: Avoid tight coupling through any common shared library, as it eliminates the
    freedom of microservices
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过任何共享的共同库避免紧密耦合，因为它会消除微服务的自由。
- en: Enable simple changes in order to sync the code we can share between our microservices
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使同步我们可以在微服务之间共享的代码变得简单
- en: Microservices are something that introduce code duplications. Creating an `npm`
    package with a new code base for any such business use case is highly impractical
    as it will generate a lot of overhead to make it harder to maintain any code changes.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务会引入代码重复。为任何业务用例创建一个新的`npm`包是非常不切实际的，因为这将产生大量的开销，使维护任何代码更加困难。
- en: We are going to use **bit** ([https://bitsrc.io/](https://bitsrc.io/)) to solve
    our dependency problem and to achieve our goals. Bit operates on the philosophy
    that components are the building blocks, you are the architect. Using bit, we
    don't have to create a new repository or add packages to share code instead of
    duplicating it. You just need to define reusable parts of any existing microservices
    and share them to other microservices as any package or tracked source code. This
    way, we can easily make parts of any service reusable without modifying any single
    line of code and not introduce tight coupling among services. The major advantage
    of bit is that it gives us the flexibility to make the changes to code that are
    shared with any other service, thus allowing us to develop and modify the code
    from anywhere in our microservice ecosystem.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用**bit**（[https://bitsrc.io/](https://bitsrc.io/)）来解决我们的依赖问题并实现我们的目标。Bit的运作理念是组件是构建块，你是架构师。使用bit，我们不必创建新的存储库或添加包来共享代码，而不是重复。您只需定义任何现有微服务的可重用部分，并将其共享到其他微服务作为任何包或跟踪的源代码。这样，我们可以轻松地使任何服务的部分可重用，而无需修改任何一行代码，也不会在服务之间引入紧密耦合。Bit的主要优势在于它为我们提供了灵活性，使我们能够对与任何其他服务共享的代码进行更改，从而使我们能够在微服务生态系统中的任何地方开发和修改代码。
- en: Getting started with bit
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用bit
- en: 'Coupling microservices via common libraries is very bad. Bit promotes building
    components. We simply isolate and sync any reusable code and let bit handle how
    to isolate and track source code among the projects. This can still be installed
    with NPM and make changes from any end. Let''s say you are making some great system
    with top-notch functionalities that are common everywhere. You want to share code
    among these services. You can follow along with the code inside the `bit-code-sharing`
    folder in [Chapter 7](162a0f25-2890-4a58-aa41-e9c9b5fc6c2d.xhtml), *Service State
    and Interservice Communication*:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 通过共同的库耦合微服务是非常糟糕的。Bit提倡构建组件。我们只需隔离和同步任何可重用的代码，让bit处理如何在项目之间隔禅和跟踪源代码。这仍然可以通过NPM安装，并且可以从任何端口进行更改。假设您正在创建一些具有顶级功能的出色系统，这些功能在任何地方都很常见。您希望在这些服务之间共享代码。您可以在[第7章](162a0f25-2890-4a58-aa41-e9c9b5fc6c2d.xhtml)的`bit-code-sharing`文件夹中跟随代码，*服务状态和服务间通信*：
- en: 'Bit would be installed as a global module. Install `bit` by typing the following:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Bit将作为全局模块安装。通过输入以下内容安装`bit`：
- en: '[PRE21]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: For this example, check out `demo-microservice`, which has common utilities
    such as fetching from the cache, common logging utility, and so on. We want these
    functionalities everywhere. That's where we are going to use `bit` to make our
    file `common/logging.ts` available everywhere.
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个例子中，查看`demo-microservice`，它具有常见的实用程序，比如从缓存中获取、常见的日志实用程序等。我们希望这些功能在任何地方都可以使用。这就是我们将使用`bit`使我们的文件`common/logging.ts`在任何地方都可用的地方。
- en: Time to initialize `bit` and tell `bit` to add `logging.ts` in the tracking
    list. Open up `demo-microservice` in the Terminal and type the `bit init `command.
    This will create a `bit.json` file.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是时候初始化`bit`并告诉`bit`在跟踪列表中添加`logging.ts`。在终端中打开`demo-microservice`，然后输入`bit init`命令。这将创建一个`bit.json`文件。
- en: 'Next, we will tell `bit` to start tracking the `common` folder. Hit the following
    command in Terminal:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将告诉`bit`开始跟踪`common`文件夹。在终端中输入以下命令：
- en: '[PRE22]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Here we used `*` as a global pattern so we can track multiple components on
    the same path. It will track all the components inside the `common` folder and
    you should be able to see a message tracking two new components.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用`*`作为全局模式，这样我们就可以跟踪相同路径上的多个组件。它将跟踪`common`文件夹中的所有组件，你应该能够看到一个跟踪两个新组件的消息。
- en: Bit components are added to our bit tracking list. We can simply hit `bit status`
    to check the current status of bit in our microservices. It will show two components
    under the New Components section.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Bit组件已添加到我们的bit跟踪列表。我们可以简单地输入`bit status`来检查我们微服务中bit的当前状态。它将在“新组件”部分下显示两个组件。
- en: Next, we will add build and test environments so we don't introduce any abnormalities
    in our ecosystem before sharing the component. First off is our build environment.
    The build environment is essentially a build task that is used by bit to run and
    compile the component, since our file is written in TypeScript. To import dependencies
    you need to create an account at [https://bitsrc.io](https://bitsrc.io) and sign
    up for the public tier.
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将添加构建和测试环境，以便在分享组件之前不会引入任何异常。首先是我们的构建环境。构建环境本质上是一个构建任务，由bit用于运行和编译组件，因为我们的文件是用TypeScript编写的。要导入依赖项，你需要在[https://bitsrc.io](https://bitsrc.io)创建一个账户，并注册公共层。
- en: 'Import the TypeScript compiler by adding the following line:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过添加以下行来导入TypeScript编译器：
- en: '[PRE23]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: You will need to enter the user credentials for the account you just made. Once
    installed, we will go with a public scope as of now.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要输入刚刚创建的账户的用户凭据。安装后，我们将使用公共作用域。
- en: 'Hit the command `bit build` to see the `distribution` folder with our generated
    files. You can write tests similarly to check whether unit test cases pass or
    not. Bit has support in-built for mocha and jest. We will just create a `hello-world`
    test right now. We need to specify to bit for what component, which would be the
    `test` file explicitly. So let''s untrack previously added files, as we need to
    pass on our spec files:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入命令`bit build`，查看带有我们生成文件的`distribution`文件夹。你可以类似地编写测试来检查单元测试用例是否通过。Bit内置支持mocha和jest。我们现在只是创建一个`hello-world`测试。我们需要明确告诉bit对于哪个组件，哪个将是`test`文件。因此，让我们取消跟踪先前添加的文件，因为我们需要传递我们的规范文件：
- en: '[PRE24]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Create a `test` folder inside `src` and install testing libraries by hitting
    the following command:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`src`文件夹内创建一个`test`文件夹，并通过以下命令安装测试库：
- en: '[PRE25]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Create `logging.spec.ts` inside the `tests` folder and add the following code.
    Similarly, create `cacheReader.spec.ts`:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`tests`文件夹内创建`logging.spec.ts`，并添加以下代码。类似地，创建`cacheReader.spec.ts`：
- en: '[PRE26]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We will see detailed testing concepts in [Chapter 8](a7273aa2-2981-4013-8d5f-dbee87462d35.xhtml),
    *Testing, Debugging, and Documenting*.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第8章](a7273aa2-2981-4013-8d5f-dbee87462d35.xhtml)中看到详细的测试概念，*测试、调试和文档*。
- en: 'To tell `bit` about our testing strategy, hit the following commands:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要告诉`bit`我们的测试策略，输入以下命令：
- en: '[PRE27]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Hit the command `bit test` and it will print the test results against each component
    added.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入命令`bit test`，它将打印针对每个添加的组件的测试结果。
- en: 'We are all done. Time to share our brand new component with the world. First,
    we will lock a version and isolate it from other components from this project.
    Hit the following command:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已经完成了。是时候与世界分享我们全新的组件了。首先，我们将锁定一个版本，并将其与此项目的其他组件隔离开来。输入以下命令：
- en: '[PRE28]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: You should be able to see an output stating added components `common/logging@1.0.0`
    and `common@cache-reader@1.0.0`. When you do a `bit status` you will be able to
    see that these components have moved from new components to staged components.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能够看到一个输出，指出已添加组件`common/logging@1.0.0`和`common@cache-reader@1.0.0`。当你执行`bit
    status`时，你将能够看到这些组件已从新组件移动到了暂存组件。
- en: 'To share it with other services we export it using `bit export`. We will push
    it to the remote scope so it can be accessed from anywhere. Go to [http://bitsrc.io/](http://bitsrc.io/),
    log in, and then create a new scope there. Now we will push our code to that scope:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了与其他服务共享，我们使用`bit export`导出它。我们将把它推送到远程作用域，这样它就可以从任何地方访问。转到[http://bitsrc.io/](http://bitsrc.io/)，登录，然后在那里创建一个新的作用域。现在我们将把我们的代码推送到那个作用域：
- en: '[PRE29]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: You can log in to your account and then check code in pushed repositories.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以登录你的账户，然后检查推送存储库中的代码。
- en: 'To import in other workspaces, you can follow these steps:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要在其他工作区中导入，可以按照以下步骤进行：
- en: 'We need to tell the node that bit is one of our registries from where to download
    modules. So add the `bit` repository as one of the registries with alias `@bit`
    in `npm config`:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要告诉节点，bit是我们的一个注册表之一，从中下载模块。因此，在`npm config`中添加`bit`仓库作为带有别名`@bit`的注册表之一：
- en: '[PRE30]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'To download from any other project, use the following:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要从任何其他项目中下载，请使用以下命令：
- en: '[PRE31]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The command is similar to `npm i <alias we created>/<username>.<scopename>.<username>`.
    Once installed, you can use it just like any other node module. Check out `chapter
    9/bit-code-sharing/consumer` for this.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令类似于`npm i <我们创建的别名>/<用户名>.<作用域名称>.<用户名>`。安装后，你可以像使用任何其他节点模块一样使用它。查看`chapter
    9/bit-code-sharing/consumer`。
- en: You can also use `bit import` and other utilities such as making changes, syncing
    code, and so on.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以使用`bit import`和其他实用程序，比如进行更改、同步代码等。
- en: Sharing code is a must for development and maintenance offers. However, tightly
    coupling services through shared libraries ruins the point of having microservices.
    Creating new repositories in NPM for any new common use case is impractical as
    we have to make many changes. Tools such as bit have the best of both worlds.
    We can easily share code and also make and sync changes from any end.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 共享代码对于开发和维护提供了必要的。然而，通过共享库紧密耦合服务破坏了微服务的意义。为任何新的常见用例在NPM中创建新的存储库是不切实际的，因为我们必须进行许多更改。像bit这样的工具拥有两全其美。我们可以轻松共享代码，还可以从任何端点进行制作和同步更改。
- en: The problem of shared data
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 共享数据的问题
- en: Having common shared data among microservices is a huge pitfall. Firstly, all
    the microservice's requirements may not be satisfied with a single database. Also,
    it increases development time coupling. For example, `InventoryService` will need
    to coordinate the schema changes with the developers of other services that use
    the same tables. It also increases runtime coupling. If, for instance, a long-running
    `ProductCheckOut` service holds a lock on the `ORDER` table, then any other service
    using that same table will be blocked. Each service must have its own databases
    and data must not be directly accessible by any other service.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在微服务之间共享常见数据是一个巨大的陷阱。首先，不一定能满足所有微服务的需求。此外，它增加了开发时间的耦合。例如，`InventoryService`将需要与使用相同表的其他服务的开发人员协调模式更改。它还增加了运行时的耦合。例如，如果长时间运行的`ProductCheckOut`服务在`ORDER`表上持有锁定，那么使用相同表的任何其他服务都将被阻塞。每个服务必须有自己的数据库，并且数据不能直接被任何其他服务访问。
- en: 'However, there is a huge situation that we need to take care of. The problem
    of transactions and how to handle them. Even though keeping transaction-related
    entities in the same database and leveraging database transactions seems the only
    option, we cannot go with that. Let''s see what should we do:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一个巨大的情况需要我们注意。事务问题以及如何处理它们。即使将与事务相关的实体保留在同一个数据库中并利用数据库事务似乎是唯一的选择，我们也不能这样做。让我们看看我们应该怎么做：
- en: '**Option 1**: If any update happens only in one microservice, then we can leverage
    an asynchronous messaging/service bus to handle that for us. Service bus will
    maintain two-way communication so as to ensure business capability is achieved.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选项1**：如果任何更新只发生在一个微服务中，那么我们可以利用异步消息/服务总线来处理。服务总线将保持双向通信，以确保业务能力得到实现。'
- en: '**Option 2**: This is where we want transactional data to be handled. For example,
    checkout should only occur if payment is done. If not, then it should not proceed
    further with anything. Either we need to merge the services or we can use transactions
    (something like Google Spanner for Distributed transactions). We are stuck with
    two options, either settle via transactions or handle situations accordingly.
    Let''s look at how to handle these scenarios in various ways.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选项2**：这是我们希望处理事务数据的地方。例如，只有在付款完成后才能进行结账。如果没有，那么它不应该继续进行任何操作。要么我们需要合并服务，要么我们可以使用事务（类似于Google
    Spanner用于分布式事务）。我们卡在两个选项上，要么通过事务解决，要么相应地处理情况。让我们看看如何以各种方式处理这些情况。'
- en: To manage data consistency, one of the most widely used patterns is the saga
    pattern. Let's understand a practical use case that we have. We have a customers
    rewards point service that maintains the total allowed points to buy. The application
    must ensure that new orders must not exceed customers allowed rewards points.
    Since orders and customers rewards points are in different databases, we must
    maintain data consistency.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 为了管理数据一致性，最常用的模式之一是saga模式。让我们了解一个我们拥有的实际用例。我们有一个客户奖励积分服务，用于维护允许购买的总积分。应用程序必须确保新订单不得超过客户允许的奖励积分。由于订单和客户奖励积分存储在不同的数据库中，我们必须保持数据一致性。
- en: 'As per the saga pattern, we must implement each business transaction that spans
    across multiple services. It would be a sequence of local transactions. Each individual
    transaction updates the database and publishes a message or an event that will
    trigger the next local transaction in the saga. If the local transaction fails,
    then saga executes a series of compensating transactions that actually undo changes
    that were made by the previous transaction. Here are the steps that we will execute
    in our case. This is one case for maintaining consistency for consistency via
    events:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 根据saga模式，我们必须实现跨多个服务的每个业务交易。这将是一系列本地事务。每个单独的事务更新数据库并发布一个消息或事件，该消息或事件将触发saga中的下一个本地事务。如果本地事务失败，那么saga将执行一系列补偿事务，实际上撤消了上一个事务所做的更改。以下是我们将在我们的案例中执行的步骤。这是通过事件维护一致性的一个案例：
- en: Rewards service creates an order in pending state and publishes a points processed
    event.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 奖励服务创建一个处于挂起状态的订单并发布一个积分处理的事件。
- en: Customer service receives the event and attempts to block rewards for that order.
    It publishes a rewards blocked event or a rewards blocked failed event.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户服务接收事件并尝试阻止该订单的奖励。它发布了一个奖励被阻止的事件或奖励被阻止失败的事件。
- en: The order service receives the event and changes the state accordingly.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 订单服务接收事件并相应地更改状态。
- en: 'The most predominant patterns used are as follows:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的模式如下：
- en: '**State store**: A service records all the state changes in a state store.
    When any failure occurs, we can query the state store to find and recover any
    incomplete transactions.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**状态存储**：一个服务记录状态存储中的所有状态更改。当发生任何故障时，我们可以查询状态存储以找到并恢复任何不完整的事务。'
- en: '**Process manager**: A process manager that listens to events generated by
    any operations and decides on whether to complete the transaction or not.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流程管理器**：一个监听任何操作生成的事件并决定是否完成事务的流程管理器。'
- en: '**Routing slip**: Another dominant approach is making all operations asynchronous.
    A service makes a message with two request commands (a debit and shipping instruction)
    in a slip called a routing slip. This message is passed to the debit service from
    the routing slip. The debit service executes the first command and fills the routing
    slip before passing the message to a shipping service that completes the shipping
    operation. If there is a failure, the message is sent back to error queue, where
    the service can watch the state and error status to compensate if needs arise.
    The following diagram describes the same process:'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**路由滑动**: 另一种主流方法是使所有操作异步进行。一个服务使用两个请求命令（借记和发货指令）创建一条称为路由滑动的滑动。这条消息从路由滑动传递到借记服务。借记服务执行第一个命令并填写路由滑动，然后将消息传递给完成发货操作的发货服务。如果出现故障，消息将被发送回错误队列，服务可以观察状态和错误状态以进行补偿。以下图表描述了相同的过程：'
- en: '![](img/77501b19-b2df-4878-9ce0-0e26bc299433.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![](img/77501b19-b2df-4878-9ce0-0e26bc299433.png)'
- en: Routing slip
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 路由滑动
- en: Data sharing in microservices always remains a pain if not handled properly.
    There are various solutions to distributed transactions across microservices.
    We saw widely used solutions such as saga and went through various ways to handle
    data eventual consistency.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务中的数据共享如果处理不当，总是会成为一个痛点。有各种解决方案可以处理微服务之间的分布式事务。我们看到了广泛使用的解决方案，比如saga，并且了解了处理数据最终一致性的各种方法。
- en: Cache
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缓存
- en: 'Now we are pretty much in the driver''s seat of our microservice development.
    We have developed microservices, connected them via a gateway, and set up a communication
    layer between them. Since we have distributed our code into various services,
    one of the problems that may arise is accessing the much-needed data at the right
    time. Using in-memory has its own set of challenges that we never want to introduce
    (for example, you need to introduce load balancers, session replicators, and so
    on). We need some way to access temporary data across services. This would be
    our caching mechanism: one service creates and stores data in cache, while others
    may use it on need and situation basis or fail basis. This is where we will introduce
    Redis as our cache database. Prominent caching solutions include Redis and Hazelcast.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们基本上掌握了微服务开发的主导权。我们已经开发了微服务，通过网关连接它们，并在它们之间建立了通信层。由于我们已经将代码分布到各种服务中，可能会出现的问题之一是在正确的时间访问所需的数据。使用内存具有一系列挑战，我们绝不希望引入（例如，需要引入负载均衡器、会话复制器等）。我们需要一种方式在服务之间访问临时数据。这将是我们的缓存机制：一个服务创建并将数据存储在缓存中，而其他服务可能根据需要和情况或失败情况使用它。这就是我们将引入Redis作为我们的缓存数据库的地方。著名的缓存解决方案包括Redis和Hazelcast。
- en: Blessing and curse of caching
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缓存的祝福和诅咒
- en: Whenever we are told to optimize the performance aspects of our application,
    the first thing that comes to mind is caching. Caching can be defined as a process
    of temporarily holding retrieved or computed data in either data store (server's
    RAM, a key-value store like Redis) in the hope that future access to this information
    will be faster. Updating of this information can be triggered or this value can
    be invalidated after some fixed interval of time. The advantages of caching seem
    huge at first. Calculating resources once and then fetching from cache (read-efficient
    resources) avoids frequent network calls and hence it can result in shorter load
    times, more responsive websites, and a more revenue-generating end user experience.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们被要求优化应用程序的性能方面时，首先想到的就是缓存。缓存可以被定义为暂时将检索或计算的数据保存在数据存储（服务器的RAM，像Redis这样的键值存储）中，希望将来访问这些信息会更快。更新这些信息可以被触发，或者这个值可以在一定的时间间隔后失效。缓存的优势一开始看起来很大。计算资源一次，然后从缓存中获取（读取有效资源）可以避免频繁的网络调用，因此可以缩短加载时间，使网站更具响应性，并提供更多的收入。
- en: However, caching is not a one-stop solution. Caching is indeed an effective
    strategy for static content and for APIs that can tolerate stale data up to some
    point, but it is not applicable elsewhere in situations as data is very huge and
    dynamic. For example, consider the inventory of a given product in our shopping
    cart microservices. This count will change very rapidly for popular products,
    while it might change for some other products. So determining the right age for
    the cache is quite a conundrum here. Adding caching introduces other components
    needed to be managed (such as Redis, Hazelcast, Memcached, and so on). It adds
    costs, the process of procuring, configuring, integrating, and maintaining. Caching
    can introduce other dangers too. Sometimes reading from the cache can be slow
    (cache layer not properly maintained, the cache is within network boundaries,
    and so on). Maintaining cache with updated deployments is also a huge nightmare.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，缓存并不是一劳永逸的解决方案。缓存确实是静态内容和可以容忍到一定程度的过时数据的API的有效策略，但在数据非常庞大和动态的情况下并不适用。例如，考虑我们购物车微服务中给定产品的库存。对于热门产品，这个数量会变化得非常快，而对于其他一些产品，它可能会变化。因此，在这里确定缓存的合适年龄是一个难题。引入缓存还需要管理其他组件（如Redis、Hazelcast、Memcached等）。这增加了成本，需要采购、配置、集成和维护的过程。缓存还可能带来其他危险。有时从缓存中读取可能会很慢（缓存层未得到良好维护，缓存在网络边界内等）。使用更新的部署维护缓存也是一个巨大的噩梦。
- en: 'The following are some of the practices that need to be maintained in order
    to use cache effectively, that is, to make our service work less:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些需要保持的实践，以有效使用缓存，即使我们的服务工作量减少：
- en: Using HTTP standards (standards such as If-modified-Since and Last-Modified
    response headers).
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用HTTP标准（如If-modified-Since和Last-Modified响应头）。
- en: Other options include ETag and If-none-match. A unique **Entity tag** (**ETag**)
    is generated and sent to service request after the first call, which the client
    sends in *if-none-match-header*. When the server finds that ETag has not been
    changed it sends an empty body with a `304 Not Modified` response.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他选项包括ETag和If-none-match。在第一次调用后，将生成并发送唯一的**实体标签**（**ETag**）到服务请求，客户端在*if-none-match-header*中发送。当服务器发现ETag未更改时，它会发送一个带有`304
    Not Modified`响应的空主体。
- en: The HTTP Cache-Control header can be used to help the service to control all
    caching entities. It has various attributes such as **private** (not allowed to
    cache the content if this header is included), **no-cache** (force server to resubmit
    to make a fresh call), **public** (mark any response as cacheable), and **max-age**
    (maximum time to be cached).
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP Cache-Control头可以用于帮助服务控制所有缓存实体。它具有各种属性，如**private**（如果包含此头，则不允许缓存内容），**no-cache**（强制服务器重新提交以进行新的调用），**public**（标记任何响应为可缓存），以及**max-age**（最大缓存时间）。
- en: 'Look at the following diagram to understand some caching scenarios:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下图表以了解一些缓存场景：
- en: '![](img/63da78bd-f083-4e76-bcbe-0c706ca5bc3f.png)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![](img/63da78bd-f083-4e76-bcbe-0c706ca5bc3f.png)'
- en: Cache scenarios
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存场景
- en: Introduction to Redis
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Redis简介
- en: Redis is a simple NoSQL database which focuses on simple data structure (key-value
    pair) with high availability and read efficiency. Redis is open source, in memory
    data structure store which can be used as database as well as cache or message
    broker. It has option for built in data structure like strings, hashes, lists,
    sets, range queries, geospatial indexes,and so on. It has out of the box built
    in replication, transactions, different levels of disk persistence, and options
    of high availability and automatic partitioning. We can also add persistent storage
    as well rather than going for in-memory storage.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: Redis是一个专注于简单数据结构（键值对）的简单NoSQL数据库，具有高可用性和读取效率。Redis是一个开源的，内存数据结构存储，可以用作数据库，缓存或消息代理。它具有内置数据结构的选项，如字符串，哈希，列表，集合，范围查询，地理空间索引等。它具有开箱即用的复制，事务，不同级别的磁盘持久性，高可用性和自动分区的选项。我们还可以添加持久性存储，而不是选择内存存储。
- en: Redis when combined with Node.js is like a match made in heaven as Node.js is
    highly efficient in network I/O. NPM repository has a lot of Redis packages to
    smoothen our development. The forerunners are `redis` ([https://www.npmjs.com/package/redis](https://www.npmjs.com/package/redis)),
    `ioredis` ([https://www.npmjs.com/package/ioredis](https://www.npmjs.com/package/ioredis))
    and `hiredis` ([https://www.npmjs.com/package/hiredis](https://www.npmjs.com/package/hiredis)).
    The `hiredis` package has lots of performance benefits. To get started with our
    development we first need to install `redis`. In the next section, we will setup
    our distributed caching in our project.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 当Redis与Node.js结合使用时，就像天作之合一样，因为Node.js在网络I/O方面非常高效。NPM仓库中有很多Redis包可以使我们的开发更加顺畅。领先的包有`redis`
    ([https://www.npmjs.com/package/redis](https://www.npmjs.com/package/redis))，`ioredis`
    ([https://www.npmjs.com/package/ioredis](https://www.npmjs.com/package/ioredis))和`hiredis`
    ([https://www.npmjs.com/package/hiredis](https://www.npmjs.com/package/hiredis))。`hiredis`包具有许多性能优势。要开始我们的开发，我们首先需要安装`redis`。在下一节中，我们将在项目中设置我们的分布式缓存。
- en: Setting up our distributed caching using redis
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用redis设置我们的分布式缓存
- en: 'To understand the caching mechanism let''s take a practical example and implement
    distributed caching. We will evolve around the shopping cart example. As dividing
    business capabilities in to different services is a good thing, we are dividing
    our inventory service and checkout service into two different services. So whenever
    a user adds anything to cart, we will never persist the data, but rather store
    it temporarily as this ain''t permanent or functionality changing data. We would
    persist such kind of ephemeral data into Redis as its read efficiency is super
    awesome. Our solution for this problem would be divided in to following steps:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解缓存机制，让我们举一个实际的例子并实现分布式缓存。我们将围绕购物车的例子进行演变。将业务能力划分到不同的服务是一件好事，我们将我们的库存服务和结账服务划分为两个不同的服务。所以每当用户添加任何东西到购物车时，我们都不会持久化数据，而是将其临时存储，因为这不是永久的或功能性改变的数据。我们会将这种短暂的数据存储到Redis中，因为它的读取效率非常棒。我们对这个问题的解决方案将分为以下步骤：
- en: First we focus on setting up our `redis` client. Like everything pull out a
    docker image by `docker pull redis`.
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们专注于设置我们的`redis`客户端。像所有其他东西一样，通过`docker pull redis`拉取一个docker镜像。
- en: Once the image is in our local just hit `docker run --name tsms -d redis`. There
    are also options for persistence storage volume. You just have to append a parameter
    `docker run --name tsms -d redis redis-server --appendonly yes`.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦镜像在我们的本地，只需运行`docker run --name tsms -d redis`。还有持久性存储卷的选项。您只需附加一个参数`docker
    run --name tsms -d redis redis-server --appendonly yes`。
- en: Verify redis running by command just hit `redis-cli`, you should be able see
    output pong.
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过命令`redis-cli`验证redis是否正在运行，您应该能够看到输出pong。
- en: Time to pull strings at Node.js. Install the module by adding `npm install redis
    --save` and `npm install @types/redis --save`.
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是时候在Node.js中拉取字符串了。通过添加`npm install redis --save`和`npm install @types/redis
    --save`来安装模块。
- en: Create a client by `import * as redis from 'redis'; let client=redis.createClient('127.0.0.1',
    6379);`.
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过`import * as redis from 'redis'; let client=redis.createClient('127.0.0.1',
    6379);`创建一个客户端。
- en: 'Use Redis just like any other datastore:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 像任何其他数据存储一样使用Redis：
- en: '[PRE32]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Similarly you can play with redis as and where required. It can be even used
    as command library. For detailed documentation please check this link ([https://www.npmjs.com/package/redis](https://www.npmjs.com/package/redis)).
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，您可以根据需要随时使用redis。它甚至可以用作命令库。有关详细文档，请查看此链接 ([https://www.npmjs.com/package/redis](https://www.npmjs.com/package/redis))。
- en: 'We had to replicate the code in each of the three service for Redis. To avoid
    that in the later section we would be using Bit: a code sharing tool.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不得不在每个服务中复制Redis的代码。为了避免这种情况，在后面的部分中，我们将使用Bit：一个代码共享工具。
- en: In the next section, we are going to see How to version microservices and make
    our microservices to have fail safe mechanism.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将看到如何对微服务进行版本控制，并使我们的微服务具有故障安全机制。
- en: Summary
  id: totrans-315
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we looked at collaboration among microservices. There are three
    kinds of microservice collaborations. Command-based collaboration (where one microservice
    uses an HTTP POST or PUT to make another microservice to perform any action),
    query-based collaboration (one microservice leverages an HTTP GET to query state
    of another service), and event-based collaboration (one microservice exposes an
    event feed to another microservice that can subscribe by polling the feed constantly
    for any new events). We saw various collaboration techniques, which included the
    pub-sub pattern and NextGen communication techniques such as gRPC, Thrift, and
    so on. We saw communication via service bus and saw how to share code among microservices.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们研究了微服务之间的协作。有三种类型的微服务协作。基于命令的协作（其中一个微服务使用HTTP POST或PUT来使另一个微服务执行任何操作），基于查询的协作（一个微服务利用HTTP
    GET来查询另一个服务的状态），以及基于事件的协作（一个微服务向另一个微服务公开事件源，后者可以通过不断轮询源来订阅任何新事件）。我们看到了各种协作技术，其中包括发布-订阅模式和NextGen通信技术，如gRPC、Thrift等。我们看到了通过服务总线进行通信，并了解了如何在微服务之间共享代码。
- en: In the next chapter, we are going to look into aspects of testing, monitoring,
    and documentation. We will look into different kinds of tests that we can do and
    how to write test cases and execute them before releasing them to production.
    Next we will look into contract testing using PACT. Then we will move on to debugging
    and looking into how to leverage debugging and profiling tools to effectively
    monitor the bottlenecks in our collaboration portal. Finally, we will generate
    documentation for our microservices using Swagger, which can be read by anyone.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将研究测试、监控和文档的方面。我们将研究我们可以进行的不同类型的测试，以及如何编写测试用例并在发布到生产环境之前执行它们。接下来，我们将研究使用PACT进行契约测试。然后，我们将转向调试，并研究如何利用调试和性能分析工具有效监视我们协作门户中的瓶颈。最后，我们将使用Swagger为我们的微服务生成文档，这些文档可以被任何人阅读。

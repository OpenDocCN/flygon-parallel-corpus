- en: '*Chapter 10*: Troubleshooting Kubernetes'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter reviews the best-practice methods for effectively troubleshooting
    Kubernetes clusters and the applications that run on them. This includes a discussion
    of common Kubernetes issues, as well as how to debug the masters and workers separately.
    The common Kubernetes issues will be discussed and taught in a case study format,
    split into cluster issues and application issues.
  prefs: []
  type: TYPE_NORMAL
- en: We will start with a discussion of some common Kubernetes failure modes, before
    moving on to how to best troubleshoot clusters and applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding failure modes for distributed applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Troubleshooting Kubernetes clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Troubleshooting applications on Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to run the commands detailed in this chapter, you will need a computer
    that supports the `kubectl` command-line tool along with a working Kubernetes
    cluster. See [*Chapter 1*](B14790_01_Final_PG_ePub.xhtml#_idTextAnchor016), *Communicating
    with Kubernetes*, for several methods for getting up and running with Kubernetes
    quickly, and for instructions on how to install the `kubectl` tool.
  prefs: []
  type: TYPE_NORMAL
- en: The code used in this chapter can be found in the book's GitHub repository at
    [https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter10](https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter10).
  prefs: []
  type: TYPE_NORMAL
- en: Understanding failure modes for distributed applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes components (and applications running on Kubernetes) are distributed
    by default if they run more than one replica. This can result in some interesting
    failure modes, which can be hard to debug.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, applications on Kubernetes are less prone to failure if they
    are stateless – in which case, the state is offloaded to a cache or database running
    outside of Kubernetes. Kubernetes primitives such as StatefulSets and PersistentVolumes
    can make it much easier to run stateful applications on Kubernetes – and with
    every release, the experience of running stateful applications on Kubernetes improves.
    Still, deciding to run fully stateful applications on Kubernetes introduces complexity
    and therefore the potential for failure.
  prefs: []
  type: TYPE_NORMAL
- en: Failure in distributed applications can be introduced by many different factors.
    Things as simple as network reliability and bandwidth constraints can cause major
    issues. These are so varied that *Peter Deutsch* at *Sun Microsystems* helped
    pen the *Fallacies of distributed computing* (along with *James Gosling*, who
    added the 8th point), which are commonly agreed-upon factors for failures in distributed
    applications. In the paper *Fallacies of distributed computing explained*, *Arnon
    Rotem-Gal-Oz* discusses the source of these fallacies ([https://www.rgoarchitects.com/Files/fallacies.pdf](https://www.rgoarchitects.com/Files/fallacies.pdf)).
  prefs: []
  type: TYPE_NORMAL
- en: 'The fallacies are as follows, in numerical order:'
  prefs: []
  type: TYPE_NORMAL
- en: The network is reliable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Latency is zero.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bandwidth is infinite.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The network is secure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The topology doesn't change.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There is one administrator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Transport cost is zero.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The network is homogeneous.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kubernetes has been engineered and developed with these fallacies in mind and
    is therefore more tolerant. It also helps address these issues for applications
    running on Kubernetes – but not perfectly. It is therefore very possible that
    your applications, when containerized and running on Kubernetes, will exhibit
    problems when faced with any of these issues. Each fallacy, when assumed to be
    untrue and taken to its logical conclusion, can introduce failure modes in distributed
    applications. Let's go through each of the fallacies as applied to Kubernetes
    and applications running on Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: The network is reliable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Applications running on multiple logical machines must communicate over the
    internet – so any reliability problems in the network can introduce issues. On
    Kubernetes specifically, the control plane itself can be distributed in a highly
    available setup (which means a setup with multiple master Nodes – see [*Chapter
    1*](B14790_01_Final_PG_ePub.xhtml#_idTextAnchor016), *Communicating with Kubernetes*),
    which means that failure modes can be introduced at the controller level. If the
    network is unreliable, then kubelets may not be able to communicate with the control
    plane, leading to Pod placement issues.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the Nodes of the control plane may not be able to communicate with
    each other – though `etcd` is of course built with a consensus protocol that can
    tolerate communication failures.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the worker Nodes may not be able to communicate with each other – which,
    in a microservices scenario, could cause problems depending on Pod placement.
    In some cases, the workers may all be able to communicate with the control plane
    while still not being able to communicate with each other, which can cause issues
    with the Kubernetes overlay network.
  prefs: []
  type: TYPE_NORMAL
- en: As with general unreliability, latency can also cause many of the same problems.
  prefs: []
  type: TYPE_NORMAL
- en: Latency is zero
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If network latency is significant, many of the same failures as with network
    unreliability will also apply. For instance, calls between kubelets and the control
    plane may fail, leading to periods of inaccuracy in `etcd` because the control
    plane may not be able to contact the kubelets – or properly update `etcd`. Similarly,
    requests could be lost between applications running on worker Nodes that would
    otherwise work perfectly if the applications were collocated on the same Node.
  prefs: []
  type: TYPE_NORMAL
- en: Bandwidth is infinite
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bandwidth limitations can expose similar issues as with the previous two fallacies.
    Kubernetes does not currently have a fully supported method to place Pods based
    on bandwidth subscription. This means that Nodes that are hitting their network
    bandwidth limits can still have new Pods scheduled to them, causing increased
    failure rates and latency issues for requests. There have been requests to add
    this as a core Kubernetes scheduling feature (basically, a way to schedule on
    Node bandwidth consumption as with CPU and memory), but for now, the solutions
    are mostly restricted to **Container Network Interface** (**CNI**) plugins.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: For instance, the CNI bandwidth plugin supports traffic shaping at the Pod level
    – see [https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#support-traffic-shaping](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#support-traffic-shaping).
  prefs: []
  type: TYPE_NORMAL
- en: Third-party Kubernetes networking implementations may also provide additional
    features around bandwidth – and many are compatible with the CNI bandwidth plugin.
  prefs: []
  type: TYPE_NORMAL
- en: The network is secure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Network security has effects that reach far beyond Kubernetes – as any insecure
    network is privy to a whole class of attacks. Attackers may be able to gain SSH
    access to the master or worker Nodes in a Kubernetes cluster, which can cause
    significant breaches. Since so much of Kubernetes' magic happens over the network
    rather than in a single machine, access to the network is doubly problematic in
    an attack situation.
  prefs: []
  type: TYPE_NORMAL
- en: The topology doesn't change
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This fallacy is extra relevant in the context of Kubernetes, since not only
    can the meta network topology change with new Nodes being added and removed –
    the overlay network topology is also altered directly by the Kubernetes control
    plane and CNI.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, an application that is running in one logical location at one
    moment may be running in a completely different spot in the network. For this
    reason, the use of Pod IPs to identify logical applications is a bad idea – this
    is one of the purposes of the Service abstraction (see [*Chapter 5*](B14790_05_Final_PG_ePub.xhtml#_idTextAnchor127),
    *Service and Ingress* – *Communicating with the outside world*). Any application
    concerns that do not assume an indefinite topology (at least concerning IPs) within
    the cluster may have issues. As an example, routing applications to a specific
    Pod IP only works until something happens to that Pod. If that Pod shuts down,
    the Deployment (for instance) controlling it will start a new Pod to replace it,
    but the IP will be completely different. A cluster DNS (and by extension, Services)
    offers a much better way to make requests between applications in a cluster, unless
    your application has the capability to adjust on the fly to cluster changes such
    as Pod placements.
  prefs: []
  type: TYPE_NORMAL
- en: There is only one administrator
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Multiple administrators and conflicting rules can cause issues in the base network,
    and multiple Kubernetes administrators can cause further issues by changing resource
    configurations such as Pod resource limits, leading to unintended behavior. Use
    of Kubernetes **Role-Based Access Control** (**RBAC**) capabilities can help address
    this by giving Kubernetes users only the permissions they need (read-only, for
    instance).
  prefs: []
  type: TYPE_NORMAL
- en: Transport cost is zero
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are two common ways this fallacy is interpreted. Firstly, that the latency
    cost of transport is zero – which is obviously untrue, as the speed of data transfer
    over wires is not infinite, and lower-level networking concerns add latency. This
    is essentially identical to the effects stemming from the *latency is zero* fallacy.
  prefs: []
  type: TYPE_NORMAL
- en: Secondly, this statement can be interpreted to mean that the cost of creating
    and operating a network for the purposes of transport is zero – as in zero dollars
    and zero cents. While also being patently untrue (just look at your cloud provider's
    data transfer fees for proof of this), this does not specifically correspond to
    application troubleshooting on Kubernetes, so we will focus on the first interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: The network is homogeneous
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This final fallacy has less to do with Kubernetes' components, and more to do
    with applications running on Kubernetes. However, the fact is that developers
    operating in today's environment are well aware that application networking may
    have different implementations across applications – from HTTP 1 and 2 to protocols
    such as *gRPC*.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've reviewed some major reasons for application failure on Kubernetes,
    we can dive into the actual process of troubleshooting both Kubernetes and applications
    that run on Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting Kubernetes clusters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since Kubernetes is a distributed system that has been designed to tolerate
    failure where applications are run, most (but not all) issues tend to be centered
    on the control plane and API. A worker Node failing, in most scenarios, will just
    result in the Pods being rescheduled to another Node – though compounding factors
    can introduce issues.
  prefs: []
  type: TYPE_NORMAL
- en: In order to walk through common Kubernetes cluster issue scenarios, we will
    use a case study methodology. This should give you all the tools you need to investigate
    real-world cluster issues. Our first case study is centered on the failure of
    the API server itself.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: For the purposes of this tutorial, we will assume a self-managed cluster. Managed
    Kubernetes services such as EKS, AKS, and GKE generally remove some of the failure
    domains (by autoscaling and managing master Nodes, for instance). A good rule
    is to check your managed service documentation first, as any issues may be specific
    to the implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Case study – Kubernetes Pod placement failure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s set the scene. Your cluster is up and running, but you are experiencing
    a problem with Pod scheduling. Pods stay stuck in the `Pending` state indefinitely.
    Let''s confirm this with the command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the command is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, none of our Pods are running. Furthermore, we''re running three
    replicas of the application and none of them are getting scheduled. A great next
    step would be to check the Node state and see if there are any issues there. Run
    the following command to get the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This output gives us some good information – we only have one worker Node, and
    it isn't available for scheduling. When a `get` command doesn't give us enough
    information to go by, `describe` is usually a good next step.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s run `kubectl describe node node-01` and check the `conditions` key.
    We''ve dropped a column in order to fit everything neatly on the page, but the
    most important columns are there:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Describe Node Conditions output](image/B14790_10_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.1 – Describe Node Conditions output
  prefs: []
  type: TYPE_NORMAL
- en: 'What we have here is an interesting split: both `MemoryPressure` and `DiskPressure`
    are fine, while the `OutOfDisk` and `Ready` conditions are unknown with the message
    `kubelet stopped posting node status`. At a first glance this seems nonsensical
    – how can `MemoryPressure` and `DiskPressure` be fine while the kubelet stopped
    working?'
  prefs: []
  type: TYPE_NORMAL
- en: The important part is in the `LastTransitionTime` column. The kubelet's most
    recent memory- and disk-specific communication sent positive statuses. Then, at
    a later time, the kubelet stopped posting its Node status, leading to `Unknown`
    statuses for the `OutOfDisk` and `Ready` conditions.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we're certain that our Node is the problem – the kubelet is no
    longer sending the Node status to the control plane. However, we don't know why
    this occurred. It could be a network error, a problem with the machine itself,
    or something more specific. We'll need to dig further to figure it out.
  prefs: []
  type: TYPE_NORMAL
- en: A good next step here is to get closer to our malfunctioning Node, as we can
    reasonably assume that it is encountering some sort of issue. If you have access
    to the `node-01` VM or machine, now is a great time to SSH into it. Once we are
    in the machine, let's start troubleshooting further.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s check whether the Node can access the control plane over the
    network. If not, this is an obvious reason why the kubelet wouldn''t be able to
    post statuses. Let''s assume a scenario where our cluster control plane (for instance
    an on-premise load balancer) is available at `10.231.0.1`. In order to check whether
    our Node can access the Kubernetes API server, we can ping the control plane as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: In order to find the control plane IP or DNS, please check your cluster configuration.
    In a managed Kubernetes service such as AWS Elastic Kubernetes Service or Azure
    AKS, this will likely be available to view in the console. If you bootstrapped
    your own cluster using kubeadm, for instance, this is a value that you provided
    during the setup as part of the installation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s check the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: That confirms it – our Node can indeed talk to the Kubernetes control plane.
    So, the network isn't the issue. Next, let's check the actual kubelet service.
    The Node itself seems to be operational, and the network is fine, so logically,
    the kubelet is the next thing to check.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes components run as system services on Linux Nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: On Windows Nodes, the troubleshooting instructions will be slightly different
    – see the Kubernetes documentation for more information ([https://kubernetes.io/docs/setup/production-environment/windows/intro-windows-in-kubernetes/](https://kubernetes.io/docs/setup/production-environment/windows/intro-windows-in-kubernetes/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to find out the status of our `kubelet` service, we can run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Looks like our kubelet is currently not running – it exited with a failure.
    This explains everything we've seen as far as cluster status and Pod issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'To actually fix the issue, we can first try to restart the `kubelet` using
    the command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s re-check the status of our `kubelet` with our status command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: It looks like the `kubelet` failed again. We're going to need to source some
    additional information about the failure mode in order to find out what happened.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use the `journalctl` command to find out if there are any relevant logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should show us logs of the `kubelet` service where a failure occurred:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Looks like we've found the cause – Kubernetes does not support running on Linux
    machines with `swap` set to `on` by default. Our only choices here are either
    disabling `swap` or restarting the `kubelet` with the `--fail-swap-on` flag set
    to `false`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our case, we''ll just change the `swap` setting by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, restart the `kubelet` service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let''s check to see if our fix worked. Check the Nodes using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This should show output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Our Node is finally posting a `Ready` status!
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s check on our Pod with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This should show output like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Success! Our cluster is healthy, and our Pods are running.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's look at how to troubleshoot applications on Kubernetes once any
    cluster issues are sorted out.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting applications on Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A perfectly running Kubernetes cluster may still have application issues to
    debug. These could be due to bugs in the application itself, or due to misconfigurations
    in the Kubernetes resources that make up the application. As with troubleshooting
    the cluster, we will dive into these concepts by using a case study.
  prefs: []
  type: TYPE_NORMAL
- en: Case study 1 – Service not responding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We're going to break this section down into troubleshooting at various levels
    of the Kubernetes stack, starting with higher-level components, then ending with
    a deep dive into Pod and container debugging.
  prefs: []
  type: TYPE_NORMAL
- en: Let's assume that we have configured our application `app-1` to respond to requests
    via a `NodePort` Service, on port `32688`. The application listens on port `80`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can try to access our application via a `curl` request on one of our Nodes.
    The command will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the `curl` command if it fails will look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, our `NodePort` Service isn''t routing requests to any Pod. Following
    our typical debug path, let''s first see which resources are running in the cluster
    with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the `-o` wide flag to see additional information. Next, run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: It is clear that our Service exists with a proper Node port – but our requests
    are not being routed to the Pods, as is obvious from the failed `curl` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see which routes our Service has set up, let''s use the `get endpoints`
    command. This will list the Pod IPs, if any, for the Service as configured:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s check the resulting output of the command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Well, something is definitely wrong here.
  prefs: []
  type: TYPE_NORMAL
- en: Our Service isn't pointing to any Pods. This likely means that there aren't
    any Pods matching our Service selector available. This could be because there
    are no Pods available at all – or because those Pods don't properly match the
    Service selector.
  prefs: []
  type: TYPE_NORMAL
- en: 'To check on our Service selector, let''s take the next step in the debug path
    and use the `describe` command as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us an output like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, our Service is configured to talk to the correct port on our
    application. However, the selector is looking for Pods that match the label `app
    = app-11`. Since we know our application is named `app-1`, this could be the cause
    of our issue.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s edit our Service to look for the correct Pod label, `app-1`, running
    another `describe` command to be sure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, you can see in the output that our Service is looking for the proper Pod
    selector, but we still do not have any endpoints. Let''s check to see what is
    going on with our Pods by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This shows the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Our Pods are still waiting to be scheduled. This explains why, even with the
    proper selector, our Service isn''t functioning. To get some granularity on why
    our Pods aren''t being scheduled, let''s use the `describe` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output. Let''s focus on the `Events` section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2 – Describe Pod Events output](image/B14790_10_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.2 – Describe Pod Events output
  prefs: []
  type: TYPE_NORMAL
- en: From the `Events` section, it looks like our Pod is failing to be scheduled
    due to container image pull failure. There are many possible reasons for this
    – our cluster may not have the necessary authentication mechanisms to pull from
    a private repository, for instance – but that would present a different error
    message.
  prefs: []
  type: TYPE_NORMAL
- en: From the context and the `Events` output, we can probably assume that the issue
    is that our Pod definition is looking for a container named `myappimage:lates`
    instead of `myappimage:latest`.
  prefs: []
  type: TYPE_NORMAL
- en: Let's update our Deployment spec with the proper image name and roll out the
    update.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following command to get confirmation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The output looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Our Pods are now running – let''s check to see that our Service has registered
    the proper endpoints. Use the following command to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Success! Our Service is properly pointing to our application Pods.
  prefs: []
  type: TYPE_NORMAL
- en: In the next case study, we'll dig a bit deeper by troubleshooting a Pod with
    incorrect startup parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Case study 2 – Incorrect Pod startup command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's assume we have our Service properly configured and our Pods running and
    passing health checks. However, our Pod is not responding to requests as we would
    expect. We are sure that this is less of a Kubernetes problem and more of an application
    or configuration problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our application container works as follows: it takes a startup command with
    a flag for `color` and combines it with a variable for `version number` based
    on the container''s `image` tag, and echoes that back to the requester. We are
    expecting our application to return `green 3`.'
  prefs: []
  type: TYPE_NORMAL
- en: Thankfully, Kubernetes gives us some good tools to debug applications, which
    we can use to delve into our specific containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s `curl` the application to see what response we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: We expected `green 3` but got `red 2`, so it looks like something is wrong with
    the input, and the version number variable. Let's start with the former.
  prefs: []
  type: TYPE_NORMAL
- en: 'As usual, we begin with checking our Pods with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Everything looks good in this output. It seems that our app is running as part
    of a Deployment (and therefore, a ReplicaSet) – we can make sure by running the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s look a bit closer at our Deployment to see how our Pods are configured
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The output looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Broken-deployment-output.yaml
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Let's see if we can fix our issue, which is really quite simple. We're using
    the wrong version of our application, and our startup command is wrong. In this
    case, let's assume we don't have a file with our Deployment spec – so let's just
    edit it in place.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use `kubectl edit deployment app-1-pod`, and edit the Pod spec to the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: fixed-deployment-output.yaml
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the Deployment is saved, you should start seeing your new Pods come up.
    Let''s double-check by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'And finally – let''s make a `curl` request to check that everything is working:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Success!
  prefs: []
  type: TYPE_NORMAL
- en: Case study 3 – Pod application malfunction with logs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After spending the previous chapter, [*Chapter 9*](B14790_9_Final_PG_ePub.xhtml#_idTextAnchor212),
    *Observability on Kubernetes*, implementing observability to our applications,
    let's take a look at a case where those tools can really come in handy. We will
    use manual `kubectl` commands for the purposes of this case study – but know that
    by aggregating logs (for instance, in our EFK stack implementation), we could
    make the process of debugging this application significantly easier.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case study, we once again have a deployment of Pods – to check it,
    let''s run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: It looks like, in this case, we are working with a StatefulSet instead of a
    Deployment – a key characteristic here is the incrementing Pod IDs starting from
    0.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can confirm this by checking for StatefulSets using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Let's take a closer look at our StatefulSet with `kubectl get statefulset -o
    yaml app-2-ss`. By using the `get` command along with `-o yaml` we can get our
    `describe` output in the same format as the typical Kubernetes resource YAML.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of the preceding command is as follows. We''ve removed the Pod spec
    section to keep it shorter:'
  prefs: []
  type: TYPE_NORMAL
- en: statefulset-output.yaml
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: We know that our app is using a service. Let's see which one it is!
  prefs: []
  type: TYPE_NORMAL
- en: 'Run `kubectl get services -o wide`. The output should be something like the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s clear that our service is called `app-2-svc`. Let''s see our exact service
    definition using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'To see exactly what our application is returning for a given input, we can
    use `curl` on our `NodePort` Service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Based on our existing knowledge of the application, we would assume that this
    call should return `2`, not `3`. The application developer on our team has asked
    us to investigate any logging output that would help them figure out what the
    issue is.
  prefs: []
  type: TYPE_NORMAL
- en: 'We know from previous chapters that you can investigate the logging output
    with `kubectl logs <pod name>`. In our case, we have three replicas of our application,
    so we may not be able to find our logs in a single iteration of this command.
    Let''s pick a Pod at random and see if it was the one that served our request:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: It looks like this was not the Pod that served our request, as our application
    developer has told us that the application definitely logs to `stdout` when a
    `GET` request is made to the server.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of checking through the other two Pods individually, we can use a joint
    command to get logs from all three Pods. The command will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'And the output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: That did the trick – and what's more, we can see some good insight into our
    issue.
  prefs: []
  type: TYPE_NORMAL
- en: Everything seems as we would expect, other than the log line reading `Second
    Number`. Our request clearly used `1plus1` as the query string, which would make
    both the first number and the second number (split by the operator value) equal
    to one.
  prefs: []
  type: TYPE_NORMAL
- en: This will take some additional digging. We could triage this issue by sending
    additional requests and checking the output in order to guess what is happening,
    but in this case it may be better to just get bash access to the Pod and figure
    out what is going on.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s check our Pod spec, which was removed from the preceding StatefulSet
    YAML. To see the full StatefulSet spec, check the GitHub repository:'
  prefs: []
  type: TYPE_NORMAL
- en: Statefulset-output.yaml
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: It looks like our Pod is mounting an empty volume as a scratch disk. It also
    has two containers in each Pod – a sidecar used for application tracing, and our
    app itself. We'll need this information to `ssh` into one of the Pods (it doesn't
    matter which one for this exercise) using the `kubectl exec` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can do it using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'This command should give you a bash terminal as the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Now, using the terminal we just created, we should be able to investigate our
    application code. For the purposes of this tutorial, we are using a highly simplified
    Node.js application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s check our Pod filesystem to see what we''re working with using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: Looks like we have two JavaScript files, and our previously mentioned `scratch`
    folder. It's probably a good bet to assume that `app.js` contains the logic for
    bootstrapping and serving the application, and `calculate.js` contains our controller
    code for doing the calculations.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can confirm by printing the contents of the `calculate.js` file:'
  prefs: []
  type: TYPE_NORMAL
- en: Broken-calculate.js
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Even with little to no knowledge of JavaScript, it's pretty obvious what the
    issue is here. The code is incrementing the `second` variable before performing
    the calculation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we''re inside of the Pod, and we''re using a non-compiled language, we
    can actually edit this file inline! Let''s use `vi` (or any text editor) to correct
    this file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'And edit the file to read as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: fixed-calculate.js
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: Now, our code should run properly. It's important to state that this fix is
    only temporary. As soon as our Pod shuts down or gets replaced by another Pod,
    it will revert to the code that was originally included in the container image.
    However, this pattern does allow us to try out quick fixes.
  prefs: []
  type: TYPE_NORMAL
- en: 'After exiting the `exec` session using the `exit` bash command, let''s try
    our URL again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, our hotfixed container shows the right result! Now, we can update
    our code and Docker image in a more permanent way with our fix. Using `exec` is
    a great way to troubleshoot and debug running containers.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about troubleshooting applications on Kubernetes.
    First, we covered some common failure modes of distributed applications. Then,
    we learned how to triage issues with Kubernetes components. Finally, we reviewed
    several scenarios where Kubernetes configuration and application debugging were
    performed. The Kubernetes debugging and troubleshooting techniques you learned
    in this chapter will help you when triaging issues with any Kubernetes clusters
    and applications you may work on.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, [*Chapter 11*](B14790_11_Final_PG_ePub.xhtml#_idTextAnchor251),
    *Template Code Generation and CI/CD on Kubernetes*, we will look into some ecosystem
    extensions for templating Kubernetes resource manifests and continuous integration/continuous
    deployment with Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How does the distributed systems fallacy, "*the topology doesn't change*," apply
    to applications on Kubernetes?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How are the Kubernetes control plane components (and kubelet) implemented at
    the OS level?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How would you go about debugging an issue where Pods are stuck in the `Pending`
    status? What would be your first step? And your second?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The CNI plugin for traffic shaping: [https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#support-traffic-shaping](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#support-traffic-shaping)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL

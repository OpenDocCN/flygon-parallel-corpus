- en: Deadlocks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deadlocks, one of the most common concurrency problems, will be the first problem
    that we analyze in this book. In this chapter, we will discuss the theoretical
    causes of deadlocks in concurrent programming. We will cover a classical synchronization
    problem in concurrency, called the Dining Philosophers problem, as a real-life
    example of deadlock. We will also illustrate an actual implementation of deadlock
    in Python. We will discuss several methods to address the problem. This chapter
    will also cover the concept of livelock, which is relevant to deadlock and is
    a relatively common problem in concurrent programming.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind deadlock, and how to simulate it in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common solutions to deadlock, and how to implement them in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The concept of livelock, and its connection to deadlock
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following is a list of prerequisites for this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that you have Python 3 installed on your computer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Download the GitHub repository at** [https://github.com/PacktPublishing/Mastering-Concurrency-in-Python](https://github.com/PacktPublishing/Mastering-Concurrency-in-Python)**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will be working with the subfolder titled **`Chapter12`**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check out the following video to see the Code in Action: [http://bit.ly/2r2WKaU](http://bit.ly/2r2WKaU)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The concept of deadlock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the field of computer science, deadlock refers to a specific situation in
    concurrent programming, in which no progress can be made and the program becomes
    locked in its current state. In most cases, this phenomenon is caused by a lack
    of, or mishandled, coordination between different lock objects (for thread synchronization
    purposes). In this section, we will discuss a thought experiment commonly known
    as the Dining Philosophers problem, in order to illustrate the concept of deadlock
    and its causes; from there, you will learn how to simulate the problem in a Python
    concurrent program.
  prefs: []
  type: TYPE_NORMAL
- en: The Dining Philosophers problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Dining Philosophers problem was first introduced by Edgar Dijkstra (who,
    as you learned in **[Chapter 1](0159c46a-c66b-4ba3-87b5-81dbeb3bcf02.xhtml)**, *Advanced
    Introduction to Concurrent and Parallel Programming* was a leading pioneer in
    concurrent programming) in 1965\. The problem was first demonstrated using different
    technical terms (resource contention in computer systems), and was later rephrased
    by Tony Hoare, a British computer scientist and the inventor of the quicksort
    sorting algorithm. The problem statement is as follows.
  prefs: []
  type: TYPE_NORMAL
- en: 'Five philosophers sit around a table, and each has a bowl of food in front
    of them. Placed between these five bowls of food are five forks, so each philosopher
    has a fork on their left side, and one on their right side. This setup is demonstrated
    by the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/4d3213aa-ee0f-4d22-a967-af295e8e34b5.png)'
  prefs: []
  type: TYPE_IMG
- en: An illustration of the Dining Philosophers problem
  prefs: []
  type: TYPE_NORMAL
- en: Each silent philosopher is to alternate between thinking and eating. Each philosopher
    is required to have both of the forks around them to be able to pick up the food
    from their individual bowl, and no fork can be shared between two or more different
    philosophers. When a philosopher finishes eating a specific amount of food, they
    are to place both of the forks back in their respective, original locations. At
    this point, the philosophers around that philosopher will be able to use those
    forks.
  prefs: []
  type: TYPE_NORMAL
- en: Since the philosophers are silent and cannot communicate with each other, they
    have no method to let each other know they need the forks to eat. In other words,
    the only way for a philosopher to eat is to have both of the forks already available
    to them. The question of this problem is to design a set of instructions for the
    philosophers to efficiently switch between eating and thinking, so that each philosopher
    is provided with enough food.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, a potential approach to this problem would be the following set of instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: A philosopher must think until the fork on their left side becomes available.
    When that happens, the philosopher is to pick it up.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A philosopher must think until the fork on their right side becomes available.
    When that happens, the philosopher is to pick it up.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If a philosopher is holding two forks, they will eat a specific amount of food
    from the bowl in front of them, and then the following will apply:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Afterwards, the philosopher has to put the right fork down in its original place
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Afterwards, the philosopher has to put the left fork down in its original place
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The process repeats from the first bullet point.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is quite clear how this set of instructions can lead to a situation where
    no progress can be made; namely, if at the beginning, all of the philosophers
    start to execute their instructions at the same time. Since all of the forks are
    on the table at the beginning, and are therefore available to be picked up by
    nearby philosophers, each philosopher will be able to execute the first instruction
    (picking up the fork on their left side).
  prefs: []
  type: TYPE_NORMAL
- en: Now, after this step, each philosopher will be holding a fork with their left
    hand, and no forks will be left on the table. Since no philosopher has both forks
    in their hands, they cannot proceed to eat their food. Furthermore, the set of
    instructions that they were given specifies that only after a philosopher has
    eaten a specific amount of food can they put their forks down on the table. This
    means that as long as a philosopher has not eaten, they will not release any fork
    that they are holding.
  prefs: []
  type: TYPE_NORMAL
- en: So, as each philosopher is holding only one fork with their left hand, they
    cannot proceed to eat or put down the fork they are holding. The only time a philosopher
    gets to eat their food is when their neighboring philosopher puts their fork down,
    which is only possible if they can eat their own food; this creates a never-ending
    circle of conditions that can never be satisfied. This situation is, in essence,
    the nature of a deadlock, in which all of the elements of a system are stuck in
    place, and no progress can be made.
  prefs: []
  type: TYPE_NORMAL
- en: Deadlock in a concurrent system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the example of the Dining Philosophers problem in mind, let us consider
    the formal concept of deadlock, and the relevant theories around it. Given a concurrent
    program with multiple threads or processes, the execution flow enters a situation
    of deadlock if a process (or thread) is waiting on a resource that is being held
    and utilized by another process, which is, in turn, waiting for another resource
    that is held by a different process. In other words, processes cannot proceed
    with their execution instructions while waiting for resources that can only be
    released after the execution is completed; therefore, these processes are unable
    to change their execution states.
  prefs: []
  type: TYPE_NORMAL
- en: 'Deadlock is also defined by the conditions that a concurrent program needs
    to have at the same time in order for deadlock to occur. These conditions were
    first proposed by the computer scientist Edward G. Coffman, Jr., and are therefore
    known as the Coffman conditions. These conditions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: At least one resource has to be in a non-shareable state. This means that that
    resource is being held by an individual process (or thread), and cannot be accessed
    by others; the resource can only be accessed and held by a single process (or
    thread) at any given time. This condition is also known as mutual exclusion.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There exists one process (or thread) that is simultaneously accessing a resource
    and waiting for another held by other processes (or threads). In other words,
    this process (or thread) needs access to two resources in order to execute its
    instructions, one of which it is already holding, the other of which it is waiting
    for from other processes (or threads). This condition is called hold and wait.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resources can only be released by a process (or a thread) holding them if there
    are specific instructions for the process (or thread) to do so. This is to say
    that unless the process (or thread) voluntarily and actively releases the resource,
    that resource remains in a non-shareable state. This is the no preemption condition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The final condition is called circular wait. As suggested by the name, this
    condition specifies that there exists a set of processes (or threads) such that the
    first process (or thread) in the set is in a waiting state for a resource to be
    released by the second process (or thread), which, in turn, needs to be waiting
    for the third process (or thread); finally, the last process (or thread) in the
    set is waiting for the first one.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let us quickly take a look at a basic example of deadlock. Consider a concurrent
    program in which there are two different processes (process **A** and process
    **B**), and two different resources (resource **R1** and resource **R2**), as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/e440b909-cfa2-4257-9c5c-6ab2a8eb71e2.png)'
  prefs: []
  type: TYPE_IMG
- en: Sample deadlock diagram
  prefs: []
  type: TYPE_NORMAL
- en: Neither of the resources can be shared across separate processes, and each process
    needs to access both resources to execute its instructions. Take process **A**,
    for example. It is already holding resource **R1**, but its also needs **R2**
    to proceed with its execution. However, **R2** cannot be acquired by process **A**,
    as it is being held by process **B**. So, process **A** cannot proceed. The same
    goes for process **B**, which is holding **R2** and needs **R1** to proceed. **R1**
    is, in turn, held by process **A**.
  prefs: []
  type: TYPE_NORMAL
- en: Python simulation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will implement the preceding situation in an actual Python
    program. Specifically, we will have two locks (we will call them lock A and lock
    B), and two separate threads interacting with the locks (thread A and thread B).
    In our program, we will set up a situation in which thread A has acquired lock
    A and is waiting to acquire lock B, which has already been acquired by thread
    B, which is, in turn, waiting for lock A to be released.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have already downloaded the code for this book from the GitHub page,
    go ahead and navigate to the `Chapter12` folder. Let us consider the `Chapter12/example1.py`
    file, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In this script, the `thread_a()` and `thread_b()` functions specify our thread
    A and thread B, respectively. In our main program, we also have two `threading.Lock`
    objects: lock A and lock B. The general structure of the thread instructions is
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Start the thread
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try to acquire the lock with the same name as the thread (thread A will try
    to acquire lock A, and thread B will try to acquire lock B)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform some calculations
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try to acquire the other lock (thread A will try to acquire lock B, and thread
    B will try to acquire lock A)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform some other calculations
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Release both locks
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: End the thread
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that we are using the `time.sleep()` function to simulate the action of
    some calculations being processed.
  prefs: []
  type: TYPE_NORMAL
- en: First of all, we are starting both thread A and thread B almost simultaneously,
    within the main program. With the structure of the thread instruction set in mind,
    we can see that at this point, both threads will be initiated; thread A will try
    to acquire lock A, and will succeed in doing so, since lock A is still available
    at this point. The same goes for thread B and lock B. The two threads will then
    go on to perform some calculations on their own.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us consider the current state of our program: lock A has been acquired
    by thread A, and lock B has been acquired by thread B. After their respective
    calculation processes are complete, thread A will then try to acquire lock B,
    and thread B will try to acquire lock A. We can easily see that this is the beginning
    of our deadlock situation: since lock B is already being held by thread B, and
    cannot be acquired by thread A, thread B, for the same reason, cannot acquire
    lock A.'
  prefs: []
  type: TYPE_NORMAL
- en: Both of the threads will now wait infinitely, in order to acquire their respective
    second lock. However, the only way a lock can be released is for a thread to continue
    its execution instructions and release all of the locks it has at the end. Our
    program will therefore be stuck in its execution at this point, and no further
    progress will be made.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram further illustrates the process of how the deadlock unfolds,
    in sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bd657a2f-bc26-424b-a3ef-06c0bd441ffa.png)'
  prefs: []
  type: TYPE_IMG
- en: Deadlock sequence diagram
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s see the deadlock that we have created in action. Run the script,
    and you should obtain the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As we discussed, since each thread is trying to acquire a lock that is currently
    held by the other thread, and the only way for a lock to be released is for a
    thread to continue its execution. This is a deadlock, and your program will hang
    infinitely, never reaching the final print statement in the last line of the program.
  prefs: []
  type: TYPE_NORMAL
- en: Approaches to deadlock situations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have seen, deadlock can lead our concurrent programs to an infinite hang,
    which is undesirable in every way. In this section, we will be discussing potential
    approaches to prevent deadlocks from occurring. Intuitively, each approach looks
    to eliminate one of the four Coffman conditions from our program, in order to
    prevent deadlocks.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing ranking among resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From both the Dining Philosophers problem and our Python example, we can see
    that the last condition of the four Coffman conditions, circular wait, is at the
    heart of the problem of deadlock. It specifies that the different processes (or
    threads) in our concurrent program wait for resources held by other processes
    (or threads) in a circular manner. Giving this a closer look, we can see that
    the root cause for this condition is the order (or lack thereof) in which the
    processes (or threads) access the resources.
  prefs: []
  type: TYPE_NORMAL
- en: In the Dining Philosophers problem, each philosopher is instructed to pick up
    the fork on their left side first, while in our Python example, the threads always
    try to acquire the locks with the same name before performing any calculations.
    As you have seen, when the philosophers want to start eating at the same time,
    they will pick up their respective left forks, and will be stuck in an infinite
    wait; similarly, when the two threads start their execution at the same time,
    they will acquire their individual locks, and, again, they will wait for the other
    locks infinitely.
  prefs: []
  type: TYPE_NORMAL
- en: The conclusion that we can infer from this is that if, instead of accessing
    the resources arbitrarily, the processes (or threads) were to access them in a
    predetermined, static order, the circular nature of the way that they acquire
    and wait for the resources will be eliminated. So, for our two-lock Python example,
    instead of having thread A try to acquire lock A and thread B try to acquire lock
    B in their respective execution instructions, we will require that both threads
    try to acquire the locks in the same order. For example, both threads will now
    try to acquire lock A first, perform some calculations, try to acquire lock B,
    perform further calculations, and finally, release both threads.
  prefs: []
  type: TYPE_NORMAL
- en: 'This change is implemented in the `Chapter12/example2.py` file, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This version of the script is now able to finish its execution, and should
    produce the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This approach efficiently eliminates the problem of deadlock in our two-lock
    example, but how well does it hold up for the Dining Philosophers problem? To
    answer this question, let''s try to simulate the problem and the solution in Python
    by ourselves. The `Chapter12/example3.py` file contains the implementation of
    the Dining Philosophers problem in Python, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here, we have the `philospher()` function as the underlying logic for our separate
    threads. It takes in two `Threading.Lock` objects and simulates the previously
    discussed eating procedure, with two context managers. In our main program, we
    create a list of five lock objects, named `forks`, and a list of five threads,
    named `phils`, with the specification that the first thread will take in the first
    and second locks, the second thread will take in the second and third locks, and
    so on; and the fifth thread will take in the fifth and first locks (in order).
    Finally, we start all five threads simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the script, and it can easily be observed that deadlock occurs almost immediately.
    The following is my output, up until the program hangs infinitely:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The question that naturally follows is: how can we implement an order in which
    the locks are acquired in the `philosopher()` function? We will be using the built-in
    `id()` function in Python, which returns the unique, constant identity of the
    parameter, as the keys to sort the lock objects. We will also implement a custom
    context manager, in order to factor out this sorting logic in a separate class.
    Navigate to `Chapter12/example4.py` for this specific implementation, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: With the main program remaining in the same, this script will produce an output
    showing that this solution of ranking can effectively address the Dining Philosophers
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: However, there is a problem with this approach when it is applied to some particular
    cases. Keeping the high-level idea of concurrency in mind, we know that one of
    our main goals when applying concurrency to our programs is to improve the speed.
    Let us go back to our two-lock example and examine the execution time of our program
    with resource ranking implemented. Take a look at the `Chapter12/example5.py`
    file; it is simply the two-lock program with ranked (or ordered) locking implemented,
    combined with a timer that is added to keep track of how much time it takes for
    the two threads to finish executing.
  prefs: []
  type: TYPE_NORMAL
- en: 'After running the script, your output should look similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: You can see that the combined execution of both threads took around 14 seconds.
    However, if we take a closer look at the specific instructions in the two threads,
    we can see that aside from interacting with the locks, thread A would take around
    4 seconds to do its calculations (simulated by two `time.sleep(2)` commands),
    while thread B would take around 10 seconds (two `time.sleep(5)` commands).
  prefs: []
  type: TYPE_NORMAL
- en: 'Does this mean that our program is taking as long as it would if we were to
    execute the two threads sequentially? We will test this theory with our `Chapter12/example6.py`
    file, in which we specify that each thread should execute its instructions one
    at a time, in our main program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Run this script, and you will see that this sequential version of our two-lock
    program will take the same amount of time as its concurrent counterpart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This interesting phenomenon is a direct result of the heavy requirements that
    we have placed on the locks in the program. In other words, since each thread
    has to acquire both locks to complete its execution, each lock cannot be acquired
    by more than one thread at any given time, and finally, the locks are required
    to be acquired in a specific order, and the execution of individual threads cannot
    happen simultaneously. If we were to go back and examine the output produced by
    the `Chapter12/example5.py` file, it would be apparent that thread B could not
    start its calculations after thread A released both locks at the end of its execution.
  prefs: []
  type: TYPE_NORMAL
- en: It is quite intuitive, then, to arrive at the conclusion that if you placed
    enough locks on the resources of your concurrent program, it would become entirely
    sequential in its execution, and, combined with the overhead of concurrent programming
    functionalities, it would have an even worse speed than the purely sequential
    version of the program. However, we did not see in the Dining Philosophers problem
    (simulated in Python) this sequentiality created by locks. This is because in
    the two-thread problem, two locks were enough to sequentialize the program execution,
    while five were not enough to do the same for the Dining Philosophers problem.
  prefs: []
  type: TYPE_NORMAL
- en: We will explore another instance of this phenomenon in [Chapter 14](d87c597d-2130-4847-9ca9-e12021bc7a0c.xhtml),
    *Race Conditions*.
  prefs: []
  type: TYPE_NORMAL
- en: Ignoring locks and sharing resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Locks are undoubtedly an important tool in synchronization tasks, and in concurrent
    programming in general. However, if the use of locks leads to an undesirable situation,
    such as a deadlock, then it is quite natural for us to explore the option of simply
    not using locks in our concurrent programs. By ignoring locks, our program''s
    resources effectively become shareable among different processes/threads in a
    concurrent program, thus eliminating the first of the four Coffman conditions:
    mutual exclusion.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This approach to the problem of deadlock can be straightforward to implement;
    let us try with the two preceding examples. In the two-lock example, we simply
    remove the code specifying any interaction with the lock objects both inside the
    thread functions and in the main program. In other words, we are not utilizing
    a locking mechanism anymore. The `Chapter12/example7.py` file contains the implementation
    of this approach, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the script, and your output should look similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'It is clear that since we are not using locks to restrict access to any calculation
    processes, the executions of the two threads have now become entirely independent
    of one another, and the threads were therefore run completely in parallel. For
    this reason, we also obtained a better speed: since the threads ran in parallel,
    the total time that the whole program took was the same as the time that the longer
    task of the two threads took (in other words, thread B, with 10 seconds).'
  prefs: []
  type: TYPE_NORMAL
- en: What about the Dining Philosophers problem? It seems that we can also conclude
    that without locks (the forks), the problem can be solved easily. Since the resources
    (food) are unique to each philosopher (in other words, no philosopher should eat
    another philosopher's food), it should be the case that each philosopher can proceed
    with their execution without worrying about the others. By ignoring the locks,
    each can be executed in parallel, similar to what we saw in our two-lock example.
  prefs: []
  type: TYPE_NORMAL
- en: Doing this, however, means that we are completely misunderstanding the problem.
    We know that locks are utilized so that processes and threads can access the shared
    resources in a program in a systematic, coordinated way, to avoid mishandling
    the data. Therefore, removing any locking mechanisms in a concurrent program means
    that the likelihood of the shared resources, which are now free from access limitations,
    being manipulated in an uncoordinated way (and therefore, becoming corrupted)
    increases significantly.
  prefs: []
  type: TYPE_NORMAL
- en: So, by ignoring locks, it is relatively likely that we will need to completely
    redesign and restructure our concurrent program. If the shared resources still
    need to be accessed and manipulated in an organized way, other synchronization
    methods will need to be implemented. The logic of our processes and threads might
    need to be altered to appropriately interact with this new synchronization method,
    the execution time might be negatively affected by this change in the structure
    of the program, and other potential synchronization problems might also arise.
  prefs: []
  type: TYPE_NORMAL
- en: An additional note about locks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While the approach of dismissing locking mechanisms in our program to eliminate
    deadlocks might raise some questions and concerns, it does effectively reveal
    a new point for us about lock objects in Python: it is possible for an element
    of a concurrent program to completely bypass the locks when accessing a given
    resource. In other words, lock objects only prevent different processes/threads
    from accessing and manipulating a shared resource if those processes or threads
    actually acquire the lock objects.'
  prefs: []
  type: TYPE_NORMAL
- en: Locks, then, do not actually lock anything. They are simply flags that help
    to indicate whether a resource should be accessed at a given time; if a poorly
    instructed, or even malicious, process/thread attempts to access that resource
    without checking the lock object exists, it will most likely be able to do that
    without difficulty. In other words, locks are not at all connected to the resources
    that they are supposed to lock, and they most certainly do not block processes/threads
    from accessing those resources.
  prefs: []
  type: TYPE_NORMAL
- en: The simple use of locks is therefore inefficient to design and implement a secure,
    dynamic, concurrent data structure. To achieve that, we would need to either add
    more concrete links between the locks and their corresponding resources, or utilize
    a different synchronization tool altogether (for example, atomic message queues).
  prefs: []
  type: TYPE_NORMAL
- en: Concluding note on deadlock solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have seen two of the most common approaches to the problem of deadlock.
    Each addresses one of the four Coffman conditions, and, while both (somewhat)
    successfully prevent deadlocks from occurring in our examples, each raises different,
    additional problems and concerns. It is therefore important to truly understand
    the nature of your concurrent programs, in order to know which of the two is applicable,
    if either of them are.
  prefs: []
  type: TYPE_NORMAL
- en: It is also possible that some programs, through deadlock, are revealed to us
    as unsuitable to be made concurrent; some programs are better left sequential,
    and will be made worse with forced concurrency. As we have discussed, while concurrency
    provides significant improvements in many areas of our applications, some are
    inherently inappropriate for the application of concurrent programming. In situations
    of deadlock, developers should be ready to consider different approaches to designing
    a concurrent program, and should not be reluctant to implement another method
    when one concurrent approach does not work.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of livelock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The concept of livelock is connected to deadlock; some even consider it an alternate
    version of deadlock. In a livelock situation, the processes (or threads) in the
    concurrent program are able to switch their states; in fact, they switch states
    constantly. Yet, they simply switch back and forth infinitely, and no progress
    is made. We will now consider an actual scenario of livelock.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose that a pair of spouses are eating dinner together at a table. They
    only have one fork to share with each other, so only one of them can eat at any
    given point. Additionally, the spouses are really polite to each other, so even
    if one spouse is hungry and wants to eat their food, they will leave the fork
    on the table if their partner is also hungry. This specification is at the heart
    of creating a livelock for this problem: when both spouses are hungry, each will
    wait for the other to eat first, creating a infinite loop in which each spouse
    switches between wanting to eat and waiting for the other spouse to eat.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s simulate this problem in Python. Navigate to `Chapter12/example8.py`,
    and take a look at the `Spouse` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This class inherits from the `threading.Thread` class and implements the logic
    that we discussed previously. It takes in a name for the `Spouse` instance and
    another `Spouse` object as its partner; when initialized, a `Spouse` object is
    also always hungry (the `hungry` attribute is always set to `True`). The `run()`
    function in the class specifies the logic when the thread is started: as long
    as the `Spouse` object''s `hungry` attribute is set to `True`, the object will
    attempt to use the fork, which is a lock object, to eat. However, it always checks
    to see whether its partner also has its `hungry` attribute set to `True`, in which
    case, it will not proceed to acquire the lock, and will instead wait for its partner
    to do it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In our main program, we create the fork as a lock object first; then, we create
    two `Spouse` thread objects, which are each other''s `partner` attributes. Finally,
    we start both threads, and run the program until both threads finish executing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the script, and you will see that, as we discussed, each thread will go
    into an infinite loop, switching between wanting to eat and waiting for its partner
    to eat; the program will run forever, until Python is interrupted. The following
    code shows the first few lines of the output that I obtained:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the field of computer science, deadlock refers to a specific situation in
    concurrent programming, in which no progress is made and the program is locked
    in its current state. In most cases, this phenomenon is caused by a lack of, or
    mishandled, coordination between different lock objects, and it can be illustrated
    with the Dining Philosophers problem.
  prefs: []
  type: TYPE_NORMAL
- en: Potential approaches to preventing deadlocks from occurring include imposing
    an order for the lock objects and sharing non-shareable resources by ignoring
    lock objects. Each solution addresses one of the four Coffman conditions, and,
    while both solutions can successfully prevent deadlocks, each raises different,
    additional problems and concerns.
  prefs: []
  type: TYPE_NORMAL
- en: 'Connected to the concept of deadlock is livelock. In a livelock situation,
    processes (or threads) in the concurrent program are able to switch their states,
    but they simply switch back and forth infinitely, and no progress is made. In
    the next chapter, we will discuss another common problem in concurrent programming:
    starvation.'
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What can lead to a deadlock situation, and why is it undesirable?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How is the Dining Philosophers problem related to the problem of deadlock?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the four Coffman conditions?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can resource ranking solve the problem of deadlock? What other problems
    can occur when this is implemented?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can ignoring locks solve the problem of deadlock? What other problems can
    occur when this is implemented?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How is livelock related to deadlock?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information, you can refer to the following links:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Parallel Programming with Python*, by Jan. Palach, Packt Publishing Ltd, 2014'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Python Parallel Programming Cookbook*, by Giancarlo Zaccone, Packt Publishing
    Ltd, 2015'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Python Thread Deadlock Avoidance* ([dabeaz.blogspot.com/2009/11/python-thread-deadlock-avoidance_20](http://dabeaz.blogspot.com/2009/11/python-thread-deadlock-avoidance_20.html))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
